<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>K 站中转内最便宜的航班(Leetcode 787)</title>
    <url>/2021/08/24/program%20Leetcode787/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode787.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目小伙伴们会下意识的想到使用记忆化+DFS来解决，但是因为题目的特殊性，会导致记忆化DFS也会占用非常多的时间，所以还会给小伙伴们推荐动态规划的解法。<br><a id="more"></a></p>
<h1 id="记忆化-DFS"><a href="#记忆化-DFS" class="headerlink" title="记忆化+DFS"></a><font size="5" color="red">记忆化+DFS</font></h1><p>在常规的记忆化DFS算法中，使用memory数组或者哈希表保存已搜索过的状态，下一次访问时，如果存在于哈希表中，直接取出即可，不需要进行搜索。</p>
<p>假设本题最多经历11次中转，如果已经搜索到了某个点k，可能经过了10次中转，花费了100元，但是这次经过了1次中转，花费了110元，那么可能10次中转的最后无法抵达终点，而1次中转的可以抵达终点，说明仍然需要重新搜索该节点。</p>
<p>但是仍然可以使用记忆化，如果存在某次遍历，中转次数小于本次，并且花费小于本次，那么就可以省去本次遍历，这也是非常好理解的。但是条件稍微苛刻一些，记忆化的效率一般。</p>
<p>算法的<strong>时间复杂度为$O(k x n!)$，空间复杂度为$O(nk)$</strong>，因为可以记忆化剪枝，所以时间复杂度远远小于这个值，本题可以勉强通过。</p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    private int cost = Integer.MAX_VALUE;</span><br><span class="line"></span><br><span class="line">    public int findCheapestPrice(int n, int[][] flights, int src, int dst, int k) {</span><br><span class="line">        int[][] map = new int[n][n];</span><br><span class="line">        for (int[] flight : flights) {</span><br><span class="line">            map[flight[0]][flight[1]] = flight[2];</span><br><span class="line">        }</span><br><span class="line">        int[][] visit = new int[n][k + 1];</span><br><span class="line">        for (int i = 0; i &lt; n; i++) {</span><br><span class="line">            Arrays.fill(visit[i], Integer.MAX_VALUE);</span><br><span class="line">        }</span><br><span class="line">        dfs(n, src, dst, k, map, visit, 0);</span><br><span class="line">        return cost == Integer.MAX_VALUE ? -1 : cost;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    private void dfs(int n, int cur, int dst, int k, int[][] map, int[][] visit, int curCost) {</span><br><span class="line">        if (cur == dst) {</span><br><span class="line">            cost = Math.min(cost, curCost);</span><br><span class="line">            return;</span><br><span class="line">        }</span><br><span class="line">        if (k &lt; 0) {</span><br><span class="line">            return;</span><br><span class="line">        }</span><br><span class="line">        for (int i = k; i &lt; visit[0].length; i++) {</span><br><span class="line">            if (visit[cur][k] &lt;= curCost) {</span><br><span class="line">                return;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        visit[cur][k] = curCost;</span><br><span class="line">        for (int i = 0; i &lt; n; i++) {</span><br><span class="line">            if (map[cur][i] &gt;= 1) {</span><br><span class="line">                dfs(n, i, dst, k - 1, map, visit, curCost + map[cur][i]);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>DP的思想就非常巧妙，dp[i][j]表示经过i次中转到达第j个城市需要的花费。</p>
<script type="math/tex; mode=display">dp[i][j] = min(dp[i][j], dp[i - 1][k] + cost[k][j])</script><p>其中cost[k][j]表示从k到j节点的花费，最后返回dp[0][src], dp[1][src], …, dp[k][src]中的最小值即可。</p>
<p>算法的<strong>时间复杂度为$O(k x n^2)$，空间复杂度为$O(nk)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int findCheapestPrice(int n, int[][] flights, int src, int dst, int k) {</span><br><span class="line">        int MAX = 1000000;</span><br><span class="line">        int[][] dp = new int[k + 1][n];</span><br><span class="line">        Arrays.fill(dp[0], MAX);</span><br><span class="line">        for (int[] flight : flights) {</span><br><span class="line">            if (flight[0] == src) {</span><br><span class="line">                dp[0][flight[1]] = flight[2];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        int res = dp[0][dst];</span><br><span class="line">        for (int i = 1; i &lt; k + 1; i++) {</span><br><span class="line">            Arrays.fill(dp[i], MAX);</span><br><span class="line">            for (int[] flight : flights) {</span><br><span class="line">                dp[i][flight[1]] = Math.min(dp[i][flight[1]], dp[i - 1][flight[0]] + flight[2]);</span><br><span class="line">            }</span><br><span class="line">            res = Math.min(res, dp[i][dst]);</span><br><span class="line">        }</span><br><span class="line">        return res == MAX ? -1 : res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  DP的思想是保存之前计算过的结果，那么看起来记忆化DFS也是一种DP，小伙伴们要好好理解两者之间的关系。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>划分为k个相等的子集(Leetcode 698)</title>
    <url>/2021/08/20/program%20Leetcode698/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode698.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和前几天做的第473题类似，不过难度要更大一些，在473题中，要使用火柴棒拼成一个正方形，是本题k为4的一个特例。<br><a id="more"></a></p>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>本题类似与排列组合题目，n个数，先判断n个数之和是否能被k整除，如果能整除，求出整除后的值mean。然后进行全排列，和小于mean的值则给当前集合添加元素，和等于mean则开始判断下一个集合，和大于mean则说明该排列不符合要求。</p>
<p>算法的<strong>时间复杂度为$O(n!)$，空间复杂度为$O(n)$</strong>，因为n最大可以为16，因此可能会产生TLE的情况，但是存在剪枝操作，因此不会真正进行全排列的操作，所以本题可以勉强通过。</p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public boolean canPartitionKSubsets(int[] nums, int k) {</span><br><span class="line">        int sums = 0;</span><br><span class="line">        for (int val : nums) {</span><br><span class="line">            sums += val;</span><br><span class="line">        }</span><br><span class="line">        if (sums % k != 0) {</span><br><span class="line">            return false;</span><br><span class="line">        }</span><br><span class="line">        int mean = sums / k;</span><br><span class="line">        return dfs(1, 0, new boolean[nums.length], nums, mean, k);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    private boolean dfs(int layer, int cur, boolean[] visit, int[] nums, int mean, int k) {</span><br><span class="line">        if (layer &gt; k - 1) {</span><br><span class="line">            return true;</span><br><span class="line">        }</span><br><span class="line">        for (int i = 0; i &lt; visit.length; i++) {</span><br><span class="line">            if (!visit[i]) {</span><br><span class="line">                if (cur + nums[i] &lt;= mean) {</span><br><span class="line">                    visit[i] = true;</span><br><span class="line">                    boolean res = cur + nums[i] == mean ? dfs(layer + 1, 0, visit, nums, mean, k) : dfs(layer, cur + nums[i], visit, nums, mean, k);</span><br><span class="line">                    if (res) {</span><br><span class="line">                        return true;</span><br><span class="line">                    }</span><br><span class="line">                    visit[i] = false;</span><br><span class="line">                } else {</span><br><span class="line">                    return false;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="状态压缩DP"><a href="#状态压缩DP" class="headerlink" title="状态压缩DP"></a><font size="5" color="red">状态压缩DP</font></h1><p>状态压缩DP的思想非常巧妙，状态压缩是指用bit位来表示该元素是否已经选择。本题的n最大位16，而int值为32位，因此足够表示16个数，0…0001表示选择了第一个数，0…1010表示选择了第二个数和第四个数。sum[i]表示状态i所选取的数字之和，isSatisfy[i]表示状态i所选取的数字是否有可能满足条件。</p>
<p>其中状态i从0到(1 &lt;&lt; n) - 1，然后遍历元素索引j，如果当前状态的第j位为不为0，定义前一个状态为pre = i ^ (1 &lt;&lt; j)。说明该状态i可由pre添加第j个元素转化而来，但是此时不一定能够成功转化。如果状态pre是满足条件的，并且sum[pre] % mean + nums[j] &lt;= mean说明本状态可以由pre状态成功转化而来。</p>
<p>算法的<strong>时间复杂度为$O(k x 2^n)$，空间复杂度为$O(2^n)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public boolean canPartitionKSubsets(int[] nums, int k) {</span><br><span class="line">        int sums = 0;</span><br><span class="line">        for (int val : nums) {</span><br><span class="line">            sums += val;</span><br><span class="line">        }</span><br><span class="line">        if (sums % k != 0) {</span><br><span class="line">            return false;</span><br><span class="line">        }</span><br><span class="line">        int length = nums.length;</span><br><span class="line">        int mean = sums / k;</span><br><span class="line">        int bit = 1 &lt;&lt; length;</span><br><span class="line">        boolean[] isSatisfy = new boolean[bit];</span><br><span class="line">        int[] sum = new int[bit];</span><br><span class="line">        isSatisfy[0] = true;</span><br><span class="line">        for (int i = 0; i &lt; bit; i++) {</span><br><span class="line">            for (int j = 0; j &lt; length; j++) {</span><br><span class="line">                if ((i &amp; (1 &lt;&lt; j)) != 0 &amp;&amp; isSatisfy[i ^ (1 &lt;&lt; j)] &amp;&amp; (sum[i ^ (1 &lt;&lt; j)] % mean) + nums[j] &lt;= mean) {</span><br><span class="line">                    isSatisfy[i] = true;</span><br><span class="line">                    sum[i] = sum[i ^ (1 &lt;&lt; j)] + nums[j];</span><br><span class="line">                    break;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return isSatisfy[bit - 1];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  小伙伴们要仔细比较两中算法在时间复杂度上的差异，并深刻理解$2^n$和$n!$在速度上相差了多少。很多人默认为指数爆炸的时间复杂都最高，其实阶乘的复杂度会更大一些，一般来说1e8是我们写算法题的极限运算量，此时对于指数量级来说，n可以取到26-27左右，但是对于阶乘来说，n只能取到12-13左右，所以对于全排列这类问题，一定要小心谨慎。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>数组中最大数对和的最小值(Leetcode 1877)</title>
    <url>/2021/07/20/program%20Leetcode1877/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1877.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   小伙伴们遇到这样的题目，不能傻乎乎的去配对，要从中间找到规律，能否使用贪心的思路进行求解呢？<br><a id="more"></a></p>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>如何配对能使最大数对和最小呢？小伙伴想一想，如果将最大值和次大值配对，那么无论后面的元素如何配对，最大数对和都是最大值和次大值之和，这是最大数对和最大的情况。同理，如果想使最大数对和最小，能否将最大值和最小值配对呢？让次大值和次小值配对，让他们的值都尽量相等，是不是更合理一些？</p>
<p>这里不妨设最大值为max，最小值为min，以及任意两个值为m和n，组成$min \le n \le m \le max$<br>此时有三种配对方法<br>max + min和m + n，max + m和min + n，max + n和min + m<br>因为$max + m \ge max + min$且$max + n \ge max + min$，因此将最大值和最小值进行配对的方法是最优的。</p>
<p>推广到n个数对也是可以证明的，感兴趣的小伙伴们可以参考官方题解。因此本题可以排序，求将第i个元素和倒数第i个元素配对，然后计算最大值即可。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(1)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int minPairSum(int[] nums) {</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 0; i &lt; nums.length / 2; i++) {</span><br><span class="line">            res = Math.max(res, nums[i] + nums[nums.length - 1 - i]);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题是一个非常有趣的数学题，这里告诉大家的是在考试的过程中，有思路就可以去写，只要不限制次数，时间就是最重要的。不需要每一道题都严格证明，可以在考试完成后再进行推导。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>绝对差值和(Leetcode 1838)</title>
    <url>/2021/07/19/program%20Leetcode1838/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1838.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   一开始做这个题目的时候，使用暴力法进行求解，先进行排序，再以每一个数为基准，并将小于该元素的数加至该元素，当加k个值时停止。这种方法时间复杂都为O(nk)，因为n和k都是1e5的数据，因此无法通过所有样例。小伙伴们能否找到更好的算法呢？<br><a id="more"></a></p>
<h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a><font size="5" color="red">滑动窗口</font></h1><p>我们寻找时间复杂都较大的原因，我们对于从低到高的所有元素都计算了差值，举一个例子nums = [1,2,3,4,5,6] , k = 4，使用分析中的方法时<br>以1为上界，后面没有元素，因此频数为1<br>以2为上界，后面只有1，而且2 - 1 = 1，可以将1变为2，因此频数为2<br>以3为上界，后面有2和1，而且3 - 2 = 1，3 - 1 = 2，将2和1都变为3，因此频数为3<br>以4为上界，后面有3，2和1，而且4 - 3 = 1，4 - 2 = 2，4 - 1 = 3 将3和2都变为4，因此频数为3<br>后面同理，可以发现一个问题，下标为i的数到后面的距离之和等于下标为i - 1的数到后面的距离之和 + (nums[i] - nums[i + 1]) * i。这个规律很好理解，后面的数不但要补齐与第i - 1个元素的差距，还要额外补齐到第i个元素的差距。因此就可以省去遍历后面元素的计算过程。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(1)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int maxFrequency(int[] nums, int k) {</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        int left = 0;</span><br><span class="line">        int right = 1;</span><br><span class="line">        long cur = 0;</span><br><span class="line">        int res = 1;</span><br><span class="line">        while (right &lt; nums.length) {</span><br><span class="line">            while (right &lt; nums.length &amp;&amp; cur + (right - left) * (nums[right] - nums[right - 1]) &lt;= k) {</span><br><span class="line">                cur += (right - left) * (nums[right] - nums[right++ - 1]);</span><br><span class="line">            }</span><br><span class="line">            res = Math.max(res, right - left);</span><br><span class="line">            cur -= nums[right - 1] - nums[left++];</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题是一个非常有趣的滑动窗口题目，小伙伴们没有思路时可以从暴力法中获得灵感。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>滑动窗口</category>
      </categories>
  </entry>
  <entry>
    <title>天际线问题(Leetcode 218)</title>
    <url>/2021/07/13/program%20Leetcode218/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode218.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目很清晰，很容易能想到$O(n^2)$的算法进行求解。但是本题的数据量为1e4，因此使用暴力法求解会导致TLE，因此需要寻找一种更合适的算法解答。<br><a id="more"></a></p>
<h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a><font size="5" color="red">堆</font></h1><p>我们可以先将每一段的起始点和终止点都加入到一个数组中，因为在这些点会产生突变，因此输出结果一定是数组中的某些点。我们将数组进行排序，因此得到按照时间排序的节点。</p>
<p>遍历这些节点，将起点出现在该节点之前的所有建筑入堆，其中堆中元素按照建筑高度从大到小排序，并将堆顶元素中结束时间小于该节点的元素出堆。此时堆顶元素就是满足时间条件且建筑最高的元素。如果该元素的高度不等于前一个元素的高度，则该高度是一个天际线，需要记录该高度。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public List&lt;List&lt;Integer&gt;&gt; getSkyline(int[][] buildings) {</span><br><span class="line">        int length = buildings.length;</span><br><span class="line">        PriorityQueue&lt;int[]&gt; queue = new PriorityQueue&lt;&gt;(new Comparator&lt;int[]&gt;() {</span><br><span class="line">            @Override</span><br><span class="line">            public int compare(int[] o1, int[] o2) {</span><br><span class="line">                return o2[1] - o1[1];</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line">        int[] timeNodes = new int[length * 2];</span><br><span class="line">        for (int i = 0; i &lt; length; i++) {</span><br><span class="line">            timeNodes[i * 2] = buildings[i][0];</span><br><span class="line">            timeNodes[i * 2 + 1] = buildings[i][1];</span><br><span class="line">        }</span><br><span class="line">        Arrays.sort(timeNodes);</span><br><span class="line">        int idx = 0;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">        for (int time : timeNodes) {</span><br><span class="line">            while (idx &lt; length &amp;&amp; buildings[idx][0] &lt;= time) {</span><br><span class="line">                queue.add(new int[]{buildings[idx][1], buildings[idx][2]});</span><br><span class="line">                idx++;</span><br><span class="line">            }</span><br><span class="line">            while (!queue.isEmpty() &amp;&amp; queue.peek()[0] &lt;= time) {</span><br><span class="line">                queue.poll();</span><br><span class="line">            }</span><br><span class="line">            int cur = queue.isEmpty() ? 0 : queue.peek()[1];</span><br><span class="line">            if (res.size() == 0 || res.get(res.size() - 1).get(1) != cur) {</span><br><span class="line">                res.add(Arrays.asList(time, cur));</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题的难点是在于能否想到将每一个建筑的起始时间和终止时间进行统计排序，然后利用堆的思想进行元素判断。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
      </categories>
  </entry>
  <entry>
    <title>绝对差值和(Leetcode 1818)</title>
    <url>/2021/07/13/program%20Leetcode1818/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1818.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目有一定的难度，如果想明白一个问题，则本题可以迎刃而解。下面给小伙伴们一些提示，其实本题就是在nums1中寻找与每个nums1元素对应的num2元素最接近的一个数。<br><a id="more"></a></p>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>遍历num1所有索引，可以得到对应的num2元素，因此原本的绝对值之差为abs(nums1[i] - nums2[i])，如果将num1[i]换成与num2[i]最接近的一个数，那么绝对值之差就会最小，本题即寻找每一个索引对应的绝对值之差最小值。</p>
<p>我们可以新建一个数组，其中对nums1的元素进行排序，这样可以通过二分查找距离nums2[i]最近的元素，因为距离最近可以是大于nums2[i]的值，也可以是小于num2[i]的值，所以先找到大于等于nums[i]的最小值，然后找小于nums[i]的最大值即可。找到了距离nums2[i]最近的元素，我们判断该索引的绝对差变化了多少，原始的绝对差为abs(nums1[i] - nums2[i])，现在的绝对差为abs(find - nums2[i])，因此求abs(nums1[i] - nums2[i]) - abs(find - nums2[i])的最大值。</p>
<p>在每一步索引都计算绝对差，最后用总绝对差减去绝对差的变化量，即可求得替换后绝对差的最小值。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int minAbsoluteSumDiff(int[] nums1, int[] nums2) {</span><br><span class="line">        int mod = 1000000007;</span><br><span class="line">        int length = nums1.length;</span><br><span class="line">        int[] sortNum1 = Arrays.copyOf(nums1, length);</span><br><span class="line">        Arrays.sort(sortNum1);</span><br><span class="line">        int res = 0;</span><br><span class="line">        int diff = 0;</span><br><span class="line">        for (int i = 0; i &lt; length; i++) {</span><br><span class="line">            int cur = Math.abs(nums1[i] - nums2[i]);</span><br><span class="line">            res = (res + cur) % mod;</span><br><span class="line">            int left = 0, right = length - 1;</span><br><span class="line">            while (left &lt; right) {</span><br><span class="line">                int mid = left + ((right - left) &gt;&gt; 1);</span><br><span class="line">                if (sortNum1[mid] &gt;= nums2[i]) {</span><br><span class="line">                    right = mid;</span><br><span class="line">                } else {</span><br><span class="line">                    left = mid + 1;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            diff = Math.max(diff, cur - Math.abs(sortNum1[left] - nums2[i]));</span><br><span class="line">            if (left &gt; 0) { diff = Math.max(diff, cur - Math.abs(sortNum1[left - 1] - nums2[i])); }</span><br><span class="line">        }</span><br><span class="line">        return (res - diff + mod) % mod;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题是一个非常有趣的二分查找算法，希望小伙伴们能够举一反三多加练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>基于时间的键值存储(Leetcode 981)</title>
    <url>/2021/07/10/program%20Leetcode981/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode981.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目描述的比较复杂，简单说来就是set方法第一个参数为key，将第二个参数value和第三个参数timestamp都放在其中，取出时只能看到时间戳之前的字符串，比如在key为foo，时刻为1时插入一个字符串bar，那么取出foo时在时刻1之后才能看到bar，在时刻1之前无法看到，同理如果在时刻4时放入bar2，那么在时刻4后bar2会替换bar，此后只能看到bar2了，但是在时刻1和时刻4之间只能看到bar。而且本题的时间戳时递增的，这一点非常重要，小伙伴们能够根据有序的线索得到哪些重要信息呢？<br><a id="more"></a></p>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>我们使用哈希表记录TimeMap，其中键就是题目中的存储键key，值是一个可变数组，其中每一个元素都是一个二元组，包括时间和值两个数据。现在本题就变成在一个有序数组中，查找指定时间之前的索引位置。就是一个经典的二分查找问题，相信小伙伴们能够很轻松的写出来，直接看代码即可。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong></p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class TimeMap {</span><br><span class="line">private:</span><br><span class="line">    unordered_map&lt;string, vector&lt;pair&lt;int, string&gt;&gt;&gt; map;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    /** Initialize your data structure here. */</span><br><span class="line">    TimeMap() {</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void set(string key, string value, int timestamp) {</span><br><span class="line">        map[key].push_back({ timestamp, value });</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    string get(string key, int timestamp) {</span><br><span class="line">        if (map[key].size() == 0 || timestamp &lt; map[key][0].first) { return ""; }</span><br><span class="line">        int left = 0, right = map[key].size() - 1;</span><br><span class="line">        while (left &lt; right) {</span><br><span class="line">            int mid = (left + right + 1) &gt;&gt; 1;</span><br><span class="line">            if (map[key][mid].first &gt; timestamp) {</span><br><span class="line">                right = mid - 1;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                left = mid;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return map[key][left].second;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class TimeMap() {</span><br><span class="line">    private val dic = HashMap&lt;String, ArrayList&lt;Pair&lt;Int, String&gt;&gt;&gt;()</span><br><span class="line">    /** Initialize your data structure here. */</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    fun set(key: String, value: String, timestamp: Int) {</span><br><span class="line">        val tmp = dic.getOrDefault(key, ArrayList())</span><br><span class="line">        tmp.add(Pair(timestamp, value))</span><br><span class="line">        dic[key] = tmp</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    fun get(key: String, timestamp: Int): String {</span><br><span class="line">        val tmp = dic.getOrDefault(key, ArrayList())</span><br><span class="line">        if (tmp.isEmpty() || tmp[0].first &gt; timestamp) { return "" }</span><br><span class="line">        var left = 0</span><br><span class="line">        var right = tmp.size - 1</span><br><span class="line">        while (left &lt; right) {</span><br><span class="line">            val mid = (left + right + 1) shr 1</span><br><span class="line">            if (tmp[mid].first &gt; timestamp) {</span><br><span class="line">                right = mid - 1</span><br><span class="line">            } else {</span><br><span class="line">                left = mid</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return tmp[left].second</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目的难度不大，主要是能否充分利用有序的特点进行解答，抽出问题的本质，相信小伙伴们都能够轻松写出本题。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>和相同的二元子数组(Leetcode 930)</title>
    <url>/2021/07/08/program%20Leetcode930/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode930.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   本题是连续子数组求和问题，子数组求和往往需要用到前缀和，因此可以使用sums记录前缀和，然后遍历起始和终止位置即可。这是本题的一般解法，时间复杂度为$O(n^2)$，空间复杂度为$O(n)$。但是有没有更精妙的解法呢？给小伙伴们提示一下，可以观察leetcode入坑题即第一题两数之和。<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>前缀和sums[k]表示从索引0到索引k的元素之和，那么子数组i到j的元素之和是否可以表示为sums[k] - sums[i - 1]呢？因此即求前缀和数组中两数之差为goal的个数。</p>
<p>使用哈希表dic记录前缀和出现的次数，假设当前索引为j，前缀和为m，满足从i到j的元素之和为goal的子数组个数为dic[m - goal]。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int numSubarraysWithSum(int[] nums, int goal) {</span><br><span class="line">        HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">        int sums = 0;</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            map.put(sums, map.getOrDefault(sums, 0) + 1);</span><br><span class="line">            sums += x;</span><br><span class="line">            res += map.getOrDefault(sums - goal, 0);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun numSubarraysWithSum(nums: IntArray, goal: Int): Int {</span><br><span class="line">        val map = HashMap&lt;Int, Int&gt;()</span><br><span class="line">        var sums = 0</span><br><span class="line">        var res = 0</span><br><span class="line">        for (x in nums) {</span><br><span class="line">            map[sums] = map.getOrDefault(sums, 0) + 1</span><br><span class="line">            sums += x</span><br><span class="line">            res += map[sums - goal] ?: 0</span><br><span class="line">        }</span><br><span class="line">        return res</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题的数据只有0和1，还可以使用滑动窗口进行求解，因为不是通用的解法，因此这里不做过多介绍。想了解的小伙伴们可以取力扣官网查看本题题解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>原子的数量(Leetcode 726)</title>
    <url>/2021/07/05/program%20Leetcode726/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode726.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   本题虽然是一个困难题，但是思路却很清晰，难点主要在于代码量和对字符串的处理操作。这个题目有点类似于括号匹配和带有括号的计算问题，都是栈的经典解法，这给小伙伴们一些提示，能否使用栈的思想解决本题呢？<br><a id="more"></a></p>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p>对于化学表达式来说，括号外面的数字k表示括号里面的所有元素都有k个，若括号里面的某个元素有m个，则该元素有m x k个。所以类似于括号匹配问题，要一层一层将括号拆开。</p>
<p>但是本题的难点在于，元素和数字可能是多个字符，如Mg，20等，而且如果元素个数为1也会省略数字。所以字符串的处理会让本题的代码量变多。</p>
<p>为了便于处理，我们将本题可能出现的几种字符串类型进行区分<br>一个是数字类型，如20、4等<br>一个是元素类型，如N、Mg等<br>一个是括号类型，如(、)</p>
<p>用一个链表作为栈，其中元素为字符串</p>
<p>从第一个字符开始访问<br>如果当前字符是数字，则迭代去找后面的连续数字，然后判断前面是否有括号。如果有括号，则将括号内的元素全部取出，然后将括号去掉计算括号内外个数的乘积，如(O2)20，则先迭代找出20，然后将括号去掉，计算2x20=40，然后插入O40；如果没有括号直接将数字作为字符串插入如O20，则直接将20插入即可</p>
<p>如果当前字符是括号，直接将括号作为字符串入栈，然后判断该括号是否为右括号，如果是右括号，需要额外判断右括号的后面是否为数字，如果不是数字说明括号里面的内容只重复一次，如(H2)O2，右括号后面是O，等价于(H2)1O2，直接将括号去掉即可变为H2O2，如果后面是数字，则不用管它，在遍历到后面的数字时，会进行处理</p>
<p>如果当前字符是字母，则递归寻找后面的小写字母，不能寻找大写字母，因为这不是同一个元素，如MgO，找到Mg应该停止，说明是一个元素。此时也要进行额外判断，如果元素后面不是数字，则要加一个1，说明当前元素的个数为1。</p>
<p>一切都处理完后字符串中的所有括号都被去除，元素和个数成对出现，偶数下标为元素，奇数下标为对应的个数。如”K4(ON(SO3)2)2”，则会变为[“K”, “4”, “O”, “2”, “N”, “2”, “S”, “4”, “O”, “12”]，这时使用哈希表进行合并，因为同一个元素可能出现在多个地方，如O元素，而且根据TreeMap红黑树的底层实现，会自动进行排序，所以直接取出即可，否则还需要进行排序操作。</p>
<p>在取出的时候，也要判断，如果元素的个数为1，则不加入字符串中。</p>
<p>因为括号弹出可能会弹出栈中的所有元素，因此算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public String countOfAtoms(String formula) {</span><br><span class="line">        int length = formula.length();</span><br><span class="line">        LinkedList&lt;String&gt; tmpStack = new LinkedList&lt;&gt;();</span><br><span class="line">        LinkedList&lt;String&gt; stack = new LinkedList&lt;&gt;();</span><br><span class="line">        TreeMap&lt;String, Integer&gt; map = new TreeMap&lt;&gt;();</span><br><span class="line">        for (int i = 0; i &lt; length;) {</span><br><span class="line">            StringBuilder tmp = new StringBuilder();</span><br><span class="line">            char cur = formula.charAt(i);</span><br><span class="line">            if (cur &gt;= '0' &amp;&amp; cur &lt;= '9') {</span><br><span class="line">                while (cur &gt;= '0' &amp;&amp; cur &lt;= '9') {</span><br><span class="line">                    tmp.append(cur);</span><br><span class="line">                    ++i;</span><br><span class="line">                    if (i == length) { break; }</span><br><span class="line">                    cur = formula.charAt(i);</span><br><span class="line">                }</span><br><span class="line">                if (stack.getLast().equals(")")) {</span><br><span class="line">                    int num = Integer.parseInt(tmp.toString());</span><br><span class="line">                    stack.removeLast();</span><br><span class="line">                    while (!stack.getLast().equals("(")) {</span><br><span class="line">                        tmpStack.add(stack.removeLast());</span><br><span class="line">                    }</span><br><span class="line">                    stack.removeLast();</span><br><span class="line">                    while (!tmpStack.isEmpty()) {</span><br><span class="line">                        stack.add(tmpStack.removeLast());</span><br><span class="line">                        stack.add(Integer.toString(Integer.parseInt(tmpStack.removeLast()) * num));</span><br><span class="line">                    }</span><br><span class="line">                } else {</span><br><span class="line">                    stack.add(tmp.toString());</span><br><span class="line">                }</span><br><span class="line">            } else if (cur == '(' || cur == ')') {</span><br><span class="line">                tmp.append(cur);</span><br><span class="line">                stack.add(tmp.toString());</span><br><span class="line">                i++;</span><br><span class="line">                if (cur == ')' &amp;&amp; (i == length || (formula.charAt(i) &lt; '0' || formula.charAt(i) &gt; '9'))) {</span><br><span class="line">                    stack.removeLast();</span><br><span class="line">                    while (!stack.getLast().equals("(")) {</span><br><span class="line">                        tmpStack.add(stack.removeLast());</span><br><span class="line">                    }</span><br><span class="line">                    stack.removeLast();</span><br><span class="line">                    while (!tmpStack.isEmpty()) {</span><br><span class="line">                        stack.add(tmpStack.removeLast());</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            } else {</span><br><span class="line">                tmp.append(cur);</span><br><span class="line">                if (i == length - 1) {</span><br><span class="line">                    stack.add(tmp.toString());</span><br><span class="line">                    stack.add("1");</span><br><span class="line">                    break;</span><br><span class="line">                }</span><br><span class="line">                cur = formula.charAt(++i);</span><br><span class="line">                while (cur &gt;= 'a' &amp;&amp; cur &lt;= 'z') {</span><br><span class="line">                    tmp.append(cur);</span><br><span class="line">                    ++i;</span><br><span class="line">                    if (i == length) { break; }</span><br><span class="line">                    cur = formula.charAt(i);</span><br><span class="line">                }</span><br><span class="line">                stack.add(tmp.toString());</span><br><span class="line">                if (cur &lt; '0' || cur &gt; '9') {</span><br><span class="line">                    stack.add("1");</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        while (!stack.isEmpty()){</span><br><span class="line">            String key = stack.removeFirst();</span><br><span class="line">            int value = Integer.parseInt(stack.removeFirst());</span><br><span class="line">            map.put(key, map.getOrDefault(key, 0) + value);</span><br><span class="line">        }</span><br><span class="line">        StringBuilder res = new StringBuilder();</span><br><span class="line">        for (Map.Entry&lt;String, Integer&gt; entry : map.entrySet()) {</span><br><span class="line">            res.append(entry.getKey());</span><br><span class="line">            if (entry.getValue() &gt; 1) {</span><br><span class="line">                res.append(entry.getValue());</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun countOfAtoms(formula: String): String {</span><br><span class="line">        val stack = LinkedList&lt;String&gt;()</span><br><span class="line">        val tmpStack = LinkedList&lt;String&gt;()</span><br><span class="line">        val length = formula.length</span><br><span class="line">        var idx = 0</span><br><span class="line">        while (idx &lt; length) {</span><br><span class="line">            var cur = formula[idx]</span><br><span class="line">            val tmp = StringBuilder()</span><br><span class="line">            if (cur in '0'..'9') {</span><br><span class="line">                while (cur in '0'..'9') {</span><br><span class="line">                   tmp.append(cur)</span><br><span class="line">                   ++idx</span><br><span class="line">                   if (idx == length) { break }</span><br><span class="line">                   cur = formula[idx]</span><br><span class="line">                }</span><br><span class="line">                if (stack.last() == ")") {</span><br><span class="line">                    val num = tmp.toString().toInt()</span><br><span class="line">                    stack.removeLast()</span><br><span class="line">                    while (stack.last() != "(") {</span><br><span class="line">                        tmpStack.add(stack.removeLast())</span><br><span class="line">                    }</span><br><span class="line">                    stack.removeLast()</span><br><span class="line">                    while (tmpStack.isNotEmpty()) {</span><br><span class="line">                        stack.add(tmpStack.removeLast())</span><br><span class="line">                        stack.add((tmpStack.removeLast().toInt() * num).toString())</span><br><span class="line">                    }</span><br><span class="line">                } else {</span><br><span class="line">                    stack.add(tmp.toString())</span><br><span class="line">                }</span><br><span class="line">            } else if (cur == '(' || cur == ')') {</span><br><span class="line">                stack.add(cur.toString())</span><br><span class="line">                ++idx</span><br><span class="line">                if (cur == ')' &amp;&amp; (idx == length || formula[idx] !in '0'..'9')) {</span><br><span class="line">                    stack.removeLast()</span><br><span class="line">                    while (stack.last() != "(") {</span><br><span class="line">                        tmpStack.add(stack.removeLast())</span><br><span class="line">                    }</span><br><span class="line">                    stack.removeLast()</span><br><span class="line">                    while (tmpStack.isNotEmpty()) {</span><br><span class="line">                        stack.add(tmpStack.removeLast())</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            } else {</span><br><span class="line">                tmp.append(cur)</span><br><span class="line">                if (idx == length - 1) {</span><br><span class="line">                    stack.add(tmp.toString())</span><br><span class="line">                    stack.add("1")</span><br><span class="line">                    break</span><br><span class="line">                }</span><br><span class="line">                cur = formula[++idx]</span><br><span class="line">                while (cur in 'a'..'z') {</span><br><span class="line">                    tmp.append(cur)</span><br><span class="line">                    ++idx</span><br><span class="line">                    if (idx == length) { break }</span><br><span class="line">                    cur = formula[idx]</span><br><span class="line">                }</span><br><span class="line">                stack.add(tmp.toString())</span><br><span class="line">                if (cur !in '0'..'9') {</span><br><span class="line">                    stack.add("1")</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        val treeMap = TreeMap&lt;String, Int&gt;()</span><br><span class="line">        while (stack.isNotEmpty()) {</span><br><span class="line">            val key = stack.removeFirst()</span><br><span class="line">            val value = treeMap.getOrDefault(key, 0) + stack.removeFirst().toInt()</span><br><span class="line">            treeMap[key] = value</span><br><span class="line">        }</span><br><span class="line">        val res = StringBuilder()</span><br><span class="line">        for (entry in treeMap) {</span><br><span class="line">            res.append(entry.key)</span><br><span class="line">            if (entry.value != 1) { res.append(entry.value) }</span><br><span class="line">        }</span><br><span class="line">        return res.toString()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题的重点是括号匹配问题的扩展版本，能独立做出本题，这类问题都难不倒你。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
        <category>字符串</category>
      </categories>
  </entry>
  <entry>
    <title>根据字符出现频率排序(Leetcode 451)</title>
    <url>/2021/07/03/program%20Leetcode451/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode451.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是TopK类型的题目，经典的求解方法是使用大顶堆进行求解，这也是必须要掌握的一种算法，除此之外介绍另一种基于哈希表的算法。<br><a id="more"></a></p>
<h1 id="排序-哈希表"><a href="#排序-哈希表" class="headerlink" title="排序+哈希表"></a><font size="5" color="red">排序+哈希表</font></h1><p>本题要对字符串按照出现的频率进行排序，将出现频率高的字符放在字符串前方，因此我们首先要统计出每个字符串出现的次数，这里使用charToFrequency哈希表记录。然后要统计出现次数对应的字符种类，对出现次数进行从大到小排序即可。如”tree”这个字符串，出现2次的有e，出现1次的有t和r，这里使用frequencyToChar记录，其中键为出现的次数，值为一个可变列表，每个元素都是一个字符。将frequency的键k都存入数组中，表示存在某些字符出现次数为k，对数字从大到小排序，本例中数组为[2, 1]，最后作为键从frequencyToChar中取出相应的列表。先取出frequencyToChar[2]对应的列表[e]，然后再取出frequencyToChar[1]对应的列表[t, r]。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>，其中字符的种类为常数量级，因此不将其放入时间复杂度的计算中</p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    string frequencySort(string s) {</span><br><span class="line">        unordered_map&lt;char, int&gt; charToFrequency;</span><br><span class="line">        for (char c : s) { charToFrequency[c]++; }</span><br><span class="line">        map&lt;int, vector&lt;char&gt;&gt; frequencyToChar;</span><br><span class="line">        for (auto&amp; p : charToFrequency) { frequencyToChar[p.second].push_back(p.first); }</span><br><span class="line">        string res = "";</span><br><span class="line">        for (auto&amp; p : frequencyToChar) {</span><br><span class="line">            for (char c : p.second) {</span><br><span class="line">                for (int i = 0; i &lt; p.first; i++) {</span><br><span class="line">                    res.push_back(c);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        reverse(res.begin(), res.end());</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public String frequencySort(String s) {</span><br><span class="line">        HashMap&lt;Character, Integer&gt; charToFrequency = new HashMap&lt;&gt;();</span><br><span class="line">        for (char c : s.toCharArray()) { charToFrequency.put(c, charToFrequency.getOrDefault(c, 0) + 1); }</span><br><span class="line">        TreeMap&lt;Integer, ArrayList&lt;Character&gt;&gt; frequencyToChar = new TreeMap&lt;&gt;((o1, o2) -&gt; o2 - o1);</span><br><span class="line">        for (Map.Entry&lt;Character, Integer&gt; p : charToFrequency.entrySet()) {</span><br><span class="line">            ArrayList&lt;Character&gt; lst = frequencyToChar.getOrDefault(p.getValue(), new ArrayList&lt;&gt;());</span><br><span class="line">            lst.add(p.getKey());</span><br><span class="line">            frequencyToChar.put(p.getValue(), lst);</span><br><span class="line">        }</span><br><span class="line">        StringBuilder res = new StringBuilder();</span><br><span class="line">        for (int f : frequencyToChar.keySet()) {</span><br><span class="line">            for (char c : frequencyToChar.get(f)) {</span><br><span class="line">                res.append(String.valueOf(c).repeat(Math.max(0, f)));</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def frequencySort(self, s):</span><br><span class="line">        char_to_frequency = Counter(s)</span><br><span class="line">        frequency_to_char = {}</span><br><span class="line">        for (c, i) in char_to_frequency.items():</span><br><span class="line">            lst = frequency_to_char.setdefault(i, [])</span><br><span class="line">            lst.append(c)</span><br><span class="line">        res = ""</span><br><span class="line">        sort_list = sorted(frequency_to_char.keys(), key=lambda x: -x)</span><br><span class="line">        for f in sort_list:</span><br><span class="line">            for c in frequency_to_char[f]:</span><br><span class="line">                res += f * c</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun frequencySort(s: String): String {</span><br><span class="line">        val charToFrequency = HashMap&lt;Char, Int&gt;()</span><br><span class="line">        for (c in s) { charToFrequency[c] = (charToFrequency[c] ?: 0) + 1 }</span><br><span class="line">        val frequencyToChar = TreeMap&lt;Int, ArrayList&lt;Char&gt;&gt;(Comparator { o1, o2 -&gt; o2 - o1; })</span><br><span class="line">        for (p in charToFrequency) {</span><br><span class="line">            val lst = frequencyToChar.getOrDefault(p.value, ArrayList())</span><br><span class="line">            lst.add(p.key)</span><br><span class="line">            frequencyToChar[p.value] = lst</span><br><span class="line">        }</span><br><span class="line">        val res = StringBuilder()</span><br><span class="line">        for ((f, lst) in frequencyToChar) {</span><br><span class="line">            for (c in lst) {</span><br><span class="line">                res.append(c.toString().repeat(f))</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>将四种语言放在一起对比，发现C++语言在操作哈希表时可以不用先判断是否存在键是否存在，其他语言都需要先进行判断。而且在操作字符串时，Python可以进行加法和乘法操作，Java和Kotlin推荐使用StringBuilder和append实现字符串相加的操作，然后使用repeat达到字符串相乘的操作，需要注意的是Java将字符转换为字符串可以使用String的静态方法valueOf(char c)或者Character的静态方法toString(char c)。而Kotlin使用Char对象的成员方法toString()转换为字符串，或者使用字符串模板转换为字符串”$c”。在C++中，使用push_back(char c)添加字符，使用append(string s)添加字符串。如果要达到相乘操作，需要自己写循环，使用append添加字符串。还值得注意的是在C++中map、Java和Kotlin中的TreeMap是有序的，因此对key不需要排序，Python中dict是无序的，因此要进行排序操作。</p>
<h1 id="堆-哈希表"><a href="#堆-哈希表" class="headerlink" title="堆+哈希表"></a><font size="5" color="red">堆+哈希表</font></h1><p>本题要对字符串按照出现的频率进行排序，将出现频率高的字符放在字符串前方，因此我们首先要统计出每个字符串出现的次数，这里使用charToFrequency哈希表记录。然后将{f, c}放入大顶堆中，其中c代表字符串，f代表出现的次数，在大顶堆中，会将字符出现次数最多的放在堆顶，然后逐渐将其弹出即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>，其中字符的种类为常数量级，因此不将其放入时间复杂度的计算中</p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    string frequencySort(string s) {</span><br><span class="line">        unordered_map&lt;char, int&gt; charToFrequency;</span><br><span class="line">        for (char c : s) { charToFrequency[c]++; }</span><br><span class="line">        string res = "";</span><br><span class="line">        priority_queue&lt;pair&lt;int, char&gt;&gt; heap;</span><br><span class="line">        for (auto&amp; p : charToFrequency) { heap.push({ p.second, p.first }); }</span><br><span class="line">        while (!heap.empty()) {</span><br><span class="line">            auto&amp; cur = heap.top();</span><br><span class="line">            res.append(string(cur.first, cur.second));</span><br><span class="line">            heap.pop();</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public String frequencySort(String s) {</span><br><span class="line">        HashMap&lt;Character, Integer&gt; charToFrequency = new HashMap&lt;&gt;();</span><br><span class="line">        for (char c : s.toCharArray()) { charToFrequency.put(c, charToFrequency.getOrDefault(c, 0) + 1); }</span><br><span class="line">        PriorityQueue&lt;Character&gt; heap = new PriorityQueue&lt;&gt;((o1, o2) -&gt; charToFrequency.get(o2) - charToFrequency.get(o1));</span><br><span class="line">        heap.addAll(charToFrequency.keySet());</span><br><span class="line">        StringBuilder res = new StringBuilder();</span><br><span class="line">        while (!heap.isEmpty()) {</span><br><span class="line">            char cur = heap.remove();</span><br><span class="line">            res.append(String.valueOf(cur).repeat(charToFrequency.get(cur)));</span><br><span class="line">        }</span><br><span class="line">        return res.toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def frequencySort(self, s):</span><br><span class="line">        char_to_frequency = Counter(s)</span><br><span class="line">        heap = [[y, x] for x, y in char_to_frequency.items()]</span><br><span class="line">        heapq.heapify(heap)</span><br><span class="line">        res = ""</span><br><span class="line">        while heap:</span><br><span class="line">            cur = heapq.heappop(heap)</span><br><span class="line">            res = cur[0] * cur[1] + res</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun frequencySort(s: String): String {</span><br><span class="line">        val charToFrequency = HashMap&lt;Char, Int&gt;()</span><br><span class="line">        for (c in s) { charToFrequency[c] = (charToFrequency[c] ?: 0) + 1 }</span><br><span class="line">        val heap = PriorityQueue&lt;Char&gt;(Comparator { c1, c2 -&gt; charToFrequency[c2]!! - charToFrequency[c1]!! })</span><br><span class="line">        heap.addAll(charToFrequency.keys);</span><br><span class="line">        val res = StringBuilder()</span><br><span class="line">        while (heap.isNotEmpty()) {</span><br><span class="line">            val cur = heap.remove()</span><br><span class="line">            res.append(cur.toString().repeat(charToFrequency[cur]!!))</span><br><span class="line">        }</span><br><span class="line">        return res.toString()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>将四种语言放在一起对比，发现C++语言的pair可以比较大小，否则要自定义类或结构，重写operator()函数，而且priority<em>queue默认为最大堆。Java和Kotlin语言要重写Comparator，而且默认为最小堆，Python中heap也是默认最小堆，而且Python中的list和tuple也可以比较大小，否则也要自定义类，重写<em>_lt</em></em>比较函数。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题非常重要，使用到了自定义类型的堆和哈希操作，因为在实际的工作和开发过程中，往往需要自定义一些类型，因此小伙伴一定要掌握如何使用数据结构对自定义对象进行操作的方法</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>字符串</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>公交路线(Leetcode 815)</title>
    <url>/2021/06/28/program%20Leetcode815/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode815.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最近的每日一题全部都是BFS，总是给小伙伴们介绍这类题型，可能会感觉到厌倦，但是集中训练也是非常有帮助的，而且最近这几题每一题的难度都较大，能做出这几道题目，有一种五岳归来不看山，黄山归来不看岳的感觉。<br><a id="more"></a></p>
<h1 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a><font size="5" color="red">广度优先搜索</font></h1><p>BFS的代码非常简单，有公式模板可以去套用，简而言之就是建立一个队列，从队头去状态，从队尾加状态。<br>本题的难点在于如何进行状态的抽象与表示，假设当前处于第k个车站，那么乘坐该站台的所有公交线路，假设该站台有m个公交线路，那么一次乘坐可以到达哪些站呢？想通这个问题，本题的状态表示就迎刃而解了。<br>答案是一次乘坐可以到达这些所有公交线路经过的所有站点。假设可以有m1和m2两个线路经过当前车站，m1线路经过k11、k12、k13这三个站点，m2路线经过k21、k22、k23、k24这四个站点，那么一次乘坐公交，可以乘坐m1线路到达三个站点，也可以乘坐m2线路到达四个站点。</p>
<p>所以我们需要知道某个站点的所有线路，但是输入的route是线路经过的所有站点，因此要建立一个哈希表，键为站点号，值为一个set集合，存放该站点可以乘坐的所有线路。</p>
<p>并建立两个set集合，分别表示已访问的站点和已访问的路线，当站点或路线已经访问，则不添加到队列进行剪枝。</p>
<p>当然本题从起始公交站搜索到终止公交站等价于从终止公交站搜索到起始公交站，因此可以使用双向BFS进行优化。</p>
<p>算法的<strong>时间复杂度为$O(m^n)$，空间复杂度为$O(m^n)$</strong>，其中m为线路个数，n站点个数。</p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int numBusesToDestination(vector&lt;vector&lt;int&gt;&gt;&amp; routes, int source, int target) {</span><br><span class="line">        if (source == target) { return 0; }</span><br><span class="line">        unordered_map&lt;int, unordered_set&lt;int&gt;&gt; dic;</span><br><span class="line">        for (int i = 0; i &lt; routes.size(); i++) { for (int x : routes[i]) { dic[x].insert(i); } }</span><br><span class="line">        deque&lt;int&gt; beginQueue = { source };</span><br><span class="line">        unordered_set&lt;int&gt; beginStationVisited = { source };</span><br><span class="line">        deque&lt;int&gt; endQueue = { target };</span><br><span class="line">        unordered_set&lt;int&gt; endStationVisited = { target };</span><br><span class="line">        unordered_set&lt;int&gt; beginRouteIndexVisited = { };</span><br><span class="line">        unordered_set&lt;int&gt; endRouteIndexVisited = { };</span><br><span class="line">        int res = 0;</span><br><span class="line">        while (true) {</span><br><span class="line">            res++;</span><br><span class="line">            int beginSize = beginQueue.size();</span><br><span class="line">            while (beginSize-- &gt; 0) {</span><br><span class="line">                int curStation = beginQueue.front();</span><br><span class="line">                beginQueue.pop_front();</span><br><span class="line">                for (int route : dic[curStation]) {</span><br><span class="line">                    if (!beginRouteIndexVisited.count(route)) {</span><br><span class="line">                        beginRouteIndexVisited.insert(route);</span><br><span class="line">                        for (int station : routes[route]) {</span><br><span class="line">                            if (!beginStationVisited.count(station)) {</span><br><span class="line">                                if (endStationVisited.count(station)) { return res; }</span><br><span class="line">                                beginQueue.push_back(station);</span><br><span class="line">                                beginStationVisited.insert(station);</span><br><span class="line">                            }</span><br><span class="line">                        }</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (beginQueue.empty()) { return -1; }</span><br><span class="line">            res++;</span><br><span class="line">            int endSize = endQueue.size();</span><br><span class="line">            while (endSize-- &gt; 0) {</span><br><span class="line">                int curStation = endQueue.front();</span><br><span class="line">                endQueue.pop_front();</span><br><span class="line">                for (int route : dic[curStation]) {</span><br><span class="line">                    if (!endRouteIndexVisited.count(route)) { </span><br><span class="line">                        endRouteIndexVisited.insert(route);</span><br><span class="line">                        for (int station : routes[route]) {</span><br><span class="line">                            if (!endStationVisited.count(station)) {</span><br><span class="line">                                if (beginStationVisited.count(station)) { return res; }</span><br><span class="line">                                endQueue.push_back(station);</span><br><span class="line">                                endStationVisited.insert(station);</span><br><span class="line">                            }</span><br><span class="line">                        }</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (endQueue.empty()) { return -1; }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def numBusesToDestination(self, routes, source, target):</span><br><span class="line">        if source == target:</span><br><span class="line">            return 0</span><br><span class="line">        dic = {}</span><br><span class="line">        for i in range(len(routes)):</span><br><span class="line">            for x in routes[i]:</span><br><span class="line">                lst = dic.setdefault(x, set())</span><br><span class="line">                lst.add(i)</span><br><span class="line">                dic[x] = lst</span><br><span class="line">        begin_queue = deque([source])</span><br><span class="line">        end_queue = deque([target])</span><br><span class="line">        begin_station_visited = {source}</span><br><span class="line">        end_station_visited = {target}</span><br><span class="line">        begin_route_visited = set()</span><br><span class="line">        end_route_visited = set()</span><br><span class="line">        res = 0</span><br><span class="line">        while True:</span><br><span class="line">            res += 1</span><br><span class="line">            begin_size = len(begin_queue)</span><br><span class="line">            for _ in range(begin_size):</span><br><span class="line">                cur_station = begin_queue.popleft()</span><br><span class="line">                if cur_station in dic:</span><br><span class="line">                    for route in dic[cur_station]:</span><br><span class="line">                        if route not in begin_route_visited:</span><br><span class="line">                            begin_route_visited.add(route)</span><br><span class="line">                            for station in routes[route]:</span><br><span class="line">                                if station not in begin_station_visited:</span><br><span class="line">                                    if station in end_station_visited:</span><br><span class="line">                                        return res</span><br><span class="line">                                    begin_queue.append(station)</span><br><span class="line">                                    begin_station_visited.add(station)</span><br><span class="line">            if len(begin_queue) == 0:</span><br><span class="line">                return -1</span><br><span class="line">            res += 1</span><br><span class="line">            end_size = len(end_queue)</span><br><span class="line">            for _ in range(end_size):</span><br><span class="line">                cur_station = end_queue.popleft()</span><br><span class="line">                if cur_station in dic:</span><br><span class="line">                    for route in dic[cur_station]:</span><br><span class="line">                        if route not in end_route_visited:</span><br><span class="line">                            end_route_visited.add(route)</span><br><span class="line">                            for station in routes[route]:</span><br><span class="line">                                if station not in end_station_visited:</span><br><span class="line">                                    if station in begin_station_visited:</span><br><span class="line">                                        return res</span><br><span class="line">                                    end_queue.append(station)</span><br><span class="line">                                    end_station_visited.add(station)</span><br><span class="line">            if len(end_queue) == 0:</span><br><span class="line">                return -1</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比C++和Python两种语言，可以发现C++语言中，创建数据结构时，会默认创建内层的数据，如vector<int> a(10);等价于vector<int> a(10, 0); vector<vector<int>&gt; a(10);等价于vector<int> a(10, vector<int>());因此可以直接进行push_back()，如a[0].push_back();哈希表同理，unordered_map<int, vector<int="">&gt; a，此时可以直接写a[0].push_back(x)，因为哈希表中每一个元素都是vector<int>类型，会调用其默认的构造函数。而在Java、Python语言中，则必须新建一个内层数据，才可以添加元素，如Java中要写ArrayList<integer> list = a.getOrDefault(0, new ArrayList<integer>()); list.add(x); a.put(0, list);在Python中要写lst = a.setdefault(0, list()) lst.append(x)。这是本题发现两种语言的主要差异</integer></integer></int></int,></int></int></vector<int></int></int></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  听过上面的分析后，小伙伴能否自己实现BFS呢，一定要多刷多练，慢慢就会找到做题的感觉。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>广度优先搜索</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>滑动谜题(Leetcode 773)</title>
    <url>/2021/06/26/program%20Leetcode773/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode773.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是一个困难的题目，不要被它吓倒了，这个题目和昨天的打开转盘锁类似，只不过本题的状态改变和状态的表示复杂一些<br><a id="more"></a></p>
<h1 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a><font size="5" color="red">广度优先搜索</font></h1><p>本题的起始状态为board，终止状态为[[1, 2, 3], [4, 5, 0]]，因此同样可以使用双向BFS进行求解。<br>因为0代表空缺位置，因此只有0附近的元素可以进行移动，我们使用长度为6字符串表示元素的状态，分别代表board的6个数字。<br>当0出现在board[0][0]时，可以和board[0][1]、board[1][0]互换位置，因此str[0]可以和str[1]、str[3]交换<br>当0出现在board[0][1]时，可以和board[0][0]、board[0][2]、board[1][1]互换位置，因此str[1]可以和str[0]、str[2]、str[4]交换<br>当0出现在board[0][2]时，可以和board[0][1]、board[1][2]互换位置，因此str[2]可以和str[1]、str[5]交换<br>当0出现在board[1][0]时，可以和board[0][0]、board[1][1]互换位置，因此str[3]可以和str[0]、str[4]交换<br>当0出现在board[1][1]时，可以和board[0][1]、board[1][0]、board[1][2]互换位置，因此str[1]可以和str[1]、str[3]、str[5]交换<br>当0出现在board[1][2]时，可以和board[0][2]、board[1][1]互换位置，因此str[5]可以和str[2]、str[4]交换</p>
<p>用一个长度为6二维数组dir，每一个元素代表可以交换的位置列表，如dir[0] = {1， 3}代表str[0]可以和str[1]和str[3]进行交换，这样可以快速获得下一个状态的表示。</p>
<p>算法的<strong>时间复杂度为$O((mn)!)$，空间复杂度为$O((mn)! \times mn)$</strong>，其中m和n分别代表行数和列数，$(mn)!$表示所有可能的状态，即本题0-5六个数字的全排列</p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int slidingPuzzle(int[][] board) {</span><br><span class="line">        String target = "123450";</span><br><span class="line">        String begin = Integer.toString(board[0][0]) + board[0][1] + board[0][2] + board[1][0] + board[1][1] + board[1][2];</span><br><span class="line">        if (target.equals(begin)) { return 0; }</span><br><span class="line">        int[][] dir = new int[][] {{1, 3}, {0, 2, 4}, {1, 5}, {0, 4}, {1, 3, 5}, {2, 4}};</span><br><span class="line">        LinkedList&lt;String&gt; beginQueue = new LinkedList&lt;&gt;();</span><br><span class="line">        beginQueue.add(begin);</span><br><span class="line">        LinkedList&lt;String&gt; endQueue = new LinkedList&lt;&gt;();</span><br><span class="line">        endQueue.add(target);</span><br><span class="line">        HashSet&lt;String&gt; beginVisited = new HashSet&lt;&gt;();</span><br><span class="line">        beginVisited.add(begin);</span><br><span class="line">        HashSet&lt;String&gt; endVisited = new HashSet&lt;&gt;();</span><br><span class="line">        endVisited.add(target);</span><br><span class="line">        int res = 0;</span><br><span class="line">        while (true) {</span><br><span class="line">            res++;</span><br><span class="line">            int beginSize = beginQueue.size();</span><br><span class="line">            while (beginSize-- &gt; 0) {</span><br><span class="line">                String cur = beginQueue.removeFirst();</span><br><span class="line">                int zeroPos = cur.indexOf('0');</span><br><span class="line">                for (int p : dir[zeroPos]) {</span><br><span class="line">                    StringBuilder stringBuilder = new StringBuilder(cur);</span><br><span class="line">                    stringBuilder.setCharAt(zeroPos, cur.charAt(p));</span><br><span class="line">                    stringBuilder.setCharAt(p, '0');</span><br><span class="line">                    String nextString = stringBuilder.toString();</span><br><span class="line">                    if (!beginVisited.contains(nextString)) {</span><br><span class="line">                        if (endVisited.contains(nextString)) { return res; }</span><br><span class="line">                        beginVisited.add(nextString);</span><br><span class="line">                        beginQueue.add(nextString);</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (beginQueue.isEmpty()) { return -1; }</span><br><span class="line"></span><br><span class="line">            res++;</span><br><span class="line">            int endSize = endQueue.size();</span><br><span class="line">            while (endSize-- &gt; 0) {</span><br><span class="line">                String cur = endQueue.removeFirst();</span><br><span class="line">                int zeroPos = cur.indexOf('0');</span><br><span class="line">                for (int p : dir[zeroPos]) {</span><br><span class="line">                    StringBuilder stringBuilder = new StringBuilder(cur);</span><br><span class="line">                    stringBuilder.setCharAt(zeroPos, cur.charAt(p));</span><br><span class="line">                    stringBuilder.setCharAt(p, '0');</span><br><span class="line">                    String nextString = stringBuilder.toString();</span><br><span class="line">                    if (!endVisited.contains(nextString)) {</span><br><span class="line">                        if (beginVisited.contains(nextString)) { return res; }</span><br><span class="line">                        endVisited.add(nextString);</span><br><span class="line">                        endQueue.add(nextString);</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (endQueue.isEmpty()) { return -1; }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun slidingPuzzle(board: Array&lt;IntArray&gt;): Int {</span><br><span class="line">        val target = "123450"</span><br><span class="line">        val begin = board[0][0].toString() + board[0][1].toString() + board[0][2].toString() + board[1][0].toString() + board[1][1].toString() + board[1][2].toString()</span><br><span class="line">        if (target == begin) { return 0 }</span><br><span class="line">        val dir = arrayOf(intArrayOf(1, 3), intArrayOf(0, 2, 4), intArrayOf(1, 5), intArrayOf(0, 4), intArrayOf(1, 3, 5), intArrayOf(2, 4))</span><br><span class="line">        val beginQueue = LinkedList&lt;String&gt;()</span><br><span class="line">        beginQueue.add(begin)</span><br><span class="line">        val endQueue = LinkedList&lt;String&gt;()</span><br><span class="line">        endQueue.add(target)</span><br><span class="line">        val beginVisited = HashSet&lt;String&gt;()</span><br><span class="line">        beginVisited.add(begin)</span><br><span class="line">        val endVisited = HashSet&lt;String&gt;()</span><br><span class="line">        endVisited.add(target)</span><br><span class="line">        var res = 0</span><br><span class="line">        while (true) {</span><br><span class="line">            res++</span><br><span class="line">            var beginSize = beginQueue.size</span><br><span class="line">            while (beginSize-- &gt; 0) {</span><br><span class="line">                val cur = beginQueue.removeFirst()</span><br><span class="line">                val zeroPos = cur.indexOf('0')</span><br><span class="line">                for (p in dir[zeroPos]) {</span><br><span class="line">                    val stringBulider = StringBuilder(cur)</span><br><span class="line">                    stringBulider.setCharAt(zeroPos, cur[p])</span><br><span class="line">                    stringBulider.setCharAt(p, '0')</span><br><span class="line">                    val nextString = stringBulider.toString()</span><br><span class="line">                    if (!beginVisited.contains(nextString)) {</span><br><span class="line">                        if (endVisited.contains(nextString)) { return res }</span><br><span class="line">                        beginQueue.add(nextString)</span><br><span class="line">                        beginVisited.add(nextString)</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (beginQueue.isEmpty()) { return -1 }</span><br><span class="line"></span><br><span class="line">            res++</span><br><span class="line">            var endSize = endQueue.size</span><br><span class="line">            while (endSize-- &gt; 0) {</span><br><span class="line">                val cur = endQueue.removeFirst()</span><br><span class="line">                val zeroPos = cur.indexOf('0')</span><br><span class="line">                for (p in dir[zeroPos]) {</span><br><span class="line">                    val stringBulider = StringBuilder(cur)</span><br><span class="line">                    stringBulider.setCharAt(zeroPos, cur[p])</span><br><span class="line">                    stringBulider.setCharAt(p, '0')</span><br><span class="line">                    val nextString = stringBulider.toString()</span><br><span class="line">                    if (!endVisited.contains(nextString)) {</span><br><span class="line">                        if (beginVisited.contains(nextString)) { return res }</span><br><span class="line">                        endQueue.add(nextString)</span><br><span class="line">                        endVisited.add(nextString)</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (endQueue.isEmpty()) { return -1 }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  最近几天是BFS/DFS的专项训练，这是必须要掌握的算法之一，希望小伙伴要认真对待。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>广度优先搜索</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>打开转盘锁(Leetcode 752)</title>
    <url>/2021/06/25/program%20Leetcode752/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode752.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是我非常推荐小伙伴们去做的一个题目，这个题目会做以后，BFS的类似题目应该都可以顺利求解<br><a id="more"></a></p>
<h1 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a><font size="5" color="red">广度优先搜索</font></h1><p>关于BFS的基本操作前面已经有大量的讲解和练习，这里不做过多介绍。推荐本题的原因是，这个题目包含了多次优化思想，虽然不能从理论上降低时间复杂度，但是这些剪枝操作在实际的测试样例中会节约大量的时间。</p>
<ol>
<li><p>使用双向BFS进行求解，我们都知道BFS的时间复杂度为指数量级，对于m叉树来说为$O(m^n)$。因为每次都会扩展m倍的数据量。初始queue队列中仅有初始状态，第一次循环结束，初始状态弹出，会压入m个状态1，第二次循环结束，m个状态1弹出，会压入$m^2$个状态2，依此类推。所以我们要尽量减少n。本题中，一次解锁，可能产生8个状态，m = 8，极端情况下，target = “55555”，因此需要解锁20次，所以运算量为$8^20$，这是一个非常大的数。但是本题我们仅仅要搜索到target即可，在最后一次循环中，仅仅需要一个状态，因此我们可以从两端向中间搜索，从”0000”向target搜索一个循环，然后再从target向”0000”搜索一个循环，这样相当于将n减少为一半，此时运算量为$8^10$，这就极大降低了运行时间。</p>
</li>
<li><p>使用哈希表记录已经遍历过的状态，根据思路1选择了双向BFS，记从”0000”到target的队列为begin_queue，从target到”0000”的队列记为”end_queue”。从”0000”到target的寻找过程中，如果某个状态曾经出现过，可以停止搜索，因此使用begin_visited哈希表记录正向搜索过程中已经出现的状态。反向同理。这样状态最多出现$10^4$个，即从”0000”到”9999”，这种剪枝是最有效和常用的方法。往往可以将时间复杂度从指数降为线性。</p>
</li>
<li><p>第三种优化思路需要和第一种与第二种思路搭配使用，在双向BFS中，使用begin_visited和end_visited记录曾经遍历过的状态，当正向搜索时，某个状态K出现在end_visited中，说明找到了一条从”0000”到k和从target到k的通路，此时就可以直接返回当前的迭代次数，反向搜索同理</p>
</li>
</ol>
<p>算法的<strong>时间复杂度为$O(m^n \times n^2)$，空间复杂度为$O(m^n \times n)$</strong>，其中m=10为转盘数字的进制，n=4为转盘数字的位数。</p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int openLock(vector&lt;string&gt;&amp; deadends, string target) {</span><br><span class="line">        unordered_set&lt;string&gt; dead, beginVisited = { "0000" }, endVisited = { target };</span><br><span class="line">        if (target == "0000") { return 0; }</span><br><span class="line">        for (string s : deadends) { dead.insert(s); }</span><br><span class="line">        if (dead.count("0000")) { return -1; }</span><br><span class="line">        deque&lt;string&gt;* beginQueue = new deque&lt;string&gt;{ "0000" }, * endQueue = new deque&lt;string&gt;{ target };</span><br><span class="line">        int times = 0;</span><br><span class="line">        auto upChar = [](char c)-&gt;char { return c == '9' ? '0' : c + 1; };</span><br><span class="line">        auto downChar = [](char c)-&gt;char { return c == '0' ? '9' : c - 1; };</span><br><span class="line">        auto getStr = [=](string s)-&gt;vector&lt;string&gt; {</span><br><span class="line">            vector&lt;string&gt; res;</span><br><span class="line">            for (int i = 0; i &lt; 4; i++) {</span><br><span class="line">                char cur = s[i];</span><br><span class="line">                s[i] = upChar(cur);</span><br><span class="line">                res.push_back(s);</span><br><span class="line">                s[i] = downChar(cur);</span><br><span class="line">                res.push_back(s);</span><br><span class="line">                s[i] = cur;</span><br><span class="line">            }</span><br><span class="line">            return res;</span><br><span class="line">        };</span><br><span class="line">        while (true) {</span><br><span class="line">            times++;</span><br><span class="line">            deque&lt;string&gt;* newBeginQueue = new deque&lt;string&gt;();</span><br><span class="line">            while (!beginQueue-&gt;empty()) {</span><br><span class="line">                string cur = beginQueue-&gt;front();</span><br><span class="line">                beginQueue-&gt;pop_front();</span><br><span class="line">                vector&lt;string&gt; curList = getStr(cur);</span><br><span class="line">                for (string s : curList) {</span><br><span class="line">                    if (!dead.count(s) &amp;&amp; !beginVisited.count(s)) {</span><br><span class="line">                        if (endVisited.count(s)) { return times; }</span><br><span class="line">                        newBeginQueue-&gt;push_back(s);</span><br><span class="line">                        beginVisited.insert(s);</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (newBeginQueue-&gt;empty()) { return -1; }</span><br><span class="line">            beginQueue = newBeginQueue;</span><br><span class="line"></span><br><span class="line">            times++;</span><br><span class="line">            deque&lt;string&gt;* newEndQueue = new deque&lt;string&gt;();</span><br><span class="line">            while (!endQueue-&gt;empty()) {</span><br><span class="line">                string cur = endQueue-&gt;front();</span><br><span class="line">                endQueue-&gt;pop_front();</span><br><span class="line">                vector&lt;string&gt; curList = getStr(cur);</span><br><span class="line">                for (string s : curList) {</span><br><span class="line">                    if (!dead.count(s) &amp;&amp; !endVisited.count(s)) {</span><br><span class="line">                        if (beginVisited.count(s)) { return times; }</span><br><span class="line">                        newEndQueue-&gt;push_back(s);</span><br><span class="line">                        endVisited.insert(s);</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            if (newEndQueue-&gt;empty()) { return -1; }</span><br><span class="line">            endQueue = newEndQueue;</span><br><span class="line">        }</span><br><span class="line">        return times;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def openLock(self, deadends, target):</span><br><span class="line">        if target == '0000':</span><br><span class="line">            return 0</span><br><span class="line">        dead = set(deadends)</span><br><span class="line">        if '0000' in dead:</span><br><span class="line">            return -1</span><br><span class="line">        begin_visited = set(['0000'])</span><br><span class="line">        end_visited = set([target])</span><br><span class="line">        begin_queue = deque(["0000"])</span><br><span class="line">        end_queue = deque([target])</span><br><span class="line">        times = 0</span><br><span class="line"></span><br><span class="line">        def up_char(c):</span><br><span class="line">            return str(int(c) + 1) if c != '9' else '0'</span><br><span class="line"></span><br><span class="line">        def down_char(c):</span><br><span class="line">            return str(int(c) - 1) if c != '0'else '9'</span><br><span class="line"></span><br><span class="line">        def get_str(s):</span><br><span class="line">            res = []</span><br><span class="line">            for i in range(4):</span><br><span class="line">                res.append(s[:i] + up_char(s[i]) + s[i + 1:])</span><br><span class="line">                res.append(s[:i] + down_char(s[i]) + s[i + 1:])</span><br><span class="line">            return res</span><br><span class="line"></span><br><span class="line">        while True:</span><br><span class="line">            times += 1</span><br><span class="line">            new_begin_queue = deque()</span><br><span class="line">            while begin_queue:</span><br><span class="line">                cur = begin_queue.popleft()</span><br><span class="line">                cur_list = get_str(cur)</span><br><span class="line">                for x in cur_list:</span><br><span class="line">                    if x not in dead and x not in begin_visited:</span><br><span class="line">                        if x in end_visited:</span><br><span class="line">                            return times</span><br><span class="line">                        begin_visited.add(x)</span><br><span class="line">                        new_begin_queue.append(x)</span><br><span class="line">            if not new_begin_queue:</span><br><span class="line">                return -1</span><br><span class="line">            begin_queue = new_begin_queue</span><br><span class="line"></span><br><span class="line">            times += 1</span><br><span class="line">            new_end_queue = deque()</span><br><span class="line">            while end_queue:</span><br><span class="line">                cur = end_queue.popleft()</span><br><span class="line">                cur_list = get_str(cur)</span><br><span class="line">                for x in cur_list:</span><br><span class="line">                    if x not in dead and x not in end_visited:</span><br><span class="line">                        if x in begin_queue:</span><br><span class="line">                            return times</span><br><span class="line">                        end_visited.add(x)</span><br><span class="line">                        new_end_queue.append(x)</span><br><span class="line">            if not new_end_queue:</span><br><span class="line">                return -1</span><br><span class="line">            end_queue = new_end_queue</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比C++和Python两种语言，可以发现Python语言中，函数中可以嵌套定义函数，非常方便，在C++语言中函数无法嵌套定义，但是可以使用lambda表达式进行类似的操作。而且要注意的是在C++语言中，本层遍历后beginQueue要指向newBeginQueue，此时两个都应该设置为指针，否则newBeginQueue结束清空时，beginQueue也为空。而Python里面对象都是指针，因此直接赋值即可。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题的重点在于双向BFS的优化，而且小伙伴们一定要区分什么时候用BFS，什么时候用DFS，通常来说两个都可以使用，当求最短路的时候，要使用BFS，因为每一次循环代表往前进一步，第一次搜索到某个状态时，一定是最短的路径，这时如果使用DFS则需要将所有的通路都走一遍，才能找到最短的路径。当题目只需要寻找到一条通路时，往往使用DFS，因为BFS每次前进一步，假设最近为第n步，时间复杂度为$O(m^n)$，而且需要耗费$O(m^n)$的空间复杂度。但是使用DFS，可能第一次就找到通路，计算量为$O(n)$，空间复杂度为$O(n)$，表示栈空间的调用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>广度优先搜索</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>Kotlin函数</title>
    <url>/2021/06/23/Kotlin_function/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++18.png" alt="2"></p>
<h1 id="Kotlin函数"><a href="#Kotlin函数" class="headerlink" title="Kotlin函数"></a><font size="5" color="red">Kotlin函数</font></h1><p>  函数是面向过程的程序设计精髓，也是所有语言中最重要的一个内容，学好函数，可以设计出优雅的程序，下面给小伙伴们介绍Kotlin函数的定义，调用，参数传递，声明，默认参数，占位参数和函数的重载。<br><a id="more"></a></p>
<h1 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a><font size="5">函数定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 函数小伙伴们其实并不陌生，在第一行Kotlin代码中就用到了函数的知识，main函数，main函数是程序运行的起始位置，程序必须要有main函数才可以运行</span><br><span class="line">// 函数的定义包括权限修饰符，fun关键字，函数名，参数列表，返回值类型和函数体，和Java不同点在于有fun关键字，参数的类型写在参数后面，并且用冒号分隔，而且返回值不是写在函数名前面，而是写在形参后面，也使用冒号分隔，关于函数的权限修饰符会在面向对象中进行详细介绍。</span><br><span class="line">// 这里单独强调返回值，返回值代表函数运行结束后返回到调用处时产生的数据，如果没有返回值，类型省略或写Unit，可以省略return，如果有返回值，一定要写return</span><br><span class="line">// 调用时有两种方式，按照顺序传入参数，也可以通过形参名传入对应的参数，但是要注意一旦某个位置使用形参名传入参数，后面的所有参数都要使用这种方式</span><br><span class="line">fun main() {</span><br><span class="line">    println("1 + 2 = ${mySum1(1, 2)}")</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun mySum1(x: Int, y: Int): Int{</span><br><span class="line">    return x + y</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin18.png" alt="1"></p>
<h1 id="单表达式函数"><a href="#单表达式函数" class="headerlink" title="单表达式函数"></a><font size="5">单表达式函数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//当函数只有一行代码，可以将花括号改为等号，并将函数体放在等于号的后面，而且可以省略返回值的类型进行自动推断</span><br><span class="line">fun main() {</span><br><span class="line">    println("1 + 2 = ${mySum2(1, 2)}")</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun mySum2(x: Int, y: Int) = x + y</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin18.png" alt="4"></p>
<h1 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a><font size="5">默认参数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 默认参数是指函数的某个参数具有默认的值，当没用指定该值时，会代入默认值使用，但是要注意默认参数的使用顺序。</span><br><span class="line">// 在本例中，第二个参数y为默认参数，在函数定义时在后面写上默认值。调用时如果默认参数后面有普通参数，那么省略默认参数时，必须使用形参名来确定传入的值，否则会将该值当作默认参数传入。比如本例传入(1, 3)则会将x = 1，y = 3传入，此时会因为没用给z赋值而报错，有两种方法可以修改，一个是传入(1, z = 3)，这时指定传入的3是给z这个形参的。也可以给y传入一个数，这样3就会自动顺延至z。注意一般不在默认参数后面赋值普通参数，都将默认参数放在最后。</span><br><span class="line">fun main() {</span><br><span class="line">    println("1 + 2 + 3 = ${mySum3(1, z = 3)}")</span><br><span class="line">    println("1 + 3 + 5 = ${mySum3(1, 3, 5)}")</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun mySum3(x: Int, y: Int = 2, z: Int) = x + y + z</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin19.png" alt="1"></p>
<h1 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a><font size="5">函数重载</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 函数重载是指定义具有相同名字的函数，前提是函数的参数个数、顺序、类型不完全相同。在调用时更符合哪一个函数则调用哪一个函数。如mySum4(1.0, 2)此时参数为Double和Int，则调用mySum4(x:Double, y:Int)函数；如mySum4(1, 2.0)此时参数为Int和Double，则调用mySum4(x:Int, y:Double)函数；如果此时有一个函数为mySum4(x:Int, y:Double, z:Int = 2)此时仍然调用上面的函数，因为调用的函数具有两个实参，会优先使用具有两个形参的函数。如果调用的函数有三个实参，才会调用具有默认参数的函数。</span><br><span class="line">fun main() {</span><br><span class="line">    println("1 + 2 = ${mySum4(1.0, 2)}")</span><br><span class="line">    println("1 + 2 = ${mySum4(1, 2.0)}")</span><br><span class="line">    println("1 + 2 + 3 = ${mySum4(1, 2.0, 3)}")</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Int, y:Double) = x + y</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Int, y:Double, z:Int) = x + y + z</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Double, y:Int) = x + y</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin20.png" alt="1"></p>
<h1 id="函数重载-1"><a href="#函数重载-1" class="headerlink" title="函数重载"></a><font size="5">函数重载</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 函数重载是指定义具有相同名字的函数，前提是函数的参数个数、顺序、类型不完全相同。在调用时更符合哪一个函数则调用哪一个函数。如mySum4(1.0, 2)此时参数为Double和Int，则调用mySum4(x:Double, y:Int)函数；如mySum4(1, 2.0)此时参数为Int和Double，则调用mySum4(x:Int, y:Double)函数；如果此时有一个函数为mySum4(x:Int, y:Double, z:Int = 2)此时仍然调用上面的函数，因为调用的函数具有两个实参，会优先使用具有两个形参的函数。如果调用的函数有三个实参，才会调用具有默认参数的函数。</span><br><span class="line">fun main() {</span><br><span class="line">    println("1 + 2 = ${mySum4(1.0, 2)}")</span><br><span class="line">    println("1 + 2 = ${mySum4(1, 2.0)}")</span><br><span class="line">    println("1 + 2 + 3 = ${mySum4(1, 2.0, 3)}")</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Int, y:Double) = x + y</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Int, y:Double, z:Int) = x + y + z</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Double, y:Int) = x + y</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin20.png" alt="1"></p>
<h1 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a><font size="5">可变参数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 可变参数指参数类型确定，但是个数不确定的参数，可以通过vararg关键字来标识，在使用时可以当作数组，具有数组的高阶函数。对于可变参数可以使用星号*加数组名将数组进行展开传入。</span><br><span class="line">// 要注意的是可变参数一般都位于函数的末尾，如果不在函数末尾，则后面的参数需要通过形参名传入</span><br><span class="line">fun main() {</span><br><span class="line">    println(mySum5(1))</span><br><span class="line">    println(mySum5(1, 2))</span><br><span class="line">    println(mySum5(1, 2, 3))</span><br><span class="line">    println(mySum5(1, 2, 3, 4))</span><br><span class="line">    val arr = intArrayOf(1, 2, 3, 4, 5)</span><br><span class="line">    println(mySum5(*arr))</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Int, y:Double) = x + y</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Int, y:Double, z:Int) = x + y + z</span><br><span class="line"></span><br><span class="line">fun mySum4(x:Double, y:Int) = x + y</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin21.png" alt="1"></p>
<h1 id="局部函数"><a href="#局部函数" class="headerlink" title="局部函数"></a><font size="5">局部函数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 局部参数又称为嵌套函数，是在一个函数的内部定义另一个函数，在Python中也有类似的定义方式。</span><br><span class="line">// 注意：如果内部和外部具有相同的函数，不会报错，调用时会使用内部的函数。如果内部和外部具有相同的函数，不同的参数，则优先使用内部的函数。如内部是mySum(x:Int, y:Int, z:Int = 2) = x + y + z，外部是mySum(x:Int, y:Int) = x + y，如果调用传入两个参数，仍然也使用内部的函数，这和函数重载不同，函数重载会使用外部的函数，因为参数更加匹配，内外部函数的原则是能用则使用内部函数，内部函数不能用才使用外部函数。当调用传入三个参数，则内部的函数无法使用，此时会调用外部的函数</span><br><span class="line">fun main() {</span><br><span class="line">    fun mySum6(x:Int, y:Int) = x + y</span><br><span class="line">    println(1 + 2 = ${mySum6(1, 2)})</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin18.png" alt="1"></p>
<h1 id="Kotlin小结"><a href="#Kotlin小结" class="headerlink" title="Kotlin小结"></a><font size="5" color="red">Kotlin小结</font></h1><p>  函数是我们面向过程编程的重要思想，同时也是面向对象中封装特性的体现，有了函数我们可以节约大量的时间和空间管理我们的代码，提高了代码的复用率，但是我们要注意编程习惯，尽量一个函数实现一个功能，不要将多个功能写在同一个函数之中。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Kotlin</category>
      </categories>
  </entry>
  <entry>
    <title>Kotlin数组</title>
    <url>/2021/06/20/Kotlin_array/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++17.png" alt="2"></p>
<h1 id="Kotlin数组"><a href="#Kotlin数组" class="headerlink" title="Kotlin数组"></a><font size="5" color="red">Kotlin数组</font></h1><p>  在前面已经介绍了Kotlin的运算符和流程控制语句，这里主要介绍Kotlin的数组<br><a id="more"></a></p>
<h1 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a><font size="5">创建数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// Kotlin创建数组有三种常见方式</span><br><span class="line">// 使用Array创建数组，创建时指定数组的大小和初始值，其中初始值通过一个函数映射定义，也可以使用lambda表达式，在函数映射或lambda表达式中it为数组的索引，根据返回值的类型确定数组的类型</span><br><span class="line">// 使用arrayOf创建数组，直接给数组赋值</span><br><span class="line">// 使用arrayOfNulls创建可以为空的数组，创建时指定数组的大小</span><br><span class="line">fun main() {</span><br><span class="line">    val arr1 = Array(5, arrInit())</span><br><span class="line">    for ((idx, x) in arr1.withIndex()) { println("arr1[${idx}] = ${x}") }</span><br><span class="line"></span><br><span class="line">    val arr2 = Array(5) { "arr2[${it}] = ${it * 2}" }</span><br><span class="line">    for (x in arr2) { println(x) }</span><br><span class="line"></span><br><span class="line">    val arr3 = arrayOf(0, 2, 4, 6, 8)</span><br><span class="line">    for ((idx, x) in arr3.withIndex()) { println("arr3[${idx}] = ${x}") }</span><br><span class="line"></span><br><span class="line">    val arr4 = arrayOfNulls&lt;Int&gt;(5)</span><br><span class="line">    for ((idx, x) in arr4.withIndex()) { println("arr4[${idx}] = ${x}") }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">fun arrInit(): (Int) -&gt; Int = { it -&gt; it * 2 }</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin14.png" alt="1"></p>
<h1 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a><font size="5">二维数组</font></h1><p>// 二维数组和一维数组的创建方法类似，也有三种创建方法。但是第一种方法中，it要指向一个新的一维数组<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">fun main() {</span><br><span class="line">    val arr1 = Array(3) { it1 -&gt; Array(4) {it1 * 4 + it} }</span><br><span class="line">    for ((idx1, x) in arr1.withIndex()) {</span><br><span class="line">        for ((idx2, y) in x.withIndex()) {</span><br><span class="line">            print("arr1[${idx1}][${idx2}] = ${y} ")</span><br><span class="line">        }</span><br><span class="line">        println()</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    println("------------------------------------------------------------")</span><br><span class="line"></span><br><span class="line">    val arr2 = arrayOf(arrayOf(0, 1, 2, 3), arrayOf(4, 5, 6, 7), arrayOf(8, 9, 10, 11))</span><br><span class="line">    for ((idx1, x) in arr2.withIndex()) {</span><br><span class="line">        for ((idx2, y) in x.withIndex()) {</span><br><span class="line">            print("arr2[${idx1}][${idx2}] = ${y} ")</span><br><span class="line">        }</span><br><span class="line">        println()</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    println("------------------------------------------------------------")</span><br><span class="line"></span><br><span class="line">    val arr3 = Array(3) { arrayOfNulls&lt;Int&gt;(4) }</span><br><span class="line">    for ((idx1, x) in arr3.withIndex()) {</span><br><span class="line">        for ((idx2, y) in x.withIndex()) {</span><br><span class="line">            print("arr3[${idx1}][${idx2}] = ${y} ")</span><br><span class="line">        }</span><br><span class="line">        println()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/Kotlin15.png" alt="4"></p>
<h1 id="确定类型数组"><a href="#确定类型数组" class="headerlink" title="确定类型数组"></a><font size="5">确定类型数组</font></h1><p>// 除了上面介绍的使用Array和arrayOf创建数组以外，还可以指定数组的类型，使用IntArray或者intArrayOf创建Int类型的数组，Byte、Short、Long、Char、Float、Double、Boolean同理<br>// 正是因为arrayOf没有指定元素的类型，因此可以放入不同的元素<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">fun main() {</span><br><span class="line">    val arr1 = arrayOf(0, 2.0, '4', 6.toShort(), "8")</span><br><span class="line">    for ((idx, x) in arr1.withIndex()) { println("arr1[${idx}] = ${x}") }</span><br><span class="line"></span><br><span class="line">    val arr2 = IntArray(5) {it * 2}</span><br><span class="line">    for ((idx, x) in arr2.withIndex()) { println("arr2[${idx}] = ${x}") }</span><br><span class="line"></span><br><span class="line">    val arr3 = doubleArrayOf(0.0, 2.0, 4.0, 6.0, 8.0)</span><br><span class="line">    for ((idx, x) in arr3.withIndex()) { println("arr3[${idx}] = ${x}") }</span><br><span class="line"></span><br><span class="line">    val arr4 = charArrayOf('0', '2', '4', '6', '8')</span><br><span class="line">    for ((idx, x) in arr4.withIndex()) { println("arr4[${idx}] = ${x}") }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/Kotlin16.png" alt="4"></p>
<h1 id="数组高阶操作"><a href="#数组高阶操作" class="headerlink" title="数组高阶操作"></a><font size="5">数组高阶操作</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// Kotlin中的数组和Java中的差异很大，具有非常多的高阶操作，有些类似于其他语言中的集合框架，如C++中的vector，Java中的ArrayList，Python中的list，这里将常用的一些操作介绍给大家。</span><br><span class="line">fun main() {</span><br><span class="line">    val arr1 = arrayOf(28, 10, 50, 40, 20)</span><br><span class="line"></span><br><span class="line">    // copyOf函数，是复制一个新的数组，和原数组内容相同，但是地址不同，修改原数组，新数组不会改变</span><br><span class="line">    val arr2 = arr1.copyOf()</span><br><span class="line">    arr1[0]++</span><br><span class="line">    for ((idx, x) in arr2.withIndex()) { print("arr2[${idx}] = ${x} ") }</span><br><span class="line">    println()</span><br><span class="line"></span><br><span class="line">    // 这是直接赋值操作，可以看出两个指针指向同一个地址，因此修改原数组，新数组也发生变化</span><br><span class="line">    val  arr3 = arr1</span><br><span class="line">    arr1[0]++</span><br><span class="line">    for ((idx, x) in arr3.withIndex()) { print("arr3[${idx}] = ${x} ") }</span><br><span class="line">    println()</span><br><span class="line"></span><br><span class="line">    // silce切片操作，取出切片范围内的元素形成新List集合，不是数组，通过对象.javaClass可以查看对象的类型。但是要注意两边都是闭区间</span><br><span class="line">    val arr4 = arr1.slice(0..2)</span><br><span class="line">    println("${arr4.javaClass}类型的arr4 = ${arr4}")</span><br><span class="line"></span><br><span class="line">    // plus追加操作，在原数组后面追加元素形成新数组，原数组不会发生变化，可以是单个元素，也可以是数组或者集合</span><br><span class="line">    val arr5 = arr1.plus(arrayOf(70, 60))</span><br><span class="line">    for ((idx, x) in arr5.withIndex()) { print("arr5[${idx}] = ${x} ") }</span><br><span class="line">    println()</span><br><span class="line">    println("arr5的大小为 = ${arr5.size}")</span><br><span class="line"></span><br><span class="line">    // contains判断数组中是否包含元素，返回Boolean类型true或者false</span><br><span class="line">    val arr6 = arr1.contains(50)</span><br><span class="line">    println("arr1是否包含50 = ${arr6}")</span><br><span class="line">    val arr7 = arr1.contains(60)</span><br><span class="line">    println("arr1是否包含60 = ${arr7}")</span><br><span class="line"></span><br><span class="line">    // all判断数组中的元素是否都满足某一条件，any判断数组中的元素是否存在满足某一条件，其中条件是一个谓词，常用lambda表达式</span><br><span class="line">    val arr8 = arr1.all { it &gt; 1 }</span><br><span class="line">    println("arr1是否全都大于1 = ${arr8}")</span><br><span class="line">    val arr9 = arr1.any { it &gt; 1 }</span><br><span class="line">    println("arr1是否存在大于1 = ${arr9}")</span><br><span class="line"></span><br><span class="line">    // 判断数组中满足条件的元素个数，其中条件是一个谓词，常用lambda表达式</span><br><span class="line">    val arr10 = arr1.count { it &gt; 2 }</span><br><span class="line">    println("arr1中大于1的数有 = ${arr10}个")</span><br><span class="line"></span><br><span class="line">    // drop在原数组中删除前面n个元素组成新List集合，原数组不发生变化</span><br><span class="line">    val arr11 = arr1.drop(2)</span><br><span class="line">    println("arr1删去前两个元素为 = ${arr11}")</span><br><span class="line"></span><br><span class="line">    // dropWhile在原数组中删除前面符合条件的所有元素组成新List集合，原数组不发生变化，其中条件是一个谓词，常用lambda表达式</span><br><span class="line">    val arr12 = arr1.dropWhile { it &gt; 15 }</span><br><span class="line">    println("arr1从前面删除所有大于15的元素 = ${arr12}")</span><br><span class="line"></span><br><span class="line">    // dropLast在原数组中删除后面n个元素组成新List集合，原数组不发生变化</span><br><span class="line">    val arr13 = arr1.dropLast(2)</span><br><span class="line">    println("arr1删除后两个元素为 = ${arr13}")</span><br><span class="line"></span><br><span class="line">    // dropLastWhile在原数组中删除后面符合条件的所有元素组成新List集合，原数组不发生变化，其中条件是一个谓词，常用lambda表达式</span><br><span class="line">    val arr14 = arr1.dropLastWhile { it &gt; 15 }</span><br><span class="line">    println("arr1从后面删除所有大于15的元素 = ${arr14}")</span><br><span class="line"></span><br><span class="line">    // reversed将原数组逆序排列组成新List集合，原数组不发生变化。如果想直接修改原始数组，使用reverse方法</span><br><span class="line">    val arr15 = arr1.reversed()</span><br><span class="line">    println("arr1逆序排列为 = ${arr15}")</span><br><span class="line"></span><br><span class="line">    // sorted将原数组从小到大排序组成新List集合，原数组不发生变化。如果想直接修改原始数组，使用sort方法</span><br><span class="line">    val arr16 = arr1.sorted()</span><br><span class="line">    println("arr1从小到大排列为 = ${arr16}")</span><br><span class="line"></span><br><span class="line">    // sortedDescending将原数组从大到小排序组成新List集合，原数组不发生变化。如果想直接修改原始数组，使用sortDescending方法</span><br><span class="line">    val arr17 = arr1.sortedDescending()</span><br><span class="line">    println("arr1从大到小排列为 = ${arr17}")</span><br><span class="line"></span><br><span class="line">    // sortedBy将原数组根据条件从小到大排序组成新List集合，原数组不发生变化，其中条件是一个谓词，常用lambda表达式。如果想直接修改原始数组，使用sortBy方法</span><br><span class="line">    val arr18 = arr1.sortedBy { Math.abs(it - 36) }</span><br><span class="line">    println("arr1中的按照元素减36并取绝对值从小到大排列为 = ${arr18}")</span><br><span class="line"></span><br><span class="line">    // sortedByDescending将原数组根据条件从大到小排序组成新List集合，原数组不发生变化，其中条件是一个谓词，常用lambda表达式。如果想直接修改原始数组，使用sortByDescending方法</span><br><span class="line">    val arr19 = arr1.sortedByDescending() { Math.abs(it - 36) }</span><br><span class="line">    println("arr1中的按照元素减36并取绝对值从大到小排列为 = ${arr19}")</span><br><span class="line"></span><br><span class="line">    // filter删除数组中所有满足条件的元素，其中条件是一个谓词，常用lambda表达式</span><br><span class="line">    val arr20 = arr1.filter { it &gt; 25 }</span><br><span class="line">    println("arr1删除大于25的所有元素为 = ${arr20}")</span><br><span class="line"></span><br><span class="line">    // forEach将数组中的元素取出，进行某些操作。forEachIndexed将数组中的索引和对应的元素都取出，进行某些操作，其中操作，常用lambda表达式</span><br><span class="line">    arr1.forEachIndexed { index, i -&gt; print("arr1[${index}] = ${i} ") }</span><br><span class="line">    println()</span><br><span class="line"></span><br><span class="line">    // first返回数组的第一个元素</span><br><span class="line">    val arr21 = arr1.first()</span><br><span class="line">    println("arr1的第一个元素为 = ${arr21}")</span><br><span class="line"></span><br><span class="line">    // first带有谓词作为参数，返回数组第一个符合条件的元素，其中谓词常用lambda表达式</span><br><span class="line">    val arr22 = arr1.first() {it &gt; 30}</span><br><span class="line">    println("arr1中大于30的第一个元素为 = ${arr22}")</span><br><span class="line"></span><br><span class="line">    // indexOfFirst返回数组第一个符合条件的元素的索引，其中谓词常用lambda表达式</span><br><span class="line">    val arr23 = arr1.indexOfFirst { it &gt; 30 }</span><br><span class="line">    println("arr1中大于30的第一个元素的索引为 = ${arr23}")</span><br><span class="line"></span><br><span class="line">    // last返回数组的最后一个元素</span><br><span class="line">    val arr24 = arr1.last()</span><br><span class="line">    println("arr1的最后一个元素为 = ${arr24}")</span><br><span class="line"></span><br><span class="line">    // last带有谓词作为参数，返回数组最后一个符合条件的元素，其中谓词常用lambda表达式</span><br><span class="line">    val arr25 = arr1.last() {it &gt; 30}</span><br><span class="line">    println("arr1中大于30的最后一个元素为 = ${arr25}")</span><br><span class="line"></span><br><span class="line">    // indexOfLast返回数组最后一个符合条件的元素的索引，其中谓词常用lambda表达式</span><br><span class="line">    val arr26 = arr1.indexOfLast() { it &gt; 30 }</span><br><span class="line">    println("arr1中大于30的最后一个元素的索引为 = ${arr26}")</span><br><span class="line"></span><br><span class="line">    // indexOf返回数组中某元素的索引</span><br><span class="line">    val arr27 = arr1.indexOf(10)</span><br><span class="line">    println("arr1中1的索引为 = ${arr27}")</span><br><span class="line"></span><br><span class="line">    // isEmpty判断数组是否为空，即大小是否为0</span><br><span class="line">    val arr28 = arr1.isEmpty()</span><br><span class="line">    println("arr1是否为空 = ${arr28}")</span><br><span class="line"></span><br><span class="line">    // isNotEmpty判断数组是否不为空，即大小是否不为0</span><br><span class="line">    val arr29 = arr1.isNotEmpty()</span><br><span class="line">    println("arr1是否不为空 = ${arr29}")</span><br><span class="line"></span><br><span class="line">    // getOrElse获取指定位置的元素，如果不存在则返回映射对应的元素，其中映射常用lambda表达式</span><br><span class="line">    val arr30 = arr1.getOrElse(10) { it * 2 }</span><br><span class="line">    println("arr1[10]的值为 = ${arr30}")</span><br><span class="line"></span><br><span class="line">    // getOrNull获取指定位置的元素，如果不存在则返回Null</span><br><span class="line">    val arr31 = arr1.getOrNull(10)</span><br><span class="line">    println("arr1[10]的值为 = ${arr31}")</span><br><span class="line"></span><br><span class="line">    // joinToString将元素根据映射转换为字符串，并进行组合，其中第一个参数为两个元素之间的连接符，第二个参数为第一个元素之前的字符串，第三个参数为最后一个元素之后的字符串，第四个参数为显示的元素个数</span><br><span class="line">    val arr32 = arr1.joinToString("-&gt;", "begin-&gt;", "-&gt;end", 4) { "${it}" }</span><br><span class="line">    println(arr32)</span><br><span class="line"></span><br><span class="line">    // max返回数组最大的元素</span><br><span class="line">    val arr33 = arr1.max()</span><br><span class="line">    println("arr1的最大值为 = ${arr33}")</span><br><span class="line"></span><br><span class="line">    // maxBy根据条件返回数组最大的元素，其中条件常用lambda表达式</span><br><span class="line">    val arr34 = arr1.maxBy { Math.abs(it - 36) }</span><br><span class="line">    println("arr1元素减36并取绝对值的最大值为 = ${arr34}")</span><br><span class="line"></span><br><span class="line">    // min返回数组最小的元素</span><br><span class="line">    val arr35 = arr1.min()</span><br><span class="line">    println("arr1的最小值为 = ${arr35}")</span><br><span class="line"></span><br><span class="line">    // minBy根据条件返回数组最小的元素，其中条件常用lambda表达式</span><br><span class="line">    val arr36 = arr1.minBy { Math.abs(it - 36) }</span><br><span class="line">    println("arr1元素减36并取绝对值的最大值为 = ${arr36}")</span><br><span class="line"></span><br><span class="line">    // random随机返回数组中的任意一个元素</span><br><span class="line">    val arr37 = arr1.random()</span><br><span class="line">    println("arr1随机取出一个元素为 = ${arr37}")</span><br><span class="line"></span><br><span class="line">    // random根据种子点随机返回数组中的任意一个元素</span><br><span class="line">    val arr38 = arr1.random(Random(20))</span><br><span class="line">    println("arr1随机取出种子点为20的元素为 = ${arr38}")</span><br><span class="line"></span><br><span class="line">    // reduce将元素进行迭代计算后返回计算的结果，在本例中，数组为[30, 10, 50, 40, 20]，先将30赋值给x，10赋值给y，进行2x + y操作得到70，然后将70赋值给x，50赋值给y，得到190，同理得到420，最后得到860</span><br><span class="line">    val arr39 = arr1.reduce() { x, y -&gt; 2 * x + y }</span><br><span class="line">    println("arr1迭代求解2 * x + y的值为 = ${arr39}")</span><br><span class="line"></span><br><span class="line">    // sum返回数组所有元素之和</span><br><span class="line">    val arr40 = arr1.sum()</span><br><span class="line">    println("arr1元素之和为 = ${arr40}")</span><br><span class="line"></span><br><span class="line">    // sumBy返回数组所有元素映射结果之和，其中映射常用lambda表达式</span><br><span class="line">    val arr41 = arr1.sumBy { it * it }</span><br><span class="line">    println("arr1元素平方之和为 = ${arr41}")</span><br><span class="line"></span><br><span class="line">    // zip将两个数组进行结合形成新List集合，结合后集合每个元素是一个Pair二元组，二元组对象具有.first和.second两个属性，可以获取对应的值</span><br><span class="line">    val arr42 = arr1.zip(arr1.reversed())</span><br><span class="line">    print("将arr1和其逆序组合后, ")</span><br><span class="line">    arr42.forEachIndexed { index, i -&gt; print("arr42[${index}] = &lt;${i.first} ${i.second}&gt; ") }</span><br><span class="line">    println()</span><br><span class="line"></span><br><span class="line">    // map将数组中的每个元素按照映射形成新List集合，其中映射常用lambda表达式</span><br><span class="line">    val arr43 = arr1.map { it * 2 }</span><br><span class="line">    println("arr1所有元素乘2为 = ${arr43}")</span><br><span class="line"></span><br><span class="line">    // union将两个数组求并集形成Set集合</span><br><span class="line">    val arr44 = arr1.union(arr43)</span><br><span class="line">    println("arr1和arr1乘2的并集为 = ${arr44}")</span><br><span class="line"></span><br><span class="line">    // intersect将两个数组求交集形成Set集合、此外还有subtract求差集</span><br><span class="line">    val arr45 = arr1.intersect(arr43)</span><br><span class="line">    println("arr1和arr1乘2的交集为 = ${arr45}")</span><br><span class="line"></span><br><span class="line">    // toList根据数组创建List集合</span><br><span class="line">    val arr47 = arr1.toList()</span><br><span class="line">    println("${arr47.javaClass}类型的arr47 = ${arr47}")</span><br><span class="line"></span><br><span class="line">    // toMutableList根据数组创建可变List集合</span><br><span class="line">    val arr48 = arr1.toMutableList()</span><br><span class="line">    println("${arr48.javaClass}类型的arr48 = ${arr48}")</span><br><span class="line"></span><br><span class="line">    // toSet根据数组创建Set集合</span><br><span class="line">    val arr49 = arr1.toSet()</span><br><span class="line">    println("${arr49.javaClass}类型的arr49 = ${arr49}")</span><br><span class="line"></span><br><span class="line">    // toMutableSet根据数组创建可变Set集合</span><br><span class="line">    val arr50 = arr1.toMutableSet()</span><br><span class="line">    println("${arr50.javaClass}类型的arr50 = ${arr50}")</span><br><span class="line"></span><br><span class="line">    // toHashSet根据数组创建HashSet集合</span><br><span class="line">    val arr51 = arr1.toHashSet()</span><br><span class="line">    println("${arr51.javaClass}类型的arr51 = ${arr51}")</span><br><span class="line"></span><br><span class="line">    // toSortedSet根据数组创建toSortedSet集合</span><br><span class="line">    val arr52 = arr1.toSortedSet()</span><br><span class="line">    println("${arr52.javaClass}类型的arr52 = ${arr52}")</span><br><span class="line"></span><br><span class="line">    // fill将数组用指定元素进行填充，其中第一个参数为指定的元素，第二个参数和第三个参数为起始和终止的位置，默认填充所有元素</span><br><span class="line">    arr1.fill(0)</span><br><span class="line">    print("将arr1全部填充为0后, ")</span><br><span class="line">    for ((idx, x) in arr1.withIndex()) { print("arr1[${idx}] = ${x} ") }</span><br><span class="line">    println()</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin17.png" alt="4"></p>
<h1 id="Kotlin小结"><a href="#Kotlin小结" class="headerlink" title="Kotlin小结"></a><font size="5" color="red">Kotlin小结</font></h1><p>  数组是我们存放数据的好方法，就如同抽屉一样，每一个抽屉都放置同样的物品，数组的学习非常重要，无论以后从事什么样的研究，数组的使用都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Kotlin</category>
      </categories>
  </entry>
  <entry>
    <title>串联字符串的最大长度(Leetcode 1239)</title>
    <url>/2021/06/19/program%20Leetcode1239/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1239.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目的数据量是经典的BFS和DFS问题，这类问题难点较小，是笔试面试中常考的题型，也是小伙伴们必须要掌握的。为什么要介绍这个题目呢？是因为这个题目还使用到状态压缩和位运算的知识。<br><a id="more"></a></p>
<h1 id="深度优先搜索"><a href="#深度优先搜索" class="headerlink" title="深度优先搜索"></a><font size="5" color="red">深度优先搜索</font></h1><p>本题要注意两个小技巧</p>
<ol>
<li>可能有一些字符串本身不满足条件，如”aa”，因此可以在arr中将其排除。</li>
<li>如果每一次搜索都需要判断26个字符是否重复出现，时间会变为原来的26倍，可以使用位运算，其中第n位为0说明没有出现过a+n字符，第n位为1说明出现过。如3，二进制为11，说明此时字符串为”ab”</li>
</ol>
<p>关于深搜的思想已经介绍过很多次，这里不做过多介绍，思路非常简单，其中cur_val为当前的二进制数字，cur_bit为当前字符串个数，cur_loc为当前遍历到哪一个元素，遍历过的元素不需要重复遍历</p>
<p>算法的<strong>时间复杂度为$O(2^n)$，空间复杂度为$O(n)$</strong></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxLength(self, arr):</span><br><span class="line">        def dfs(cur_val, cur_bit, cur_loc):</span><br><span class="line">            nonlocal res</span><br><span class="line">            res = max(res, cur_bit)</span><br><span class="line">            for i in range(cur_loc, length):</span><br><span class="line">                if not(cur_val &amp; dic[arr[i]]):</span><br><span class="line">                    dfs(cur_val | dic[arr[i]], cur_bit + len(arr[i]), i + 1)</span><br><span class="line"></span><br><span class="line">        arr = list(filter(lambda x: len(set(x)) == len(x), arr))</span><br><span class="line">        length = len(arr)</span><br><span class="line">        res = 0</span><br><span class="line">        dic = {x: sum([2 ** (ord(i) - ord('a')) for i in x]) for x in arr}</span><br><span class="line">        dfs(0, 0, 0)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun maxLength(arr: List&lt;String&gt;): Int {</span><br><span class="line">        val newArr = arr.filter { it.toSet().size == it.length }</span><br><span class="line">        val dic = newArr.associate { it to it.sumBy { 1 shl (it - 'a') } }</span><br><span class="line">        var res = 0</span><br><span class="line">        val length = newArr.size</span><br><span class="line">        fun dfs(curVal:Int, curBit:Int, curLoc:Int) {</span><br><span class="line">            res = Math.max(res, curBit)</span><br><span class="line">            for (i in curLoc until length) {</span><br><span class="line">                val bit = dic[newArr[i]]!!</span><br><span class="line">                if (curVal and bit == 0) {</span><br><span class="line">                    dfs(curVal or bit, curBit + newArr[i].length, i + 1)</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        dfs(0,0,0)</span><br><span class="line">        return res</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a><font size="5" color="red">广度优先搜索</font></h1><p>广搜和深搜的本质是一样的，但是需要使用额外的空间复杂度记录当前所有状态</p>
<p>算法的<strong>时间复杂度为$O(2^n)$，空间复杂度为$O(2^n)$</strong></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxLength(self, arr):</span><br><span class="line">        arr = list(filter(lambda x: len(set(x)) == len(x), arr))</span><br><span class="line">        queue = deque([[0, 0, 0]])</span><br><span class="line">        length = len(arr)</span><br><span class="line">        res = 0</span><br><span class="line">        dic = {x: sum([2 ** (ord(i) - ord('a')) for i in x]) for x in arr}</span><br><span class="line">        while queue:</span><br><span class="line">            cur_val, cur_bit, cur_loc = queue.popleft()</span><br><span class="line">            res = max(res, cur_bit)</span><br><span class="line">            for i in range(cur_loc, length):</span><br><span class="line">                if not(cur_val &amp; dic[arr[i]]):</span><br><span class="line">                    queue.append([cur_val | dic[arr[i]], cur_bit + len(arr[i]), i + 1])</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun maxLength(arr: List&lt;String&gt;): Int {</span><br><span class="line">        val newArr = arr.filter { it.toSet().size == it.length }</span><br><span class="line">        val dic = newArr.associate { it to it.sumBy { 1 shl (it - 'a') } }</span><br><span class="line">        var res = 0</span><br><span class="line">        val length = newArr.size</span><br><span class="line">        val queue = ArrayDeque&lt;IntArray&gt;()</span><br><span class="line">        queue.add(intArrayOf(0, 0, 0))</span><br><span class="line">        while (queue.isNotEmpty()) {</span><br><span class="line">            val cur = queue.removeFirst()</span><br><span class="line">            res = Math.max(res, cur[1])</span><br><span class="line">            for (i in cur[2]..length - 1) {</span><br><span class="line">                val bit = dic[newArr[i]]!!</span><br><span class="line">                if (cur[0] and bit == 0) {</span><br><span class="line">                    queue.add(intArrayOf(cur[0] or bit, cur[1] + newArr[i].length, i + 1))</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比Python和Kotlin两种语言，都可以在函数中嵌套定义函数，而且在Python中可以使用filter将元素进行过滤，还可以使用内置的表达式将列表元素按照要求转换为字典。在Kotlin中使用数组的成员方法filter将元素进行过滤，使用associate方法将数组转换为字典，非常方便，极大减少代码量。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这类题目是必须掌握的，小伙伴们可以进行总结分类，多做一些BFS和DFS的题目，就会发现这类题目都有一个固定的模板，BFS是创建queue，DFS是进行回溯。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>最小好进制(Leetcode 483)</title>
    <url>/2021/06/18/program%20Leetcode483/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode483.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   很久没有看到这种数学题了，数学题是一些大厂的偏爱，如腾讯和阿里，如果有小伙伴想去大厂，可以多多练习。本题的数据量非常大，最大为1e18，因此线性复杂度以上的解法都会TLE，因此只能寻找$O(1)$或者$O(log(n))$时间复杂度的方法。<br><a id="more"></a></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>我们先分析一下可能出现的位数，k进制中最小的k为2，而且进制越小位数越多。所以可以推出，位数最多有$log_{2}(n)$个。不妨设有m位</p>
<script type="math/tex; mode=display">\therefore n = k^0 + k^1 + k^2 + ... + k^{m - 1}</script><script type="math/tex; mode=display">\because (k + 1)^{m - 1} = C_{m - 1}^{0}k^0 + C_{m - 1}^{1}k^1 + C_{m - 1}^{2}k^2 + ... + C_{m - 1}^{m - 1}k^{m - 1}</script><script type="math/tex; mode=display">\because C_{m - 1}_{i} \ge 1</script><script type="math/tex; mode=display">\therefore k^{m - 1} \le n \le (k + 1)^{m - 1}</script><script type="math/tex; mode=display">\therefore k \le \sqrt[m - 1]{n} \le k + 1</script><p>因为$\sqrt[m - 1]{n}$是一个小数，所以k为其整数部分。<br>此时我们只要遍历位数m从$log_{2}(n)$到3，对于每个位数m确定k进制，并判断$k^0 + k^1 + k^2 + … + k^{m - 1}$是否等于n。如果等于则立即停止，此时位数是最多的，所以是好进制。如果都没有找到，位数为2，k = n - 1。直接返回n - 1即可</p>
<p>算法的<strong>时间复杂度为$O(log^{2}(n))$，空间复杂度为$O(1)$</strong></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import math</span><br><span class="line">import functools</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def smallestGoodBase(self, n):</span><br><span class="line">        """</span><br><span class="line">        :type n: str</span><br><span class="line">        :rtype: str</span><br><span class="line">        """</span><br><span class="line">        n = int(n)</span><br><span class="line">        bit = int(math.log2(n)) + 1</span><br><span class="line">        for m in range(bit, 2, -1):</span><br><span class="line">            k = int(n ** (1 / (m - 1)))</span><br><span class="line">            if n == functools.reduce(lambda x, _: x * k + 1, [1] * m):</span><br><span class="line">                return str(k)</span><br><span class="line">        return str(n - 1)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import kotlin.math.log2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">    fun smallestGoodBase(n: String): String {</span><br><span class="line">        val nn = n.toLong()</span><br><span class="line">        val bit = log2(nn.toDouble()).toInt() + 1</span><br><span class="line">        for (m in bit downTo 3) {</span><br><span class="line">            val k = (Math.pow(nn.toDouble(), 1 / (m - 1).toDouble())).toInt()</span><br><span class="line">            if (nn == LongArray(m) {1}.reduce() {x, _ -&gt; x * k + 1}) { return k.toString() }</span><br><span class="line">        }</span><br><span class="line">        return (nn - 1).toString()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比Python和Kotlin两种语言，Python语言更加简洁，不需要将数据类型toLong, toDouble互相转换。在Python中reduce在functools包中，而在Kotlin中，reduce是数组的一个成员方法，在使用时通常都使用lambda表达式。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题类似于高中数列的证明题，难度不算大，题解也能很容易的理解，使用简单的放缩法即可，但是能否想到放缩是本题的难点。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>有效数字(Leetcode 65)</title>
    <url>/2021/06/17/program%20Leetcode65/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode65.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   在博客中介绍过类似的题目leetcode剑指Offer第20题，但我认为那个题目稍微复杂一点点，只要思路明白了，做法都是相同的。只不过那个题目可能会出现空格，这个题目没用空格。<br><a id="more"></a></p>
<h1 id="有限状态自动机"><a href="#有限状态自动机" class="headerlink" title="有限状态自动机"></a><font size="5" color="red">有限状态自动机</font></h1><p>观察发现有效数字中字符出现的顺序是有规律可循的，我们将其称为状态，如起始状态我们设置为0<br>起始状态0后面可以跟正负号、数字和小数点，分别记正负号为状态1，数字为状态2，小数点为状态4<br>正负号状态1后面可以跟数字和小数点，数字为状态2，小数点为状态4<br>数字状态2后面可以跟数字、小数点、指数e和结束状态，数字已经标记过为状态2，注意此时的数字为状态2表示正负号之后小数点之前的数字，如+5.3中的5，记小数点为状态3，并不是之前定义过的状态4，这非常重要，因为两个小数点并不是同一个状态，因为起始状态后面直接跟随的小数点状态为.5中的小数点，此时小数点后面必须跟随数字，而这里定义的小数点状态是指数字后面的小数点，可以不跟随数字，如5.。所以虽然都是小数点，但是所在的状态不同。记指数e为状态6<br>小数点状态3后面可以跟数字、指数e和结束状态，此时的数字也不是状态2表示的数字，因为状态2表示的数字后可以跟小数点，而这里指的数字是小数点后面的数字，已经不能跟随小数点了，记为状态5，指数e已经标记过为状态6<br>小数点状态4后面只能跟数字状态5<br>数字状态5后面可以跟数字状态5、指数e状态6和结束状态<br>指数e状态6后面可以跟正负号和数字、此时正负号和状态1不相同，数字和状态2和状态5都不相同，记正负号为状态7，数字为状态8<br>正负号状态7后面只能跟数字状态8<br>数字状态8后面可以跟数字状态8和结束状态</p>
<p>经过上面的分析后，可以画出如下的状态转移图<br><img src="/images/ALGORITHM/leetcode65_solve.png" alt="1"></p>
<p>我们使用一个字典记录当前状态的所有后继状态，从初始状态0出发，经过一个字符，状态产生一次转移，如果下一个字符是当前状态的后继状态其中之一，那么继续判断，否则直接返回false。如果所有字符都满足条件，那么在循环出口判断当前状态后面是否可以跟随结束状态即可。即最后一个字符一定是结束状态的前驱状态。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong></p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool isNumber(string s) {</span><br><span class="line">        vector&lt;unordered_map&lt;string, int&gt;&gt; dic = {</span><br><span class="line">            {{"sign", 1}, {"digit", 2}, {"dot", 4}},</span><br><span class="line">            {{"digit", 2}, {"dot", 4}},</span><br><span class="line">            {{"digit", 2}, {"dot", 3}, {"e", 6}},</span><br><span class="line">            {{"digit", 5}, {"e", 6}},</span><br><span class="line">            {{"digit", 5}},</span><br><span class="line">            {{"digit", 5}, {"e", 6}},</span><br><span class="line">            {{"sign", 7}, {"digit", 8}},</span><br><span class="line">            {{"digit", 8}},</span><br><span class="line">            {{"digit", 8}}</span><br><span class="line">        };</span><br><span class="line">        int cur = 0;</span><br><span class="line">        for (char c : s) {</span><br><span class="line">            string p;</span><br><span class="line">            if (c == '+' || c == '-') { p = "sign"; }</span><br><span class="line">            else if (c == '.') { p = "dot"; }</span><br><span class="line">            else if (c == 'e' || c == 'E') { p = "e"; }</span><br><span class="line">            else if (c &gt;= '0' &amp;&amp; c &lt;= '9') { p = "digit"; }</span><br><span class="line">            else { return false; }</span><br><span class="line">            if (dic[cur].count(p)) { cur = dic[cur][p]; }</span><br><span class="line">            else { return false; }</span><br><span class="line">        }</span><br><span class="line">        return cur == 2 || cur == 3 || cur == 5 || cur == 8;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public boolean isNumber(String s) {</span><br><span class="line">        ArrayList&lt;HashMap&lt;String, Integer&gt;&gt; dic = new ArrayList&lt;&gt;(9);</span><br><span class="line">        for (int i = 0; i &lt; 9; i++) { dic.add(new HashMap&lt;&gt;()); }</span><br><span class="line">        dic.get(0).put("sign", 1);</span><br><span class="line">        dic.get(0).put("digit", 2);</span><br><span class="line">        dic.get(0).put("dot", 4);</span><br><span class="line">        dic.get(1).put("digit", 2);</span><br><span class="line">        dic.get(1).put("dot", 4);</span><br><span class="line">        dic.get(2).put("digit", 2);</span><br><span class="line">        dic.get(2).put("dot", 3);</span><br><span class="line">        dic.get(2).put("e", 6);</span><br><span class="line">        dic.get(3).put("digit", 5);</span><br><span class="line">        dic.get(3).put("e", 6);</span><br><span class="line">        dic.get(4).put("digit", 5);</span><br><span class="line">        dic.get(5).put("digit", 5);</span><br><span class="line">        dic.get(5).put("e", 6);</span><br><span class="line">        dic.get(6).put("sign", 7);</span><br><span class="line">        dic.get(6).put("digit", 8);</span><br><span class="line">        dic.get(7).put("digit", 8);</span><br><span class="line">        dic.get(8).put("digit", 8);</span><br><span class="line">        int cur = 0;</span><br><span class="line">        for (int i = 0; i &lt; s.length(); i++) {</span><br><span class="line">            String p;</span><br><span class="line">            if (s.charAt(i) == '+' || s.charAt(i) == '-') { p = "sign"; }</span><br><span class="line">            else if (s.charAt(i) == '.') { p = "dot"; }</span><br><span class="line">            else if (s.charAt(i) == 'e' || s.charAt(i) == 'E') { p = "e"; }</span><br><span class="line">            else if (s.charAt(i) &gt;= '0' &amp;&amp; s.charAt(i) &lt;= '9') { p = "digit"; }</span><br><span class="line">            else { return false; }</span><br><span class="line">            if (dic.get(cur).containsKey(p)) { cur = dic.get(cur).get(p); }</span><br><span class="line">            else { return false; }</span><br><span class="line">        }</span><br><span class="line">        return cur == 2 || cur == 3 || cur == 5 || cur == 8;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比C++和Java两种语言，在C++中，字典创建比较简单，可以通过中括号[]来进行访问，花括号{}键值对的方式初始化，而Java要通过get方法进行访问，put方法进行初始化。而且在字符串的遍历过程中，C++可以直接使用for循环取出字符，Java必须转成CharArray类型，或者根据索引使用charAt访问，也不能使用中括号[]访问字符串中的字符。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题的重点是有限状态自动机，当然小伙伴们也可以使用if…else if…else进行分类讨论，不过讨论的过程非常繁琐，也不是本题考查的重点，因此不做讨论。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>有限状态自动机</category>
      </categories>
  </entry>
  <entry>
    <title>石子游戏(Leetcode 877)</title>
    <url>/2021/06/16/program%20Leetcode877/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode877.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   本题是一个博弈的题目，之前也给小伙伴们介绍过许多有关博弈的题型，博弈的题目有两类经典的解法，一个是动态规划，一个是数学方法，其中动态规划的思想类似于记忆化深度优先搜索。小伙伴能否根据这个提示写出正确的代码呢？<br><a id="more"></a></p>
<h1 id="记忆化"><a href="#记忆化" class="headerlink" title="记忆化"></a><font size="5" color="red">记忆化</font></h1><p>第一眼我就想到了使用DFS进行求解，每次拿出一个数进行模拟，递归出口是只存在一个元素。但是要注意的是普通的DFS会产生TLE错误，因为本题可以从最前端或者最后端取出元素，所以每个元素有两种取法。本题的数组长度可以达到500，会超出时间限制。其中包括了很多的重复计算。如先取最右边，再取最左边和先取最左边再取最右边的结果是完全相同的。此时可以利用记忆化的思想，只需要遍历最左端和最右端两个端点即可。</p>
<p><strong>令子问题表示为亚历克斯从left到right可以获得的石子数量之和f(left, right)，假如亚历克斯拿了最左边的石子，那么李会从left + 1到right获得石子总数为f(left + 1, right)。亚历克斯获得石子的个数为sum(left, right) - f(left + 1, right)。同理，当亚历克斯拿了最右边啊的石子，那么亚历克斯获得的石子的个数为sum(left, right) - f(left, right - 1)。因此亚历克斯获得的石子数量之和最大值为sum(left, right) - max(f(left + 1, right), f(left, right - 1))</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n^2)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public boolean stoneGame(int[] piles) {</span><br><span class="line">        int[][] dic = new int[piles.length][piles.length];</span><br><span class="line">        int sums = 0;</span><br><span class="line">        for (int x : piles) { sums += x; }</span><br><span class="line">        return 2 * find(0, piles.length - 1, sums, dic, piles) &gt; sums;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    private int find(int left, int right, int sums, int[][] dic, int[] piles) {</span><br><span class="line">        if (left == right) { return piles[left]; }</span><br><span class="line">        if (dic[left][right] == 0) {</span><br><span class="line">            dic[left][right] = sums - Math.min(find(left + 1, right, sums - piles[left], dic, piles), find(left, right - 1, sums - piles[right], dic, piles));</span><br><span class="line">        }</span><br><span class="line">        return dic[left][right];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun stoneGame(piles: IntArray): Boolean {</span><br><span class="line">        val dic = mutableMapOf&lt;Pair&lt;Int, Int&gt;, Int&gt;()</span><br><span class="line">        val sums = piles.sum()</span><br><span class="line">        return 2 * find(0, piles.size - 1, dic, sums, piles) &gt; sums</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    private fun find(left:Int, right:Int, dic:MutableMap&lt;Pair&lt;Int, Int&gt;, Int&gt;, sums:Int, piles:IntArray):Int {</span><br><span class="line">        if (left == right) { return piles[left] }</span><br><span class="line">        val pair = Pair&lt;Int, Int&gt;(left, right)</span><br><span class="line">        if (!dic.contains(pair)) {</span><br><span class="line">            dic[pair] = sums - Math.min(find(left + 1, right, dic, sums - piles[left], piles), find(left, right - 1, dic, sums - piles[right], piles))</span><br><span class="line">        }</span><br><span class="line">        return dic[pair]!!</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  在前面也说过，动态规划类似于记忆化，本题也可以使用动态规划进行求解，只不过dp[i][j]要使用到dp[i][j - 1]和dp[i + 1][j]的状态，不能使用常规的遍历方法。本题还有一种更精妙的解法，可以直接return true，先手选择一定胜利，因为不是通用的解法，这里不做过多介绍，感兴趣的小伙伴们可以去看官方题解或其他博主的题解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>博弈</category>
        <category>记忆化</category>
      </categories>
  </entry>
  <entry>
    <title>Kotlin流程控制</title>
    <url>/2021/06/16/Kotlin_control/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python4.jpg" alt="2"></p>
<h1 id="Kotlin流程控制"><a href="#Kotlin流程控制" class="headerlink" title="Kotlin流程控制"></a><font size="5" color="red">Kotlin流程控制</font></h1><p>  在前面已经介绍了Kotlin的运算符，这里主要介绍Kotlin的流程控制，包括if条件语句，when条件语句，while循环，do…while循环，for循环，以及continue和break跳转语句，尤其要注意when语句和switch语句的区别。<br><a id="more"></a></p>
<h1 id="Kotlin条件语句"><a href="#Kotlin条件语句" class="headerlink" title="Kotlin条件语句"></a><font size="5" color="red">Kotlin条件语句</font></h1><h2 id="if条件语句"><a href="#if条件语句" class="headerlink" title="if条件语句"></a><font size="4">if条件语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 和Java语言具有相同的结构。if (布尔表达式) { 表达式为真时要执行的代码 }</span><br><span class="line">// 区间表达，a..b step c代表区间[a, b]，并且步长为c，其中c默认为1，等价于Python中的range(a, b + 1, c)，但是要注意c必须为正数。如果要表达开区间[a, b)，则使用a until b。如果要表达从大到小，则使用b downTo a表示[b, a]，此时和Python不同的是，从大到小的步长也必须是正数，在Python中为负数。</span><br><span class="line">fun main() {</span><br><span class="line">    val stu = 85</span><br><span class="line">    if (stu &lt; 60) {</span><br><span class="line">        println("fail")</span><br><span class="line">    } else if (stu in 60..79) {</span><br><span class="line">        println("so so")</span><br><span class="line">    } else if (stu in 80..89) {</span><br><span class="line">        println("good")</span><br><span class="line">    } else {</span><br><span class="line">        println("excellent")</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin9.png" alt="1"></p>
<h2 id="when语句"><a href="#when语句" class="headerlink" title="when语句"></a><font size="4">when语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// when语句是Kotlin的特点，类似于其他语言的switch...case...，区别是没有穿透效应，使用箭头指向将执行的代码，最重要的是可以使用范围进行调节判断，非常灵活。</span><br><span class="line">fun main() {</span><br><span class="line">    val stu = 6</span><br><span class="line">    when (stu) {</span><br><span class="line">        in 0..4, 5 -&gt; println("fail")</span><br><span class="line">        6, 7 -&gt; println("so so")</span><br><span class="line">        8 -&gt; println("good")</span><br><span class="line">        9, 10 -&gt; println("excellent")</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin10.png" alt="2"></p>
<h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a><font size="4">while循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// while 语句和C++、Java中完全相同，先进行判断然后再执行循环体内的代码</span><br><span class="line">fun main() {</span><br><span class="line">    var sum = 0;</span><br><span class="line">    var i = 0;</span><br><span class="line">    while (i &lt;= 100) {</span><br><span class="line">        sum += i++;</span><br><span class="line">    }</span><br><span class="line">    println("0 + 1 + .. + 100 = $sum")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin11.png" alt="4"></p>
<h2 id="do…while循环"><a href="#do…while循环" class="headerlink" title="do…while循环"></a><font size="4">do…while循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// do...while 语句和C++、Java中几乎相同，先执行循环体内的代码然后再进行判断，唯一的区别是while后面省略分号</span><br><span class="line">fun main() {</span><br><span class="line">    var sum = 0;</span><br><span class="line">    var i = 0;</span><br><span class="line">    do {</span><br><span class="line">        sum += i++;</span><br><span class="line">    } while (i &lt;= 100)</span><br><span class="line">    println("0 + 1 + .. + 100 = $sum")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin11.png" alt="5"></p>
<h2 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a><font size="4">for循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// for循环类似于Java和Python语言的结合体，不需要定义循环遍历的类型，可以使用in从可迭代对象中直接取出，这非常像Python语言。但是使用小括号和花括号，这又很像Java语言。</span><br><span class="line">fun main() {</span><br><span class="line">    var sum = 0;</span><br><span class="line">    for (j in 0..100) {</span><br><span class="line">        sum += j</span><br><span class="line">    }</span><br><span class="line">    println("0 + 1 + .. + 100 = $sum")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin11.png" alt="6"></p>
<h2 id="break关键字"><a href="#break关键字" class="headerlink" title="break关键字"></a><font size="4">break关键字</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// break关键字和其他语言一样，跳出循环，执行循环后面的语句</span><br><span class="line">fun main() {</span><br><span class="line">    var sum = 0</span><br><span class="line">    for (j in 0..100) {</span><br><span class="line">        if (j == 50) {</span><br><span class="line">            break</span><br><span class="line">        }</span><br><span class="line">        sum += j</span><br><span class="line">    }</span><br><span class="line">    println("0 + 1 + .. + 49 = $sum")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin12.png" alt="4"></p>
<h2 id="continue关键字"><a href="#continue关键字" class="headerlink" title="continue关键字"></a><font size="4">continue关键字</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// continue关键字和其他语言一样，跳出本次循环，进行下一次循环</span><br><span class="line">fun main() {</span><br><span class="line">    var sum = 0</span><br><span class="line">    for (j in 0..100) {</span><br><span class="line">        if (j == 50) {</span><br><span class="line">            continue</span><br><span class="line">        }</span><br><span class="line">        sum += j</span><br><span class="line">    }</span><br><span class="line">    println("0 + 1 + .. + 49 + 51 + .. + 100 = $sum")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin13.png" alt="5"></p>
<h1 id="Kotlin小结"><a href="#Kotlin小结" class="headerlink" title="Kotlin小结"></a><font size="5" color="red">Kotlin小结</font></h1><p>  流程控制每种语言都大同小异，因为流程控制是所有语言的基础，只有掌握不同的流程控制语句，才能达到我们想要的目的，虽然难度较小，但是非常重要，无论以后从事什么样的研究，流程控制都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Kotlin</category>
      </categories>
  </entry>
  <entry>
    <title>Kotlin运算符</title>
    <url>/2021/06/14/Kotlin_operator/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python3.jpg" alt="2"></p>
<h1 id="Kotlin运算符"><a href="#Kotlin运算符" class="headerlink" title="Kotlin运算符"></a><font size="5" color="red">Kotlin运算符</font></h1><p>  在前面已经介绍了Kotlin的发展，这里主要介绍Kotlin的运算符，包括赋值运算符，算术运算符，关系运算符，逻辑运算符，三目运算符。<br><a id="more"></a></p>
<h1 id="Kotlin创建变量"><a href="#Kotlin创建变量" class="headerlink" title="Kotlin创建变量"></a><font size="4">Kotlin创建变量</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// Kotlin中的变量创建时和Java与Python都有些类似，类似于Python不用明确指出变量的类别，编译器会进行自动推断，而且不需要在末尾写分号，但是类似于Java，也可以明确指定变量的类别，而且可以先声明，然后在使用时进行初始化。</span><br><span class="line">//在Kotlin中，所有的变量都是对象，用指针表示，创建变量必须指定指针是否可变，可变用var表示，不可变用val表示。</span><br><span class="line">//注意Int类型是默认的整型，如果要指定Byte、Short要使用变量名+:类型名的方式指定，如果要指定Long类型，可以使用类似Byte的方式，也可以在数字后面加上L表示Long，Float则要加上f或者F表示。</span><br><span class="line">//字符串模板是指，用美元符号$括起来的变量或者表达式，会先进行计算，然后将结果作为字符串显示。</span><br><span class="line"></span><br><span class="line">fun main() {</span><br><span class="line">    var b:Byte = 0</span><br><span class="line">    val s:Short</span><br><span class="line">    s = 10</span><br><span class="line">    var i = 200</span><br><span class="line">    val l:Long = 3000L</span><br><span class="line">    var f = 3.14F</span><br><span class="line">    val d = 1.234567</span><br><span class="line">    var c = 'A'</span><br><span class="line">    val st = "Hello kotlin"</span><br><span class="line">    var bo = true</span><br><span class="line"></span><br><span class="line">    println("可变Byte类型b = ${b}")</span><br><span class="line">    println("不可变Short类型s = ${s}")</span><br><span class="line">    println("可变Int类型b = ${i}")</span><br><span class="line">    println("不可变Long类型b = ${l}")</span><br><span class="line">    println("可变Float类型b = ${f}")</span><br><span class="line">    println("不可变Double类型b = ${d}")</span><br><span class="line">    println("可变Char类型b = ${c}")</span><br><span class="line">    println("不可变String类型b = ${st}")</span><br><span class="line">    println("可变Boolean类型b = ${bo}")</span><br><span class="line"></span><br><span class="line">    b = 1</span><br><span class="line">    i = 300</span><br><span class="line">    f = 3.15F</span><br><span class="line">    c = 'B'</span><br><span class="line">    bo = false</span><br><span class="line"></span><br><span class="line">    println("----------修改后----------")</span><br><span class="line"></span><br><span class="line">    println("可变Byte类型b = ${b}")</span><br><span class="line">    println("可变Int类型b = ${i}")</span><br><span class="line">    println("可变Float类型b = ${f}")</span><br><span class="line">    println("可变Char类型b = ${c}")</span><br><span class="line">    println("可变Boolean类型b = ${bo}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin2.png" alt="1"></p>
<h1 id="Kotlin算术运算"><a href="#Kotlin算术运算" class="headerlink" title="Kotlin算术运算"></a><font size="4">Kotlin算术运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// +(加)，-(减)，*(乘)，/(除)，%(求余)，整数除法结果只能得到整数，注意字符型可以参与运算，字符型的值为ASCII码对应的值，但是布尔型不可以参与算术运算。</span><br><span class="line">fun main() {</span><br><span class="line">// 不能声明某一类型的变量指向其他类型，如val d2:Int = a2是错误的，可以不声明类型指向某一类型，则该变量为指向的类型</span><br><span class="line">// 在计算过程中，可以根据类型范围自动转化，两个不同的类型进行计算时，结果为范围较大的类型，如val d2:Int = a2 + 0是正确的。但是要注意Char类型无法和浮点进行运算。</span><br><span class="line">// 如果想将某一类型强制转换为其他类型，可以使用.to类型名的方法进行转换</span><br><span class="line">    val a1:Int = 10</span><br><span class="line">    val b1 = a1</span><br><span class="line">    val c1 = a1.toByte()</span><br><span class="line">    println("${a1.javaClass}类型a1 = ${a1}")</span><br><span class="line">    println("${b1.javaClass}类型b1 = ${b1}")</span><br><span class="line">    println("${c1.javaClass}类型c1 = ${c1}")</span><br><span class="line"></span><br><span class="line">    val a2:Byte = 20</span><br><span class="line">    val b2 = a2</span><br><span class="line">    val c2 = a2.toInt()</span><br><span class="line">    println("${a2.javaClass}类型a2 = ${a2}")</span><br><span class="line">    println("${b2.javaClass}类型b2 = ${b2}")</span><br><span class="line">    println("${c2.javaClass}类型c2 = ${c2}")</span><br><span class="line"></span><br><span class="line">    val a:Byte = 9</span><br><span class="line">    val b = 2</span><br><span class="line">    val c = 2.0</span><br><span class="line">    val d = 'a'</span><br><span class="line">    println("${a.javaClass}类型${a} + ${b.javaClass}类型${b} = ${(a + b).javaClass}类型${a + b}")</span><br><span class="line">    println("${a.javaClass}类型${a} - ${b.javaClass}类型${b} = ${(a - b).javaClass}类型${a - b}")</span><br><span class="line">    println("${a.javaClass}类型${a} * ${c.javaClass}类型${c} = ${(a * c).javaClass}类型${a * c}")</span><br><span class="line">    println("${a.javaClass}类型${a} / ${c.javaClass}类型${c} = ${(a / c).javaClass}类型${a / c}")</span><br><span class="line">    println("${d.javaClass}类型${d} + ${b.javaClass}类型${b} = ${(d + b).javaClass}类型${d + b}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin3.png" alt="2"></p>
<h1 id="Kotlin关系运算"><a href="#Kotlin关系运算" class="headerlink" title="Kotlin关系运算"></a><font size="4">Kotlin关系运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// &gt;(大于)，&lt;(小于)，&gt;=(大于等于)，&lt;=(小于等于)，==(等于)，!=(不等于)</span><br><span class="line">// ==比较两个对象的值是否相等，===比较两个对象的地址是否相等</span><br><span class="line">// 在a1、b1和c1的比较过程中，a1、b1和c1值相等，类型相同，并且指向同一个地址</span><br><span class="line">// 在a2、b2和c2的比较过程中，a2、b2和c2值相等，但是b2和c2类型可以为空，进行了重新包装，但是在-127到128之间，所有的对象都具有同样的地址，虽然重新包装但是地址仍一样</span><br><span class="line">// 在a3、b3和c3的比较过程中，a3、b3和c3值相等，并且指向同一个地址，但是b3和c3类型可以为空，进行了重新包装，不在-127到128之间，因此地址不相同</span><br><span class="line">// 在a4、b4和c4的比较过程中，a4、b4和c4值相等，类型相同，并且指向同一个地址</span><br><span class="line">fun main() {</span><br><span class="line">    val a = 10</span><br><span class="line">    val b = 20</span><br><span class="line">    val c = 'c'</span><br><span class="line">    println("${a} == ${b}? -&gt; ${a == b}")</span><br><span class="line">    println("${a} * 2 == ${b}? -&gt; ${a * 2 == b}")</span><br><span class="line">    println("${c} &lt; d? -&gt; ${c &lt; 'd'}")</span><br><span class="line"></span><br><span class="line">    println("--------------------")</span><br><span class="line"></span><br><span class="line">    val a1 = 20</span><br><span class="line">    val b1 = a1</span><br><span class="line">    val c1 = a1</span><br><span class="line">    println("b1 == c1? -&gt; ${b1 == c1}")</span><br><span class="line">    println("b1 === c1? -&gt; ${b1 === c1}")</span><br><span class="line"></span><br><span class="line">    println("--------------------")</span><br><span class="line"></span><br><span class="line">    val a2 = 20</span><br><span class="line">    val b2:Int? = a2</span><br><span class="line">    val c2:Int? = a2</span><br><span class="line">    println("b2 == c2? -&gt; ${b2 == c2}")</span><br><span class="line">    println("b2 === c2? -&gt; ${b2 === c2}")</span><br><span class="line"></span><br><span class="line">    println("--------------------")</span><br><span class="line"></span><br><span class="line">    val a3 = 200</span><br><span class="line">    val b3:Int? = a3</span><br><span class="line">    val c3:Int? = a3</span><br><span class="line">    println("b3 == c3? -&gt; ${b3 == c3}")</span><br><span class="line">    println("b3 === c3? -&gt; ${b3 === c3}")</span><br><span class="line"></span><br><span class="line">    println("--------------------")</span><br><span class="line"></span><br><span class="line">    val a4:Int? = 200</span><br><span class="line">    val b4:Int? = a4</span><br><span class="line">    val c4:Int? = a4</span><br><span class="line">    println("b4 == c4? -&gt; ${b4 == c4}")</span><br><span class="line">    println("b4 === c4? -&gt; ${b4 === c4}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin4.png" alt="4"></p>
<h1 id="Kotlin自增自减运算符"><a href="#Kotlin自增自减运算符" class="headerlink" title="Kotlin自增自减运算符"></a><font size="4">Kotlin自增自减运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// ++(自增运算符)，--(自减运算符)，++在前代表先进行加1，然后将值代入表达式，++在后代表先将值代入表达式，然后再进行加1，自减操作符同理。</span><br><span class="line">fun main() {</span><br><span class="line">    var k = 1</span><br><span class="line">    println("k++ = ${k++}")</span><br><span class="line">    println("++k = ${++k}")</span><br><span class="line">    println("--k = ${--k}")</span><br><span class="line">    println("k-- = ${k--}")</span><br><span class="line">    println("k = ${k}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin5.png" alt="5"></p>
<h1 id="Kotlin逻辑运算"><a href="#Kotlin逻辑运算" class="headerlink" title="Kotlin逻辑运算"></a><font size="4">Kotlin逻辑运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// &amp;&amp;(与)，||(或)，!(非)，注意与或操作只要可以判断出最后结果则停止，具有短路效果。</span><br><span class="line">//如果与操作的第一个条件为假，则不执行第二个条件，如果或操作的第一个条件为真，则不执行第二个条件。</span><br><span class="line">fun main() {</span><br><span class="line">    val a = 5</span><br><span class="line">    val b = 6</span><br><span class="line">    var i = 0</span><br><span class="line">    val c = a &gt; b || (++i &gt; 0)</span><br><span class="line">    println("i = ${i}")</span><br><span class="line">    println("c = ${c}")</span><br><span class="line">    val d = a &gt; b &amp;&amp; (++i &gt; 0)</span><br><span class="line">    println("i = ${i}")</span><br><span class="line">    println("d = ${d}")</span><br><span class="line">    val e = !d</span><br><span class="line">    println("e = ${e}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin6.png" alt="6"></p>
<h1 id="Kotlin三目运算符"><a href="#Kotlin三目运算符" class="headerlink" title="Kotlin三目运算符"></a><font size="4">Kotlin三目运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//在C++和Java语言中，三目表达式为，条件?表达式1:表达式2，当条件成立时，执行表达式1的内容，否则执行表达式2的内容。</span><br><span class="line">//在Python语言中，三目表达式为，表达式1 if 条件 else 表达式2</span><br><span class="line">//在Kotlin语言中，三目表达式为，if (条件) 表达式1 else 表达式2</span><br><span class="line">fun main() {</span><br><span class="line">    val a = 10</span><br><span class="line">    val b = if (a &gt; 3) 2 else 1</span><br><span class="line">    println("b = ${b}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin7.png" alt="7"></p>
<h1 id="Kotlin位运算符"><a href="#Kotlin位运算符" class="headerlink" title="Kotlin位运算符"></a><font size="4">Kotlin位运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// and/or/xor/inv/shl/shr/ushr分别代表与/或/非/求反</span><br><span class="line">// 可以对象名1.方法(对象名2)也可以对象名1 方法 对象名2，如a.and(b) 或者 a and b</span><br><span class="line">// shr代表连同符号位右移，并且当前符号位和原始符号位相同，ushr代表连同符号位右移，当前符号位补0</span><br><span class="line">fun main() {</span><br><span class="line">    val a = -7</span><br><span class="line">    println("${a} 左移两位 -&gt; ${a.shl(2)}")</span><br><span class="line">    println("${a} 右移两位 -&gt; ${a.shr(2)}")</span><br><span class="line">    println("${a} 无符号右移两位 -&gt; ${a.ushr(2)}")</span><br><span class="line"></span><br><span class="line">    val b = 5</span><br><span class="line">    println("${b} and 3 -&gt; ${b.and(3)}")</span><br><span class="line">    println("${b} or 3 -&gt; ${b.or(3)}")</span><br><span class="line">    println("${b} xor 3 -&gt; ${b.xor(3)}")</span><br><span class="line">    println("${b} 求反 -&gt; ${b.inv()}")</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Kotlin8.png" alt="7"></p>
<h1 id="Kotlin小结"><a href="#Kotlin小结" class="headerlink" title="Kotlin小结"></a><font size="5" color="red">Kotlin小结</font></h1><p>  运算符操作每种语言都大同小异，因为运算符是所有语言的基础，学习每一种语言都离不开运算操作，虽然难度较小，但是非常重要，无论以后从事什么样的研究，都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Kotlin</category>
      </categories>
  </entry>
  <entry>
    <title>Kotlin介绍</title>
    <url>/2021/06/13/Kotlin_introduction/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Kotlin1.png" alt="0"></p>
<h1 id="Kotlin由来"><a href="#Kotlin由来" class="headerlink" title="Kotlin由来"></a><font size="5" color="red">Kotlin由来</font></h1><p>  接下来是一段华为的社畜生活，在IT的市场中，移动端扮演着越来越重要的角色。谈到移动端，必然无法离开Android和IOS操作系统。之前没有接触过Android开发，这里趁着入职之前的一段时间，学习一下Android开发。Kotlin由JetBrains公司开发，于2016年2月15日发布Kotlin v1.0，与Java语言完全互通，并且具有Java语言暂不支持的新特性。在2017年谷歌宣布在Android Studio IDE中支持Kotlin，在2019年谷歌正式宣布Kotlin语言是Android应用程序开发人员的首选语言。在短短的5年时间里，Kotlin受欢迎程度也在不断提高。接下来的一段时间给大家介绍Kotlin的一些基本语法，因为没有多年的Kotlin开发经验，在这里只能点到为止，带着大家入门，如何提升代码能力和实际开发能力，还需要小伙伴们多多刷题，多多进行工程实践。<br><a id="more"></a></p>
<h1 id="Kotlin语言的特点"><a href="#Kotlin语言的特点" class="headerlink" title="Kotlin语言的特点"></a><font size="5" color="red">Kotlin语言的特点</font></h1><p>  <font size="3">定义安全性：Kotlin语言中所有对象由指针持有，且在定义时明确指出指针可变var或者不可变val。</font><br>  <font size="3">空指针安全性：Kotlin具有NULL检查机制，可以通过加问号?和双感叹号!!来指定对象类型是否可空或者不为空。</font><br>  <font size="3">简洁性：Kotlin可以使用字符串模板直接访问变量，而且在类的定义上具有更加简洁的形式。</font><br>  <font size="3">高效性：Kotlin可以使用比switch更强大的when语句进行多重分支选择，也具有更高效的lambda编程思想。</font></p>
<h1 id="Kotlin小结"><a href="#Kotlin小结" class="headerlink" title="Kotlin小结"></a><font size="5" color="red">Kotlin小结</font></h1><p>  由于Kotlin和Java相比的诸多优势，在Android开发领域会有占有越来越多的市场份额，而且在《第一行Android代码》这本经典的Android入门书籍中，也已经从Java语言开始向Kotlin语言发展。在移动端迅速发展的时代，了解一些Android开发技巧和布局思想是很有必要的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Kotlin</category>
      </categories>
  </entry>
  <entry>
    <title>数位成本和为目标值的最大数字(Leetcode 1449)</title>
    <url>/2021/06/12/program%20Leetcode1449/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1449.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   本题难度较大，题目的信息绕人，虽然能够想到动态规划，但是很难想到最优的状态转移方程。<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>本题的亮点是dp[i][j]不是最终求得的结果，而是最终解的位数，因为最终解一定是位数最多的解。通过另一个状态转移方程from[i][j]记录位数的变化，逆推出选择的数字。</p>
<p>先来分析dp[i][j]，dp[i][j]表示前i个数字，满足成本为j时，产生的最大位数。而且数字可以重复使用，满足完全背包的性质。当成本小于第i个数字的成本时，dp[i][j] = dp[i - 1][j]，当成本大于等于第i个数字的成本时dp[i][j] = max(dp[i - 1][j], dp[i][j - cost[i]] + 1)</p>
<script type="math/tex; mode=display">\begin{cases} dp[i][j] = max(dp[i - 1][j], dp[i][j - cost[i]] + 1) &  j \ge cost[i] \\ dp[i - 1][j] & else \end{cases}</script><p>然后分析from[i][j]，from[i][j]表示前i个数字，满足成本为j时，上一个状态的成本。假设没有使用第i个数字，那么上一个状态就是dp[i - 1][j]，因此成本为j，则from[i][j] = j，如果使用第i个数字，那么上一个状态就是dp[i][j - cost[i]]，因此成本为j - cost[i]。要注意的是，如果从在遍历中发现dp[i][j - cost[i]] + 1 = dp[i - 1][j]。说明在之前的遍历中，已经找到了一种方法使得产生的位数最大，这时from[i][j]是否需要更新呢？是使用之前的数字呢还是使用当前的数字呢？因为我们对数字从1搜索到9，因此当前的数字更大，应该使用当前的数字，当dp[i][j - cost[i]] + 1 = dp[i - 1][j]时，from[i][j] = j - cost[i]。</p>
<script type="math/tex; mode=display">\begin{cases} from[i][j] = j &  j < cost[i] \&\& dp[i][j - cost[i]] + 1 < dp[i - 1][j] \\ j -cost[i] & else \end{cases}</script><p>在完成dp和from的正向遍历后，逆序确定所选择的数字，如果j == from[i][j]，说明dp[i][j]是从dp[i - 1][j]转移而来的，没用选择第i个数字，—i。否则选择了第i个数字，然后将当前成本j变为上一个状态的成本from[i][j]。</p>
<p>算法的<strong>时间复杂度为$O(10 \times target)$，空间复杂度为$O(20 \times target)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public String largestNumber(int[] cost, int target) {</span><br><span class="line">        int[][] dp = new int[10][target + 1];</span><br><span class="line">        int[][] from = new int[10][target + 1];</span><br><span class="line">        for (int i = 0; i &lt; 10; ++i) {</span><br><span class="line">            for (int j = 0; j &lt;= target; ++j) {</span><br><span class="line">                dp[i][j] = Integer.MIN_VALUE;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        dp[0][0] = 0;</span><br><span class="line">        for (int i = 0; i &lt; 9; ++i) {</span><br><span class="line">            for (int j = 0; j &lt;= target; ++j) {</span><br><span class="line">                if (j &lt; cost[i] || dp[i + 1][j - cost[i]] + 1 &lt; dp[i][j]) {</span><br><span class="line">                    dp[i + 1][j] = dp[i][j];</span><br><span class="line">                    from[i + 1][j] = j;</span><br><span class="line">                } else {</span><br><span class="line">                    dp[i + 1][j] = dp[i + 1][j - cost[i]] + 1;</span><br><span class="line">                    from[i + 1][j] = j - cost[i];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        if (dp[9][target] &lt;= 0) { return "0"; }</span><br><span class="line">        StringBuilder res = new StringBuilder();</span><br><span class="line">        int i = 9;</span><br><span class="line">        int j = target;</span><br><span class="line">        while (i &gt; 0) {</span><br><span class="line">            if (j == from[i][j]) {</span><br><span class="line">                --i;</span><br><span class="line">            } else {</span><br><span class="line">                res.append(i);</span><br><span class="line">                j = from[i][j];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun largestNumber(cost: IntArray, target: Int): String {</span><br><span class="line">        val dp = Array(10) {IntArray(target + 1)}</span><br><span class="line">        val from = Array(10) {IntArray(target + 1)}</span><br><span class="line">        for (i in 0..9) {</span><br><span class="line">            for (j in 0..target) {</span><br><span class="line">                dp[i][j] = Int.MIN_VALUE</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        dp[0][0] = 0</span><br><span class="line">        for (i in 0..8) {</span><br><span class="line">            for (j in 0..target) {</span><br><span class="line">                if (j &lt; cost[i] || dp[i + 1][j - cost[i]] + 1 &lt; dp[i][j]) {</span><br><span class="line">                    dp[i + 1][j] = dp[i][j]</span><br><span class="line">                    from[i + 1][j] = j</span><br><span class="line">                } else {</span><br><span class="line">                    dp[i + 1][j] = dp[i + 1][j - cost[i]] + 1</span><br><span class="line">                    from[i + 1][j] = j - cost[i]</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        if (dp[9][target] &lt;= 0) { return "0" }</span><br><span class="line">        val res = StringBuilder()</span><br><span class="line">        var i = 9</span><br><span class="line">        var j = target</span><br><span class="line">        while (i &gt;= 0) {</span><br><span class="line">            if (j == from[i][j]) { --i }</span><br><span class="line">            else {</span><br><span class="line">                res.append(i)</span><br><span class="line">                j = from[i][j]</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化动态规划"><a href="#优化动态规划" class="headerlink" title="优化动态规划"></a><font size="5" color="red">优化动态规划</font></h1><p>因为这个问题是一个完全背包问题，第i层的状态仅和第i层和第i - 1层有关，因此可以对空间复杂度进行压缩。</p>
<p>dp[i]表示成本为i时，产生的最大位数。</p>
<script type="math/tex; mode=display">dp[i] = max(dp[i], dp[i - cost[i]])</script><p>遍历dp以后，可以根据dp[i - cost[i]] + 1和dp[i]的关系来判断是否选择了第i个数字，如果选择了第i个数字，那么dp[i - cost[i]] + 1的值等于dp[i]的值</p>
<p>算法的<strong>时间复杂度为$O(10 \times target)$，空间复杂度为$O(target)$</strong></p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public String largestNumber(int[] cost, int target) {</span><br><span class="line">        int[] dp = new int[target + 1];</span><br><span class="line">        for (int i = 0; i &lt;= target; ++i) {</span><br><span class="line">                dp[i] = Integer.MIN_VALUE;</span><br><span class="line">        }</span><br><span class="line">        dp[0] = 0;</span><br><span class="line">        for (int x : cost) {</span><br><span class="line">            for (int i = x; i &lt;= target; ++i) {</span><br><span class="line">                dp[i] = Math.max(dp[i], dp[i - x] + 1);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        if (dp[target] &lt;= 0) { return "0"; }</span><br><span class="line">        StringBuilder res = new StringBuilder();</span><br><span class="line">        int i = 8;</span><br><span class="line">        int j = target;</span><br><span class="line">        while (i &gt;= 0) {</span><br><span class="line">            if (j &gt;= cost[i] &amp;&amp; dp[j - cost[i]] + 1 == dp[j]) {</span><br><span class="line">                res.append(i + 1);</span><br><span class="line">                j -= cost[i];</span><br><span class="line">            } else {</span><br><span class="line">                --i;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun largestNumber(cost: IntArray, target: Int): String {</span><br><span class="line">        val dp = IntArray(target + 1)</span><br><span class="line">        for (i in 0..target) {</span><br><span class="line">            dp[i] = Int.MIN_VALUE</span><br><span class="line">        }</span><br><span class="line">        dp[0] = 0</span><br><span class="line">        for (x in cost) {</span><br><span class="line">            for (i in x..target) {</span><br><span class="line">                dp[i] = Math.max(dp[i], dp[i - x] + 1)</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        if (dp[target] &lt;= 0) { return "0" }</span><br><span class="line">        val res = StringBuilder()</span><br><span class="line">        var i = 8</span><br><span class="line">        var j = target</span><br><span class="line">        while (i &gt;= 0) {</span><br><span class="line">            if (j &gt;= cost[i] &amp;&amp; dp[j - cost[i]] + 1 == dp[j]) {</span><br><span class="line">                res.append(i + 1)</span><br><span class="line">                j -= cost[i]</span><br><span class="line">            } else {</span><br><span class="line">                --i</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.toString()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目看了答案之后发现并不是很困难，但是在看答案之前觉得非常复杂，在一般的背包问题中，数组最后一维的值就是问题的最优解，而这个题目最后一维的值只是一个中间步骤，这个题目非常好，开阔了我们的思维，需要多多练习这类题目，对自己的提升才能更快。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>零钱兑换 II(Leetcode 518)</title>
    <url>/2021/06/10/program%20Leetcode518/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode518.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目也是一个经典的背包问题，只不过和Leetcode494题不同点在于，本题的硬币数量可以无限个，被称为完全背包，解决思路是类似的，小伙伴们先思考一下如何去解<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>用dp[i][j]表示前i个硬币能凑出j块钱的方案数量，可以不使用第i个硬币，即dp[i - 1][j]，也可以使用第i个硬币，dp[i][j - coins[i]]，在Leetcode第494题中，这个表达式为dp[i - 1][j - coins[i]]，这是两道题目的关键差异。在494题中，一个硬币只能选择一次，只能加上前i - 1个硬币凑出j - coins[i]的方案数，本题可以多次使用，因此无论第i个硬币使用多少次，都可以加上前i个硬币凑出j - coins[i]的方案数，只要再次使用第i个硬币即可。</p>
<script type="math/tex; mode=display">dp[i][j] = dp[i - 1][j] + dp[i][j - nums[i]]</script><p>因为第i层状态仅与第i - 1层有关，可以使用一维dp进行求解，此时因为使用本层更新后的数据，所以要顺序遍历。</p>
<p>算法的<strong>时间复杂度为$O(n \cdot amount)$，空间复杂度为$O(amount)$</strong>，其中n为硬币种类</p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int change(int amount, int[] coins) {</span><br><span class="line">        int[] dp = new int[amount + 1];</span><br><span class="line">        dp[0] = 1;</span><br><span class="line">        for (int coin : coins) {</span><br><span class="line">            for (int i = coin; i &lt;= amount; i++) {</span><br><span class="line">                dp[i] += dp[i - coin];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp[amount];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun change(amount: Int, coins: IntArray): Int {</span><br><span class="line">        val dp = IntArray(amount + 1)</span><br><span class="line">        dp[0] = 1</span><br><span class="line">        for (coin in coins) {</span><br><span class="line">            for (i in coin..amount) {</span><br><span class="line">                dp[i] += dp[i - coin]</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp.last()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  最近Leetcode的每日一题都是背包问题，小伙伴们可以从网上搜索背包九讲相关的知识点进行集中练习，仔细区别各个体型之间的差异。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>盈利计划(Leetcode 879)</title>
    <url>/2021/06/09/program%20Leetcode879/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode879.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   又遇到困难题了，心态崩了啊。小伙伴们不要害怕困难题，在面试的时候遇到困难题，不会做是正常的，可以向面试官询问解题思路或者更换题目，虽然不推荐这样做，但是也总比浪费面试时间更好，如果在那里啃半天也没有想出来，基本上是挂了。如果是笔试遇到了困难题，没用思路，可以先跳过这个题目，最后有时间再做。这个题目和前两天遇到的题目有些类似，都是可以回溯求解，但是时间复杂度又很大的题型。遇到这类题，我们首先要去想动态规划<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>共有m个任务，n个工人，最小利润为minProfit。那么本问题具有最优子问题，第m个任务需要的工人数为group[m]，可以获得的利润为profit[m]。如果做第m个任务，那么就是求子问题共有m - 1个任务，n - group[m]个工人，最小利润为minProfit - profit[m]的解，如果不做第m个任务，就是求子问题共有m - 1个任务，n个工人，最小利润为minProfit的解。将两个解相加即可。</p>
<p>我们使用dp[i][j][k]代表本问题的解，i代表前i个任务，j代表有j个工人，k代表最小利润为k。有如下关系</p>
<script type="math/tex; mode=display">dp[i][j][k] = dp[i - 1][j][k] + dp[i - 1][j - group[i]][k - profit[i]]</script><p>因为最小利润为0，因此使用max(0, k - profit[i])代替k - profit[i]。</p>
<p>在状态转移方程中，第i层状态仅与第i - 1层有关，可以使用二维dp进行求解。</p>
<p>值得注意的是动态规划的初始状态，当最小利润为0时，使用0个工人是一种解决方案。如果j表示已经使用j个工人，那么dp[0][0] = 1。但是最终求的结果，要从使用0个工人dp[0][minProfit]累积求和到使用n个工人dp[n][minProfit]。如果j表示可以使用j个工人，那么对于所有的dp[j][0] = 1，因为可以使用j个工人都包括使用0个工人。最终求的结果直接返回dp[n][profit]即可。在Python语言的题解中，j代表已经使用j个工人，在Kotlin语言的题解中，j代表可以使用j个工人，小伙伴们认真理解这句话的涵义。</p>
<p>算法的<strong>时间复杂度为$O(mn \cdot minProfit)$，空间复杂度为$O(n \cdot minProfit)$</strong>。</p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def profitableSchemes(self, n, minProfit, group, profit) -&gt; int:</span><br><span class="line">        mod = 10 ** 9 + 7</span><br><span class="line">        dp = [[0 for _ in range(minProfit + 1)] for _ in range(n + 1)]</span><br><span class="line">        dp[0][0] = 1</span><br><span class="line">        for i in range(len(group)):</span><br><span class="line">            for j in range(n, group[i] - 1, -1):</span><br><span class="line">                for k in range(minProfit, -1, -1):</span><br><span class="line">                    dp[j][k] = (dp[j][k] + dp[j - group[i]][max(0, k - profit[i])]) % mod</span><br><span class="line">        return sum(dp[j][-1] for j in range(n + 1)) % mod</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun profitableSchemes(n: Int, minProfit: Int, group: IntArray, profit: IntArray): Int {</span><br><span class="line">        val mod = (1e9 + 7).toInt()</span><br><span class="line">        val dp = Array(n + 1) {IntArray(minProfit + 1)}</span><br><span class="line">        for (j in 0..n) { dp[j][0] = 1 }</span><br><span class="line">        for (i in group.indices) {</span><br><span class="line">            for (j in n downTo group[i]) {</span><br><span class="line">                for (k in minProfit downTo 0) {</span><br><span class="line">                    dp[j][k] = (dp[j][k] + dp[j - group[i]][Math.max(0, k - profit[i])]) % mod</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp[n][minProfit]</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  前几天介绍的题目难度较小，可能只是笔试面试题目的下限，这个题目难度较大，可能达到了笔试面试题目的上限，如果出现是压轴的题目，如果面试中能够手撕出来，基本上本轮面试的算法部分就可以通过了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>最后一块石头的重量 II(Leetcode 1049)</title>
    <url>/2021/06/08/program%20Leetcode1049/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1049.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目描述非常有趣，小伙伴们深入挖掘其中的隐藏信息，先尝试求解一下吧。</p>
<a id="more"></a>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p><strong>题目的隐藏信息是，将石头分为最接近的两堆。然后两堆的差值就是题目的最优解。下面就转化为如何将石头分为最接近的两堆</strong>。</p>
<p>石头分为两堆，必然有一堆不多于另一堆，假设共有x个石头，那么将一定有一堆不多于x / 2，有一堆不少于x / 2。因此我们用一个大小为x / 2的包裹去装石头，看能够装入的最大重量就是较小堆的最大值，此时两堆石头最接近，是本题的最优解，下面转化为0-1背包问题，用dp[i][j]表示前i个石头装入容量为j的背包，能放入的石头的最大重量。</p>
<script type="math/tex; mode=display">dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - nums[i]])</script><p>因为第i层状态仅与第i - 1层有关，可以使用一维dp进行求解。</p>
<p>算法的<strong>时间复杂度为$O(n \cdot sum)$，空间复杂度为$O(sum)$</strong>，其中sum为所有石头重量之和</p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int lastStoneWeightII(vector&lt;int&gt;&amp; stones) {</span><br><span class="line">        int sums = accumulate(stones.begin(), stones.end(), 0);</span><br><span class="line">        int stone = sums &gt;&gt; 1;</span><br><span class="line">        vector&lt;int&gt; dp(stone + 1);</span><br><span class="line">        for (int x : stones) {</span><br><span class="line">            for (int i = stone; i &gt;= x; i--) {</span><br><span class="line">                dp[i] = max(dp[i], dp[i - x] + x);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return sums - 2 * dp.back();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun lastStoneWeightII(stones: IntArray): Int {</span><br><span class="line">        var sums = 0</span><br><span class="line">        for (x in stones) { sums += x }</span><br><span class="line">        val stone = sums.shr(1)</span><br><span class="line">        val dp = IntArray(stone + 1)</span><br><span class="line">        for (x in stones) {</span><br><span class="line">            for (i in stone downTo x) {</span><br><span class="line">                dp[i] = Math.max(dp[i], dp[i - x] + x)</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return sums - 2 * dp.last()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  0-1背包问题是程序员必知必会的算法之一，很多题目都是从0-1背包问题转化而来，小伙伴们一定要打好基础，多多总结，多做练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>一和零(Leetcode 474)</title>
    <url>/2021/06/06/program%20Leetcode474/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode474.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目第一眼看上去，很面熟，但是又想不起来在哪里见到过。在翻看题解之后，发现这个题目和之前的背包问题非常相似，类似于一个二维的背包问题。下面我将题目进行转化，给你一个背包，背包的宽度和高度为m和n，其中宝物数组为strs，每个宝物也有宽度和高度两个属性，问最多能够装入多少个宝物？现在小伙伴们尝试一下能否独立求解出本题呢？<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>背包问题的经典解法是动态规划，在0-1背包中，一维问题，创建一个二维数组dp[k][n]，其中k为宝物的个数，n为空间的大小。dp[i][j]代表遍历底i个物体时，当使用j个空间时能装入的物品个数。</p>
<script type="math/tex; mode=display">\begin{cases} dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - w[i]] + 1) & j \ge w[i] \\ dp[i - 1][j] & j < w[i] \end{cases}</script><p>在本题二维问题中，创建一个三位数组dp[k][m][n]，其中k为字符串个数，m为0的个数，n为1的个数。dp[k][i][j]代表遍历底k个字符串时，共有i个0，j个1时子集中包含字符串的最大个数。</p>
<script type="math/tex; mode=display">\begin{cases} dp[k][i][j] = max(dp[k - 1][i][j], dp[k - 1][i - mm[k]][j - nn[k]] + 1) & i \ge mm[k] \&\& j \ge nn[k] \\ dp[k - 1][i][j] & else \end{cases}</script><p>算法的<strong>时间复杂度为$O(mnk)$，空间复杂度为$O(mnk)$</strong></p>
<p><strong>在0-1背包中，因为dp[i]仅与dp[i - 1]的状态有关，因此在一维问题中，可以使用一维数组记录状态，为了第i层的状态变化不影响上一层，可以使用倒序遍历实现。如果使用顺序遍历，dp[j] = dp[j - w[i]]会更新dp[j]的值，当使用dp[j]的值时，就不是更新前的值了，因此顺序遍历是不正确的，而逆序遍历，每次先更新后面的值，可以保证以后不会使用到。同理二维问题类似，可以进一步将时间复杂都缩小为$O(mn)$</strong></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findMaxForm(self, strs: List[str], m: int, n: int) -&gt; int:</span><br><span class="line">        dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]</span><br><span class="line">        for s in strs:</span><br><span class="line">            mm = s.count('0')</span><br><span class="line">            nn = len(s) - mm</span><br><span class="line">            for i in range(m, mm - 1, -1):</span><br><span class="line">                for j in range(n, nn - 1, -1):</span><br><span class="line">                    dp[i][j] = max(dp[i - mm][j - nn] + 1, dp[i][j])</span><br><span class="line">        return dp[-1][-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun findMaxForm(strs: Array&lt;String&gt;, m: Int, n: Int): Int {</span><br><span class="line">        val dp = Array(m + 1){IntArray(n + 1)}</span><br><span class="line">        for (str in strs) {</span><br><span class="line">            val mm = str.count{it == '0'}</span><br><span class="line">            val nn = str.length - mm</span><br><span class="line">            for (i in m downTo mm) {</span><br><span class="line">                for (j in n downTo nn) {</span><br><span class="line">                    dp[i][j] = Math.max(dp[i][j], dp[i - mm][j - nn] + 1)</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp[m][n];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比Python和Kotlin两种语言，可以发现在创建多维数组时，相对于C++或Java语言较为麻烦，在字符串操作时，Python的内置函数较为方便，Kotlin语言需要使用lambda表达式。而且在倒序时，Python和正序类似，只用修改倒序的步长，Kotlin需要使用downTo语句。可以看出来Kotlin更像一种Java和Python的结合体，在变量声明和每行代码结尾不用分号，更类似于Python，而循环，选择结构中的大括号，以及代码的逻辑结构上更类似于Java。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目难度适中，如果能够联想到背包问题，相信对于小伙伴们来说是不难的，如果联想不到，暴力法或者回溯法可能无法求解本题。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>目标和(Leetcode 494)</title>
    <url>/2021/06/06/program%20Leetcode494/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode494.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   本题也是一个非常有趣的题目，很容易想到回溯法进行求解，但是时间复杂度为$O(2^n)$，对于数据量稍大的场景都无法适用。小伙伴们思考是否还要其他的方法？<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>如果数据量较大，又没有特殊方法的题目，小伙伴们思路可以向动态规划靠近。</p>
<p><strong>本题的要求是从前n个数，进行组合找到和为target的数。因此存在最优子问题，假设最后一个数为k，那么最优子问题等价于从前n - 1个数，组合找到和为target - k或者target + k的结果之和。用dp[i][j]代表前i个数之和为j的表达式数目</strong>。</p>
<script type="math/tex; mode=display">dp[i][j] = dp[i - 1][j - nums[i]] + dp[i - 1][j + nums[i]]</script><p>算法的<strong>时间复杂度为$O(n \cdot target)$，空间复杂度为$O(n \cdot target)$</strong></p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int findTargetSumWays(vector&lt;int&gt;&amp; nums, int target) {</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; dp(nums.size() + 1, vector&lt;int&gt;(2001));</span><br><span class="line">        dp[0][1000] = 1;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) {</span><br><span class="line">            for (int j = -1000; j &lt;= 1000; j++) {</span><br><span class="line">                if (j + nums[i] &gt;= -1000 &amp;&amp; j + nums[i] &lt;= 1000) { dp[i + 1][j + nums[i] + 1000] += dp[i][j + 1000]; }</span><br><span class="line">                if (j - nums[i] &gt;= -1000 &amp;&amp; j - nums[i] &lt;= 1000) { dp[i + 1][j - nums[i] + 1000] += dp[i][j + 1000]; }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp.back()[target + 1000];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun findTargetSumWays(nums: IntArray, target: Int): Int {</span><br><span class="line">        val dp = Array(nums.size + 1) {IntArray(2001)}</span><br><span class="line">        dp[0][1000] = 1</span><br><span class="line">        for ((idx, x) in nums.withIndex()) {</span><br><span class="line">            for (i in -1000..1000) {</span><br><span class="line">                if (i + x &gt;= -1000 &amp;&amp; i + x &lt;= 1000) { dp[idx + 1][i + x + 1000] += dp[idx][i + 1000]}</span><br><span class="line">                if (i - x &gt;= -1000 &amp;&amp; i - x &lt;= 1000) { dp[idx + 1][i - x + 1000] += dp[idx][i + 1000]}</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp[nums.size][target + 1000]</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化动态规划"><a href="#优化动态规划" class="headerlink" title="优化动态规划"></a><font size="5" color="red">优化动态规划</font></h1><p>上面这种做法已经可以满足面试笔试的需求，但是本题有一种更巧妙的方法，转化为0-1背包问题进行求解。</p>
<p><strong>因为nums都是正数，假设将其全部相加结果为sums，如果在某些位置加上负号，令这些数字之和为neg，所以其余的正数之和为sums - neg，此时整体数组之和为sums - neg + (-neg) = sums - 2neg = target</strong>。所以</p>
<script type="math/tex; mode=display">neg = \frac{sums - target}{2}</script><p>即我们从nums中找出和为neg的子集数量即可，可以采用0-1背包的问题进行求解。用dp[i][j]表示前i个数和为j的子集数量。</p>
<script type="math/tex; mode=display">dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - nums[i]])</script><p>因为第i层状态仅与第i - 1层有关，可以使用一维dp进行求解。</p>
<p>算法的<strong>时间复杂度为$O(n \cdot (sum - target))$，空间复杂度为$O(sum - target)$</strong></p>
<p>下面是C++语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int findTargetSumWays(vector&lt;int&gt;&amp; nums, int target) {</span><br><span class="line">        int sums = 0;</span><br><span class="line">        for (int x : nums) { sums += x; }</span><br><span class="line">        int diff = sums - target;</span><br><span class="line">        if (diff &lt; 0 || diff &amp; 1) { return 0; }</span><br><span class="line">        int neg = diff &gt;&gt; 1;</span><br><span class="line">        vector&lt;int&gt; dp(neg + 1);</span><br><span class="line">        dp[0] = 1;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) {</span><br><span class="line">            for (int j = neg; j &gt;= nums[i]; j--) {</span><br><span class="line">                dp[j] += dp[j - nums[i]];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp.back();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun findTargetSumWays(nums: IntArray, target: Int): Int {</span><br><span class="line">        var sums = 0</span><br><span class="line">        for (x in nums) { sums += x }</span><br><span class="line">        val diff = sums - target</span><br><span class="line">        if (diff &lt; 0 || diff.and(1) == 1) { return 0 }</span><br><span class="line">        val neg = diff.shr(1)</span><br><span class="line">        val dp = IntArray(neg + 1)</span><br><span class="line">        dp[0] = 1</span><br><span class="line">        for (x in nums) {</span><br><span class="line">            for (i in neg downTo x) {</span><br><span class="line">                dp[i] += dp[i - x]</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp.last()</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比C++和Kotlin两种语言，可以看出C++语言中布尔类型就是0和1，可以直接将运算结果进行布尔判断，而Kotlin布尔和整型不可以直接运算。而且在位操作时，C++是使用位运算符进行操作，如a&amp;b，Kotlin使用成员方法进行操作，如a.and(b)或者a and b。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  本题的重点是动态规划思路，并不是说优化的DP比普通的DP更好，小伙伴们要进行对比，将两者方法都掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>连续的子数组和(Leetcode 523)</title>
    <url>/2021/06/02/program%20Leetcode523/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode523.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和Leetcode第560题很像，第560题是最基础的前缀和题目，本题进行了扩展，不是求和为k的子数组，而是要求和为k的倍数的子数组，且必须满足子数组的长度至少为2。能否使用类似的方法进行求解呢？<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>本题的题解是第560题的扩展，如果没有做过第560题的小伙伴，建议先去学习该题目。掌握如何在线性的时间复杂度内完成子数组之和的题目。</p>
<p>我们可以通过哈希表查找dic[curSum - k]来判断是否含有值为curSum - k的前缀和，假设第i个前缀和为curSum，第j个前缀和为curSum - k，则从j + 1到i的子数组和为k。这是第560题的主要思路。在本题中k的倍数，无法枚举curSum - k，curSum - 2k等等，要挖掘倍数的特征，<strong>如果前i个前缀和模k为p，前j个前缀和模k也为p，则可以得到从j + 1到i的子数组和为k的倍数</strong>。此时如果子数组的长度大于等于2，则返回true即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$</strong>，因为哈希表只需要保留模k后第一次出现的索引，<strong>空间复杂度为$O(k)$</strong>。</p>
<p>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public boolean checkSubarraySum(int[] nums, int k) {</span><br><span class="line">        HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">        map.put(0, -1);</span><br><span class="line">        int cur = 0;</span><br><span class="line">        for (int i = 0; i &lt; nums.length; i++) {</span><br><span class="line">            cur = (cur + nums[i]) % k;</span><br><span class="line">            if (map.containsKey(cur)) {</span><br><span class="line">                if (map.get(cur) + 1 &lt; i) {</span><br><span class="line">                    return true;</span><br><span class="line">                }</span><br><span class="line">            } else {</span><br><span class="line">                map.put(cur, i);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun checkSubarraySum(nums: IntArray, k: Int): Boolean {</span><br><span class="line">        val map = mutableMapOf&lt;Int, Int&gt;(0 to -1)</span><br><span class="line">        var cur = 0</span><br><span class="line">        for ((idx, x) in nums.withIndex()) {</span><br><span class="line">            cur = (cur + x) % k</span><br><span class="line">            if (map.containsKey(cur)) {</span><br><span class="line">                if (idx - map[cur]!! &gt; 1) {</span><br><span class="line">                    return true</span><br><span class="line">                }</span><br><span class="line">            } else {</span><br><span class="line">              map[cur] = idx</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return false</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比两种语言，可以看出在哈希表的获取和插入时，<strong>Java语言必须通过put和get方法进行操作，而Kotlin可以类似于数组一样进行操作</strong>，但是<strong>Kotlin语言获取哈希表中的value时，要防止为null，否则无法直接和数值进行计算，因此要使用特殊符号?:0(如果为空则等于0)或者!!(一定不为空)</strong>。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  前缀和的题目也已经做过很多次了，多总结，多练习，时间久了就会从量变引起质变。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>和为K的子数组(Leetcode 1074)</title>
    <url>/2021/05/31/program%20Leetcode1074/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1074.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是一个困难题，问题描述比较简单，就是子矩阵之和等于target，求子矩阵的个数。思路很容易想到，但是能否找到一种时间复杂都最小的方法呢？<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>看到这个题目，一开始并没有联想到Leetcode560题，而是直接使用二维数组前缀和来求解。首先计算二维数组curSum[i, j]，其中[i, j]代表从(0, 0)到(i, j)的所有元素之和。然后使用四重循环遍历矩阵的起始行，起始列，终止行和终止列，算法的时间复杂度为$O(n^2m^2)$，其中n和m分别代表行数和列数。</p>
<p>上述方法虽然可以得到正确结果，但是当n和m为1e2时，计算量达到1e8，这会TLE。因此无法正确提交，这时想到Leetcode560题，该题目是一维的问题，二维也可以类似求解。</p>
<p>遍历起始行i，在每个起始行中遍历终止行j，对于每一个终止行类似于一维问题，遍历终止列c，我们记录从[i, 0]到[j, c]之和sums，查看哈希表中sums - target的个数，然后将sums放入哈希表中。假如[i, 0]到[j, c1]之和为k1，从[i, 0]到[j, c2]之和为k1 + target，说明，从[i, c1 + 1]到[j, c2]的子矩阵是满足之和为target的。</p>
<p>算法只需要遍历起始行，终止行和终止列即可，且在循环时只需要用一维数组记录矩阵[i, 0]到[j, c]之和。<strong>时间复杂度为$O(n^2m)$，空间复杂度为$O(m)$</strong>。</p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def numSubmatrixSumTarget(self, matrix, target):</span><br><span class="line">        row, col = len(matrix), len(matrix[0])</span><br><span class="line">        res = 0</span><br><span class="line">        for i in range(row):</span><br><span class="line">            dp = [0] * (col + 1)</span><br><span class="line">            for j in range(i, row):</span><br><span class="line">                for c in range(col):</span><br><span class="line">                    dp[c + 1] += matrix[j][c]</span><br><span class="line">                dic = defaultdict(int)</span><br><span class="line">                cur = 0</span><br><span class="line">                for x in dp:</span><br><span class="line">                    cur += x</span><br><span class="line">                    res += dic[cur - target]</span><br><span class="line">                    dic[cur] += 1</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Kotlin语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    fun numSubmatrixSumTarget(matrix: Array&lt;IntArray&gt;, target: Int): Int {</span><br><span class="line">        val row = matrix.size</span><br><span class="line">        val col = matrix[0].size</span><br><span class="line">        var res = 0</span><br><span class="line">        for (i in 0 until row) {</span><br><span class="line">            val dp = IntArray(col + 1)</span><br><span class="line">            for (j in i until row) {</span><br><span class="line">                for (c in 0 until col) {</span><br><span class="line">                    dp[c + 1] += matrix[j][c]</span><br><span class="line">                }</span><br><span class="line">                val dic = mutableMapOf&lt;Int, Int&gt;()</span><br><span class="line">                var cur = 0</span><br><span class="line">                for (x in dp) {</span><br><span class="line">                    cur += x</span><br><span class="line">                    res += dic[cur - target] ?: 0</span><br><span class="line">                    dic[cur] = (dic[cur] ?: 0)  + 1</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  前缀和是经典的笔试面试题，因为这些年内卷的太严重了，导致算法题的难度逐渐增加，普通的前缀和已经不能满足要求了，需要小伙伴们多做一些难度较大的题目来扩展自己的视野。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>PPT排版</title>
    <url>/2021/05/30/skill%20PPT/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">PPT</font></strong></center><p></p>
<h1 id="PPT介绍"><a href="#PPT介绍" class="headerlink" title="PPT介绍"></a><font size="5" color="red">PPT介绍</font></h1><p>  <strong>PPT(Microsoft Office PowerPoint):</strong>是微软公司的演示文稿软件，用户可以再投影仪或者计算机上进行演示，也可以制作海报，胶片等。尤其对于学生、职工来说，PPT是必不可少的工具之一。PPT常用在组会，报告，答辩等场合，很多人都会做PPT，然而是否真正会做PPT呢？这篇博客的目的是分享一些常用的PPT制作技巧和排版方式。其中很多素材来自珞珈老师的PPT制作教程，老师讲解的很好，课程可以在Bilibili中搜索到。<br><a id="more"></a></p>
<h1 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a><font size="5" color="red">PPT</font></h1><h2 id="PPT基本操作"><a href="#PPT基本操作" class="headerlink" title="PPT基本操作"></a><font size="4">PPT基本操作</font></h2><p>1.设置PPT页面尺寸，点击设计菜单栏下的幻灯片大小选项，然后选择自定义幻灯片大小即可</p>
<p><img src="/images/SKILL/ppt14.png" alt="1"><br>2.Ctrl + Z撤回操作<br>3.保存为PDF文件，可以用于制作海报等场景，点击文件菜单栏，选择导出，创建PDF/XPS文档</p>
<p><img src="/images/SKILL/ppt15.png" alt="1"><br>4.层的概念：和PS类似，上面的图层会遮挡下面图层的形状，如果想体现下方某个形状，可以将下方的形状上移或者置于顶层</p>
<h2 id="生成页面"><a href="#生成页面" class="headerlink" title="生成页面"></a><font size="4">生成页面</font></h2><p>1.使用开始菜单栏下的新建幻灯片选项<br>2.使用快捷键Ctrl + M<br>3.使用回车快捷键</p>
<p><img src="/images/SKILL/ppt1.png" alt="1"></p>
<h2 id="调整当前视图和预览视图的比例"><a href="#调整当前视图和预览视图的比例" class="headerlink" title="调整当前视图和预览视图的比例"></a><font size="4">调整当前视图和预览视图的比例</font></h2><p>选择当前视图和预览视图中间的实线，左右拖动可以调整比例<br><img src="/images/SKILL/ppt2.png" alt="1"></p>
<h2 id="调整当前视图大小"><a href="#调整当前视图大小" class="headerlink" title="调整当前视图大小"></a><font size="4">调整当前视图大小</font></h2><p>选择右下角的缩放栏，可以调节视图大小，点击右侧的自适应选项可以调整到最合适的尺寸<br><img src="/images/SKILL/ppt3.png" alt="1"></p>
<h2 id="页面移动"><a href="#页面移动" class="headerlink" title="页面移动"></a><font size="4">页面移动</font></h2><p>如果第2页PPT想放到第1页，可以在预览视图中，将第2页拖动到第1页前面。如果跨越页面比较多，如从第10页移动到第1页，可以点击右下角的幻灯片浏览选项，然后将第10页拖拽到第1页。<br><img src="/images/SKILL/ppt4.png" alt="1"></p>
<h2 id="页面复制、粘贴和删除"><a href="#页面复制、粘贴和删除" class="headerlink" title="页面复制、粘贴和删除"></a><font size="4">页面复制、粘贴和删除</font></h2><p>复制：和文档复制一样，在预览视图中选择一页PPT，使用快捷键Ctrl+C，即可复制到剪贴板中<br>粘贴：在预览视图中点击想要插入的地方，此时可以选择两个页面之间的空白区域，使用快捷键Ctrl+V，即可插入在两页面之间<br>删除：在预览视图中点击想删除的页面，按下后退快捷键BackSpace或者删除快捷键Delete即可删除该页面，如果想删除多个页面，则可以点击幻灯片浏览，点击要删除的起始页面，然后按下Shift键，再点击要删除的最终页面即可选中中间的所有页面，然后按下Delete即可。</p>
<h2 id="插入文本框"><a href="#插入文本框" class="headerlink" title="插入文本框"></a><font size="4">插入文本框</font></h2><p>1.在开始菜单栏下的形状内，或者插入菜单栏下的形状选项内，可以选择横向或纵向文本框。</p>
<p><img src="/images/SKILL/ppt5.png" alt="1"><br>2.在插入菜单栏下有文本框的选项，可以点击默认横向文本框，也可以点击下面的小箭头，选择横向或者纵向文本框。</p>
<p><img src="/images/SKILL/ppt6.png" alt="1"><br>关于文字的操作，和Word基本相同，可以调整大小，字体，颜色，间距，斜体等操作</p>
<h2 id="插入图形"><a href="#插入图形" class="headerlink" title="插入图形"></a><font size="4">插入图形</font></h2><p>1.在开始菜单栏下的形状内，点击右侧第三个按钮，即可显示所有形状，或者点击插入菜单栏下的形状选项，也可以显示所有形状。</p>
<p><img src="/images/SKILL/ppt7.png" alt="1"><br>2.选择相应的形状，在画布上拖拽即可生成想要的图形，如果想生成标准图形，比如圆形，拖拽很可能生成一个椭圆，此时有两种方法。</p>
<p>方法一：点击右键，选择大小和位置，然后在右侧会出现设置形状格式的设置栏，在其中可以设置需要的宽和高。将椭圆的宽和高都设为相同的数字，就会变为正圆。</p>
<p><img src="/images/SKILL/ppt8.png" alt="1"><br>方法二：不拖拽生成椭圆，直接左键点击，即可生成标准正圆。<br>3.如果想等比例放大，可以按住Shift键，然后点击左上，左下，右上和右下四个拐角，即可等比例放大图形。如果想让图形中心不变，任意放大图形，可以按住Ctrl键，改变形状即可。如果想中心不变等比例放大，则需要同时按下Shift和Ctrl键。<br>4.可以点击右键设置填充颜色和轮廓，可以根据需要设置填充的样式或者轮廓的大小，线形等功能。</p>
<p><img src="/images/SKILL/ppt9.png" alt="1"></p>
<h2 id="形状高阶操作"><a href="#形状高阶操作" class="headerlink" title="形状高阶操作"></a><font size="4">形状高阶操作</font></h2><p>1.设置透明度，右键图形，点击设置形状格式，然后在右侧任务窗格中形状选项的填充与线条下可以调整透明度</p>
<p><img src="/images/SKILL/ppt59.png" alt="1"><br>2.渐变填充，在填充与线条下，选择渐变填充，然后可以看到渐变光圈调节框，可以修改颜色光圈调节渐变的属性</p>
<p><img src="/images/SKILL/ppt60.png" alt="1"><br>3.图片填充，在填充与线条下，选择图片或纹理填充，然后选中要填充的图片，按下Ctrl + C，将图片保存至剪贴板中，然后在形状任务窗格里点击插入图片来自剪贴板，而且一般要选择将图片平铺为纹理，否则图片可能产生变形，但是平铺时可能导致形状中的图片是非重点区域，可以通过调整偏移量，对其方式等将感兴趣的区域调整在形状中心</p>
<p><img src="/images/SKILL/ppt61.png" alt="1"><br>4.调整形状的样式，在形状中，某些图形可以调整样式，如圆角矩形，可以点击大小调节点旁边的黄色端点，左右拖动可以控制圆角的大小，同理，拖动三角形顶点，可以控制三角形的形状。但是不是所有的图形都可以调整，例如椭圆，没有调节点</p>
<p><img src="/images/SKILL/ppt67.png" alt="1"><br>5.编辑顶点，右键图形，点击编辑顶点，右键要编辑的顶点，可以增加顶点，删除顶点，平滑顶点，或者修改边的形状等，小伙伴们可以自己尝试使用</p>
<p><img src="/images/SKILL/ppt68.png" alt="1"></p>
<h2 id="形状组合"><a href="#形状组合" class="headerlink" title="形状组合"></a><font size="4">形状组合</font></h2><p>图形组合至少使用两个图形，因此使用一个圆形和一个矩形进行介绍<br>1.联合：对两个图形进行并集操作。选中两个图形，点击格式菜单栏下的合并形状，然后选择联合</p>
<p><img src="/images/SKILL/ppt62.png" alt="1"><br>2.组合：对两个图形进行异或操作。选中两个图形，点击格式菜单栏下的合并形状，然后选择组合</p>
<p><img src="/images/SKILL/ppt63.png" alt="1"><br>3.拆分：将两张图形根据边界进行拆分。选中两个图形，点击格式菜单栏下的合并形状，然后选择拆分</p>
<p><img src="/images/SKILL/ppt64.png" alt="1"><br>4.相交：对两个图形进行交集操作。选中两个图形，点击格式菜单栏下的合并形状，然后选择相交</p>
<p><img src="/images/SKILL/ppt65.png" alt="1"><br>5.剪除：从先选择的图形中减去后选择的图形。选中两个图形，点击格式菜单栏下的合并形状，然后选择剪除</p>
<p><img src="/images/SKILL/ppt66.png" alt="1"></p>
<h2 id="形状实战"><a href="#形状实战" class="headerlink" title="形状实战"></a><font size="4">形状实战</font></h2><p>在学习完形状高阶操作和形状组合后，基本上可以实现任意想要的形状，一些常用的形状可以到<a href="https://www.iconfont.cn/" target="_blank" rel="noopener">阿里巴巴矢量图标库</a>中下载。下面展示如何使用PPT图形制作一个简单的照相机图标<br><img src="/images/SKILL/ppt69.png" alt="1"><br>首先观察图标中的样式，由三个圆角矩形和一个圆环组成。<br>1.构建四个基本形状</p>
<p><img src="/images/SKILL/ppt70.png" alt="1"><br>2.对左上角和大的圆角矩形进行联合，设置无轮廓；修改小的圆角矩形的填充颜色，设置无轮廓；调整圆形轮廓的线宽</p>
<p><img src="/images/SKILL/ppt71.png" alt="1"></p>
<h2 id="对齐操作"><a href="#对齐操作" class="headerlink" title="对齐操作"></a><font size="4">对齐操作</font></h2><p>在PPT的制作过程中，常常需要合理放置图形的位置，下面讲解对齐操作。对齐操作至少使用两个图形，因此使用三个圆形进行介绍。选中三个图形，点击格式菜单栏下的对齐，可以进行样式选择<br>1.左对齐、右对齐、顶端对齐和底端对齐，是指将其他图形和最左端、最右端、最顶端和最底端的图形对齐，以左对齐为例，如下图所示</p>
<p><img src="/images/SKILL/ppt89.png" alt="1"><br>2.横向分布和纵向分布，是指选取两侧形状的位置不动，将中间的所有图形等比例分布。如果选择横向分布，则最左端和最右端的图形位置不动，如果选择纵向分布，则最上端和最下端的图形位置不动，以横向分布为例，如下图所示</p>
<p><img src="/images/SKILL/ppt90.png" alt="1"></p>
<h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a><font size="4">插入图片</font></h2><p>1.点击插入菜单栏下的图片选项，会弹出图片选择路径，选择合适的图片即可插入PPT中</p>
<p><img src="/images/SKILL/ppt10.png" alt="1"><br>2.一般来说图片插入后都需要调整大小，和形状类似，可以选择拖动八个方位调整大小，要注意的是图片拖动四个角是等比例放大，而且一般为了保持图片宽高比不失衡，都不会拖动上下和左右四个方向。<br>3.如果要修改图片的宽高比，如应用于16：9的背景，则一般先放大，使图片的一对边等于画布的尺寸，另一对边大于画布尺寸，然后采用裁剪的方式，右键图片，选择裁剪，八个方向的拖拽标记会变为T形，此时选择裁剪大于画布尺寸的对边，移动其中的T形标记可以裁剪图片。</p>
<p><img src="/images/SKILL/ppt11.png" alt="1"><br>4.也可以选中图片，点击格式菜单栏下，右侧裁剪选项下方的倒三角形按钮，选择一个合适的裁剪形状，并选择合适的宽高比，会出现一个裁剪框，将要保留的部分放在白色区域中即可。</p>
<p><img src="/images/SKILL/ppt12.png" alt="1"><br>5.如果想对图片增加一些特效，可以选择图片，点击格式菜单栏或者右键设置图片格式，可以在里面设置各种图片颜色、样式、边框、效果等功能，小伙伴们可以根据需要多多尝试，这里不做过多介绍。当需要取消这些效果时，点击重设图片即可。</p>
<p><img src="/images/SKILL/ppt13.png" alt="1"></p>
<h2 id="图片去除背景"><a href="#图片去除背景" class="headerlink" title="图片去除背景"></a><font size="4">图片去除背景</font></h2><p>1.选中图片，点击格式菜单栏下的删除背景</p>
<p><img src="/images/SKILL/ppt101.png" alt="1"><br>2.其中紫色的部分为要删除的区域，然后将调整框缩放到合适的位置</p>
<p><img src="/images/SKILL/ppt100.png" alt="1"><br>3.可以编辑要保留的区域和要删除的区域来调整前景和背景区域</p>
<p><img src="/images/SKILL/ppt99.png" alt="1"><br>4.最后点击保留更改或者点击空白区域可以进行背景去除</p>
<p><img src="/images/SKILL/ppt102.png" alt="1"><br>这种操作常常用于虚化背景，将整张图片进行虚化，然后在相同的位置放置原图，并中扣除人物前景进行保留，因此只对背景虚化</p>
<p><img src="/images/SKILL/ppt103.png" alt="1"></p>
<h2 id="字体选择"><a href="#字体选择" class="headerlink" title="字体选择"></a><font size="4">字体选择</font></h2><p>粗犷的字体：微软雅黑加粗，常用于封面、标题等<br>高端的字体：微软雅黑Light，常用于演讲、正文等<br>国风的字体：楷体、宋体，常用于党建、文化、历史等<br><img src="/images/SKILL/ppt16.png" alt="1"></p>
<h2 id="字体的修改"><a href="#字体的修改" class="headerlink" title="字体的修改"></a><font size="4">字体的修改</font></h2><p>这个内容和Word基本相同，这里不做过多介绍，要修改哪部分文字，选中该文字，然后在开始菜单栏字体区域中进行调整即可。可以对字体进行加粗，斜体，下划线，调整颜色，文字间距等等。<br><img src="/images/SKILL/ppt17.png" alt="1"></p>
<h2 id="字体特效"><a href="#字体特效" class="headerlink" title="字体特效"></a><font size="4">字体特效</font></h2><p>字体的特效和字体的修改类似，选择要增加特效的字体，然后点击格式菜单栏，可以看到艺术字样式的区域，可以设置已有的艺术字样式，或者给文本进行填充，设置轮廓，或者在文本效果中添加阴影，映像等操作。<br><img src="/images/SKILL/ppt18.png" alt="1"></p>
<h2 id="字体外边框"><a href="#字体外边框" class="headerlink" title="字体外边框"></a><font size="4">字体外边框</font></h2><p>1.右键点击文本框，选择轮廓，然后设置需要的颜色、线宽等。这种方法修改的是文本框的参数，因此无法绘制其他形状的边框</p>
<p><img src="/images/SKILL/ppt19.png" alt="1"><br>2.绘制之前学习的任意形状，然后将形状放在合适的位置，右键形状，设置无填充颜色，然后再右键轮廓，设置需要的颜色、线宽等，即可设置任意形状的字体外边框</p>
<p><img src="/images/SKILL/ppt20.png" alt="1"><br>推荐使用方法2，设置后效果如下</p>
<p><img src="/images/SKILL/ppt21.png" alt="1"></p>
<h2 id="图文结合"><a href="#图文结合" class="headerlink" title="图文结合"></a><font size="4">图文结合</font></h2><p>在图片中，插入合适的文字<br><img src="/images/SKILL/ppt22.png" alt="1"></p>
<h2 id="文字笔画拆分"><a href="#文字笔画拆分" class="headerlink" title="文字笔画拆分"></a><font size="4">文字笔画拆分</font></h2><p>1.在文本框中输入要拆分的文字，并设置合适的字体和大小<br>2.选择形状，插入一个大于文本框的矩形框<br>3.选中文本框和矩形框，点击格式菜单栏下的合并形状，然后选择拆分</p>
<p><img src="/images/SKILL/ppt57.png" alt="1"><br>4.此时已经将文字中的笔画进行了拆分，然后移动相应的距离，并将拆分后形状的透明度设置较高，则可以充当背景，再其中添加一些主要的字和修饰作为前景即可</p>
<p><img src="/images/SKILL/ppt58.png" alt="1"></p>
<h2 id="图片文字镂空"><a href="#图片文字镂空" class="headerlink" title="图片文字镂空"></a><font size="4">图片文字镂空</font></h2><p>1.在图片中，插入合适的文字<br>2.设置和幕布同样大小的矩形框，并设置填充为黑色，无轮廓，并且设置形状格式中透明度为需要的值</p>
<p><img src="/images/SKILL/ppt23.png" alt="1"><br>3.将幕布缩放，选择矩形框，按下Shift键，从幕布外开始拖动选中要镂空的文本框，然后点击格式菜单栏下的合并形状，选择剪除。</p>
<p><img src="/images/SKILL/ppt24.png" alt="1"></p>
<h2 id="微信九宫格"><a href="#微信九宫格" class="headerlink" title="微信九宫格"></a><font size="4">微信九宫格</font></h2><p>在朋友圈中常常出现这样的图片，将一张图片切分为3x3的方块，这是如何做到的呢？下面介绍两种方法<br><img src="/images/SKILL/ppt114.png" alt="1"></p>
<h3 id="脚本编程"><a href="#脚本编程" class="headerlink" title="脚本编程"></a><font size="4">脚本编程</font></h3><p>这个方法适合于程序员朋友，对于一些仅仅学习商务办公PPT的小伙伴们不太友好。<br>可以使用高级语言来完成，如C++、Java、Python等语言，都可以扩展图形图像库<br>1.先读取图片，然后将其resize到3的倍数<br>2.图片在程序中以矩阵的方式出现，先按照行拆分矩阵，再按列拆分矩阵<br>3.对每一个矩阵进行分别保存即可<br>该方法非常推荐，因为使用脚本不仅仅可以完成简单的裁剪操作，还可以按照自己需要的方式模糊，加噪等，最重要的是可以批处理图片，可以读取指定目录下的所有图片，都进行九宫格裁剪，这是第二种方法无法做到的。</p>
<h3 id="PPT表格绘制"><a href="#PPT表格绘制" class="headerlink" title="PPT表格绘制"></a><font size="4">PPT表格绘制</font></h3><p>这里再介绍一种仅仅使用PPT实现的方法<br>1.点击插入菜单栏下的表格，选择3x3样式</p>
<p><img src="/images/SKILL/ppt145.png" alt="1"><br>2.选中所有表格，点击布局菜单栏，设置合适的高度和宽度</p>
<p><img src="/images/SKILL/ppt146.png" alt="1"><br>3.插入图片，将图片放大到略大于表格大小，然后选中所有表格，进行图片填充，这部分内容可以参考形状高阶操作部分内容，将图片选择为平铺，并选择对齐方式为靠上，然后右键表格进行图片另存为增强型Windows元文件(.emf)<br>4.读取该图片，右键进行取消组合，此时可以将九宫格进行拆分，删掉其中的边框线即可，然后对每一格进行分别保存</p>
<p><img src="/images/SKILL/ppt147.png" alt="1"></p>
<h2 id="配色"><a href="#配色" class="headerlink" title="配色"></a><font size="4">配色</font></h2><p>1.确定主题色，一般一个PPT都有一个主基调，是标题，图形填充的颜色，这个颜色往往接近于Logo的颜色，或者从Logo中取色<br>2.颜色不要过多，一套PPT中颜色尽量不要超过5种<br>3.重点突出部分的颜色要鲜明，且突出部分不要太多，全是重点等于没有重点<br>4.不会配色可以多学习其他优秀的PPT设计，从中提取颜色<br>5.为了某一页PPT和谐，可以从当前页的配图中选取颜色<br>6.通用技巧：如果主题色较亮，如黄、绿、蓝，可以使用黑色背景，白色文字。如果主题色较暗，如深红、紫色，可以使用白色背景，黑色文字</p>
<h2 id="排版原则"><a href="#排版原则" class="headerlink" title="排版原则"></a><font size="4">排版原则</font></h2><p>1.对齐：段落和段落、文字和图、图和图之间都尽量对齐<br>2.对比：对比的原则是相同的完全一样，不相同的完全不同，不要让观看者找不同<br>3.亲密：当条形图对比时，可以将有关联的数据放置的更接近，无关的数据放置的更疏远<br>4.重复：整套PPT都有一些内容是重复的，尤其是关键配色，字体、风格等</p>
<h2 id="标尺、网格线、参考线"><a href="#标尺、网格线、参考线" class="headerlink" title="标尺、网格线、参考线"></a><font size="4">标尺、网格线、参考线</font></h2><p>点击视图菜单栏，可以看到三个复选框，点击即可添加标尺、网格线、参考下，用来PPT排版对齐的。其中点击左下角的箭头，可以设置网格线的疏密，右键参考线也可以设置增加或删除参考线或者修改参考线的颜色。<br><img src="/images/SKILL/ppt156.png" alt="1"></p>
<h2 id="经典排版"><a href="#经典排版" class="headerlink" title="经典排版"></a><font size="4">经典排版</font></h2><p>1.分割型：左右分割、上下分割，常用于目录页、过渡页、正文页</p>
<p><img src="/images/SKILL/ppt38.png" alt="1"><br>2.居中型：文字放在最中间，常用于封面页，过渡页</p>
<p><img src="/images/SKILL/ppt98.png" alt="1"><br>3.分裂型：类似于分割型，但是分割为多个部分，常用于目录页、正文页</p>
<p><img src="/images/SKILL/ppt142.png" alt="1"><br>4.矩阵型：并列很多图片或标题，常用于目录页、正文页</p>
<p><img src="/images/SKILL/ppt144.png" alt="1"></p>
<h2 id="经典形状样式"><a href="#经典形状样式" class="headerlink" title="经典形状样式"></a><font size="4">经典形状样式</font></h2><p><img src="/images/SKILL/ppt185.png" alt="1"><br>可以选择矩形、三角形、梯形、圆形、菱形、六边形或者某些图形的部分区域作为形状，进行图片填充</p>
<h2 id="经典页标题样式"><a href="#经典页标题样式" class="headerlink" title="经典页标题样式"></a><font size="4">经典页标题样式</font></h2><p><img src="/images/SKILL/ppt186.png" alt="1"><br>可以使用上面三种珞珈老师PPT教程中推荐的三种标题样式，也可以学习其他优秀作品的样式</p>
<h2 id="经典小标题样式"><a href="#经典小标题样式" class="headerlink" title="经典小标题样式"></a><font size="4">经典小标题样式</font></h2><p><img src="/images/SKILL/ppt187.png" alt="1"><br>上面六种样式，我最喜欢用的是第三种和第六种，简洁美观，小伙伴们可以根据需要选择自己喜欢的2-3种使用即可</p>
<h2 id="元素组合拼接"><a href="#元素组合拼接" class="headerlink" title="元素组合拼接"></a><font size="4">元素组合拼接</font></h2><p>认真学习上面三种经典的样式，随意组合都可以形成很好看的PPT版式<br><img src="/images/SKILL/ppt188.png" alt="1"><br>上面这页PPT就是使用梯形的形状样式、第二种页标题和第六种小标题样式进行拼接而成的</p>
<p><img src="/images/SKILL/ppt189.png" alt="1"><br>上面这页PPT就是使用圆形和上下三角形的形状样式和第六种小标题样式进行拼接而成的</p>
<p><img src="/images/SKILL/ppt181.png" alt="1"><br>上面这页PPT就是使用矩形的形状样式、第一种页标题、第五种和第六种小标题样式进行拼接而成的。而且使用这种方法制作的PPT，下次更换主题需要重新制作PPT时，只需要修改图片和相应的主题颜色即可</p>
<p><img src="/images/SKILL/ppt190.png" alt="1"></p>
<h2 id="制作PPT的样式"><a href="#制作PPT的样式" class="headerlink" title="制作PPT的样式"></a><font size="4">制作PPT的样式</font></h2><h3 id="大标题型PPT"><a href="#大标题型PPT" class="headerlink" title="大标题型PPT"></a><font size="4">大标题型PPT</font></h3><p>这类PPT的特点是当前页仅有一句关键的话，或者作为引领主题的PPT首页。<br><img src="/images/SKILL/ppt72.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt75.png" alt="1"><br>2.在幕布中间绘制一个平行四边形，设置填充颜色为黑色，并设置合适的透明度(30%左右)，然后设置边框颜色为白色，宽度为2.25磅</p>
<p><img src="/images/SKILL/ppt76.png" alt="1"><br>3.绘制一个面积稍小一些的平行四边形，设置无填充颜色，设置边框颜色为白色，宽度为1.5磅，设置合适的透明度(50%左右)</p>
<p><img src="/images/SKILL/ppt77.png" alt="1"><br>4.在平行四边形中插入文本框，设置合适的字体、大小、颜色</p>
<p><img src="/images/SKILL/ppt78.png" alt="1"><br>5.在文本框下方加入一条直线，增加美感</p>
<p><img src="/images/SKILL/ppt79.png" alt="1"></p>
<p><img src="/images/SKILL/ppt91.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt92.png" alt="1"><br>2.如果背景太亮或者太花，可以加上一个黑色的蒙版</p>
<p><img src="/images/SKILL/ppt93.png" alt="1"><br>3.插入文本框，设置合适的字体、大小、颜色</p>
<p><img src="/images/SKILL/ppt94.png" alt="1"><br>4.先绘制一个矩形框，将中国科学技术大学八个字框起来，并设置无填充颜色，轮廓为白色，然后再使用任意多边形绘制旁边的矩形框，先点击起始点，然后按住Shift键，则可以水平垂直绘制直线，绘制完成后，按下回车键，则可以停止绘制，设置轮廓为白色即可</p>
<p><img src="/images/SKILL/ppt98.png" alt="1"></p>
<p><img src="/images/SKILL/ppt95.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt96.png" alt="1"><br>2.直接在图片中留白的位置插入文本框，设置合适的字体、大小、颜色即可</p>
<p><img src="/images/SKILL/ppt97.png" alt="1"></p>
<p><img src="/images/SKILL/ppt74.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt84.png" alt="1"><br>2.在图形中选择任意多边形，沿着山脉的走向，左键点击绘制端点，最后一个端点点击起始点会形成一个封闭图形，然后设置填充颜色和透明度，选择轮廓为白色，然后右键形状编辑端点，将图形的左、右和底边稍微超出幕布，这样可以只保留上边缘的边框线</p>
<p><img src="/images/SKILL/ppt85.png" alt="1"><br>3.绘制圆形，设置填充颜色为黑色，轮廓为白色，并复制多个圆形作为山脉走向折线的端点。</p>
<p><img src="/images/SKILL/ppt86.png" alt="1"><br>4.可以添加一些文本，并且从阿里巴巴矢量库中下载一些形状进行美化</p>
<p><img src="/images/SKILL/ppt87.png" alt="1"></p>
<p><img src="/images/SKILL/ppt149.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.选择一些背景颜色作为备用，建立一张蒙版，然后选择渐变填充，类型选择射线，并使用备用颜色作为渐变光圈，调整到满意的效果</p>
<p><img src="/images/SKILL/ppt150.png" alt="1"><br>2.建立很多圆形，并设置大小为0.05，填充颜色为白色，无轮廓，作为星星</p>
<p><img src="/images/SKILL/ppt151.png" alt="1"><br>3.将这些星星组合，并复制多组，调整位置，然后将所有星星取消组合。随机选择部分星星设置透明度</p>
<p><img src="/images/SKILL/ppt152.png" alt="1"><br>4.绘制直线，设置渐变线，调整渐变光圈都为白色，一端设置透明度0，另一端设置透明度100</p>
<p><img src="/images/SKILL/ppt153.png" alt="1"><br>5.复制多个直线，并设置长短各不相同</p>
<p><img src="/images/SKILL/ppt154.png" alt="1"><br>6.插入合适的形状和文本框修饰</p>
<p><img src="/images/SKILL/ppt155.png" alt="1"></p>
<p><img src="/images/SKILL/ppt157.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt162.png" alt="1"><br>2.建立一个半透明的矩形蒙版</p>
<p><img src="/images/SKILL/ppt163.png" alt="1"><br>3.在矩形蒙版中添加合适的文本框和修饰</p>
<p><img src="/images/SKILL/ppt164.png" alt="1"></p>
<p><img src="/images/SKILL/ppt158.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.将椭圆和矩形进行相交，制作合适的形状</p>
<p><img src="/images/SKILL/ppt165.png" alt="1"><br>2.在形状中进行图片填充，这部分内容可以参考形状高阶操作部分内容</p>
<p><img src="/images/SKILL/ppt166.png" alt="1"><br>3.在空白区域插入合适的文本框和修饰</p>
<p><img src="/images/SKILL/ppt167.png" alt="1"></p>
<p><img src="/images/SKILL/ppt159.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.创建两个矩形，选择合适的填充颜色，设置无轮廓。然后插入合适的文本内容</p>
<p><img src="/images/SKILL/ppt168.png" alt="1"><br>2.新建一个小矩形，设置轮廓为白色，并进行图片填充，这部分内容可以参考形状高阶操作部分内容。</p>
<p><img src="/images/SKILL/ppt169.png" alt="1"></p>
<p><img src="/images/SKILL/ppt160.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.创建矩形，并插入合适的文本框和修饰</p>
<p><img src="/images/SKILL/ppt170.png" alt="1"><br>2.在矢量库中选择一些图片修饰，放入矩形框中</p>
<p><img src="/images/SKILL/ppt171.png" alt="1"></p>
<p><img src="/images/SKILL/ppt161.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.设置一个大矩形，选择无填充，边框为黄色，设置一个中等矩形，填充颜色为黄色，无边框，再设置一个最小的矩形，无填充颜色，边框为白色</p>
<p><img src="/images/SKILL/ppt173.png" alt="1"><br>2.插入合适的文本框和修饰</p>
<p><img src="/images/SKILL/ppt172.png" alt="1"></p>
<p><img src="/images/SKILL/ppt176.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.选择一张图片，将其缩放、裁剪到半张幕布大小</p>
<p><img src="/images/SKILL/ppt182.png" alt="1"><br>2.插入合适的Logo作为背景，图片的透明度可以使用形状填充再调整形状的透明度来设置</p>
<p><img src="/images/SKILL/ppt183.png" alt="1"><br>3.在另外半张幕布上添加合适的文本框，注意文本框的透明度和文字的透明度可以分别设置</p>
<p><img src="/images/SKILL/ppt184.png" alt="1"></p>
<h3 id="小标题型PPT"><a href="#小标题型PPT" class="headerlink" title="小标题型PPT"></a><font size="4">小标题型PPT</font></h3><p>这类PPT的特点是汇报人对关键内容进行解释和说明，可能是内容较为复杂或者文本内容较为抽象不便于展开。<br><img src="/images/SKILL/ppt73.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt80.png" alt="1"><br>2.在幕布下方绘制一个矩形框和五个合适大小的圆形，并排列至合适的位置</p>
<p><img src="/images/SKILL/ppt81.png" alt="1"><br>3.选中图形，并进行联合，然后设置填充颜色，最好使用取色器选择背景中的一个深色，并且设置轮廓线为白色，选择联合后的图形进行等比例放大，这步操作是为了使形状的底部和两侧不显露白色边框</p>
<p><img src="/images/SKILL/ppt82.png" alt="1"><br>4.选择合适的小图标，然后在下方添加子标题和相应的文字即可</p>
<p><img src="/images/SKILL/ppt83.png" alt="1"></p>
<p><img src="/images/SKILL/ppt25.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt31.png" alt="1"><br>2.选择形状，绘制两个矩形框，设置填充颜色，并设置无轮廓，分别放在顶端和底端</p>
<p><img src="/images/SKILL/ppt32.png" alt="1"><br>3.插入合适的当前页面标题，如本页介绍坚持，则可以在顶端写上总标题，并用形状中的直线将中文和英文分开，直线设置一定的宽度</p>
<p><img src="/images/SKILL/ppt33.png" alt="1"><br>4.根据要介绍的部分设置相应数量的子标题形状，这里使用圆形放置标题，调整圆形的颜色和大小，并点击形状右键设置形状格式，调整圆形的透明度</p>
<p><img src="/images/SKILL/ppt34.png" alt="1"><br>5.根据子标题的内容，选择合适的小图标，并在下方配上关键字</p>
<p><img src="/images/SKILL/ppt35.png" alt="1"></p>
<p><img src="/images/SKILL/ppt106.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先绘制三角形，并对上面三个顶端对齐，下面两个底端对齐，然后对整体横向分布</p>
<p><img src="/images/SKILL/ppt122.png" alt="1"><br>2.对形状进行图片填充，这部分内容可以参考形状高阶操作部分内容，并插入合适的文本框</p>
<p><img src="/images/SKILL/ppt123.png" alt="1"><br>3.添加直线、点以及矢量图标对PPT进行修饰</p>
<p><img src="/images/SKILL/ppt124.png" alt="1"></p>
<p><img src="/images/SKILL/ppt107.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先绘制背景图形，使用线条类中的任意多边形绘制背景</p>
<p><img src="/images/SKILL/ppt125.png" alt="1"><br>2.使用圆角矩形和普通矩形相交绘制放置图片的形状</p>
<p><img src="/images/SKILL/ppt126.png" alt="1"><br>3.对形状进行图片填充，这部分内容可以参考形状高阶操作部分内容，并插入合适的文本框，因为填充的图片亮度较高，不适合添加白色文本，这里增加了一块半透明黑色幕布</p>
<p><img src="/images/SKILL/ppt127.png" alt="1"><br>4.插入相应数量的圆形和文本作为小标题</p>
<p><img src="/images/SKILL/ppt128.png" alt="1"></p>
<p><img src="/images/SKILL/ppt113.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容，并添加一个半透明的黑色幕布</p>
<p><img src="/images/SKILL/ppt143.png" alt="1"><br>2.绘制圆形，然后进行对齐操作，并对形状图片填充，这部分内容可以参考形状高阶操作部分内容，最后插入合适的小标题文本框</p>
<p><img src="/images/SKILL/ppt144.png" alt="1"></p>
<p><img src="/images/SKILL/ppt174.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.先绘制一个矩形框，将坚持是一种态度七个字框起来，并设置填充颜色为红色，轮廓为白色，然后再使用任意多边形绘制旁边的矩形框，先点击起始点，然后按住Shift键，则可以水平垂直绘制直线，绘制完成后，按下回车键，则可以停止绘制，设置轮廓为白色即可</p>
<p><img src="/images/SKILL/ppt177.png" alt="1"><br>2.插入合适的形状、矢量图标和文本框</p>
<p><img src="/images/SKILL/ppt178.png" alt="1"></p>
<p><img src="/images/SKILL/ppt175.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.绘制最顶部的矩形框和四个小标题矩形，并摆放在合适的位置</p>
<p><img src="/images/SKILL/ppt179.png" alt="1"><br>2.插入合适的形状、矢量图标和文本框</p>
<p><img src="/images/SKILL/ppt180.png" alt="1"></p>
<h3 id="图文结合型PPT"><a href="#图文结合型PPT" class="headerlink" title="图文结合型PPT"></a><font size="4">图文结合型PPT</font></h3><p>这类PPT的特点是汇报人提取出关键的段落，适用于大段文字过于冗长，简短的标题无法包含重要内容的场景。<br><img src="/images/SKILL/ppt26.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片裁剪，切记不要缩放，然后将图片的一条边紧贴幕布，可以根据需要放在左侧、右侧、上侧或者下侧。</p>
<p><img src="/images/SKILL/ppt36.png" alt="1"><br>2.设置该页PPT的总标题，如本页介绍坚持，则可以在右上方写上总标题，并使用直线增加美感</p>
<p><img src="/images/SKILL/ppt37.png" alt="1"><br>3.根据要介绍的部分设置相应数量的子标题形状，这里使用圆形放置标题，调整圆形的颜色和大小，并选择合适的小图标，然后在右侧添加子标题</p>
<p><img src="/images/SKILL/ppt38.png" alt="1"><br>4.可以根据需要设置背景，可以选择公司logo，或者自己制作的一些小形状，这里我就将科大的校徽当作背景，设置合适的颜色并置于底层，即可使文字覆盖在上面</p>
<p><img src="/images/SKILL/ppt39.png" alt="1"></p>
<p><img src="/images/SKILL/ppt27.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt40.png" alt="1"><br>2.设置该页PPT的总标题，如本页介绍坚持，则可以在右上方写上总标题，并使用直线增加美感</p>
<p><img src="/images/SKILL/ppt41.png" alt="1"><br>3.选择圆角矩形，并设置相应的大小、颜色和透明度</p>
<p><img src="/images/SKILL/ppt42.png" alt="1"><br>4.根据要介绍的部分设置相应数量的子标题形状，这里使用圆形放置标题，设置无填充颜色，边框为白色，并根据子标题的内容，选择合适的小图标，并在下方配上关键字</p>
<p><img src="/images/SKILL/ppt43.png" alt="1"><br>5.在子标题下方添加要介绍的文本段落，并设置文字对其方式为居中</p>
<p><img src="/images/SKILL/ppt44.png" alt="1"></p>
<p><img src="/images/SKILL/ppt104.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先绘制形状，这个形状从流程图类中可以找到，也可以使用矩形和圆形组合得到，并绘制一些修饰直线或者弧线</p>
<p><img src="/images/SKILL/ppt115.png" alt="1"><br>2.对形状进行图片填充，这部分内容可以参考形状高阶操作部分内容</p>
<p><img src="/images/SKILL/ppt116.png" alt="1"><br>3.在左侧插入文本框，设置合适的字体、大小、颜色</p>
<p><img src="/images/SKILL/ppt117.png" alt="1"></p>
<p><img src="/images/SKILL/ppt105.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先绘制形状，这个形状从星与旗帜类中可以找到，选择该形状，并于矩形相交</p>
<p><img src="/images/SKILL/ppt118.png" alt="1"><br>2.插入一个圆形，并对两个形状进行图片填充，这部分内容可以参考形状高阶操作部分内容</p>
<p><img src="/images/SKILL/ppt119.png" alt="1"><br>3.插入一个类似的波形图，作为背景，填充的颜色可以从图片中取色，并设置合适的透明度</p>
<p><img src="/images/SKILL/ppt120.png" alt="1"><br>4.在右侧插入文本框，设置合适的字体、大小、颜色</p>
<p><img src="/images/SKILL/ppt121.png" alt="1"></p>
<p><img src="/images/SKILL/ppt108.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先绘制长度不等的平行四边形，并进行组合</p>
<p><img src="/images/SKILL/ppt129.png" alt="1"><br>2.对组合后的形状进行图片填充，这部分内容可以参考形状高阶操作部分内容，然后插入文本框</p>
<p><img src="/images/SKILL/ppt130.png" alt="1"></p>
<p><img src="/images/SKILL/ppt109.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.首先使用矩形绘制黑色幕布，并设置合适的透明度</p>
<p><img src="/images/SKILL/ppt131.png" alt="1"><br>2.插入一个图片，其中图片中的屏幕或者显示器可以放置图中图。</p>
<p><img src="/images/SKILL/ppt132.png" alt="1"><br>3.对要放置的图片进行缩放，放在图片中的显示器上，并插入相应的文本框</p>
<p><img src="/images/SKILL/ppt133.png" alt="1"></p>
<p><img src="/images/SKILL/ppt110.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.插入六边形，并选择其中一个进行图片填充，这部分内容可以参考形状高阶操作部分内容</p>
<p><img src="/images/SKILL/ppt134.png" alt="1"><br>2.插入修饰和文本框</p>
<p><img src="/images/SKILL/ppt135.png" alt="1"></p>
<p><img src="/images/SKILL/ppt111.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.绘制一些矩形，使其边缘对齐</p>
<p><img src="/images/SKILL/ppt136.png" alt="1"><br>2.将矩形组合，并缩放到幕布大小，然后取消组合</p>
<p><img src="/images/SKILL/ppt137.png" alt="1"><br>3.留一个矩形放置文本，对其他所有形状进行图片填充，这部分内容可以参考形状高阶操作部分内容</p>
<p><img src="/images/SKILL/ppt138.png" alt="1"><br>4.对放置文本的矩形插入合适的文本框</p>
<p><img src="/images/SKILL/ppt139.png" alt="1"></p>
<p><img src="/images/SKILL/ppt112.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.绘制一些矩形，使其边缘对齐，并进行图片填充，这部分内容可以参考形状高阶操作部分内容</p>
<p><img src="/images/SKILL/ppt140.png" alt="1"><br>2.绘制一个黑色幕布，选择渐变填充，并设置合适的透明度</p>
<p><img src="/images/SKILL/ppt141.png" alt="1"><br>3.插入合适的文本框</p>
<p><img src="/images/SKILL/ppt142.png" alt="1"></p>
<h3 id="全文字型PPT"><a href="#全文字型PPT" class="headerlink" title="全文字型PPT"></a><font size="4">全文字型PPT</font></h3><p>这类PPT的特点是段落内容都很重要，删去后会导致语句不连贯或者影响表达的完整性，因此PPT中出现大量的文字。<br><img src="/images/SKILL/ppt28.png" alt="1"><br>下面介绍这张PPT的制作过程<br>1.根据要介绍的部分设置相应数量的子标题形状，这里使用圆形放置标题，调整圆形的颜色和大小，并选择合适的小图标，然后再右侧添加子标题</p>
<p><img src="/images/SKILL/ppt45.png" alt="1"><br>2.在下方插入文本框，尽量使文本框的左侧和小标题对其</p>
<p><img src="/images/SKILL/ppt46.png" alt="1"><br>3.在子标题之间加上虚线，增加PPT的美感</p>
<p><img src="/images/SKILL/ppt47.png" alt="1"><br>4.可以根据需要设置背景，可以选择公司logo，或者自己制作的一些小形状，这里我就将科大的校徽当作背景，设置合适的颜色并置于底层，即可使文字覆盖在上面</p>
<p><img src="/images/SKILL/ppt48.png" alt="1"></p>
<p><img src="/images/SKILL/ppt29.png" alt="1"><br>这张PPT虽然有图，但是基本上被文字占据，文字数量较多，因此也归为全文字型PPT，下面介绍这张PPT的制作过程。<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt49.png" alt="1"><br>2.添加一个矩形框，设置合适的填充颜色，这里选择灰色，并且设置无边框颜色</p>
<p><img src="/images/SKILL/ppt50.png" alt="1"><br>3.后面的部分和上一张PPT的制作方法完全相同，这里不做重复介绍，直接看最终的效果图</p>
<p><img src="/images/SKILL/ppt51.png" alt="1"></p>
<p><img src="/images/SKILL/ppt30.png" alt="1"><br>这张PPT和上一张类似，文字数量较多，因此也归为全文字型PPT，下面介绍这张PPT的制作过程。<br>1.首先将图片按照要求铺面整个幕布，这部分内容可以参考插入图片相关内容</p>
<p><img src="/images/SKILL/ppt52.png" alt="1"><br>2.设置该页PPT的总标题，如本页介绍坚持，则可以在右上方写上总标题，并使用直线增加美感</p>
<p><img src="/images/SKILL/ppt53.png" alt="1"><br>3.选择矩形，并设置相应的大小、颜色和透明度。然后将矩形的一条边紧贴幕布，可以根据需要放在左侧、右侧、上侧或者下侧。</p>
<p><img src="/images/SKILL/ppt54.png" alt="1"><br>4.根据要介绍的部分设置相应数量的子标题形状，这里使用圆形放置标题，设置无填充颜色，边框为白色，并根据子标题的内容，选择合适的小图标，并在右侧配上关键字</p>
<p><img src="/images/SKILL/ppt55.png" alt="1"><br>5.在子标题下方添加要介绍的文本段落，为了增加层次感，可以设置文本为灰色，防止和小标题颜色一致</p>
<p><img src="/images/SKILL/ppt56.png" alt="1"></p>
<h2 id="动画基本操作"><a href="#动画基本操作" class="headerlink" title="动画基本操作"></a><font size="4">动画基本操作</font></h2><p>选择一个元素，点击动画菜单栏，可以从动画选择框中选择合适的动画效果，点击动画窗格按钮，可以在右侧弹出动画窗格任务栏，其中当前页面所有的动画效果都会在上面显示，可以对多个元素之间的动画关系进行调整。<br><img src="/images/SKILL/ppt191.png" alt="1"><br>点击动画选择框右下角的其他按钮，可以显示所有动画效果。动画的效果有四种，进入、强调、退出和动作路径，每一种都有很多方式，小伙伴们可以自行研究。<br>1.进入是指从无到有的过程，如出现，飞入等<br>2.强调是指对元素进行一些变化，并返回原始形态，如抖动，旋转等<br>3.退出和进入相反，是指从有到无的过程，如消失，飞出等<br>4.动作路径是指元素移动的过程，可以选择移动方式，是直线、弧形或者自定义移动方式等</p>
<p><img src="/images/SKILL/ppt192.png" alt="1"><br>有些动画没有选项效果，如出现，有些动画具有选项效果，如飞入，点击效果选项，可以选择从哪个方向进行飞入。<br><img src="/images/SKILL/ppt193.png" alt="1"><br>可以在右侧设置动画的播放方式、持续时间、延迟时间等等<br><img src="/images/SKILL/ppt194.png" alt="1"></p>
<h2 id="动画时序"><a href="#动画时序" class="headerlink" title="动画时序"></a><font size="4">动画时序</font></h2><p><img src="/images/SKILL/ppt196.png" alt="1"><br>动画时序是指多个动画之间的时间关系，一般在动画窗格里设置，以上图为例，矩形动画和圆形动画左上角都显示上标1，而三角形显示上标2，说明矩形和圆形是同一时间范围内的动画，第一次点击鼠标时会播放所有上标为1的动画效果，第二次点击鼠标才会波放三角形动画。在动画窗格中也可以看出，矩形和圆形左上角有一个鼠标的记号。值得注意的是，虽然矩形和椭圆是同一时间范围，但是动画窗格内元素右侧的矩形框长度和起始位置不一样，长度代表动画的持续时间，起始位置代表动画的开始时间，可以拖动矩形框来进行修改。</p>
<iframe height="315" width="560" src="/images/SKILL/p3.mp4" frameborder="0"></iframe>

<h2 id="文本动画"><a href="#文本动画" class="headerlink" title="文本动画"></a><font size="4">文本动画</font></h2><p>插入一个文本框，右键对应动画窗格中的动画，选择效果选项，也可以在其中设置动画的格式，如平滑开始、平滑结束等，这也是一个小技巧，为了使PPT显得更加自然，往往需要添加平滑开始和平滑结束。对于文本来说还可以设置动画文本，按照字或词发送文本。<br><img src="/images/SKILL/ppt197.png" alt="1"></p>
<iframe height="315" width="560" src="/images/SKILL/p1.mp4" frameborder="0"></iframe>

<h2 id="图表动画"><a href="#图表动画" class="headerlink" title="图表动画"></a><font size="4">图表动画</font></h2><p>1.在插入菜单栏下，选择图表，可以弹出图表类型，点击合适的图表类型</p>
<p><img src="/images/SKILL/ppt199.png" alt="1"><br>2.点击图表右键，可以修改数据、修改图表颜色等，小伙伴们使用时自己摸索即可</p>
<p><img src="/images/SKILL/ppt200.png" alt="1"><br>3.插入动画，右键对应动画窗格中的动画，选择效果选项，可以在其中设置动画的效果，是按照分类出现动画，还是按照系列出现动画</p>
<p><img src="/images/SKILL/ppt198.png" alt="1"></p>
<iframe height="315" width="560" src="/images/SKILL/p2.mp4" frameborder="0"></iframe>

<h2 id="重复和翻转动画"><a href="#重复和翻转动画" class="headerlink" title="重复和翻转动画"></a><font size="4">重复和翻转动画</font></h2><p>右键对应动画窗格中的动画，选择效果选项，点击计时，并在重复选项中选择直到幻灯片末尾，其他的方式小伙伴们也可以自行尝试观察效果<br><img src="/images/SKILL/ppt202.png" alt="1"><br><img src="/images/SKILL/ppt201.png" alt="1"></p>
<iframe height="315" width="560" src="/images/SKILL/p5.mp4" frameborder="0"></iframe>

<h2 id="转场动画"><a href="#转场动画" class="headerlink" title="转场动画"></a><font size="4">转场动画</font></h2><p>转场动画也称为切换动画，是指在两页PPT之间进行切换的动画效果，避免每次切换页面过于生硬。点击选择要插入转场动画的页面，点击切换菜单栏，选择合适的动画效果，此时从上一页到该页面会出现转场动画。转场动画也同样可以设置效果选项、持续时间、播放方式等功能<br><img src="/images/SKILL/ppt195.png" alt="1"></p>
<iframe height="315" width="560" src="/images/SKILL/p4.mp4" frameborder="0"></iframe>

<h2 id="动画实战"><a href="#动画实战" class="headerlink" title="动画实战"></a><font size="4">动画实战</font></h2><p><iframe height="315" width="560" src="/images/SKILL/p6.mp4" frameborder="0"></iframe><br>下面介绍这张PPT的制作过程<br>1.绘制一个黄色幕布<br><img src="/images/SKILL/ppt203.png" alt="1"><br>2.插入齿轮图片，并为齿轮添加两个动画，一个是从左侧飞入的动画，一个是陀螺旋动画，设置持续时间都为2秒，并且为了动画自然都设置平滑结束2秒<br><img src="/images/SKILL/ppt204.png" alt="1"></p>
<p><iframe height="315" width="560" src="/images/SKILL/p7.mp4" frameborder="0"></iframe><br>下面介绍这张PPT的制作过程<br>1.绘制一个灰色幕布<br><img src="/images/SKILL/ppt205.png" alt="1"><br>2.插入树叶图片，并为树叶添加三个动画，一个是自定义路径的动画，并右键编辑顶点，选择平滑顶点，一个是陀螺旋动画，一个是旋转动画，设置持续时间都为2.5秒，并且为了动画自然都设置平滑开始1秒，平滑结束2秒。复制该图像，粘贴一个相同的树叶动画，修改路径，并将时间都设为3秒<br><img src="/images/SKILL/ppt206.png" alt="1"></p>
<p><iframe height="315" width="560" src="/images/SKILL/p8.mp4" frameborder="0"></iframe><br>下面介绍这张PPT的制作过程<br>插入图片，设置图片的宽度大于幕布宽度，高度和幕布相等，然后左边与幕布左侧对齐，右边会超出幕布右侧，然后添加动作路径向左，设置合适的时间即可<br><img src="/images/SKILL/ppt207.png" alt="1"></p>
<p><iframe height="315" width="560" src="/images/SKILL/p9.mp4" frameborder="0"></iframe><br>下面介绍这张PPT的制作过程<br>1.绘制一个蓝色幕布<br><img src="/images/SKILL/ppt208.png" alt="1"><br>2.绘制多个矩形，设置1、3、5、7…矩形从顶部飞入，2、4、6、8…矩形从底部飞入，并将延迟设置相差0.1秒。然后在1秒后将矩形设置放大动画铺满整个屏幕<br><img src="/images/SKILL/ppt209.png" alt="1"></p>
<p><iframe height="315" width="560" src="/images/SKILL/p10.mp4" frameborder="0"></iframe><br>下面介绍这张PPT的制作过程<br>1.绘制一个黄色幕布，中间挖去一个圆，并且在中间补上一个无填充，虚线轮廓的小圆<br><img src="/images/SKILL/ppt210.png" alt="1"><br>2.打开网格线，使用形状曲线绘制波形<br><img src="/images/SKILL/ppt211.png" alt="1"><br>3.复制多个波形，并和矩形组合，设置填充颜色为蓝色<br><img src="/images/SKILL/ppt212.png" alt="1"><br>4.将组合后的波形添加动作路径，从左下方到右上方移动，然后插入多个文本框，写上波形填充的比例数字，并设置合适的淡出时间。最后给虚线轮廓的圆形加上重复的陀螺旋直到幻灯片末尾<br><img src="/images/SKILL/ppt213.png" alt="1"></p>
<h1 id="PPT小结"><a href="#PPT小结" class="headerlink" title="PPT小结"></a><font size="5" color="red">PPT小结</font></h1><p>  PPT的功能非常丰富，一篇博客很难描述完全，最关键的一点是多去欣赏优秀的作品，这样可以提高自身的审美，才能做出好看的PPT。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>PPT</category>
      </categories>
  </entry>
  <entry>
    <title>汉明距离总和(Leetcode 477)</title>
    <url>/2021/05/28/program%20Leetcode477/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode477.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是第461题的扩展，在第461题中，只需要计算两个数之间的汉明距离，这个题目是计算任意两个数之间的汉明距离之和。很简单的思路是遍历两层循环，可是数组长度最大为10000，如果两层循环会超时，会不会有更好的方法呢？<br><a id="more"></a></p>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>因为这里元素范围是1e9，因此肯定在int范围之内，而且我们发现汉明距离是衡量每一位之间的差异，汉明距离等于所有数字每一位之间的差异，因此可以按照位来衡量，以第k位为例，如果第k位为1的数字有m个，总数有n个，则第k位为0的数字有n - m个，所以第k位的汉明距离为n x (n - m)，最终的结果只需要遍历32位即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br>下面是Java语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public int totalHammingDistance(int[] nums) {</span><br><span class="line">        int cur_num = 1, length = nums.length, res = 0;</span><br><span class="line">        for (int i = 0; i &lt; 32; i++) {</span><br><span class="line">            int cur = 0;</span><br><span class="line">            for (int x : nums) {</span><br><span class="line">                cur += (cur_num &amp; x) &gt; 0 ? 1 : 0;</span><br><span class="line">            }</span><br><span class="line">            res += cur * (length - cur);</span><br><span class="line">            cur_num &lt;&lt;= 1;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面是Python语言的题解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def totalHammingDistance(self, nums: List[int]) -&gt; int:</span><br><span class="line">        length, cur, res = len(nums), 1, 0</span><br><span class="line">        for i in range(32):</span><br><span class="line">            cur_num = 0</span><br><span class="line">            for x in nums:</span><br><span class="line">                cur_num += (x &amp; cur) &gt; 0</span><br><span class="line">            res += cur_num * (length - cur_num)</span><br><span class="line">            cur &lt;&lt;= 1</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>对比两种语言，可以发现Python语言中的布尔类型可以直接参与运算，即true为1，false为0。但是Java中的boolean不能直接和int进行运算，只能通过三目运算符进行操作。</p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目不难，能否想到按位计算是关键步骤。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>反转每对括号间的子串(Leetcode 1190)</title>
    <url>/2021/05/26/program%20Leetcode1190/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1190.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   看到成对的括号问题，脑中就会自然想到括号匹配，顺理成章的想到栈的思路。这个题目是否可以从这里入手呢？前一段时间没有经常写博客，因为忙于毕业论文和答辩的事情，搞得人焦头烂额，现在很多事情已经解决，可以继续和朋友们分享博客了。因为想学习一下Android，毕竟在国内企业发展，了解一些Android毕竟不是坏事，而偏偏Google现在首推Kotlin语言进行Android开发，因此这段时间也顺带学习了一下Kotlin，有时间也会给小伙伴们科普Kotlin语言的学习。以后当作练手，在博客的题解中，从C++，Java，Python和Kotlin中随机选择2个给出答案。因为之前Python和C++练习的比较多，因此权重稍微少一些，控制在比例分别控制在0.17，0.33，0.17，0.33。希望小伙伴们也要学习我的这个方法，对新语言多多练习，对已经会使用的语言也不能放弃。</p>
<a id="more"></a>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p>这里就介绍栈的方法，以(u(love)i)为例，依次将元素入栈，如果出现了右括号，则将对应左括号之间的所有字符反转，并入栈。在本例中，e后面出现第一次右括号，对应的左括号在l之前，因此将两者之间的love反转，变为evol，然后入栈，此时栈中元素为uevol，然后i入栈，又遇到右括号，此时对应的左括号在u之前，因此将两者之间的uevoli反转，变为iloveu，然后再入栈。此时没有元素，此时顺序读出即可。但是要注意，这个题目要求将反转的结果输出，因此栈无法顺序读出，因此可以使用双端队列代替栈。<br>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br>如下使用C++语言求解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    string reverseParentheses(string s) {</span><br><span class="line">        deque&lt;int&gt; q;</span><br><span class="line">        for (char c : s) {</span><br><span class="line">            if (c != ')') q.push_back(c);</span><br><span class="line">            else {</span><br><span class="line">                string cur = "";</span><br><span class="line">                while (q.back() != '(') {</span><br><span class="line">                    cur += q.back();</span><br><span class="line">                    q.pop_back();</span><br><span class="line">                }</span><br><span class="line">                q.pop_back();</span><br><span class="line">                for (char cc : cur) q.push_back(cc);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        string res = "";</span><br><span class="line">        for (char c : q) res += c;</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>如下使用Java语言求解<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">    public String reverseParentheses(String s) {</span><br><span class="line">        LinkedList&lt;Character&gt; arr = new LinkedList&lt;&gt;();</span><br><span class="line">        for (int i = 0; i &lt; s.length(); i++) {</span><br><span class="line">            char cur = s.charAt(i);</span><br><span class="line">            if (cur != ')') arr.addLast(cur);</span><br><span class="line">            else {</span><br><span class="line">                StringBuilder pop = new StringBuilder();</span><br><span class="line">                while (arr.getLast() != '(') {</span><br><span class="line">                    pop.append(arr.removeLast());</span><br><span class="line">                }</span><br><span class="line">                arr.removeLast();</span><br><span class="line">                for (int j = 0; j &lt; pop.length(); j++) {</span><br><span class="line">                    arr.addLast(pop.charAt(j));</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        StringBuilder res = new StringBuilder();</span><br><span class="line">        while (!arr.isEmpty()) { res.append(arr.removeFirst()); }</span><br><span class="line">        return res.toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  有小伙伴们说这个题目是华为的笔试题，这太正常了，相比于字节和阿里的变态笔试题，华为的笔试题相对轻松一些，一般是中等难度的题目。而且括号问题是笔试面试的经典题型之一，一定要牢牢掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
        <category>字符串</category>
      </categories>
  </entry>
  <entry>
    <title>Turing Reward in 2020</title>
    <url>/2021/05/20/TuringReward-2020/</url>
    <content><![CDATA[<p>  2021 年 3 月 31 日，ACM 宣布了2020年图灵奖获得者，美国哥伦比亚大学教授Alfred Aho和斯坦福大学教授Jeffrey Ullman，以表彰他们在编程语言实现的基本算法和理论方面做出的巨大贡献，以及其所编撰的书籍对于几代计算机科学家所带来的积极影响。</p>
<a id="more"></a>
<p>我们目前生活在智能化的时代中，这都是人类用高级编程语言编写，再编译成计算机看得懂的低级语言并运行的。而Alfred Aho和Jeffrey Ullman的工作在让电脑认识低级语言方面起到了巨大的作用。他们连接了高级语言和低级语言的桥梁，奠定了编程语言理论，实现和算法设计的基础。</p>
<p>让我们来看看两位大佬的研究历程：<br><strong>阿尔弗雷德·艾侯(Alfred Aho)</strong><br><img src="/images/TURING/alfred.png" alt="Alfred Aho"><br>   1941年生于加拿大安大略省提明斯，是一位计算机科学家，毕业于多伦多大学，并在普林斯顿大学获得电子工程硕士学位和计算机科学博士学位。毕业后在贝尔实验室担任计算科学研究副总裁，并在此工作了三十多年。1995年加入哥伦比亚大学计算机科学系，并成为其名誉教授。</p>
<p><strong>杰弗里·乌尔曼(Jeffrey Ullman)</strong><br><img src="/images/TURING/jeffrey.png" alt="Hanrahan"><br>  生于1942年，也是一位计算机科学家，1963年获得哥伦比亚大学数学工程学士学位，1966年获得普林斯顿大学计算机科学博士学位。1966年至1969年在贝尔实验室担任技术人员，正是这段时间认识了Alfred Aho，并持续了几十年的合作。1969年至1979年在普林斯顿大学任教，在1979年后加入斯坦福大学，并称为其名誉教授。</p>
<p>   今年获奖的两位教授在计算机科学教育方面影响力全世界的计算机系学生，科学家和相关从业者。其中最著名的是他们合著的编译原理，因为封面设计是一条龙，因此也被称为”龙书”。在书中整理了高级语言到机器码的各个阶段，并深入讨论了编译器设计的重要概念和实例，可以称为计算机从业人员必读书籍之一，在全球大量高等院校均作为教材进行讲解。毫不夸张的说，Alfred Aho 和 Jeffrey Ullman 能称得上是全球程序员的启蒙老师。</p>
<p>   1977年，Alfred Aho和Jeffrey Ullman出版的《Principles of Compiler Design》,因为其封面是一只绿色的龙，因此被人称为绿龙书。<br><img src="/images/TURING/compiler1.png" alt="dragon1"> </p>
<p>   9年后，1986年对该书进行升级，增加了一位合著者Ravi Sethi，并将书名改为《Compilers: Principles, Techniques and Tools》,而封面仍然使用一条龙，龙的颜色改为红色，因此被人称为红龙书。<br><img src="/images/TURING/compiler2.png" alt="dragon1"> </p>
<p>   2006年，作者又增加了Monica Lam，书名沿用《Principles of Compiler Design》,而封面仍然使用一条龙，龙的颜色改为紫色，因此被人称为紫龙书。<br><img src="/images/TURING/compiler3.png" alt="dragon1"> </p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Turing Reward</category>
      </categories>
  </entry>
  <entry>
    <title>Word文档排版</title>
    <url>/2021/04/30/skill%20Word/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Word</font></strong></center><p></p>
<h1 id="Word介绍"><a href="#Word介绍" class="headerlink" title="Word介绍"></a><font size="5" color="red">Word介绍</font></h1><p>  <strong>Word(Microsoft Office Word):</strong>最初由”Richard Brodie”于1983年编写，一直以来都是最流行的文字处理程序。尤其对于学生、职工来说，Word是必不可少的工具之一。尤其是最近在写毕业论文的时候，遇到很多排版、格式等问题，每次都要花费一段时间去网上寻找解决方案，非常繁琐。这篇博客的目的是记录一些常用的Word操作分享给小伙伴们，而且还可以方便以后查询。<br><a id="more"></a></p>
<h1 id="Word常用操作"><a href="#Word常用操作" class="headerlink" title="Word常用操作"></a><font size="5" color="red">Word常用操作</font></h1><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a><font size="4">标题</font></h2><p>首先介绍标题的制作方法，以学习C语言为例。我们要创建一个如下图所示的标题，应该如何操作？<br><img src="/images/SKILL/word1.png" alt="1"><br>第一步：点击<strong>开始</strong>菜单，找到<strong>多级列表</strong>，选择<strong>定义新的多级列表</strong>。<br><img src="/images/SKILL/word2.png" alt="1"><br>第二步：出现一个设置页面，点击<strong>更多</strong>，然后要修改的级别选择1，将级别链接到样式选择标题1，在库中显示的级别选择级别1，起始编号设置为1，输入编号的格式写为第1章，此级别的编号样式选择1,2,3,…，文本缩进位置设置为0，编号之后设置为空格。</p>
<p>这里是设置编号的重点，其中要修改的级别代表当前是第几级标题。将级别链接到样式为标题1代表设置后，在样式的标题1就是我们刚才新建的标题。设置前的标题1是word自建的，并非我们需要的。在库中显示的级别不是特别重要，一般随着级别变化即可。起始编号一般都是从1开始，代表文章从第1章开始。输入编号的格式，其中可以看到1是有一个灰色的框，这是会变化的意思，第和章这两个字不会变化，也就是说下一章就是第2章。此级别的编号样式如果设置1,2,3,…则为第1章，如果设置一,二,三,…则是第一章，此处修改，则输入编号的格式也会跟着变化。文本缩进位置，根据需要设置，一般为0即可。编号之后，根据需要设置，一般空格即可。<br><img src="/images/SKILL/word3.png" alt="1"></p>
<p>第三步：设置二级标题，一级标题按照上述操作设置完成后，要修改的级别选择2，同理链接到样式选择标题2，在库中显示的级别选择级别2，起始编号仍然选择1，说明二级标题也是从1开始编号。此时要注意，先将输入编号的格式全部删去，然后先选择包含的级别编号来自级别1，然后加上一个小数点，再选择此级别的编号样式为1,2,3,…。这一步的目的是，首先让级别1出现在最前面，并且一级标题后面出现一个小数点，如第一章就是1.x，第2章就是2.x，最后才能选择本级别的样式。文本缩进位置，编号之后都和一级标题类似。<br><img src="/images/SKILL/word4.png" alt="1"></p>
<p>第四步：设置三级标题等，三级标题基本上和二级类似，只有一点，在选择包含的级别编号来自时，要从小到大选择，并且选择一个加上一个小数点。<br><img src="/images/SKILL/word5.png" alt="1"></p>
<p>第五步：等到所有需要的标题都设置完毕后，点击确定，此时开始中的样式栏里面就会出现我们刚才设置的标题1、2、3等等。右键点击标题1，选择修改。<br><img src="/images/SKILL/word6.png" alt="1"></p>
<p>第六步：点击格式，选择字体，设置合适的中文字体和西文字体，这里设置中文为黑体三号，西文为Times三号<br><img src="/images/SKILL/word7.png" alt="1"></p>
<p>第七步：点击格式，选择段落，设置合适的对齐方式和间距，这里让一级标题居中，间距段前24磅，段后18磅，行距为单倍行距<br><img src="/images/SKILL/word8.png" alt="1"></p>
<p>第八步：右键点击标题2、3等等，选择修改，同样修改字体，格式等内容。根据要求或者美观来自己设置。这里标题二中文为黑体四号，西文为Times四号，左对齐，段前24磅，段后6磅，单倍行距。标题三中文为黑体13磅，西文为Times13磅，左对齐，段前12磅，段后6磅，单倍行距。</p>
<p>第九步：选中要设为一级标题的文字，点击标题1，即可自动设为一级标题，二级三级同理。<br><img src="/images/SKILL/word9.png" alt="1"></p>
<p>第十步：点击菜单栏视图，将导航窗格打勾，即可看到标题页，最后设置的结果如下图。<br><img src="/images/SKILL/word10.png" alt="1"></p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a><font size="4">目录</font></h2><p>设置好标题以后，要对文档设置目录，Word给我们提供了目录的自动生成方法，只要设置好标题，即可自动生成。仍然以上例进行操作。<br>第一步：点击<strong>引用</strong>菜单，找到<strong>目录</strong>，选择<strong>自定义目录</strong>。<br><img src="/images/SKILL/word11.png" alt="1"><br>第二步：选择目录显示页码，页码右对齐，制表符前导符……，想显示的标题级别。<br><img src="/images/SKILL/word12.png" alt="1"><br>第三步：点击修改，会出现目录级别的样式，点击目录1再进行修改，可以设置一级目录的字体，段落等格式，和标题第六步和第七步相同，这里设置一级目录为宋体14磅，段前6磅，二级目录为宋体12磅，段前6磅，左侧缩进1字符，三级目录为仿宋12磅，段前6磅，左侧缩进2字符。<br><img src="/images/SKILL/word13.png" alt="1"><br>设置完毕后，可以看到目录已经自动生成。如果修改了文本，要记得更新目录页数。<br><img src="/images/SKILL/word14.png" alt="1"></p>
<h2 id="目录-1"><a href="#目录-1" class="headerlink" title="目录"></a><font size="4">目录</font></h2><p>设置好标题以后，要对文档设置目录，Word给我们提供了目录的自动生成方法，只要设置好标题，即可自动生成。仍然以上例进行操作。<br>第一步：点击<strong>引用</strong>菜单，找到<strong>目录</strong>，选择<strong>自定义目录</strong>。<br><img src="/images/SKILL/word11.png" alt="1"><br>第二步：选择目录显示页码，页码右对齐，制表符前导符……，想显示的标题级别。<br><img src="/images/SKILL/word12.png" alt="1"><br>第三步：点击修改，会出现目录级别的样式，点击目录1再进行修改，可以设置一级目录的字体，段落等格式，和标题第六步和第七步相同，这里设置一级目录为宋体14磅，段前6磅，二级目录为宋体12磅，段前6磅，左侧缩进1字符，三级目录为仿宋12磅，段前6磅，左侧缩进2字符。<br><img src="/images/SKILL/word13.png" alt="1"><br>设置完毕后，可以看到目录已经自动生成。<br><img src="/images/SKILL/word14.png" alt="1"></p>
<h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a><font size="4">插入图片</font></h2><p>第一步：选择要插入图片的位置，点击菜单栏下的插入选项。<br><img src="/images/SKILL/word21.png" alt="1"><br>第二步：从弹出的文件路径中选择需要插入的图片。<br><img src="/images/SKILL/word22.png" alt="1"><br>第三步：可以右键设置图片格式，大小位置，环绕文字格式等操作，常用的是嵌入型。</p>
<h2 id="插入表格"><a href="#插入表格" class="headerlink" title="插入表格"></a><font size="4">插入表格</font></h2><p>第一步：选择要插入表格的位置，点击菜单栏下的插入选项，点击表格，选择合适的行列数量。<br><img src="/images/SKILL/word30.png" alt="1"><br>第二步：在表格中写上相应的文字，点击表格左上方，选中所有行列，将文字居中，并且选择无框线。<br><img src="/images/SKILL/word31.png" alt="1"><br>第三步：选择第一行，点击菜单栏中的设计，选择上边框1.5磅<br><img src="/images/SKILL/word32.png" alt="1"><br>第四步：同理，选择第一行下边框0.5磅，最后一行下边框1.5磅，此时论文常用的三线表就制作完成了。<br><img src="/images/SKILL/word33.png" alt="1"></p>
<h2 id="插入公式"><a href="#插入公式" class="headerlink" title="插入公式"></a><font size="4">插入公式</font></h2><h3 id="Word插入公式"><a href="#Word插入公式" class="headerlink" title="Word插入公式"></a><font size="4">Word插入公式</font></h3><p>第一步：点击插入菜单栏右侧的公式<br><img src="/images/SKILL/word23.png" alt="1"><br>第二步：弹出一个公式编辑框，在菜单栏中选择设计，此时可以看到数学公式常用的各种符号，即可编辑公式。<br><img src="/images/SKILL/word24.png" alt="1"></p>
<h3 id="Microsoft-公式3-0"><a href="#Microsoft-公式3-0" class="headerlink" title="Microsoft 公式3.0"></a><font size="4">Microsoft 公式3.0</font></h3><p>第一步：点击插入菜单栏右侧的对象<br><img src="/images/SKILL/word25.png" alt="1"><br>第二步：选择对象类型为Microsoft 公式3.0<br><img src="/images/SKILL/word26.png" alt="1"><br>第三步：弹出一个公式编辑框，此时可以看到数学公式常用的各种符号，即可编辑公式。<br><img src="/images/SKILL/word27.png" alt="1"></p>
<h3 id="Mathtype"><a href="#Mathtype" class="headerlink" title="Mathtype"></a><font size="4">Mathtype</font></h3><p>第一步：需要下载Mathtype插件，网络上有很多教程。配置完成后，即可在菜单栏看到Mathtype的选项。<br><img src="/images/SKILL/word28.png" alt="1"><br>第二步：点击Mathtype可以看到有内联和显示两种，内联是指嵌入在文字中，显示是指单独作为一行并居中。后面的操作和插入Microsoft 公式3.0相同，下面对内联和插入进行分别展示。<br><img src="/images/SKILL/word29.png" alt="1"></p>
<h2 id="样式"><a href="#样式" class="headerlink" title="样式"></a><font size="4">样式</font></h2><p>这里的样式不仅仅是文字的样式，对于图片来说也是可以适用的，往往图片要居中处理，如果一篇文档有很多图片，每一张都要点击居中，再设置前后缩进，非常麻烦，可以定义一个图片样式，插入图片时直接选择该样式即可。</p>
<h3 id="修改已有样式"><a href="#修改已有样式" class="headerlink" title="修改已有样式"></a><font size="4">修改已有样式</font></h3><p>第一步：开始菜单栏下，已有正文样式，右键该样式，点击修改。<br><img src="/images/SKILL/word15.png" alt="1"><br>第二步：和标题第六步和第七步相同，设置需要的格式，这里设置正文字体为宋体五号，两端对其，首行缩进2字符，行距20磅。<br><img src="/images/SKILL/word16.png" alt="1"><br>第三步：选中正文，点击正文样式，则该文字会变成设置的样式。<br><img src="/images/SKILL/word17.png" alt="1"><br>要注意，当行距设为20磅时，有时内联公式较大会遮挡部分公式，此时可以设置该段落为单倍行距即可。<br><img src="/images/SKILL/word38.png" alt="1"></p>
<h3 id="新建样式"><a href="#新建样式" class="headerlink" title="新建样式"></a><font size="4">新建样式</font></h3><p>第一步：开始菜单栏下，样式列表右下角，点击会出现弹窗，再点击左下角第一个新建样式。<br><img src="/images/SKILL/word18.png" alt="1"><br>第二步：给新建的样式起名字，这里新建图片样式，命名为图片，因为图片不需要字体，只需要设置段落格式即可，居中，缩进0，单倍行距。<br><img src="/images/SKILL/word19.png" alt="1"><br>第三步：选中图片，点击图片样式，则图片会变成设置的样式。<br><img src="/images/SKILL/word20.png" alt="1"></p>
<h2 id="编号"><a href="#编号" class="headerlink" title="编号"></a><font size="4">编号</font></h2><p>对下面几个并列的内容进行编号。<br>第一步：右键开始菜单栏下样式中的列出段落，在我的Word中，列出段落样式在第三行。修改该样式，一般使用缩进0，特殊格式无。<br><img src="/images/SKILL/word34.png" alt="1"><br>第二步：选择要编号的文本，左键该格式。<br><img src="/images/SKILL/word35.png" alt="1"><br>第三步：选中文本，点击开始菜单栏下编号右侧的向下箭头，弹出编号选择页面，选择合适的编号类型。<br><img src="/images/SKILL/word36.png" alt="1"><br>编号完成后的文本如下图所示<br><img src="/images/SKILL/word37.png" alt="1"></p>
<h2 id="题注"><a href="#题注" class="headerlink" title="题注"></a><font size="4">题注</font></h2><p>题注有很多种，常用的包括图片题注，表格题注，公式题注这三类。下面进行分别介绍。</p>
<h3 id="图片题注"><a href="#图片题注" class="headerlink" title="图片题注"></a><font size="4">图片题注</font></h3><p>第一步：右键点击图片，选择插入题注<br><img src="/images/SKILL/word39.png" alt="1"><br>第二步：在题注中选择标签为图，英文的图注可以选择Figure，也可以新建标签，图片的题注一般位于图片下方。点击编号，可以设置是否包含章节号，并且章节号之间的分隔符可以选择，一般使用连字符-或者句点.<br><img src="/images/SKILL/word40.png" alt="1"><br>第三步：建立好题注后，可以为图片的题注设置一个单独的样式，这样就不需要每次修改题注的文字型号。最后给题注加上相关的文字即可。<br><img src="/images/SKILL/word41.png" alt="1"></p>
<h3 id="表格题注"><a href="#表格题注" class="headerlink" title="表格题注"></a><font size="4">表格题注</font></h3><p>第一步：全选表格，右键插入题注<br><img src="/images/SKILL/word42.png" alt="1"><br>第二步：在题注中选择标签为表，英文的图注可以选择Table，也可以新建标签，表格的题注一般位于表格上方。点击编号，可以设置是否包含章节号，并且章节号之间的分隔符可以选择，一般使用连字符-或者句点.<br><img src="/images/SKILL/word43.png" alt="1"><br>第三步：建立好题注后，可以为表格的题注设置一个单独的样式，这样就不需要每次修改题注的文字型号。最后给题注加上相关的文字即可。<br><img src="/images/SKILL/word44.png" alt="1"></p>
<h3 id="公式题注"><a href="#公式题注" class="headerlink" title="公式题注"></a><font size="4">公式题注</font></h3><p>第一步：选中公式，右键插入题注<br><img src="/images/SKILL/word45.png" alt="1"><br>第二步：新建标签(，为什么要建立左括号标签，因为这样公式的题注就是(1.1)<br><img src="/images/SKILL/word46.png" alt="1"><br>第三步：在题注中选择标签(，点击编号，可以设置是否包含章节号，并且章节号之间的分隔符可以选择，一般使用连字符-或者句点.<br><img src="/images/SKILL/word47.png" alt="1"><br>第四步：建立好题注后，结果如下图所示。<br><img src="/images/SKILL/word48.png" alt="1"><br>第五步：创建一个新的公式样式，查看页面的总字符数大约是39左右，将公式放在中间19字符处，将题注放在39字符处。选择格式制表位，先全部清除制表位，然后写入19字符，选择居中，点击设置，再写入39字符，选择右对齐，点击设置。公式样式制作完成。<br><img src="/images/SKILL/word49.png" alt="1"><br>第六步：此时公式和题注不在同一行，此时在公式后面按下Ctrl + Alt + Enter，输入一个样式分隔符，这样将公式和题注分开，方便后面的交叉引用。输入样式分隔符后公式和题注变成了同一行，如图所示。<br><img src="/images/SKILL/word50.png" alt="1"><br>第七步：删掉左括号后的一个多余空格，并选中公式和题注，应用新建立的公式样式，并在公式后，分隔符前输入Tab制表位，即可完成公式的题注插入。<br><img src="/images/SKILL/word51.png" alt="1"></p>
<h2 id="交叉引用"><a href="#交叉引用" class="headerlink" title="交叉引用"></a><font size="4">交叉引用</font></h2><p>交叉引用非常重要，图片、表格、公式、编号等都可以使用交叉引用。以图片为例，相当于将文本与图片题注进行结合，假设文字图1对应图片题注1，那么如果在前面插入一个图片题注，此时文字图1对应题注2，如果不设置交叉引用，则需要手动修改文字图1为图2，当题注很多时，可能有几百个题注，对于后面的每一个题注都要修改对应文字，容易遗漏。当使用交叉引用时，文字图1会自动变成图2。<br>第一步：使用交叉引用的前提是建立了题注，在要插入题注的位置，点击插入菜单栏下的交叉引用，选择引用类型，这里以图片题注为例，将引用内容选择只有标签和编号，并从图片题注中选择一个要引用的题注，点击插入即可。<br><img src="/images/SKILL/word52.png" alt="1"><br>第二步：新插入的交叉引用，字体可能是题注中的字体，可以选中新插入的交叉引用，点击正文样式或者使用格式刷更新插入的字体。<br><img src="/images/SKILL/word53.png" alt="1"><br>点击Ctrl + 交叉引用，可以快速访问到该题注。</p>
<h2 id="纸张大小与页边距"><a href="#纸张大小与页边距" class="headerlink" title="纸张大小与页边距"></a><font size="4">纸张大小与页边距</font></h2><p>第一步：点击菜单栏中的布局，先选择纸张大小，这个部分应该在最开始介绍，因为一般不会修改这个参数，写博客的时候忘记了。如果要指定纸张大小，记得在这里设置即可。<br><img src="/images/SKILL/word54.png" alt="1"><br>第二步：点击菜单栏中的布局，选择页边距，一般情况下也不会修改。了解如何设置即可。<br><img src="/images/SKILL/word55.png" alt="1"></p>
<h2 id="插入特殊符号"><a href="#插入特殊符号" class="headerlink" title="插入特殊符号"></a><font size="4">插入特殊符号</font></h2><p>特殊符号主要介绍分页符和分节符，分节符在下一部分页眉页脚中具体介绍，首先介绍分页符。分页符很简单，一般另起一章时常常要使用单独的一页，如果在上一章的最后加入很多回车，那么修改上一张时，回车会影响下一章的位置。举个例子，如果上一章的最后一句话在20页中间，那么下一章的标题会在20页的下方，如果加入10个回车使下一章的标题在21页最上方，但是如果修改了上一章的内容，上一章的最后一句话变成20页的下方，那么10个回车仍然存在，这样下一章的标题会出现在21页的中间，不符合要求。这个时候就需要分页符。<br>步骤：点击要插入分页符的地方，选择菜单栏中的布局，点击分隔符，选择分页符。<br><img src="/images/SKILL/word56.png" alt="1"><br>插入后的结果如图所示<br><img src="/images/SKILL/word57.png" alt="1"></p>
<h2 id="页眉"><a href="#页眉" class="headerlink" title="页眉"></a><font size="4">页眉</font></h2><p>第一步：双击页面最上方，会弹出页眉设计菜单栏，首先设置页眉到顶端的距离为1.5厘米<br>第二步：可以根据需要插入章节的名称，点击文档部件，选择域<br><img src="/images/SKILL/word58.png" alt="1"><br>第三步：在域名中选择StyleRef，并在样式名中选择标题1，在域选项中点击插入段落编号<br><img src="/images/SKILL/word59.png" alt="1"><br>第四步：重复第二步和第三步，这次域选项什么都不选择，直接确定即可<br><img src="/images/SKILL/word60.png" alt="1"><br>第五步：在章节编号和章节名中间插入空格，并调整字体大小，居中显示。可以看到每一页的页眉都自动更新完成。第一章的页眉是第一章的编号和名称，第二章的页眉是第二章的编号和名称。但是目录页出现问题。<br><img src="/images/SKILL/word61.png" alt="1"><br>第六步：此时不能直接跳转到目录页，输入目录两个字，这样做会导致后面的所有页面也会变成目录两个字。正确的做法是在第一章标题名称第一个字符前插入分节符，选中该位置，点击布局菜单栏下的分隔符，选择下一页即可插入分节符。<br><img src="/images/SKILL/word62.png" alt="1"><br>第七步：双击第一章顶部弹出页眉，可以看到此时目录的页眉是第1节，第一章的页眉是第2节，说明分节符将两个页面分开操作。将第2节页眉中链接到前一条页眉取消，这样就使得修改第1节得页眉不会影响到第2节。<br><img src="/images/SKILL/word63.png" alt="1"><br>第八步：此时再修改目录页的页眉文字即可。<br><img src="/images/SKILL/word64.png" alt="1"></p>
<h2 id="页脚"><a href="#页脚" class="headerlink" title="页脚"></a><font size="4">页脚</font></h2><p>第一步：双击页面最下方，会弹出页脚设计菜单栏，首先设置页脚到底端的距离为1.75厘米<br>第二步：可以根据需要插入页码，点击页码，选择页面底端，并挑选合适的样式，一般在底端居中的位置<br><img src="/images/SKILL/word65.png" alt="1"><br>第三步：根据需要设置合适大小，此时可以发现每一页都加上了页码，并且连续编号。<br><img src="/images/SKILL/word66.png" alt="1"><br>第四步：有时正文的页码和前言，附录等页码符号不同，这时也需要加上分节符，对每一节进行编号，分节符在页眉中进行了详细介绍，可以进行参考。因为在页眉介绍部分已经在第一章前面插入了分节符，这里不需要插入了。选择第1章的页脚，将链接到前一条页眉取消，并点击页码，设置页码格式<br><img src="/images/SKILL/word67.png" alt="1"><br>第五步：设置第一章的页码编号格式为1,2,3,…，将页码编号中的续前节取消，并将起始页码设置为1<br><img src="/images/SKILL/word68.png" alt="1"><br>第六步：设置目录的页码编号格式为I,II,III,…，将起始页码设置为I<br><img src="/images/SKILL/word69.png" alt="1"><br>设置完成后的效果如图所示<br><img src="/images/SKILL/word70.png" alt="1"></p>
<h2 id="分栏"><a href="#分栏" class="headerlink" title="分栏"></a><font size="4">分栏</font></h2><p>分栏并不常用，可能在某些期刊论文中需要进行排版<br>步骤：选中要分栏的文字，如果不选中文字则对整节进行分栏，点击布局菜单栏下的分栏，并选择两栏<br><img src="/images/SKILL/word71.png" alt="1"><br><img src="/images/SKILL/word72.png" alt="1"></p>
<h2 id="超链接"><a href="#超链接" class="headerlink" title="超链接"></a><font size="4">超链接</font></h2><p>第一步：选中要超链接的文字，点击插入菜单栏中的超链接<br><img src="/images/SKILL/word73.png" alt="1"><br>第二步：选择要超链接到网页还是电子邮箱，并输入相应的网址或者邮件地址<br><img src="/images/SKILL/word74.png" alt="1"><br>第三步：超链接完成后，发下字体不一样，并且按下Ctrl + 文字会进入相应的链接中<br><img src="/images/SKILL/word75.png" alt="1"></p>
<h2 id="查找与替换"><a href="#查找与替换" class="headerlink" title="查找与替换"></a><font size="4">查找与替换</font></h2><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a><font size="4">查找</font></h3><p>第一步：点击开始菜单栏下的查找，或者快捷键Ctrl + F<br><img src="/images/SKILL/word76.png" alt="1"><br>第二步：会在导航窗中出现要搜索的文本框，在里面输入要搜索的文字，就会在文本中高亮显示<br><img src="/images/SKILL/word77.png" alt="1"></p>
<h3 id="替换"><a href="#替换" class="headerlink" title="替换"></a><font size="4">替换</font></h3><p>第一步：点击开始菜单栏下的替换，或者快捷键Ctrl + H<br><img src="/images/SKILL/word78.png" alt="1"><br>第二步：输入查找内容和替换内容，可以手动逐一替换，也可以全部替换<br><img src="/images/SKILL/word79.png" alt="1"><br>可以发现相应的文字已被替换<br><img src="/images/SKILL/word80.png" alt="1"></p>
<h1 id="Word小结"><a href="#Word小结" class="headerlink" title="Word小结"></a><font size="5" color="red">Word小结</font></h1><p>  Word的功能非常丰富，一篇博客很难描述完全，常用的一些基本技巧已经介绍给大家，如果遇到了一些博客中没有介绍过的问题，小伙伴们可以寻求网络的帮助。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Word</category>
      </categories>
  </entry>
  <entry>
    <title>按要求补齐数组(Leetcode 189)</title>
    <url>/2021/04/24/program%20Leetcode189/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode189.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  想求解这个题目难度很小，找到规律就可以轻松的解答。但是能否按照说明中的要求，在$O(1)$的空间复杂度只内求解呢？<br><a id="more"></a></p>
<h1 id="找规律"><a href="#找规律" class="headerlink" title="找规律"></a><font size="5" color="red">找规律</font></h1><p>我们首先介绍最简单的方法，<strong>前面k个数字就是原来最后的k个数字，即newNums[i] = nums[n - k + i]，其他的所有数字都会往后移动k个位置，即newNums[i] = nums[i - k]</strong>。</p>
<p>获得新的newNums[i]就是最终的答案，因为我们没有返回值，需要在原数组修改，我们重新赋值一次即可。</p>
<p>要注意的是k可能很大，因为移动n次相当于没有移动，要对n求模。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>，其中n是数组中元素的个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void rotate(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        int lens = nums.size();</span><br><span class="line">        k %= lens;</span><br><span class="line">        vector&lt;int&gt; newNums(lens);</span><br><span class="line">        for (int i = 0; i &lt; lens; i++) {</span><br><span class="line">            newNums[i] = i &lt; k ? nums[lens - k + i] : nums[i - k];</span><br><span class="line">        }</span><br><span class="line">        copy(newNums.begin(), newNums.end(), nums.begin());</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="模拟"><a href="#模拟" class="headerlink" title="模拟"></a><font size="5" color="red">模拟</font></h1><p>模拟的思路是来自于数据结构，<strong>题目的要求类似于一个队列操作，每次从队尾取出元素，在队头插入元素</strong>。因此一个简单的做法是将元素都放入一个队列，然后移动k次即可。</p>
<p>将元素移动到队列所用的时间是$O(n)$，因此算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>，其中n是数组中元素的个数。</p>
<p>当然小伙伴们也可以在数组中进行尾部删除和头部插入，不借助队列，这样<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void rotate(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        int lens = nums.size();</span><br><span class="line">        k %= lens;</span><br><span class="line">        deque&lt;int&gt; newNums(lens);</span><br><span class="line">        for (int i = 0; i &lt; lens; i++) {</span><br><span class="line">            newNums[i] = nums[i];</span><br><span class="line">        }</span><br><span class="line">        while (k--) {</span><br><span class="line">            int x = newNums.back();</span><br><span class="line">            newNums.pop_back();</span><br><span class="line">            newNums.push_front(x);</span><br><span class="line">        }</span><br><span class="line">        for (int i = 0; i &lt; lens; i++) {</span><br><span class="line">            nums[i] = newNums[i];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="环状替换"><a href="#环状替换" class="headerlink" title="环状替换"></a><font size="5" color="red">环状替换</font></h1><p>这个方法是我参考Leetcode官方题解中的一个方法。<strong>我们的问题在于如果将第一个元素放到第1+k个元素中，这时如果考虑第二个元素就会导致第1+k个元素已经被覆盖，当考虑到第1+k的元素就会发生错误。因此我们可以将第一个元素放到第1+k个元素时，考虑第1+k个元素应该放在1+2k处。然后考虑第1+2k个元素应该放在1+3k处。。。</strong></p>
<p>用样例进行举例[1,2,3,4,5,6,7]，k=3。这时我们考虑1，移动3个单位后，1应该放在4这个位置，那么我们将4拿起来，将1放在该位置上。然后我们考虑4，4应该放在7这个位置上，那么我们将7拿起来，将4放在该位置上。然后我们考虑7，7应该放在3这个位置上，那么我们将3拿起来，将7放在该位置上。。。最后可以得到正确的结果。</p>
<p>但是这个问题的难点是当某些情况，我们如何知道后面的数字是否需要移动了呢？<br>可能这种说法难以理解，仍然举一个例子[1,2,3,4,5,6]，k=2，1放在3，3放在5，5放在1形成了一个闭环。这时就应该停止了。然后2放在4，4放在6，6放在2，也形成了一个闭环。那么我们是否还要分析3呢？答案是不需要的，如何判断3不需要是这个问题的难点。</p>
<p>其中一个思路是设置一个计数器cnt，进行一次放置操作，cnt++，当cnt等于n时，说明这n个数都已经安排过了，因此可以停下。</p>
<p>还有一个思路是数学思路，形成闭环数组一定是遍历了整数圈，不妨记为a，在本例中135是一个闭环，数组遍历了1圈。放置了b个数字，这里是3个数字。其中k=2。一定满足an = bk这个规律，这时显而易见的。因为一旦形成闭环，从i开始的放置操作就结束了。因此我们要让a最小，因为an一定是n的整数倍，也要一定是k的整数倍，我们如果证明n和k的最小公倍数满足等式，说明这时a一定是最小的。不妨设n和k的最小公倍数为m，m = pn，m = qk，那么p等于a，q = b，都是整数，满足公式，因此an = bk = n和k的最小公倍数lcm(n, k)。这时b = lcm(n, k) / k。说明一次遍历会放置b个元素，那么访问到所有的元素需要访问n / b次。根据数学概念nk / lcm(n, k) = gcd(n, k)其中gcd为最大公约数。</p>
<p>上面的分析有一些复杂，但是也比较好理解，小伙伴们用[1,2,3,4,5,6]这个样例，分别让k=2，k=3，k=4，k=5在草稿纸上面模拟一个这个过程就容易理解了。k=2时遍历1和2两个数字，遍历每个数字放置3次。k=3时，遍历1，2和3三个数字，遍历每个数字放置2次。k=4时，遍历1和2两个数字，每个数字放置3次。k=5时，遍历1这个数字，这个数字放置6次。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>，其中n是数组中元素的个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int gcd(int a, int b) {</span><br><span class="line">        return a == 0 ? b : gcd(b % a, a);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void rotate(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        int lens = nums.size();</span><br><span class="line">        k %= lens;</span><br><span class="line">        int n = gcd(k, lens);</span><br><span class="line">        for (int i = 0; i &lt; n; i++) {</span><br><span class="line">            int nextIdx = (i + k) % lens, curVal = nums[i];</span><br><span class="line">            while (nextIdx != i) {</span><br><span class="line">                swap(curVal, nums[nextIdx]);</span><br><span class="line">                nextIdx = (nextIdx + k) % lens;</span><br><span class="line">                curVal = curVal;</span><br><span class="line">            }</span><br><span class="line">            nums[nextIdx] = curVal;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化找规律"><a href="#优化找规律" class="headerlink" title="优化找规律"></a><font size="5" color="red">优化找规律</font></h1><p>这个题目的最优解法类似一个脑筋急转弯。我们想最后面的k个元素要放到最前面。我们并且要保持相对顺序。</p>
<p>那么我们先不管相对顺序，我们如何将后面k个元素放到最前面k个元素。是不是逆序即可。</p>
<p>逆序后，最后面k个元素在最前面，最前面的n-k个元素在最后面。但是这时候前面k个元素的顺序也是逆序的，并没有保持相对顺序，后面n - k个元素的顺序也是逆序的，也没有保持相对顺序，这时我们单独逆序前面k个元素和后面n - k个元素即可。</p>
<p><img src="/images/ALGORITHM/leetcode189_solve.png" alt="1"></p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>，其中n是数组中元素的个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void rotate(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        k %= nums.size();</span><br><span class="line">        reverse(nums.begin(), nums.end());</span><br><span class="line">        reverse(nums.begin(), nums.begin() + k);</span><br><span class="line">        reverse(nums.begin() + k, nums.end());</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目也是比较经典的题目了，这几种方法都非常好，希望小伙伴们都能够掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
      </categories>
  </entry>
  <entry>
    <title>函数参数</title>
    <url>/2021/04/22/compare_function%20parameter/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java75.png" alt="2"></p>
<h1 id="Java异常"><a href="#Java异常" class="headerlink" title="Java异常"></a><font size="5" color="red">Java异常</font></h1><p>  异常是指程序在执行过程中出现的非正常情况，最终导致JVM非正常停止。在Java语言中，异常的产生就是创建异常对象并抛出了一个异常对象，依次向上寻找是否有处理逻辑，如果到main方法仍然没有try…catch语句，则会继续抛出给JVM处理，JVM收到后会将异常信息以红色字体打印在控制台，并且终止程序，<br><a id="more"></a></p>
<h1 id="throw-throws关键字"><a href="#throw-throws关键字" class="headerlink" title="throw/throws关键字"></a><font size="5">throw/throws关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.io.FileNotFoundException;</span><br><span class="line"></span><br><span class="line">public class ExceptionClass {</span><br><span class="line">    //throws是异常处理的第一种方式，交给其他人处理。注意throws关键字必须写在方法声明处，throws关键字后声明的异常必须是Exception或子类，如果内部抛出了多个对象，则必须也声明多个异常，如果抛出的异常有子父类关系，则直接抛出父类异常即可。</span><br><span class="line">    public static void main(String[] args) throws FileNotFoundException {</span><br><span class="line">        test();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void test() throws FileNotFoundException {</span><br><span class="line">        //可以使用throw关键字在指定的方法中抛出指定的异常，注意throw关键字抛出的异常必须是Exception的子类对象，如果是RuntimeException或子类，我们可以不处理，如果是编译异常，则必须处理，要不继续throws，要不try...catch处理</span><br><span class="line">        throw new FileNotFoundException("没有找到文件异常！");</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java76.png" alt="1"></p>
<h1 id="try…catch关键字"><a href="#try…catch关键字" class="headerlink" title="try…catch关键字"></a><font size="5">try…catch关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class ExceptionClass {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        System.out.println("测试try...catch语句");</span><br><span class="line">        System.out.println("--------------------");</span><br><span class="line">        System.out.println(test1(10, 2));</span><br><span class="line">        System.out.println(test1(10, 0));</span><br><span class="line">        System.out.println("测试try...catch...finally语句");</span><br><span class="line">        System.out.println("--------------------");</span><br><span class="line">        System.out.println(test2(10, 2));</span><br><span class="line">        System.out.println(test2(10, 0));</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //在try...catch语句中，可能会抛出多个异常，那么就可以使用多个catch进行捕获。</span><br><span class="line">    //如果try中产生了异常，则会执行catch中的语句，执行完毕后执行try...catch语句后的代码；如果try中没有产生异常，则会执行完try中的语句，然后继续执行try...catch语句后的代码。</span><br><span class="line">    //如果有多个异常时，有三种解决方案，可以写多个try...catch语句进行分别处理，也可以写一个try语句，多个catch语句，但是子类异常的catch要写在前面，或者写一个try语句一个catch语句，在catch语句中写所有异常的父类，即可一次性抛出所有异常。</span><br><span class="line">    public static int test1(int a, int b){</span><br><span class="line">        int res;</span><br><span class="line">        try {</span><br><span class="line">            res = a / b;</span><br><span class="line">            System.out.println("执行try之后的语句");</span><br><span class="line">        }catch (ArithmeticException e) {</span><br><span class="line">            res = 0;</span><br><span class="line">            System.out.println("执行catch之后的语句");</span><br><span class="line">        }</span><br><span class="line">        System.out.println("执行try...catch之后的语句");</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //在try...catch...finally语句中，finally中的语句无论异常是否出现都会执行，常常用于资源回收和释放。</span><br><span class="line">    public static int test2(int a, int b){</span><br><span class="line">        int res;</span><br><span class="line">        try {</span><br><span class="line">            res = a / b;</span><br><span class="line">            System.out.println("执行try之后的语句");</span><br><span class="line">        }catch (ArithmeticException e) {</span><br><span class="line">            res = 0;</span><br><span class="line">            System.out.println("执行catch之后的语句");</span><br><span class="line">        }finally {</span><br><span class="line">            System.out.println("执行finally之后的语句");</span><br><span class="line">        }</span><br><span class="line">        System.out.println("执行try...catch之后的语句");</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java77.png" alt="1"></p>
<h1 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a><font size="5">自定义异常</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//自定义异常类必须继承Exception或RuntimeException</span><br><span class="line">//继承Exception：则自定义异常是编译期异常，如果抛出异常则必须处理。</span><br><span class="line">public class MyException1 extends Exception {</span><br><span class="line">    public MyException1(String message) {</span><br><span class="line">        super(message);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//继承RuntimeException：则自定义异常是运行期异常，无需处理，交给JVM也可。</span><br><span class="line">public class MyException2 extends RuntimeException {</span><br><span class="line">    public MyException2(String message) {</span><br><span class="line">        super(message);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class ExceptionClass {</span><br><span class="line">    public static void main(String[] args) throws MyException1 {</span><br><span class="line">        try{</span><br><span class="line">            test1();</span><br><span class="line">            test2();</span><br><span class="line">        }catch (Exception e){</span><br><span class="line">            System.out.println("我解决了继承Exception类的异常");</span><br><span class="line">            System.out.println("我解决了继承RuntimeException类的异常");</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void test1() throws MyException1 {</span><br><span class="line">        throw new MyException1("这是一个继承Exception类的异常");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void test2() {</span><br><span class="line">        throw new MyException2("这是一个继承RuntimeException类的异常");</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java78.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  红色的异常语句是每一个程序员都遇到过的，在这里我们对异常进行了揭秘，可能在平时的做题或者工程中很难用到，我们还是要了解它的机制，当我们需要的时候可以及时回忆起来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>风格对比</category>
      </categories>
  </entry>
  <entry>
    <title>按要求补齐数组(Leetcode 330)</title>
    <url>/2021/04/21/program%20Leetcode330/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode330.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  这个题目看起来很复杂，其实难度并不大，给小伙伴们一些提示，先补最小无法拼凑的数字。<br><a id="more"></a></p>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>什么是先补齐最小值呢？<br>以样例1来解释，我们数组中有[1,3]，而我们要凑齐1到6，因此从1开始看一看能否凑齐。1，3，4可以，2，5，6都不可以，这时我们肯定要补一个小于等于2的数，如果补大的数，那么2还是无法得到，因此先补最小的一定是最优的。那么补哪一个数合适呢？补1还剩补2呢？这时一定要补2。</p>
<p><strong>这里给出结论，如果最小无法拼凑的数字为k，那么就补k一定是最优的。因为从1到k - 1都是可以拼凑的，那么补了k，从1到2k - 1都是可以拼凑的。这样范围是最大的</strong>。</p>
<p><strong>如果没有拼凑的数字是k，数组中存在比k小的元素m，我们应该如何操作呢？我们可以使用m使得无法拼凑的最小数字变成k + m，这也非常好理解的</strong>。</p>
<p>以样例2来说明，[1,5,10]，令x是当前无法拼凑的最小值，初始值设为1，令idx = 0，代表当前已经用了多少个数字，当1无法获得的时候，我们先查数组中是否有小于等于x但是没有使用的元素，如果有，x += nums[idx++]，这句话的意思是可以用数组中的元素扩大范围。</p>
<p>那么无法拼凑的最小值为2，然后再查数组中是否有2，这里没有，那么需要补一个2，这时无法拼凑的最小值变为4。数组中也没有4，补一个4，这时无法拼凑的最小值为8。</p>
<p>这时发现有一个元素5小于等于8，没有用到，可以使用这个元素扩大范围，这时无法拼凑的最小值为8+5=13。这时发现10小于等于13，没有用到，可以进一步扩大范围到13+10=23。因此补2和4，可以最大实现到23都可以由数组中的数字表示。</p>
<p>算法的<strong>时间复杂度为$O(log(n) + m)$，空间复杂度为$O(1)$</strong>，其中n是要达到的正整数，m为数组中元素的个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int minPatches(vector&lt;int&gt;&amp; nums, int n) {</span><br><span class="line">        long long x = 1;</span><br><span class="line">        int idx = 0;</span><br><span class="line">        int res = 0;</span><br><span class="line">        while (x &lt;= n) {</span><br><span class="line">            if (idx &lt; nums.size() &amp;&amp; x &gt;= nums[idx]) { x += nums[idx++]; }</span><br><span class="line">            else { </span><br><span class="line">                x *= 2;</span><br><span class="line">                res++;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  数学问题可能需要我们开动脑筋，看一看补齐元素有什么规律，后来发现补齐小的元素一定是最优的，找到突破口，再慢慢修改调整代码即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>柱状图中最大的矩形(Leetcode 84)</title>
    <url>/2021/04/19/program%20Leetcode84/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode84.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  本题我在多个平台都见过，可以说是一个比较经典的单调栈问题了，对于单调栈类型的题目，我们要深刻理解题目，然后找出单调的关系。小伙伴们注意理解我的解题过程。<br><a id="more"></a></p>
<h1 id="优化暴力法"><a href="#优化暴力法" class="headerlink" title="优化暴力法"></a><font size="5" color="red">优化暴力法</font></h1><p>暴力法是指对于每一个数，都以该数为最右端点，寻找左边左端点的过程。也可以让该数为左端点，寻找右边右端点的过程。什么意思呢？样例中[2,1,5,6,2,3]，我们以2为右端点，2为左端点，可以得到面积为2的矩形。然后以1为右端点，1为左端点，1为右端点，2为左端点。即枚举左右端点，其中长度为左右端点索引之差 + 1，高度为区间内的最小值。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(1)$</strong>。</p>
<p>当然这个算法是无法通过样例的，我们可以对其优化。</p>
<ul>
<li>优化1<br>如果res已知很大，假设为100，那么在枚举的过程中，高度上界 x 宽度都小于等于res的索引可以没有必要搜索了。如样例中[2,1,5,6,2,3]我们以6为右端点的时候，已经得到了10。当我们以2为右端点的时候，高度上界为2，宽度为5，即使在寻找左端点的过程中，高度没有下降都小于等于10，那么一定没有必要去搜索。直接进行下一个右端点3，寻找3的左端点时，当搜索到1时，高度降低为1，因此高度上界为1，宽度为6，即使在寻找左端点的过程中，高度是上界，都已经小于等于10，那么也可以停止搜索了。</li>
</ul>
<p>上面的解释应该很好理解，类似于一种剪枝的过程。这个样例也会TLE，能否进行再一次的优化呢？</p>
<ul>
<li>优化2<br>我们首先考虑一般情况下最大面积是什么情况？如果高度都差不多，最大面积是不是宽度越大，面积越大呢？因此宽度较大左右端点出现最大面积的概率更大一些。</li>
</ul>
<p>因此我们要让res先变大，然后这样剪枝就更快，这句话非常重要。在优化1中，高度上界 x 宽度的值小于等于res，我们可以剪枝。那么res是不是越大，剪枝越快呢？在提交的样例中，有一个全是1的样例，大约有20000个。按照优化1的方法会超时，因为右端点为k时，res = k + 1，然后右端点为k + 1时，还是要遍历一次所有的情况。如果我们从后向前遍历右端点，第一次就令最后一个索引为右端点，那么第一次就可以得到res = 20001，然后就会每次都停止搜索，对于这个情况时间复杂度退化为线性。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(1)$</strong>。但是实际上会远远低于这个时间复杂度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">     int largestRectangleArea(vector&lt;int&gt;&amp; heights) {</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = heights.size() - 1; i &gt;= 0; i--) {</span><br><span class="line">            int h = heights[i];</span><br><span class="line">            for (int j = i; j &gt;= 0; j--) {</span><br><span class="line">                h = min(h, heights[j]);</span><br><span class="line">                if ((long long)h * (i + 1) &lt;= res) { break; }</span><br><span class="line">                res = max(res, h * (i - j + 1));</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a><font size="5" color="red">单调栈</font></h1><p>在题目分析中说的，深刻理解题目，是啥意思呢？<strong>在本题中，我们发现如果是一个山谷型的区间，那么前面的无论有多高，都没有作用。如[5,2,4]这个区间，前面的5因为中间的2导致不起作用。无论前面的数字有多大，都不会影响结果。因此我们要维护一个单调递增的栈，当前面的数据较大时，因为它没有用，因此要将其弹出。然而在弹出时要对其进行计算，可能在该处产生最大面积</strong>。</p>
<p>以样例[2, 1, 5, 6, 2, 3]进行说明，假如当前已经到6这个元素，此时的递增栈为[1, 2]，注意为了计算面积，因此单调栈中保存的元素不是值，而是对应的索引，当6出现时，因为6大于5，5也就是原数组中第2个元素。因此将6对应的索引3压入栈中。此时遍历到元素2，因为2小于6，此时2后面的元素无法看到6，因此6是无效的元素，我们要将6对应的索引3弹出。在弹出时需要进行计算，此时2对应的索引为4，弹出3后，栈中还剩[1, 2]说明索引为2的元素比6小，因此4 - 2 - 1是高度为6的矩形的边长。面积为6。</p>
<p>此时发现2小于5，因此继续上述操作，弹出2，栈中还剩[1]，说明，索引为1的元素比5小，说明高度为5的矩形的边长是4 - 1 - 1，面积为10。依次这样下去。</p>
<p><strong>为了让算法更加鲁棒和简单，有一个小技巧，在前面和后面都加一个元素0，这样直接使用该算法即可，不需要考虑首尾元素的判断</strong>。如果不加前面的0，可能弹出元素后，栈为空，如[2, 1]这个例子，1出现会将2弹出，这时栈中为空，矩形的边长不好计算。如果后面不加0，可能最后一个元素是递增的，如[1, 2]这个例子，直接将2的索引1加入栈中，栈中元素为[0, 1]，然后算法就结束了，需要在循环后面单独判断，如果最后元素为0，那么会向前寻找到上一个0出现才会结束，算法结束后直接返回最大值即可。</p>
<p>这个小技巧需要小伙伴们多多琢磨一下，有时候算法也很难全部讲清楚，我上面说的解题过程比较绕，需要要伙伴跟着我的叙述在纸上一步一步写一些，这样做几遍可能就清晰了。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int largestRectangleArea(vector&lt;int&gt;&amp; heights) {</span><br><span class="line">        vector&lt;int&gt; newHeights(heights.size() + 2);</span><br><span class="line">        copy(heights.begin(), heights.end(), newHeights.begin() + 1);</span><br><span class="line">        vector&lt;int&gt; s;</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 0; i &lt; newHeights.size(); i++) {</span><br><span class="line">            while (!s.empty() &amp;&amp; newHeights[s.back()] &gt; newHeights[i]) {</span><br><span class="line">                int idx = s.back();</span><br><span class="line">                s.pop_back();</span><br><span class="line">                res = max(res, (i - s.back() - 1) * newHeights[idx]);</span><br><span class="line">            }</span><br><span class="line">            s.push_back(i);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  <strong>单调栈类型的题目，代码很简单，而且有固定的写法，都是一个for循环，内嵌一个while循环。但是如何将问题抽象出一个单调栈是非常困难的</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>单调栈/单调队列</category>
      </categories>
  </entry>
  <entry>
    <title>买卖股票的最佳时机 IV(Leetcode 188)</title>
    <url>/2021/04/17/program%20Leetcode188/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode188.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  这个题目有很多人都总结了各个版本的股票问题，可以持多股的问题，有冷却期的问题，可以重复交易的问题，要手续费的问题等等，今天遇到的这个问题是最多可以交易k次的题目。这类问题的统一解法都是动态规划思路。<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>我们做动态规划问题的核心是找到状态转移方程。这个题目很明显，我们用三维DP进行求解，第一维大小是prices.size()，说明此时到哪一天，第二维的大小是k，说明此时交易了多少次，第三位的大小为2，此时手里是否还有股票。当然小伙伴们觉得复杂可以使用两个二维DP，就是将第三个维度进行拆分。</p>
<p>这里我们定义卖出股票的时候记为交易了一笔，我们先思考，<strong>dp[i][j][0]是什么意思呢？代表第i天，已经交易了j次，手中没有股票的最大收益，可能是昨天就已经交易了j次，手中没有股票，今天没有买入。也可能是昨天交易了j - 1次，手中有一支股票，今天卖出去了，因此今天手中没有股票。</strong></p>
<script type="math/tex; mode=display">dp[i][j][0] = max(dp[i - 1][j][0], dp[i - 1][j - 1][1] + prices[i])</script><p>同理可得<strong>dp[i][j][1]是什么意思呢？代表第i天，已经交易了j次，手中有一支股票，可能是昨天就交易了j次，有一只股票，没有卖出，也可能是昨天已经交易了j次，手里没有股票，在今天买入了一只股票。</strong></p>
<script type="math/tex; mode=display">dp[i][j][1] = max(dp[i - 1][j][1], dp[i - 1][j][0] - prices[i])</script><p><strong>初始值我们只当手中没有股票的时候，最小收益为0，因为一次都不买即可，当手中有股票的时候，初始值都赋值为无穷小。然后给第一天赋值即可dp[0][0][0] = 0，dp[0][0][1] = -prices[0]。说明第一天没有买股票的时候收益为0，买了股票，收益为-prices[0]</strong>。</p>
<p>我们分析算法的时间复杂度，第一层循环n次，第二层循环k次，但是题目中k是1e9量级的，因此直接无法通过，我们再观察prices的长度最大为1000。而且最后手中一定是没有股票的，如果手中最后留有股票，我们可以不进行最后一次买入。即使一天买入，一天卖出，最大的交易次数也最多为prices.size() / 2。</p>
<p>算法的<strong>时间复杂度为$O(n \times min(n, k))$，空间复杂度为$O(n \times min(n, k))$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int maxProfit(int k, vector&lt;int&gt;&amp; prices) {</span><br><span class="line">        int length = prices.size();</span><br><span class="line">        if (k == 0 || length == 0) { return 0; }</span><br><span class="line">        k = min(k, length / 2);</span><br><span class="line">        vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(length, vector&lt;vector&lt;int&gt;&gt;(k + 1, {0, INT32_MIN}));</span><br><span class="line">        dp[0][0][1] = -prices[0];</span><br><span class="line">        for (int i = 1; i &lt; length; i++) {</span><br><span class="line">            dp[i][0][1] = max(dp[i - 1][0][1], dp[i - 1][0][0] - prices[i]);</span><br><span class="line">            for (int j = 1; j &lt;= k; j++) {</span><br><span class="line">                dp[i][j][0] = max(dp[i - 1][j][0], dp[i - 1][j - 1][1] + prices[i]);</span><br><span class="line">                dp[i][j][1] = max(dp[i - 1][j][1], dp[i - 1][j][0] - prices[i]);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 0; i &lt;= k; i++) {</span><br><span class="line">            res = max(res, dp[length - 1][i][0]);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  做股票类型的题目，一定要会动态规划，然后找出各个状态之间的变化，其实难度不大，小伙伴们可以将股票问题做归类，然后多练习两次，对动态规划的理解也会提高很多。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>发糖果(Leetcode 135)</title>
    <url>/2021/04/15/program%20Leetcode135/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode135.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  题目的描述非常简单，但是题目的难度比较大，这里没有告诉我们题目的数据范围，但是我在提交时超时了，其中超时的数据有20000个，因此要想出比$O(n^2)$更小的时间复杂度。<br><a id="more"></a></p>
<h1 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a><font size="5" color="red">遍历</font></h1><p>我们要求相邻的孩子中评分高的获得更多的糖果，这句话包含了两层意思，<strong>如果比前面的人评分高，那么必须比他的糖果数多，如果比后面的人评分高，那么必须比他的糖果数多。为了保证糖果数量最少，那么我们就比他多一个即可</strong>。</p>
<p>因此我们可以<strong>先和前面的人比较，如果ratings[i] &gt; ratings[i - 1]，说明比前面那个人评分高，则res[i] = res[i - 1] + 1，否则给这个人分配一个糖果即可，res[i] = 1</strong>。遍历完成后，我们得到了满足比前面孩子评分高获得更多糖果的要求。</p>
<p><strong>然后还要和后面的人比较，如果ratings[i] &gt; ratings[i + 1]，说明比后面那个人评分高，则res[i] = max(res[i], res[i + 1] + 1)</strong>。为什么这一次稍微麻烦了一些呢？是因为要同时满足两边的要求，第i个孩子满足比前面评分高的糖果数最低为res[i]，满足比后面评分高的糖果数最低为res[i + 1] + 1，同时满足就是两者取最大值。两次遍历后得到的res数组就是最优的分配方案。要求糖果数可以在第二次遍历时求和，也可以进行第三次遍历，对res数组求和。</p>
<p>有的小朋友就会有疑问，会不会在第二次遍历时影响到第一次遍历的结果，导致不满足评分比前面的高，分到的糖果多呢？这是不会的，小伙伴担心的是这种情况，例如1354321。第一次遍历后，糖果的分配应该是1231111。小伙伴们担心第二次遍历时第四个孩子会不会在分配时超过第三个孩子。这是有可能发生的，但是发生后还会被第三个孩子超过。当第二次从后向前遍历到第四个孩子时的分配情况是这样的1234321。这时遍历到第三个孩子，因为第三个孩子比第四个孩子评分高，因此还会做res[2] = max(res[2], res[3] + 1)。这样第三个孩子又会超过第四个孩子。最优解应该是1254321。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int candy(vector&lt;int&gt;&amp; ratings) {</span><br><span class="line">        int length = ratings.size();</span><br><span class="line">        vector&lt;int&gt; res(length, 1);</span><br><span class="line">        for (int i = 1; i &lt; length; i++) {</span><br><span class="line">            if (ratings[i] &gt; ratings[i - 1]) { res[i] = res[i - 1] + 1; }</span><br><span class="line">        }</span><br><span class="line">        int candy = res.back();</span><br><span class="line">        for (int i = length - 2; i &gt;= 0; i--) {</span><br><span class="line">            if (ratings[i] &gt; ratings[i + 1]) { res[i] = max(res[i], res[i + 1] + 1); }</span><br><span class="line">            candy += res[i];</span><br><span class="line">        }</span><br><span class="line">        return candy;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化遍历"><a href="#优化遍历" class="headerlink" title="优化遍历"></a><font size="5" color="red">优化遍历</font></h1><p>上面的算法比较容易理解，代码写起来也非常简单和美观，推荐小伙伴们使用第一种算法。</p>
<p>第二种算法是一个拓展，希望小伙伴们了解即可。</p>
<p><strong>我们将孩子看成一个山峰，其中上坡的高度记为inc，下坡的高度记为dec。上坡高度指该同学左边最近的一次连续上升数量。如12321，那么3的上坡高度就是3，因为1&lt;2&lt;3，上坡高度k也指这个孩子应该分发的个数。因为上坡的起点可以分发1个糖果，那么上坡高度就是分发k个糖果。这和第一种算法的前半部分是类似的</strong>。</p>
<p><strong>我们现在关心下坡的情况。下坡是指该同学连续下降次数，但是下坡不包括山顶元素，如12321，在3这个时候，上坡高度为3，然后开始下坡，到达2时，下坡高度为1，到达末尾时，下坡的高度是2</strong>。</p>
<p>**假如下坡的高度是k，下坡时，有两种情况。</p>
<ol>
<li>如果下坡的高度小于上坡的高度，那么我们就从1加到k即可。如13543，到达4时下坡高度为1，说明，可以给评分为4的孩子1个糖果，到达3时，下坡高度为2，此时糖果总数+2，可理解为将评分为4的孩子的糖果给评分为3的孩子，然后给评分为4的孩子两个糖果。即糖果向后移动一个。</li>
<li>如果下坡的高度大于上坡的高度，如1354321。到达3时，下坡高度为2，糖果数+2。到达2时，下坡高度为3，这样就会产生一些问题，如果将评分为3孩子的一个糖果给评分为2的孩子，评分为4的孩子的两个糖果给评分为3的孩子，再给评分为4的孩子3个糖果，就会错误。因为此时评分为5的孩子也是3个糖果，评分为4的孩子也是3个糖果。不满足评分高的孩子糖果数多。那么当上坡高度等于下坡高度时，我们就要额外给山顶的孩子一个糖果，让他高于右边的孩子。此时到达2时应该+4，而不是+3。这样的分配方案就是124321。然后最后一个评分为1的孩子，将4321向后移动，加上一个5给山顶的孩子**。</li>
</ol>
<p>小伙伴们可以拿起笔和纸绘制一下这个过程，理清楚以后还是比较清晰的。可以配合这代码一起看。</p>
<p>在这个过程中，我们只需要判断处在上升还是下降过程中，记录上坡高度，下坡高度，第i个孩子前面那个孩子的糖果数即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int candy(vector&lt;int&gt;&amp; ratings) {</span><br><span class="line">        int length = ratings.size(), candy = 1, inc = 1, dec = 0, cur = 1;</span><br><span class="line">        for (int i = 1; i &lt; length; i++) {</span><br><span class="line">            if (ratings[i] &gt;= ratings[i - 1]) {</span><br><span class="line">                dec = 0;</span><br><span class="line">                cur = ratings[i] == ratings[i - 1] ? 1 : cur + 1;</span><br><span class="line">                candy += cur;</span><br><span class="line">                inc = cur;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                dec++;</span><br><span class="line">                if (dec == inc) { dec++; }</span><br><span class="line">                candy += dec;</span><br><span class="line">                cur = 1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return candy;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目我推荐小伙伴们使用第一种算法，第二种算法比较绕，也难以想到。第一次做这个题目的小伙伴可能会被难住，多做一些题目，多见识一些方法就会更加得心应手。在笔试中遇到原题的概率相对较少，但是在面试中经常会遇到原题，因此多做题是非常有必要的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
      </categories>
  </entry>
  <entry>
    <title>使用最小花费爬楼梯(Leetcode 746)</title>
    <url>/2021/04/11/program%20Leetcode746/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode746.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  爬楼梯问题大家都已经很熟悉了，这个问题比爬楼梯问题稍微复杂一些，不过思路和方法都是类似的，小伙伴们还记得如何求解吗？<br><a id="more"></a></p>
<h1 id="记忆化-DFS"><a href="#记忆化-DFS" class="headerlink" title="记忆化+DFS"></a><font size="5" color="red">记忆化+DFS</font></h1><p>经典的爬楼梯问题和斐波那契数列问题是相同的，可以通过记忆化+DFS或者DP来求解。</p>
<p>我们要求从0号或者1号位置出发到达n的最小花费。我们可以<strong>从后向前</strong>计算，<strong>令dfs(k)代表从k出发到达n的最小花费</strong>，先算从n - 1出发到达n的最小花费，从n - 2出发的最小花费……</p>
<p><strong>从k出发可以到k + 1索引，也可以到达k + 2索引，因此我们要求从k出发的最小花费，就要求min(dfs(k + 1), dfs(k + 2)) + cost[k]。为了节省冗余计算，我们使用一个哈希表记住从k出发的最小花费，这样递归的时候可以进行剪枝</strong>。</p>
<p>最后比较dfs(0)和dfs(1)的最小值即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int minCostClimbingStairs(vector&lt;int&gt;&amp; cost) {</span><br><span class="line">        unordered_map&lt;int, int&gt; mem;</span><br><span class="line">        int length = cost.size();</span><br><span class="line">        return min(dfs(cost, 0, mem, length), dfs(cost, 1, mem, length));</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int dfs(vector&lt;int&gt;&amp; cost, int idx, unordered_map&lt;int, int&gt;&amp; mem, int&amp; length) {</span><br><span class="line">        if (idx &gt;= length) { return 0; }</span><br><span class="line">        if (!mem.count(idx)) { mem[idx] = min(dfs(cost, idx + 1, mem, length), dfs(cost, idx + 2, mem, length)) + cost[idx]; }</span><br><span class="line">        return mem[idx];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我认为DP解法是解决这类问题的最优解法，也是需要小伙伴掌握的一种解法。</p>
<p>其实DFS+记忆化本质上就是一种DP思想，只不过用递归的方式进行实现罢了。</p>
<p>DP介绍的是<strong>从前向后</strong>的计算方法，<strong>令dp[k]是到达k的最小花费</strong>，先算到达2的最小花费，到达3的最小花费……</p>
<p><strong>从k - 2出发可以到k索引，从k - 1出发也可以到达k索引，因此我们要求到达k的最小花费，就要求min(dp[k - 1], dp[k - 2]) + cost[k]。因为我们每次只用到前两次的数据，因此我们还可以进一步减小空间复杂度</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int minCostClimbingStairs(vector&lt;int&gt;&amp; cost) {</span><br><span class="line">        int f0 = cost[0], f1 = cost[1];</span><br><span class="line">        for (int i = 2; i &lt; cost.size(); i++) {</span><br><span class="line">            int f2 = min(f0, f1) + cost[i];</span><br><span class="line">            f0 = f1;</span><br><span class="line">            f1 = f2;</span><br><span class="line">        }</span><br><span class="line">        return min(f0, f1);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  爬楼梯问题太经典了，小伙伴们一定要学会DP求解的思路。如果还能提出DFS+记忆化的方案，也能给你在面试中的表现大大加分，可能不需要写DFS+记忆化的过程，只需要实现DP，然后口述记忆化的流程即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
        <category>记忆化</category>
      </categories>
  </entry>
  <entry>
    <title>去除重复字母(Leetcode 316)</title>
    <url>/2021/04/08/program%20Leetcode316/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode316.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  第一次做这个题目的时候，犯了一个错误，没有注意到不能打乱其他字符的相对位置这个要求，也正是因为这个要求让这个题目的难度上升了一个档次，小伙伴们想一想如何解答？<br><a id="more"></a></p>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p>我们分析下面几种场景</p>
<p>**1. 如果当前字符已经出现在res中，那么直接跳过。如res = “bc”，此时遍历到b，b已经存在res中，遍历下一个字符。</p>
<ol>
<li>如果res为空或者当前字符大于res中的最后一个字符或者res最后一个字符在后面不会出现，那么直接将该字符放在末尾。如res = “bc”，此时遍历到d，那么res = “bcd”一定是最优解。</li>
<li>如果当前字符小于res中的最后一个字符，并且res最后一个字符在后面还会出现，如样例1中s = “bcabc”，res = “bc”，此时遍历到a，c &lt; a，而且c在a后面还出现过，那么将c弹出，到a后面的c出现的时候在插入，这样的字典序会更小**。</li>
</ol>
<p>分析了这三个场景，我们用样例2来模拟这个过程。<br><img src="/images/ALGORITHM/leetcode316_solve.png" alt="1"></p>
<p>因为s由小写英文字母组成，建立一个长度为26的数组，其中<strong>保存每一个字符最后出现的位置，这样就可以判断该某个字符在后面是否还会出现</strong>。如c最后出现的位置是5，此时遍历到第3个元素a，那么就可以将c弹出，因为在3后面还会有c出现。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    string removeDuplicateLetters(string s) {</span><br><span class="line">        vector&lt;int&gt; alpha(26);</span><br><span class="line">        vector&lt;bool&gt; visited(26, false);</span><br><span class="line">        string res;</span><br><span class="line">        for (int i = 0; i &lt; s.size(); i++) { alpha[s[i] - 'a'] = i; }</span><br><span class="line">        for (int i = 0; i &lt; s.size(); i++) {</span><br><span class="line">            if (!visited[s[i] - 'a']) {</span><br><span class="line">                while (res.size() &amp;&amp; res.back() &gt; s[i] &amp;&amp; alpha[res.back() - 'a'] &gt; i) {</span><br><span class="line">                    visited[res.back() - 'a'] = false;</span><br><span class="line">                    res.pop_back();</span><br><span class="line">                }</span><br><span class="line">                res.push_back(s[i]);</span><br><span class="line">                visited[res.back() - 'a'] = true;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这是一个栈的变形问题，稍微困难一些，不容易想到栈的方法去解答，这时候我们可以模拟输出的过程，可能会引导我们想出栈的思路。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
        <category>字符串</category>
      </categories>
  </entry>
  <entry>
    <title>栈排序(Leetcode 程序员面试金典03.05)</title>
    <url>/2021/04/05/program%20Leetcode_interview03.05/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview03_05.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  这个题目考察我们对栈的理解和我们的思维能力，不难想到，希望小伙伴们可以先思考。</p>
<a id="more"></a>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p>我们只能利用两个栈，而且栈只可以取出顶部元素，无法进行排序，因此我们要好好使用它的性质。</p>
<p>因为每次push一个数，而不是将乱序的栈进行排序，这就给我们提供了思路。如果栈是有序的，那么再插入一个元素时有什么变化呢？如栈s是7，5，3，1。这时插入4，我们还想让栈是有序的，那么我们就需要将小于4的元素先存放起来，我们可以先存到另一个栈tmpS中，此时s：7，5，tmpS：1，3。这时我们可以将4加入到s中，再将tmpS中的元素取出放回到s中即可。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>，其中n为元素个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;stack&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class SortedStack {</span><br><span class="line">private:</span><br><span class="line">    stack&lt;int&gt; s, tmpS;</span><br><span class="line">public:</span><br><span class="line">    SortedStack() {</span><br><span class="line">        </span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void push(int val) {</span><br><span class="line">        while (!s.empty() &amp;&amp; s.top() &lt; val) {</span><br><span class="line">            tmpS.push(s.top());</span><br><span class="line">            s.pop();</span><br><span class="line">        }</span><br><span class="line">        s.push(val);</span><br><span class="line">        while (!tmpS.empty()) { </span><br><span class="line">            s.push(tmpS.top());</span><br><span class="line">            tmpS.pop();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void pop() {</span><br><span class="line">        if (!s.empty()) { s.pop(); }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int peek() {</span><br><span class="line">        return s.empty() ? -1 : s.top();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool isEmpty() {</span><br><span class="line">        return s.empty();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化栈"><a href="#优化栈" class="headerlink" title="优化栈"></a><font size="5" color="red">优化栈</font></h1><p>在上面的方法中，我们每次push都需要将小于val的元素都放入tmpS中，最后将tmpS中的元素再放回到s中。val的值非常大，那么每次都需要将所有元素弹出再插入一次，会浪费非常多的时间。</p>
<p><strong>我们可以不将tmpS栈中的元素都压入s中。就保持s中的元素是大于等于val的，并且s是递减栈，而tmpS中的元素是递增的，且元素值都小于val。这样再插入下一个值k时，如果k &gt;= val，我们就只用将s中小于k，大于等于val的值放入tmpS中即可，因为小于val的值已经放入tmpS中了，同理如果k &lt; val，我们只用将tmpS中大于等于k，小于val的值放入s中即可，因为大于等于val的值已经放入s中了</strong>。</p>
<p>我们可以比较一下7，5，3，1插入2，4，6时，两个方法操作push和pop的次数。</p>
<p>方案一：tmpS压入1，s弹出1，s压入2，s压入1，tmpS弹出1。此时2插入完毕，push3次，pop2次。tmpS压入1，s弹出1，tmpS压入2，s弹出2，tmpS压入3，s弹出3，s压入4，s压入3，tmpS弹出3，s压入2，tmpS弹出2，s压入1，tmpS弹出1。此时4插入完毕，push7次，pop6次。tmpS压入1，s弹出1，tmpS压入2，s弹出2，tmpS压入3，s弹出3，tmpS压入4，s弹出4，tmpS压入5，s弹出5，s压入6，s压入5，tmpS弹出5，s压入4，tmpS弹出4，s压入3，tmpS弹出3，s压入2，tmpS弹出2，s压入1，tmpS弹出1。此时6插入完毕，push11次，pop10次。一共三次操作后，push21次，pop18次。</p>
<p>方案二：tmpS压入1，s弹出1，s压入2。此时2插入完毕，push2次，pop1次。tmpS压入3，s弹出3，s压入4。此时4插入完毕，push2次，pop1次。tmpS压入5，s弹出5，s压入6。此时6插入完毕，push2次，pop1次。一共三次操作后，push6次，pop3次。</p>
<p>但是要注意peek操作和pop操作。因为要获取全体元素的最小值，而最小值存放在tmpS栈中，因此要先将tmpS中的元素全部压入s中才能够peek和pop。</p>
<p>最坏情况下算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>，其中n为元素个数，但是绝大多数情况下都比第一种算法快得多。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;stack&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class SortedStack {</span><br><span class="line">private:</span><br><span class="line">    stack&lt;int&gt; s1, s2;</span><br><span class="line">public:</span><br><span class="line">    SortedStack() {</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void push(int val) {</span><br><span class="line">        while (!s1.empty() &amp;&amp; s1.top() &lt; val) {</span><br><span class="line">            s2.push(s1.top());</span><br><span class="line">            s1.pop();</span><br><span class="line">        }</span><br><span class="line">        while (!s2.empty() &amp;&amp; s2.top() &gt;= val) {</span><br><span class="line">            s1.push(s2.top());</span><br><span class="line">            s2.pop();</span><br><span class="line">        }</span><br><span class="line">        s1.push(val);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void pop() {</span><br><span class="line">        move();</span><br><span class="line">        if (!s1.empty()) { s1.pop(); }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int peek() {</span><br><span class="line">        move();</span><br><span class="line">        return s1.empty() ? -1 : s1.top();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool isEmpty() {</span><br><span class="line">        return s1.empty() &amp;&amp; s2.empty();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void move() {</span><br><span class="line">        while (!s2.empty()) {</span><br><span class="line">            s1.push(s2.top());</span><br><span class="line">            s2.pop();</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  有趣的想法，方案二是我在看题解中发现的一种解法，非常非常的牛，因此介绍给小伙伴们学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
      </categories>
  </entry>
  <entry>
    <title>LRU 缓存(Leetcode 程序员面试金典16.25)</title>
    <url>/2021/04/03/program%20Leetcode_interview16.25/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview16_25.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   LRU缓存是一种常见的内存页面置换算法，其思想是：<strong>如果内存已满，并且需要新的数据，那么就需要从内存中将已有的数据和新的数据进行置换，置换的原则是将哪一个最近没有使用，就将哪一个替换出去</strong>。小伙伴们了解原理之后，能否实现这个算法呢？</p>
<a id="more"></a>
<h1 id="链表-哈希表"><a href="#链表-哈希表" class="headerlink" title="链表+哈希表"></a><font size="5" color="red">链表+哈希表</font></h1><p>要根据键key查找值value，因此我们需要一个哈希映射，因为我们有容量，有时间顺序，因此我们需要一个顺序容器。顺序容器有很多，有vector，deque，list，我们选择哪一个最合适呢？</p>
<p>首先我们比较这三个的区别<br><strong>vector：动态数组，元素连续存放。随机访问，或者在尾部插入和删除都是O(1)的时间复杂度，而普通的插入和删除需要移动元素，时间复杂度是O(n)</strong>。</p>
<p><strong>list：双向链表，内存空间是不连续的。在任何地方插入和删除都是O(1)的时间复杂度，但是随机访问的时间复杂度是O(n)的，且必须一个一个进行对比，无法直接索引</strong>。</p>
<p><strong>deque：双端队列，介于vector和list之间，内存分块，每一个存储块之间是连续存放的。允许头部操作和尾部操作。随机访问，头部操作和尾部操作都是O(1)的时间复杂度，而普通的插入和删除时间复杂度是O(n)</strong>。</p>
<p><strong>这里需要大量的移动操作，如果最近使用了内存中的数据，则需要将该数据放入尾部，说明最近已经使用，因此需要频繁的用到删除和插入操作。插入操作都是在尾部插入，vector，deque和list都可以，但是删除操作会在数据中间使用，因此使用list效率更高</strong>。</p>
<p>但是问题是我们需要找到该元素，才能将其删除，找到该元素的操作是O(n)的，那应该如何优化呢？</p>
<p>我们可以在哈希表中不仅仅存放键对应的值，而是将键的迭代器指针也存放进哈希表中，这样在查询时，不仅一次能够查到值，而且也能将该迭代器指针查到，这样可以直接操作这个指针。</p>
<p>然后我们分别分析下面这两个步骤的具体实现过程。<br><strong>put：put操作是向内存中放入元素，如果内存中已经有该元素，那么从哈希映射中查到该元素的指针，从list中移除该指针，并且在尾部重新添加键。修改哈希映射中的值和新的指针。如果内存中没有该元素，则需要分情况讨论，如果内存已满，需要将头部元素剔除，并且将对应的哈希表的键也剔除，因为头部元素是最久没有使用到的数据。然后再在尾部重新添加键，修改哈希映射中的值和新的指针</strong>。</p>
<p><strong>get：get操作相对于put操作简单一些，如果哈希表中没有查到，则返回-1，如果哈希表中查到了，说明本次使用到了该数据，需要将这个数据从原来的位置删除，并且添加到尾部。这个过程类似于放入已存在的元素。从哈希映射中查到该元素的指针，从list中移除该指针，并且在尾部重新添加键，修改哈希映射中的指针，并且返回值是哈希映射中的值</strong>。</p>
<p>算法的<strong>时间复杂度为$O(1)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;list&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class LRUCache {</span><br><span class="line">private:</span><br><span class="line">    int capacity;</span><br><span class="line">    list&lt;int&gt; lis;</span><br><span class="line">    unordered_map&lt;int, pair&lt;int, list&lt;int&gt;::iterator&gt;&gt; dic;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    LRUCache(int capacity) {</span><br><span class="line">        this-&gt;capacity = capacity;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int get(int key) {</span><br><span class="line">        if (!dic.count(key)) { return -1; }</span><br><span class="line">        list&lt;int&gt;::iterator it = dic[key].second;</span><br><span class="line">        lis.erase(it);</span><br><span class="line">        lis.push_back(key);</span><br><span class="line">        dic[key].second = --lis.end();</span><br><span class="line">        return dic[key].first;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void put(int key, int value) {</span><br><span class="line">        if (!dic.count(key)) {</span><br><span class="line">            if (lis.size() == capacity) {</span><br><span class="line">                dic.erase(lis.front());</span><br><span class="line">                lis.pop_front();</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        else {</span><br><span class="line">            list&lt;int&gt;::iterator it = dic[key].second;</span><br><span class="line">            lis.erase(it);</span><br><span class="line">        }</span><br><span class="line">        lis.push_back(key);</span><br><span class="line">        dic[key] = { value, --lis.end() };</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="自定义双向链表"><a href="#自定义双向链表" class="headerlink" title="自定义双向链表"></a><font size="5" color="red">自定义双向链表</font></h1><p>这个方法是小伙伴们务必掌握的，这非常锻炼小伙伴们对于数据结构的知识。</p>
<p>我们<strong>手动创建一个双向链表，和上面一样，实现在尾部插入和任意节点删除即可</strong>，思路和上面完全相同，直接看代码吧。</p>
<p>算法的<strong>时间复杂度为$O(1)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Node {</span><br><span class="line">public:</span><br><span class="line">    int key, value;</span><br><span class="line">    Node* prev, * next;</span><br><span class="line"></span><br><span class="line">    Node() : key(0), value(0), prev(NULL), next(NULL) {}</span><br><span class="line"></span><br><span class="line">    Node(int key, int value) : key(key), value(value), prev(NULL), next(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class LRUCache {</span><br><span class="line">private:</span><br><span class="line">    unordered_map&lt;int, Node*&gt; dic;</span><br><span class="line">    Node* head, * tail;</span><br><span class="line">    int capacity;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    LRUCache(int capacity) : capacity(capacity) {</span><br><span class="line">        head = new Node;</span><br><span class="line">        tail = new Node;</span><br><span class="line">        head-&gt;next = tail;</span><br><span class="line">        tail-&gt;prev = head;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int get(int key) {</span><br><span class="line">        if (!dic.count(key)) { return -1; }</span><br><span class="line">        Node* node = dic[key];</span><br><span class="line">        remove(node);</span><br><span class="line">        addToTail(node);</span><br><span class="line">        return node-&gt;value;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void put(int key, int value) {</span><br><span class="line">        if (!dic.count(key)) {</span><br><span class="line">            if (capacity == dic.size()) {</span><br><span class="line">                dic.erase(head-&gt;next-&gt;key);</span><br><span class="line">                delete remove(head-&gt;next);</span><br><span class="line">            }</span><br><span class="line">            Node* node = new Node(key, value);</span><br><span class="line">            addToTail(node);</span><br><span class="line">            dic[key] = node;</span><br><span class="line">        }</span><br><span class="line">        else {</span><br><span class="line">            Node* node = dic[key];</span><br><span class="line">            remove(node);</span><br><span class="line">            addToTail(node);</span><br><span class="line">            dic[key]-&gt;value = value;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void addToTail(Node* node) {</span><br><span class="line">        node-&gt;next = tail;</span><br><span class="line">        node-&gt;prev = tail-&gt;prev;</span><br><span class="line">        tail-&gt;prev-&gt;next = node;</span><br><span class="line">        tail-&gt;prev = node;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    Node* remove(Node* node) {</span><br><span class="line">        node-&gt;prev-&gt;next = node-&gt;next;</span><br><span class="line">        node-&gt;next-&gt;prev = node-&gt;prev;</span><br><span class="line">        return node;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  构建类的题型一般都是考察在已有的数据结构上加以变化，形成一种针对于特定问题的数据结构。这要求小伙伴们对数据结构的熟练程度非常高，虽然在笔试中很少遇到这样的题目，但是在面试中可能会让小伙伴们实现某种特定的结果，如字节跳过就曾考察过构造类的问题。可能一道题就会让你与某个岗位失之交臂，或者待遇相差很大，因此小伙伴们要重视起来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>哈希表</category>
        <category>链表</category>
      </categories>
  </entry>
  <entry>
    <title>商品折扣后的最终价格(Leetcode 738)</title>
    <url>/2021/04/01/program%20Leetcode738/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode738.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是一个数学题，数学题的做法是找到规律，往往可以用贪心的思路进行解题。<br><a id="more"></a></p>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>要求是满足每一位都是单调递增的。那么如果出现递减应该如何修改呢？</p>
<p><strong>如果出现递减，我们就要将前一位减1，然后将后面的所有位都置为9，这样才能满足小于等于N，且结果最大，这就是本题的贪心思想</strong>。</p>
<p>但是小伙伴们要注意向前面借一位，可能会导致前面的位数不是单调递减的。如332这个例子，我们发现第二个3后面有一个2，因此2会向3借一位，因此第二个3变成了2，然后在后面所有位置9，变为329。但是这就会导致新产生的2和前面的3不满足单调递增关系，因此要再次操作，最多会操作9次。</p>
<p>因为我们按照位来操作，因此算法的<strong>时间复杂度为$O(log^2(n))$，空间复杂度为$O(log(n))$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int monotoneIncreasingDigits(int N) {</span><br><span class="line">        string strN = to_string(N);</span><br><span class="line">        while (1) {</span><br><span class="line">            for (int i = 1; i &lt; strN.size(); i++) {</span><br><span class="line">                if (strN[i - 1] &gt; strN[i]) {</span><br><span class="line">                    strN[i - 1] -= 1;</span><br><span class="line">                    for (int j = i; j &lt; strN.size(); j++) {</span><br><span class="line">                        strN[j] = '9';</span><br><span class="line">                    }</span><br><span class="line">                    break;</span><br><span class="line">                }</span><br><span class="line">                if (i == strN.size() - 1) { return stoi(strN); }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return stoi(strN);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化贪心"><a href="#优化贪心" class="headerlink" title="优化贪心"></a><font size="5" color="red">优化贪心</font></h1><p>我们发现上面做法虽然很快，但是仍然有很多冗余操作，因为<strong>对于后面置9的操作可能会做很多次</strong>。</p>
<p>举一个例子，33332，第一次遍历后会变成33329，此时最后一位置9，第二次遍历后会变成33299，此时最后两位置9，第三次遍历后会变成32999，此时最后三位置9，第四次遍历后会变成29999，此时最后4位置9。最后一位置了4次9，每一次遍历都会重新赋值一次。因为题目中的整数是位于[0, 1e9]，所以$log^2(1e9)$也非常小，因此感觉速度非常快。</p>
<p>我们还可以对其优化，如果我们用right表示末尾置9的位置，如上例，第一次将最后一位置9后，第二次遍历我们就将倒数第二位置9即可，这样最多置log(n)个9。</p>
<p>算法的<strong>时间复杂度为$O(log(n))$，空间复杂度为$O(log(n))$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int monotoneIncreasingDigits(int N) {</span><br><span class="line">        string strN = to_string(N);</span><br><span class="line">        int right = strN.size();</span><br><span class="line">        while (right &gt; 1) {</span><br><span class="line">            for (int i = 1; i &lt; right; i++) {</span><br><span class="line">                if (strN[i - 1] &gt; strN[i]) {</span><br><span class="line">                    strN[i - 1]--;</span><br><span class="line">                    for (int j = i; j &lt; right; j++) {</span><br><span class="line">                        strN[j] = '9';</span><br><span class="line">                    }</span><br><span class="line">                    right = i;</span><br><span class="line">                    break;</span><br><span class="line">                }</span><br><span class="line">                if (i == right - 1) { return stoi(strN); }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return stoi(strN);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a><font size="5" color="red">双指针</font></h1><p>这个题目还可以进行优化，我们仍然举33332的例子说明，<strong>每次修改时，只可能影响到前一位</strong>，如第一次遍历后会变成33329，此时只可能影响到第三个3，对前两个3不会产生影响。我们在第二次遍历时，直接从2开始和前面的3比较即可，不用从第一位开始。同理第二次遍历后会变成33299，此时只可能影响到第二个3，对第一个3也不会产生影响。</p>
<p>我们再用left表示从哪一位开始比较，又可以对其进行优化。算法的<strong>时间复杂度为$O(log(n))$，空间复杂度为$O(log(n))$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int monotoneIncreasingDigits(int N) {</span><br><span class="line">        string strN = to_string(N);</span><br><span class="line">        int left = 1, right = strN.size();</span><br><span class="line">        while (left &lt; right) {</span><br><span class="line">            for (int i = left; i &lt; right; i++) {</span><br><span class="line">                if (strN[i - 1] &gt; strN[i]) {</span><br><span class="line">                    left = i &gt; 1 ? i - 1 : 1;</span><br><span class="line">                    strN[i - 1]--;</span><br><span class="line">                    for (int j = i; j &lt; right; j++) {</span><br><span class="line">                        strN[j] = '9';</span><br><span class="line">                    }</span><br><span class="line">                    right = i;</span><br><span class="line">                    break;</span><br><span class="line">                }</span><br><span class="line">                if (i == right - 1) { return stoi(strN); }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return stoi(strN);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  数学问题有时候比较绕人，思路不清晰会被绕进去，不过数学问题一般都是按位进行操作，方法正确不会出现超时。这个题目在笔试面试时只要找准贪心的核心思想，即使没有想到双指针的思路，用普通的方法也是可以的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>贪心</category>
        <category>双指针</category>
      </categories>
  </entry>
  <entry>
    <title>商品折扣后的最终价格(Leetcode 1475)</title>
    <url>/2021/03/28/program%20Leetcode1475/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1475.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目简单的原因不是因为算法简单，而是数据量简单。使用暴力法都可以通过，小伙伴们想一想如何优化？<br><a id="more"></a></p>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>思路非常简单，遍历每一个数，对于prices[i]，枚举j，找到满足条件的j。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; finalPrices(vector&lt;int&gt;&amp; prices) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        for (int i = 0; i &lt; prices.size(); i++) {</span><br><span class="line">            int diff = 0;</span><br><span class="line">            for (int j = i + 1; j &lt; prices.size(); j++) {</span><br><span class="line">                if (prices[j] &lt;= prices[i]) { diff = prices[j]; break; }</span><br><span class="line">            }</span><br><span class="line">            res.push_back(prices[i] - diff);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a><font size="5" color="red">单调栈</font></h1><p>暴力法我们每次都要从i+1开始向后比较，如果样例是2，3，4，5，1，那么2后面小于等于2的数是1，3后面小于等于3的数是1，这样会浪费大量的时间。</p>
<p><strong>我们可以维护一个递增的栈，当出现一个较小的数k时，我们依次弹出栈顶元素直到栈为空或者栈顶元素小于k。那么弹出的元素，都满足大于等于k，而且k是第一个满足条件的数，因此我们让这些数-k即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; finalPrices(vector&lt;int&gt;&amp; prices) {</span><br><span class="line">        vector&lt;int&gt; s;</span><br><span class="line">        for (int i = 0; i &lt; prices.size(); i++) {</span><br><span class="line">            while (!s.empty() &amp;&amp; prices[i] &lt;= prices[s.back()]) {</span><br><span class="line">                prices[s.back()] -= prices[i];</span><br><span class="line">                s.pop_back();</span><br><span class="line">            }</span><br><span class="line">            s.push_back(i);</span><br><span class="line">        }</span><br><span class="line">        return prices;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  有几类问题是小伙伴们必须必须掌握的，在这里进行一个列举，动态规划，双指针，单调栈，深搜，广搜，哈希表，递归，排序，堆，贪心。这是最最重要的一些算法类型，希望小伙伴们可以有针对性的进行训练。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>单调栈</category>
      </categories>
  </entry>
  <entry>
    <title>堆叠长方体的最大高度(Leetcode 219场单周赛第4题)</title>
    <url>/2021/03/25/program%20Leetcode1691/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1691.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第219场周赛的第四题，是一个我们有点面熟的题目了，但是难度要比之前的大得多。<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>我们拿到这个题目时，有些束手无策。但是我们发下满足条件的子序列中，一定满足一个规律。</p>
<p>我们<strong>将这个长方体都摆成width &lt; length &lt; height的形状，依然是满足条件的。如最终结果最底下长方体width，length和height分别记为a0, b0, c0，而上面的长方体记为a1, b1, c1。那么有$a0 \le a1, \ b0 \le b1, \ c0 \le c1$。这里将a0，b0，c0按照从小到大排序得到i0，j0，k0，再将a1，b1，c1按照从小到大排序得到i1，j1，k1。那么此时仍然满足$i0 \le i1, \ j0 \le j1, \ k0 \le k1$</strong>。这个逻辑小伙伴们可以进行证明，可以将a0，b0，c0，a1，b1，c1分成36种关系进行论证。</p>
<p><strong>因此我们将所有的长方体都按照该形状进行排列，不会影响最终结果。排列后，我们对整体进行排列，让width小的放在前面，width相同的将length小的放在前面，width和length都相同则将height小的放在前面。这样排序的目的是，让后面的长方体一定不能放在前面的长方体之上</strong>。</p>
<p>然后类似动态规划寻找最长递增子序列一样，满足width，length，height都大于之前的长方体才可以放入。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int maxHeight(vector&lt;vector&lt;int&gt;&gt;&amp; cuboids) {</span><br><span class="line">        for (auto&amp; v : cuboids) {</span><br><span class="line">            sort(v.begin(), v.end());</span><br><span class="line">        }</span><br><span class="line">        sort(cuboids.begin(), cuboids.end());</span><br><span class="line">        vector&lt;int&gt; dp(cuboids.size());</span><br><span class="line">        for (int i = 0; i &lt; cuboids.size(); i++) {</span><br><span class="line">            for (int j = 0; j &lt; i; j++) {</span><br><span class="line">                if (cuboids[i][1] &gt;= cuboids[j][1] &amp;&amp; cuboids[i][2] &gt;= cuboids[j][2]) {</span><br><span class="line">                    dp[i] = max(dp[i], dp[j]);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            dp[i] += cuboids[i][2];</span><br><span class="line">        }</span><br><span class="line">        return *max_element(dp.begin(), dp.end());</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目我没有做出来，我想到了第一步的内部排序，排完序后，我就不知道怎么进行下面的操作了。学习了这个方法之后，我在Leetcode354题俄罗斯套娃信封问题上，发现也是可以通过的。只不过这个方法不是那个题目的最优解。因此对于多维问题，都是可以使用这个方案的，希望小伙伴们能灵活运用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>排序</category>
      </categories>
  </entry>
  <entry>
    <title>石子游戏 VII(Leetcode 219场单周赛第3题)</title>
    <url>/2021/03/23/program%20Leetcode1690/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1690.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第219场周赛的第三题，这个题目难度不大，还记得我之前说过的思路吗？遇到博弈的题型，一般要去寻找<strong>贪心，动态规划和数学</strong>这三个方法，小伙伴们先想一想爱丽丝和鲍勃之间的胜败关系是如何转化的。<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p><strong>用dp[i][j]表示从i到j区间爱丽丝先手，最后得分的差值。那么爱丽丝可以有两种选择，一个是取第i个石子，也可以取第j个石子。取第i个石子就变成了dp[i + 1][j]，此时是鲍勃先手，代表鲍勃与爱丽丝的差值。因此爱丽丝与鲍勃之间的差值是-dp[i + 1][j]，而且爱丽丝取第i个石子后，还要加上剩余石子的得分，即stones[i + 1] + … + stones[j]。同理，如果取第j个石子，就是-dp[i][j - 1] + stones[i] + … + stones[j - 1]</strong>。所以状态转移方程可得</p>
<script type="math/tex; mode=display">dp[i][j] = max(-dp[i + 1][j] + cursum[j + 1] - cursum[i + 1], -dp[i][j - 1] + cursum[j] - cursum[i])</script><p><strong>其中cursum[i]是前i - 1个元素之和，称为前缀和</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n^2)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int stoneGameVII(vector&lt;int&gt;&amp; stones) {</span><br><span class="line">        int length = stones.size();</span><br><span class="line">        vector&lt;int&gt; cursum(length + 1);</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; dp(length, vector&lt;int&gt;(length));</span><br><span class="line">        for (int i = 1; i &lt; length + 1; i++) {</span><br><span class="line">            cursum[i] = cursum[i - 1] + stones[i - 1];</span><br><span class="line">        }</span><br><span class="line">        for (int l = 1; l &lt; length; l++) {</span><br><span class="line">            for (int i = 0; i &lt; length - l; i++) {</span><br><span class="line">                int j = i + l;</span><br><span class="line">                dp[i][j] = max(-dp[i + 1][j] + cursum[j + 1] - cursum[i + 1], -dp[i][j - 1] + cursum[j] - cursum[i]);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return dp[0].back();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  博弈的题目是非常有意思的，第一次做这种题型可能会有一些懵，多做一些就明白了其中的道理。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>博弈</category>
      </categories>
  </entry>
  <entry>
    <title>运算(Leetcode 程序员面试金典16.09)</title>
    <url>/2021/03/20/program%20Leetcode_interview16.09/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview16_09.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最头痛的题目来了，实现减法，乘法，除法操作，其中不能使用位运算操作。这个题目简直是折磨，但是也挺锻炼人对于计算机数据存储的知识。</p>
<a id="more"></a>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>这个问题太复杂了，我们先要实现取负数运算，因为减去一个数相当于加上这个数的相反数。这不仅在减法中用得到，在乘除法也可以用到，乘除一个负数等于乘这个数的相反数再取相反数。</p>
<p>其中难点不仅仅是正负的问题，还有INT32_MAX和INT32_MIN不相等的问题，因为负数是可以取到-2147483648，而正数只能取到2147483647。我看题解中很多人的方法都不周全，对于-1 - (-2147483648)这个例子，很多方法都不能通过。可能是官方的测试样例不够充分，所以都能够提交成功。</p>
<p>其中有一个人减法的方法是a + neg(b)。但是对于b=-2147483648这个情况，是不能直接取负数的。因此要进行特判。</p>
<p>下面我分成四个部分叙述我的方法。</p>
<h2 id="neg取相反数"><a href="#neg取相反数" class="headerlink" title="neg取相反数"></a><font size="4">neg取相反数</font></h2><p><strong>对于一个数217来说，我们如何得到-217呢？我们不可能每次都从0加(-1)，先尝试-1，然后再尝试-2，直到-217为止。题目中说我们可以使用常数，可以模拟计算机二进制的存储方式。我们先看217 + (-512)是否小于0，如果小于0，说明加上负数太大了，我们换-256，看217 + (-256)是否小于0，还是小于0，我们继续看217 + (-128)是否小于0，发现大于0，说明负数小了，我们就保留-128，此时仍然剩余89，继续寻找-64，发现-64也可以，保留-64，此时剩余25，继续寻找-32，-16，-8，-4，-2，-1。最后的结果是(-128) + (-64) + (-16) + (-8) + (-1) = -217</strong>。</p>
<p>对于负数取相反数同理，对于-217取相反数，那就判断-217 + 512是否大于0，如果大于0，说明加上正数太大了，就换256。最后也能得到217。</p>
<p>因此<strong>我们要提前记录下-1，-2，-4，-8…常数，和1，2，4，8…常数</strong>，这样不用每次都推导。</p>
<p>至于-2147483648取相反数，我们只用在对应的操作中进行特判即可。如减法，我们在减法函数中进行特判，因此不会出现传入-2147483648数的情况。</p>
<h2 id="minus减法"><a href="#minus减法" class="headerlink" title="minus减法"></a><font size="4">minus减法</font></h2><p><strong>对于b = INT32_MIN，我们可以返回a + INT32_MAX + 1即可。其他情况下返回a + neg(b)</strong>。</p>
<h2 id="multiply乘法"><a href="#multiply乘法" class="headerlink" title="multiply乘法"></a><font size="4">multiply乘法</font></h2><p>当b == 0时，return 0。当b == INT32_MIN，为了保证题目有意义，a一定是0或者1，a = 0时返回0，a = 1时返回b即可。当b &lt; 0 时，return neg(multiply(a, neg(b)))。这用到了数学中的交换律。a x b = -1 x (a x (-1 x b))。因此我们只用考虑b是正数的情况即可。</p>
<p>如13 x 14，我们13相加14次，虽然可以，但是一定会TLE，因此我们仍然要用到二进制的知识。14的二进制最后四位是1110。(1110 = 8 + 4 + 2+ 0)，因此我们可以使用乘法结合律，13 x 14 = 13 x (8 + 4 + 2 + 0) = 13 x 8 + 13 x 4 + 13 x 2 + 13 x 0。我们需要直到b的二进制表示，用一个bit数组和getBin函数，获取正数b的二进制表达，因为是正数，只需要31位。然后得到了二进制位以后，tmp = a，在这个例子中tmp = 13，每次移动一个tmp += tmp，等价于tmp翻倍。如果该位是1，则加上，该位是0继续下一位。</p>
<p>模拟计算的过程：<strong>最低为是0，因此res += 0，此时tmp = 26，第二位是1，因此res += 26，tmp = 52，第三位是1，因此res += 52，tmp = 104，第四位是1，因此res += 104。最后res = 0 + 26 + 52 + 104 = 182。当a为负数，计算过程是一样的</strong>。</p>
<p>其中注意tmp要用long long类型接收，否则可能会超出表达范围。</p>
<h2 id="divide除法"><a href="#divide除法" class="headerlink" title="divide除法"></a><font size="4">divide除法</font></h2><p>除法是最复杂的过程。但原理都是类似的。当a == 0时，return 0。当b == INT32_MIN时，如果a == b时，return 1，其余情况都return 0。当b == 1时，return a。当b &lt; 0 时，我们也和乘法做类似处理，这样b就一定为正数。</p>
<p>下面要分类讨论a的情况。如果a为正数<br>如180 / 13，和乘法一样，我们也要计算13的倍数表示，13， 26， 52， 104， 208…。因为180小于208，那么说明13的16倍是不够的，但是108大于104，说明13的8倍是超过的。这时要计算-13的倍数表示，-13，-26，-52，-104，-208。为什么还需要负数表示呢？因为要用180 + (-104)，表示当前还剩余的数字。</p>
<p>最高位是$b \times 2^{30}$，因为b不能为0，b = 1时前面已经特判，b最小是2，因此最高位已经远远超过了所有的整型范围。因此要用long long类型保存。如果使用vector容器保存，当这个值大于a就可以停止了，为了小伙伴理解方便，就用数组保存。如本例中，我们只用保存到104和-104即可，要使用数组来保存，就需要设置一个停止位，或者用long long保存。这里为了简单，就使用long long类型。在104后面的数组都大于180，因此都是不够的，都会跳过比较。我们直接从104开始模拟。</p>
<p>模拟计算的过程：<strong>180大于等于104，说明180大于等于13的8倍，我们让res += 8，然后180 + (-104) = 76。继续比较，76大于等于52，说明76大于等于13的4倍，我们让res += 4，然后76 + (-52) = 24。继续比较，24小于26，说明24不够13的2倍，不做操作。继续比较，24 大于等于13，说明24大于等于13的1倍，我们让res += 1。比较完成，res = 8 + 4 + 1 = 13</strong>。</p>
<p>上面是a为正数的情况，a为负数类似<br>如-180 / 13，-180小于等于-104，说明-180小于等于13的-8倍，res += -8，然后-180 + 104 = -76。继续比较，后面的过程就不重复了，最后res = (-8) + (-4) + (-1) = 13。</p>
<p>有的小伙伴们就会问了，为什么a为负数时不能也利用交换律返回neg(divide(neg(a), b))呢？这个我是想过的，因为a可能等于-2147483648，那么取负数就会出现问题。因此还是分类讨论稳妥一些。</p>
<p>这就是上面所有的分析过程，小伙伴们也可以简单一些，全部转换为long long类型，然后都改成只看前32位。最后计算完再强制转换为int返回即可。但是核心思想全部都是一样的。</p>
<p>算法的<strong>时间复杂度为$O(nlog(m))$，空间复杂度为$O(log(m))$</strong>，其中n为操作次数，m为数据的范围，这里为int的数据大小。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Operations {</span><br><span class="line">    int positive[31];</span><br><span class="line">    int negative[32];</span><br><span class="line">public:</span><br><span class="line">    Operations() {</span><br><span class="line">        int pos = 1, neg = -1;</span><br><span class="line">        for (int i = 0; i &lt; 31; i++) {</span><br><span class="line">            positive[i] = pos;</span><br><span class="line">            negative[i] = neg;</span><br><span class="line">            neg += neg;</span><br><span class="line">            if (i == 30) { break; }</span><br><span class="line">            pos += pos;</span><br><span class="line">        }</span><br><span class="line">        negative[31] = neg;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int neg(int a) {</span><br><span class="line">        int res = 0;</span><br><span class="line">        if (a &gt; 0) {</span><br><span class="line">            for (int i = 31; i &gt;= 0; i--) {</span><br><span class="line">                if (res + negative[i] + a &gt;= 0) {</span><br><span class="line">                    res += negative[i];</span><br><span class="line">                    if (res + a == 0) { break; }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        else if (a &lt; 0) {</span><br><span class="line">            for (int i = 30; i &gt;= 0; i--) {</span><br><span class="line">                if (res + positive[i] + a &lt;= 0) {</span><br><span class="line">                    res += positive[i];</span><br><span class="line">                    if (res + a == 0) { break; }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void getBin(int a, int* bit) {</span><br><span class="line">        for (int i = 30; i &gt;= 0; i--) { </span><br><span class="line">            if (a &gt;= positive[i]) {</span><br><span class="line">                bit[i] = 1;</span><br><span class="line">                a += negative[i];</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                bit[i] = 0;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int minus(int a, int b) {</span><br><span class="line">        return b == INT32_MIN ? a + INT32_MAX + 1 : a + neg(b);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int multiply(int a, int b) {</span><br><span class="line">        if (b == 0) { return 0;  }</span><br><span class="line">        if (b == INT32_MIN) { return a ? 0 : b; }</span><br><span class="line">        if (b &lt; 0) { return neg(multiply(a, neg(b))); }</span><br><span class="line">        int bit[31];</span><br><span class="line">        getBin(b, bit);</span><br><span class="line">        int res = 0;</span><br><span class="line">        long long tmp = a;</span><br><span class="line">        for (int i = 0; i &lt; 31; i++) {</span><br><span class="line">            if (bit[i]) { res += tmp; }</span><br><span class="line">            tmp += tmp;</span><br><span class="line">            if (tmp &gt; INT32_MAX || tmp &lt; INT32_MIN) { break; }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int divide(int a, int b) {</span><br><span class="line">        if (a == 0) { return 0; }</span><br><span class="line">        if (b == INT32_MIN) { return a == b ? 1 : 0; }</span><br><span class="line">        if (b == 1) { return a; }</span><br><span class="line">        return b &lt; 0 ? neg(divide(a, neg(b), b)) : divide(a, b, neg(b));</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int divide(int a, int positiveB, int negativeB) {</span><br><span class="line">        long long Ptimes[31], Ntimes[31];</span><br><span class="line">        long long Ptmp = positiveB, Ntmp = negativeB;</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 0; i &lt; 31; i++) {</span><br><span class="line">            Ptimes[i] = Ptmp;</span><br><span class="line">            Ptmp += Ptmp;</span><br><span class="line">            Ntimes[i] = Ntmp;</span><br><span class="line">            Ntmp += Ntmp;</span><br><span class="line">        }</span><br><span class="line">        if (a &gt; 0) {</span><br><span class="line">            for (int i = 30; i &gt;= 0; i--) {</span><br><span class="line">                if (a &gt;= Ptimes[i]) {</span><br><span class="line">                    res += positive[i];</span><br><span class="line">                    a += Ntimes[i];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        else {</span><br><span class="line">            for (int i = 30; i &gt;= 0; i--) {</span><br><span class="line">                if (a &lt;= Ntimes[i]) {</span><br><span class="line">                    res += negative[i];</span><br><span class="line">                    a += Ptimes[i];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目真的是太复杂了，但是其中蕴含着二进制的奥秘，这个知识点是需要小伙伴们掌握的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>最佳直线(Leetcode 程序员面试金典16.14)</title>
    <url>/2021/03/16/program%20Leetcode_interview16.14/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview16_14.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目比较经典，和Leetcode149题几乎相同，有很多人吐槽这个问题，说题目不清晰，样例看不懂，这里我说明一下，Leetcode149题是找出直线上最多的点数，一条直线最多能穿过多少个点，题意非常清晰。而这个题目的意思是找到这个直线，因为两个点才能确定一条直线，因此返回直线上索引最小的两个点。如这条直线穿过了3，6，7，9这四个点，那么就返回3和6即可。</p>
<a id="more"></a>
<h1 id="数学-哈希表"><a href="#数学-哈希表" class="headerlink" title="数学+哈希表"></a><font size="5" color="red">数学+哈希表</font></h1><p>这个题目有暴力解法，确定前两个点，判断第三个点是否在前两个点所在直线上。判断的方法有很多，可以根据前两个点确定直线方程，然后代入第三个点进行计算。也可以利用数学中向量共线知识进行求解。</p>
<script type="math/tex; mode=display">\frac{y3 - y2}{x3 - x2} = \frac{y2 - y1}{x2 - x1}</script><p>其中推荐使用向量共线进行求解，因为确定直线方程时可能存在着精度问题。但是这个两个方法的时间复杂度都是$O(n^3)$，我们就不过多介绍。</p>
<p><strong>这里介绍一种哈希表存储的方法。我们只要枚举第i个点，然后比较从i + 1到最后的点与第一个点的斜率。假设枚举第1个点，然后比较第2个点，第3个点…与第一个点的斜率，如果斜率相同，说明它们都在一条直线上。那么我们将斜率作为键进行保存，是不是就可以统计出来了呢</strong>？</p>
<p>这里要注意的是精度问题，因为<strong>除法可能会损失精度</strong>。我们应该如何去做呢？</p>
<p>斜率的计算公式是</p>
<script type="math/tex; mode=display">k = \frac{y2 - y1}{x2 - x1}</script><p><strong>如果我们用一个pair记录分子和分母，那么就用pair来查询，而且不损失精度。这时我们要保证分子和分母是互质的，而且分子和分母都取反后和原pair是相同的</strong>。如{2, 6}和{1, 3}是相同的，{2, 6}和{-2, -6}是相同的。我们可以去分母和分子的最大公约数，然后让它们都除以这个数，可以保证互质。然后让分子都变为大于等于0的数，如果分子等于0，那么让分子变为正数。那么{-2, -6}就会变成{1, 3}。{0, -10}就会变成{0, 1}。</p>
<p><strong>还要注意的是C++中unordered_map容器无法直接存储pair，vector等元素作为key，要实现哈希函数和判断相等的函数。因为pair中存在判断相等的函数，因此我们只需要实现哈希函数。写一个类，重载调用操作符operator()</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。</p>
<p>这个题目应该这样求解，使用C++语言难度还是比较大的，考察的知识点也很多，希望小伙伴们能够自己实现一遍。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class PairHash {</span><br><span class="line">public:</span><br><span class="line">    size_t operator() (const pair&lt;int, int&gt; p) const {</span><br><span class="line">        return hash&lt;int&gt;()(p.first) ^ hash&lt;int&gt;()(p.second);</span><br><span class="line">    }</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; bestLine(vector&lt;vector&lt;int&gt;&gt;&amp; points) {</span><br><span class="line">        vector&lt;int&gt; res = { 0, 1 };</span><br><span class="line">        int maxi = 2;</span><br><span class="line">        for (int i = 0; i &lt; points.size() - maxi; i++) {</span><br><span class="line">            unordered_map&lt;pair&lt;int, int&gt;, vector&lt;int&gt;, PairHash&gt; dic;</span><br><span class="line">            for (int j = i + 1; j &lt; points.size(); j++) {</span><br><span class="line">                int dx = points[j][0] - points[i][0], dy = points[j][1] - points[i][1];</span><br><span class="line">                int g = gcd(dx, dy);</span><br><span class="line">                dx = dx / g;</span><br><span class="line">                dy = dy / g;</span><br><span class="line">                if (dx &lt; 0) {</span><br><span class="line">                    dx = -dx;</span><br><span class="line">                    dy = -dy;</span><br><span class="line">                }</span><br><span class="line">                if (dx == 0 &amp;&amp; dy &lt; 0) {</span><br><span class="line">                    dy = -dy;</span><br><span class="line">                }</span><br><span class="line">                pair&lt;int, int&gt; p = { dx, dy };</span><br><span class="line">                if (dic.count(p)) { dic[p][0]++; }</span><br><span class="line">                else { dic[p] = { 2, i, j }; }</span><br><span class="line">                if (dic[p][0] &gt; maxi || (dic[p][0] == maxi &amp;&amp; dic[p][1] &lt; res[0]) || (dic[p][0] == maxi &amp;&amp; dic[p][1] == res[0] &amp;&amp; dic[p][2] &lt; res[1])) {</span><br><span class="line">                    maxi = dic[p][0];</span><br><span class="line">                    res[0] = dic[p][1];</span><br><span class="line">                    res[1] = dic[p][2];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int gcd(int a, int b) {</span><br><span class="line">        int c;</span><br><span class="line">        while (b) {</span><br><span class="line">            c = a % b;</span><br><span class="line">            a = b;</span><br><span class="line">            b = c;</span><br><span class="line">        }</span><br><span class="line">        return a;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  纯数学或者是几何的题目往往难度都比较复杂，需要考虑到精度问题，小伙伴们要使用一些奇技淫巧去躲避它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>Dota2 参议院(Leetcode 649)</title>
    <url>/2021/03/13/program%20Leetcode649/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode649.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目有难度，可能理解起来都比较困难。题目我是读了好久，然后样例也是迷迷糊糊不太清晰，应该多给出一些样例。不明白的小伙伴可以看我的分析，然后自己实现。<br><a id="more"></a></p>
<h1 id="队列-贪心"><a href="#队列-贪心" class="headerlink" title="队列+贪心"></a><font size="5" color="red">队列+贪心</font></h1><p>我最后理解了题意，这个问题是不会平局的，如果第一次没有结束，那么剩余的人还会进行第二次投票。<br>举个例子，”RRDDD”这个例子，一开始我的理解是平局，因为前面两个R会禁赛前面两个D，最后一个D会禁赛第一个R。因此只有一个R和一个D有投票权，因此平局。但是没有平局的输出，看了评论区和题解才明白，这时的顺序是R和D，因为第一个R和前两个D没有投票权，相当于踢出场外，剩下的是RD，继续投票，R会禁赛D，因此R胜利。</p>
<p>小伙伴们看了上面的分析能否写出这个题目呢？</p>
<p>这里用到了贪心的思路，我们都想胜利，那么如何做才能最优呢？<strong>我们要封禁即将要投票的对手，这是最优解，这样我们才能更好的保护我们的队员。如RDRD，第一个R要优先封印第一个D，将第一个D踢出场外，这样第二个R才不会被踢出场外</strong>。</p>
<p><strong>我们按照顺序将R和D分成两排，其中存储着所在位置的索引。比较两个队头元素哪一个小，说明哪一个有优先封印权，然后封印另一个队列的第一个元素。被封印的元素踢出场外，使用封印权的元素加到队列末尾。因为进入了下一轮，因此索引要+n，确保一定比上一轮的所有元素的索引都要大。等到哪一个队伍的元素都被踢出，则另一个队伍胜利</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    string predictPartyVictory(string senate) {</span><br><span class="line">        deque&lt;int&gt; R, D;</span><br><span class="line">        int n = senate.size();</span><br><span class="line">        for (int i = 0; i &lt; senate.size(); i++) {</span><br><span class="line">            senate[i] == 'R' ? R.push_back(i) : D.push_back(i);</span><br><span class="line">        }</span><br><span class="line">        while (!R.empty() &amp;&amp; !D.empty()) {</span><br><span class="line">            R.front() &lt; D.front() ? R.push_back(R.front() + n) : D.push_back(D.front() + n);</span><br><span class="line">            D.pop_front();</span><br><span class="line">            R.pop_front();</span><br><span class="line">        }</span><br><span class="line">        return R.empty() ? "Dire" : "Radiant";</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  博弈的题目都比较有意思，博弈题在这里总结一下，往往都有3个思路，一个是<strong>动态规划</strong>，要求解最后问题的最优解，我们先看子问题的最优解。另一个是<strong>贪心</strong>，如果当前最优就是全局最优，就可以使用贪心。最后一个是<strong>数学</strong>，有的博弈问题可以用数学公司或者数学思路求解，这个难度也是最大的。希望小伙伴们遇到这种问题能够想到这三个思路。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>博弈</category>
        <category>贪心</category>
        <category>队列</category>
      </categories>
  </entry>
  <entry>
    <title>奇数值单元格的数目(Leetcode 1252)</title>
    <url>/2021/03/11/program%20Leetcode1252/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1252.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   来一个简单题，看看小伙伴们能优化到什么程度？能否使用线性复杂度做出来这个题目呢？<br><a id="more"></a></p>
<h1 id="模拟"><a href="#模拟" class="headerlink" title="模拟"></a><font size="5" color="red">模拟</font></h1><p>数据量较小，我们使用模拟方法也可以求解。即<strong>建立一个大小为n x m的矩阵，然后遍历indices数组，每次修改n行和m列即可，最后判断矩阵中有多少个奇数</strong>。</p>
<p>算法的<strong>时间复杂度为$O(max(mn, k \times max(m, n)))$，空间复杂度为$O(mn)$</strong>，其中n，m是矩阵的行和列，k是索引数组indices的长度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int oddCells(int n, int m, vector&lt;vector&lt;int&gt;&gt;&amp; indices) {</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; array(n, vector&lt;int&gt;(m));</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (auto v : indices) {</span><br><span class="line">            for (int j = 0; j &lt; m; j++) { array[v[0]][j]++; }</span><br><span class="line">            for (int i = 0; i &lt; n; i++) { array[i][v[1]]++; }</span><br><span class="line">        }</span><br><span class="line">        for (int i = 0; i &lt; n; i++) {</span><br><span class="line">            for (int j = 0; j &lt; m; j++) { res += array[i][j] &amp; 1; }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化模拟"><a href="#优化模拟" class="headerlink" title="优化模拟"></a><font size="5" color="red">优化模拟</font></h1><p>要判断一个数是奇数还是偶数，我们只用关系它所在的行和列改变了多少次。因此我们使用两个一维矩阵表示所在的行改变了奇数次还是偶数次。false代表改变了偶数次，true代表改变了奇数次。</p>
<p>因此我们<strong>模拟时不用改变具体的每一个数，而是改变一行或者一列即可。最后计算第i行第j列是否为奇数时，只用关心对应的行和列是否不相等，如果行和列相等，那么说明它们改变了相同的次数，那么一定是偶数，否则一定是奇数</strong>。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(m + n)$</strong>，其中n，m是矩阵的行和列。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int oddCells(int n, int m, vector&lt;vector&lt;int&gt;&gt;&amp; indices) {</span><br><span class="line">        vector&lt;bool&gt; row(n, false), col(m, false);</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (auto v : indices) {</span><br><span class="line">            row[v[0]] = !row[v[0]];</span><br><span class="line">            col[v[1]] = !col[v[1]];</span><br><span class="line">        }</span><br><span class="line">        for (int i = 0; i &lt; n; i++) {</span><br><span class="line">            for (int j = 0; j &lt; m; j++) {</span><br><span class="line">                res += row[i] ^ col[j];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学优化"><a href="#数学优化" class="headerlink" title="数学优化"></a><font size="5" color="red">数学优化</font></h1><p>数学优化就更加巧妙了，我们不关心每一个数是否为奇数还是偶数，只关心该行或者列是否为奇数还是偶数。有的小伙伴好奇，这不是和上面的算法一样吗？</p>
<p>但是上面的算法虽然在模拟时没有考虑每一个元素，但是在最后判断时仍然遍历了所有的元素。我们可以通过数学的方法节省遍历时的时间复杂度。</p>
<p>思考：如果某一行修改了奇数次，那么该行所有元素为奇数的个数为多少？是不是修改了偶数列的次数。对于每一个修改了奇数次的行都是这样。因此<strong>对于所有奇数行来说，元素为奇数的个数为：修改奇数次的行数量 x 修改偶数次的列数量。同理，对于所有偶数行来说，元素为奇数的个数为：修改偶数次的行数量 x 修改奇数次的列数量</strong>。</p>
<p>因此我们只要在优化模拟方法中，直接统计修改奇数次的行数量，和修改奇数次的列数量即可。修改偶数次的行数量 = n - 修改奇数次的行数量，列数量同理。</p>
<p>算法的<strong>时间复杂度为$O(max(m, n, k))$，空间复杂度为$O(m + n)$</strong>，其中n，m是矩阵的行和列，k是索引数组indices的长度。。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int oddCells(int n, int m, vector&lt;vector&lt;int&gt;&gt;&amp; indices) {</span><br><span class="line">        vector&lt;bool&gt; row(n, false), col(m, false);</span><br><span class="line">        int rowOdd = 0, colOdd = 0, res = 0;</span><br><span class="line">        for (auto v : indices) {</span><br><span class="line">            row[v[0]] = !row[v[0]];</span><br><span class="line">            col[v[1]] = !col[v[1]];</span><br><span class="line">        }</span><br><span class="line">        for (int i = 0; i &lt; n; i++) {</span><br><span class="line">            rowOdd += row[i];</span><br><span class="line">        }</span><br><span class="line">        for (int j = 0; j &lt; m; j++) {</span><br><span class="line">            colOdd += col[j];</span><br><span class="line">        }</span><br><span class="line">        return rowOdd * (m - colOdd) + colOdd * (n - rowOdd);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  数学技巧在某些场合下能够大大提高我们的算法复杂度，但是有些数学技巧难以想到，因此我们多做题的目的就是开拓自己的视野，以后遇到相似问题可以有所启发。这个题目重点掌握第二个方法，对于修改一行或者一列的问题很有帮助。做这类问题很少进行完全的模拟，都需要用到一些小技巧。但是像第三个数学优化，有的问题可能没有这个方法，但是第二个方法基本上都可以用得到。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
      </categories>
  </entry>
  <entry>
    <title>数组拆分 I(Leetcode 561)</title>
    <url>/2021/03/08/program%20Leetcode561/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode561.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是一个贪心问题，有思路很好写，没有思路就非常困难，能难倒你们吗？<br><a id="more"></a></p>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a><font size="5" color="red">排序</font></h1><p>我们观察样例，<strong>假如有a &lt; b &lt; c &lt; d四个数，那么应该如何配对呢？如果a和谁配对，那么最小值都是a，因此我们尽量让a和次小值b配对，如果a不和b配对，假设a和c或者d配对，那么b就和d或者c配对，那么之和为a+b，如果a和b配对，那么之和为a+c，是大于a+b的，因此我们要让最小的两个数配对</strong>。那么多组数也是同理。</p>
<p>因此我们可以让数组进行排序，0，1为一组，2，3为一组，这样排序后nums[0] &lt; nums[1]，nums[2] &lt; nums[3]。因此我们把下标为偶数的求和，即可得到最后的结果。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int arrayPairSum(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        sort(nums.begin(), nums.end());</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i += 2) { res += nums[i]; }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a><font size="5" color="red">计数排序</font></h1><p>排序方法有很多，在这里不一一列举，常见的10种排序方法在Leetcode912题有详细介绍。这里主要说一下计数排序的思路。</p>
<p>因为这个题目已经告诉了我们整数的范围，范围不是很大，sort排序算法的时间复杂度是$O(nlog(n))$的，而<strong>计数排序特别适合于整数范围不大的情况</strong>，因此可以进行优化。</p>
<p><strong>我们统计每个元素出现次数，然后从小到大取出，在取出的过程中只取出下标为偶数的值即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int arrayPairSum(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int array[20001], init = -10000, res = 0, idx = 0;</span><br><span class="line">        memset(array, 0, sizeof(array));</span><br><span class="line">        for (int x : nums) { array[x - init]++; }</span><br><span class="line">        for (int i = init; i &lt;= 10000; i++) {</span><br><span class="line">            while (array[i - init]--) { res += (++idx % 2) * i; }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  排序是数组类型题目的常考知识点，<strong>当我们看到数据范围在1e4~1e7，我们要想到排序方法，在这个范围内$O(nlog(n))$的算法恰好满足条件，当数据范围达到1e8时，我们就不能用系统的排序方案，只能去寻找线性时间复杂度的解法</strong>。希望小伙伴们要有这个反应和判断。因为<strong>在笔试中，往往都会告诉我们数据的范围</strong>，因此这个能力非常重要。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
        <category>贪心</category>
        <category>排序</category>
      </categories>
  </entry>
  <entry>
    <title>下一个数(Leetcode 程序员面试金典05.04)</title>
    <url>/2021/03/05/program%20Leetcode_interview05.04/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview05_04.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目一看就是位运算来求解，小伙伴们看一看能找到什么规律。</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>这个题目可以看成两个问题，一个是找到比它大的最小的数，一个是比它小的最大的数。</p>
<p><img src="/images/ALGORITHM/leetcodeinterview05_04.png" alt="1"></p>
<p>因此这个问题变成了<strong>找第一个1后面出现的第一个0和第一个0后面出现的第一个1</strong>。</p>
<p>算法的<strong>时间复杂度为$O(log(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; findClosedNumbers(int num) {</span><br><span class="line">        if (num == INT32_MAX) return { -1, -1 };</span><br><span class="line">        int findOne = 1, findZero = 1;</span><br><span class="line">        vector&lt;int&gt; res(2, num);</span><br><span class="line"></span><br><span class="line">        int cntOne = -1;</span><br><span class="line">        while (!(num &amp; findOne)) {</span><br><span class="line">            findOne &lt;&lt;= 1;</span><br><span class="line">        }</span><br><span class="line">        while (findOne != INT32_MIN &amp;&amp; num &amp; findOne) {</span><br><span class="line">            res[0] ^= findOne;</span><br><span class="line">            cntOne++;</span><br><span class="line">            findOne &lt;&lt;= 1;</span><br><span class="line">        }</span><br><span class="line">        res[0] |= findOne;</span><br><span class="line">        if (findOne == INT32_MIN) { res[0] = -1; }</span><br><span class="line">        else {</span><br><span class="line">            findOne = 1;</span><br><span class="line">            while (cntOne--) {</span><br><span class="line">                res[0] |= findOne;</span><br><span class="line">                findOne &lt;&lt;= 1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        cntOne = 0;</span><br><span class="line">        while (num &amp; findZero) {</span><br><span class="line">            cntOne++;</span><br><span class="line">            res[1] ^= findZero;</span><br><span class="line">            findZero &lt;&lt;= 1;</span><br><span class="line">        }</span><br><span class="line">        while (findZero != INT32_MIN &amp;&amp; !(num &amp; findZero)) {</span><br><span class="line">            findZero &lt;&lt;= 1;</span><br><span class="line">        }</span><br><span class="line">        if (findZero == INT32_MIN) { res[1] = -1; }</span><br><span class="line">        else {</span><br><span class="line">            res[1] = (res[1] | (findZero &gt;&gt; 1)) ^ findZero;</span><br><span class="line">            findZero &gt;&gt;= 2;</span><br><span class="line">            while (cntOne--) {</span><br><span class="line">                res[1] |= findZero;</span><br><span class="line">                findZero &gt;&gt;= 1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目是一个难度较大的位运算，其中不仅仅包含了位运算的知识，还牵扯了许多数学的知识进去，而且还用到了一些贪心的思想，小伙伴们遇到这样的题目，可以先找一找规律，举两个例子，这样解题思路可能就会冒出来了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>将数组拆分成斐波那契序列(Leetcode 842)</title>
    <url>/2021/03/03/program%20Leetcode842/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode842.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目看起来非常简单，操作起来比较复杂，尤其是使用C++语言进行解答时，比Python语言困难得多。<br><a id="more"></a></p>
<h1 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a><font size="5" color="red">迭代</font></h1><p>先给小伙伴们介绍一下迭代解法，思路非常简答，<strong>枚举前两个数，然后递推后面的数即可</strong>。</p>
<p>其中介绍代码中一些变量的意义，其中p0等于0，说明第一个数是从0号索引开始的，p1从1到(S.size() + 1) / 2，当p1 = k时，说明第一个数的长度为k，因为第三个数的长度一定大于等于第一个，因此第一个数最多只有字符串长度的一半。p2是第三个数是从p2开始的。所以f0 = S.substr(0, p1)，f1 = S.substr(p1, p2 - p1)。</p>
<p>然后我们令curF0 = f0，curF1 = f1，curF2 = f0 + f1，curP2 = p2，我们只要查看S字符串从curP2开始，是否出现curF2即可。如果没有出现，说明f0和f1构造的不正确，如果出现则继续判断下一个元素是否出现。</p>
<p>因为我们只要枚举前两个数，每一次最多枚举log(C)位，在每一次枚举中，都需要验证后面的斐波那契数列是否正确，因此算法的<strong>时间复杂度为$O(nlog^2(C))$，空间复杂度为$O(1)$</strong>，其中C是整数的范围。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; splitIntoFibonacci(string S) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        char tmpC[20];</span><br><span class="line">        sprintf(tmpC, "%d", INT32_MAX);</span><br><span class="line">        string maxi = tmpC;</span><br><span class="line">        for (int p1 = 1; p1 &lt; (S.size() + 1) / 2; p1++) {</span><br><span class="line">            string s0 = S.substr(0, p1);</span><br><span class="line">            if ((s0.size() &gt; 1 &amp;&amp; s0.substr(0, 1) == "0") || (s0.size() &gt; maxi.size() || (s0.size() == maxi.size() &amp;&amp; s0 &gt; maxi))) { break; }</span><br><span class="line">            long long f0 = stoll(s0);</span><br><span class="line">            for (int p2 = p1 + 1; p2 &lt; S.size(); p2++) {</span><br><span class="line">                string s1 = S.substr(p1, p2 - p1);</span><br><span class="line">                if ((s1.size() &gt; 1 &amp;&amp; s1.substr(0, 1) == "0") || (s1.size() &gt; maxi.size() || (s1.size() == maxi.size() &amp;&amp; s1 &gt; maxi))) { break; }</span><br><span class="line">                long long f1 = stoll(s1);</span><br><span class="line">                long long curF0 = f0, curF1 = f1, curF2 = f0 + f1;</span><br><span class="line">                int curP2 = p2;</span><br><span class="line">                res.push_back(int(curF0));</span><br><span class="line">                res.push_back(int(curF1));</span><br><span class="line">                bool flag = true;</span><br><span class="line">                while (curP2 &lt; S.size() &amp;&amp; flag) {</span><br><span class="line">                    sprintf(tmpC, "%d", curF2);</span><br><span class="line">                    string tmp = tmpC;</span><br><span class="line">                    if (curF2 &gt; INT32_MAX || (tmp.size() &gt; 1 &amp;&amp; tmp.substr(0, 1) == "0") || tmp.size() + curP2 &gt; S.size() || tmpC != S.substr(curP2, tmp.size())) { flag = false; }</span><br><span class="line">                    else {</span><br><span class="line">                        res.push_back(int(curF2));</span><br><span class="line">                        long long curF3 = curF1 + curF2;</span><br><span class="line">                        curF0 = curF1, curF1 = curF2, curF2 = curF3;</span><br><span class="line">                        curP2 += tmp.size();</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">                if (flag) { return res; }</span><br><span class="line">                else { res.clear(); }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="递归-DFS"><a href="#递归-DFS" class="headerlink" title="递归/DFS"></a><font size="5" color="red">递归/DFS</font></h1><p>DFS也是一种递归，我们已知前两个数，和前一个数，去搜索当前数值。这就是一种深度优先搜索算法。只不过稍微复杂的是<strong>在搜索过程中要判断，当数组中没有前两个数时，我们要将当前的结果不加判断的加入到数组中去搜索。只有数组中存在了两个数据时，我们才能验证第三个数是否正确</strong>。</p>
<p>因为我们只需要搜索一个数据，因此我们一旦搜到字符串结尾，说明找到了一个合理的路径，因此return true即可。</p>
<p>算法的<strong>时间复杂度为$O(nlog^2(C))$，空间复杂度为$O(n)$</strong>，其中C是整数的范围，空间复杂度变大是因为函数会调用栈空间，最多为n层。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; splitIntoFibonacci(string S) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        dfs(S, res, 0, S.size(), 0, 0);</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool dfs(string S, vector&lt;int&gt;&amp; res, int idx, int length, int sum, int f1) {</span><br><span class="line">        if (idx == length) {</span><br><span class="line">            return res.size() &gt;= 3;</span><br><span class="line">        }</span><br><span class="line">        long long f2 = 0;</span><br><span class="line">        for (int i = idx; i &lt; length; i++) {</span><br><span class="line">            if (i &gt; idx &amp;&amp; S[idx] == '0') { break; }</span><br><span class="line">            f2 = f2 * 10 + (S[i] - '0');</span><br><span class="line">            if (f2 &gt; INT32_MAX) { break; }</span><br><span class="line">            if (res.size() &gt;= 2) {</span><br><span class="line">                if (f2 &lt; sum) { continue; }</span><br><span class="line">                else if (f2 &gt; sum) { break; }</span><br><span class="line">            }</span><br><span class="line">            res.push_back(f2);</span><br><span class="line">            if (dfs(S, res, i + 1, length, f1 + f2, f2)) {</span><br><span class="line">                return true;</span><br><span class="line">            }</span><br><span class="line">            res.pop_back();</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p><strong>能用DFS的题目，我一般都会使用BFS再做一次，只不过是将DFS中的参数列表封装起来，然后使用deque双端队列来手动实现BFS。其代码核心部分基本上是不变的</strong>。</p>
<p><strong>如果只想求一条路径，那么在第一次搜索到的时候直接return即可，那么它一定是最短的那一条。BFS搜索一条和搜索全部的时间复杂都是相同的，因为BFS搜索会将所有的斐波那契数列都保存下来，因此我就将本题做了扩展，求出所有的斐波那契数列，返回任意一条即可</strong>。</p>
<p>代码的核心内容和DFS完全一样，只不过要将DFS的参数用一个类封装起来。</p>
<p><strong>但是时间复杂度要大得多，因为这个题目的特殊性，以及要求除0外首位不能为0，时间复杂度会大大缩小，因此这个算法是可以通过的</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Element {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; array;</span><br><span class="line">    int idx, sum, f1;</span><br><span class="line"></span><br><span class="line">    Element(vector&lt;int&gt;&amp; array, int idx, int sum, int f1) {</span><br><span class="line">        this-&gt;array = array;</span><br><span class="line">        this-&gt;idx = idx;</span><br><span class="line">        this-&gt;sum = sum;</span><br><span class="line">        this-&gt;f1 = f1;</span><br><span class="line">    }</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; splitIntoFibonacci(string S) {</span><br><span class="line">        int length = S.size();</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; res;</span><br><span class="line">        vector&lt;int&gt; v = {};</span><br><span class="line">        deque&lt;Element*&gt; queue = { new Element(v, 0, 0, 0) };</span><br><span class="line">        while (!queue.empty()) {</span><br><span class="line">            Element* cur = queue.front();</span><br><span class="line">            queue.pop_front();</span><br><span class="line">            if (cur-&gt;idx == length &amp;&amp; cur-&gt;array.size() &gt;= 3) {</span><br><span class="line">                res.push_back(cur-&gt;array);</span><br><span class="line">                continue;</span><br><span class="line">            }</span><br><span class="line">            long f2 = 0;</span><br><span class="line">            for (int i = cur-&gt;idx; i &lt; length; i++) {</span><br><span class="line">                if (i &gt; cur-&gt;idx &amp;&amp; S[cur-&gt;idx] == '0') { break; }</span><br><span class="line">                f2 = 10 * f2 + (S[i] - '0');</span><br><span class="line">                if (f2 &gt; INT32_MAX) { break; }</span><br><span class="line">                if (cur-&gt;array.size() &gt;= 2) {</span><br><span class="line">                    if (f2 &gt; cur-&gt;sum) { break; }</span><br><span class="line">                    else if (f2 &lt; cur-&gt;sum) { continue; }</span><br><span class="line">                }</span><br><span class="line">                cur-&gt;array.push_back(f2);</span><br><span class="line">                queue.push_back(new Element(cur-&gt;array, i + 1, cur-&gt;f1 + f2, f2));</span><br><span class="line">                cur-&gt;array.pop_back();</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res.size() ? res[0] : vector&lt;int&gt;();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  搜索类的题目是笔试面试的常考题型，已经多次强调，要想拿到心动的offer，那就赶紧刷题吧。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
        <category>递归</category>
        <category>迭代</category>
      </categories>
  </entry>
  <entry>
    <title>最短超串(Leetcode 程序员面试金典16.16)</title>
    <url>/2021/02/28/program%20Leetcode_interview16.16/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview16_16.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   我个人很喜欢这样的题目，题目难度适中，题意清晰，简洁。一道题上来就是一大段文字，比较晦涩的那种，我比较头痛。废话少说，小伙伴们看题。</p>
<a id="more"></a>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a><font size="5" color="red">排序</font></h1><p>这个题目的意思是，有一个排好序的数组，其中有一个区间内数据打乱了，我们要找到这个最小的区间。</p>
<p><strong>我的直观想法是，既然最后整个数组是有序的，那么我们可以将排好序的结果打印出来，然后进行对比，看一看从哪里开始不同的，到哪里相同不就是找到了这个区间吗？</strong></p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; subSort(vector&lt;int&gt;&amp; array) {</span><br><span class="line">        vector&lt;int&gt; sortArray(array);</span><br><span class="line">        sort(sortArray.begin(), sortArray.end());</span><br><span class="line">        int left = 0, right = array.size() - 1;</span><br><span class="line">        while (left &lt; array.size() &amp;&amp; array[left] == sortArray[left]) { left++; }</span><br><span class="line">        while (right &gt;= 0 &amp;&amp; array[right] == sortArray[right]) { right--; }</span><br><span class="line">        return left &lt; right ? vector&lt;int&gt;{ left, right } : vector&lt;int&gt;{ -1, -1 };</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p><strong>这个题目还有时间复杂度更短的做法，这用到了一些数学知识。如果第k个数，小于前k - 1个数的最大值，那么k一定是区间内的，因此我们可以找到最后一个k，当m &gt; k时，都大于等于前m - 1个数的最大值。那么这个k就是这个区间的右端点</strong>。</p>
<p><strong>同理，如果第k个数，大于后面所有数字的最小值，那么k也是这个区间内的，我们找到第一个k，当m &lt; k时，都小于等于后面所有数字的最小值，那么这个k就是这个区间的左端点</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; subSort(vector&lt;int&gt;&amp; array) {</span><br><span class="line">        int maxi = INT32_MIN, mini = INT32_MAX, left = -1, right = -1;</span><br><span class="line">        for (int i = 0; i &lt; array.size(); i++) {</span><br><span class="line">            if (array[i] &lt; maxi) { right = i; }</span><br><span class="line">            else { maxi = array[i]; }</span><br><span class="line">            if (array[array.size() - 1 - i] &gt; mini) { left = array.size() - 1 - i; }</span><br><span class="line">            else { mini = array[array.size() - 1 - i]; }</span><br><span class="line">        }</span><br><span class="line">        return { left, right };</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  现在是寒假时间，寒假结束后，暑期实习，春招就要来到了，很多公司的提前批也是方法春天进行的，因此小伙伴们在放假长膘的期间内别忘了加强自己的coding能力。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
        <category>排序</category>
      </categories>
  </entry>
  <entry>
    <title>最短超串(Leetcode 程序员面试金典17.18)</title>
    <url>/2021/02/25/program%20Leetcode_interview17.18/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_18.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和Leetcode76题是类似的，只不过第76题是字符串，而这个题目是数组。当时做那个题目的时候，还没有想记录自己的刷题过程，因此那个题目没有写博客，今天做了这个题目，发现似曾相识，给小伙伴们介绍一下这样的题目应该如何求解。</p>
<a id="more"></a>
<h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a><font size="5" color="red">双指针</font></h1><p>这个题目肯定是不能使用暴力法进行求解的，就算是使用DP来解，也要$O(n^2)$的时间复杂度，对于1e5这个量级的数据，我们只能使用$O(nlog(n))$以下的算法进行求解。</p>
<p><strong>双指针是求解这个问题的最优方案，也可以称之为滑动窗口(Sliding Window)。什么意思呢？就是建立左右两个指针，其中左右指针中间的元素称为窗口，因为左右指针在不断右移，因此称为滑动窗口</strong>。</p>
<p><strong>我们先找到满足条件的右窗口，然后再收缩左窗口。如果左窗口不满足条件，说明此时左右窗口处恰好满足其中一个解。然后我们继续右移有窗口，到下一次满足条件的位置，然后再次收缩左窗口，直到右窗口到达数组的边界</strong>。</p>
<p>在滑动过程中，我们要<strong>用哈希表记录small中每一个元素出现的次数。如果次数都大于1，说明满足条件，右窗口停止滑动，开始滑动左窗口，如果次数有一个等于0，那么不满足条件，左窗口停止，开始滑动右窗口</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; shortestSeq(vector&lt;int&gt;&amp; big, vector&lt;int&gt;&amp; small) {</span><br><span class="line">        unordered_map&lt;int, int&gt; dict;</span><br><span class="line">        for (int x : small) { dict[x] = 0; }</span><br><span class="line">        int left = 0, right = 0, cnt = 0, bigLen = big.size(), smallLen = small.size();</span><br><span class="line">        vector&lt;int&gt; res = { -1, bigLen };</span><br><span class="line">        while (right &lt; bigLen) {</span><br><span class="line">            while (right &lt; bigLen &amp;&amp; cnt &lt; smallLen) {</span><br><span class="line">                int curVal = big[right++];</span><br><span class="line">                if (dict.count(curVal) &amp;&amp; !(dict[curVal]++)) { cnt++; }</span><br><span class="line">            }</span><br><span class="line">            while (left &lt;= right &amp;&amp; cnt == smallLen) {</span><br><span class="line">                int curVal = big[left++];</span><br><span class="line">                if (dict.count(curVal) &amp;&amp; !(--dict[curVal])) { cnt--; }</span><br><span class="line">            }</span><br><span class="line">            if (res[1] - res[0] &gt; right - left) { res = { left - 1, right - 1 }; }</span><br><span class="line">        }</span><br><span class="line">        return res[0] &gt;= 0 ? res : vector&lt;int&gt;();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  滑动窗口是一个非常非常重要的知识点，和单调栈，单调队列类似，都是线性的时间复杂度，是面试笔试中的常客，小伙伴们要多多留心。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
        <category>双指针</category>
      </categories>
  </entry>
  <entry>
    <title>翻转矩阵后的得分(Leetcode 861)</title>
    <url>/2021/02/21/program%20Leetcode861/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode861.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   小伙伴们看一看如何做到得分最高吧，没有思路的童鞋可以先模拟一下找规律。<br><a id="more"></a></p>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>题目是比较简单的，<strong>我们要想让得分最高，因此我们要满足高位一定是1，要将高位都变成1，可以先按照行来翻转，这里将高位都翻转为1，或者将高位都翻转为0再翻转高位这一列都是可以的</strong>。为了代码的简洁，就直接将高位按行翻转为1。</p>
<p><strong>然后下面只能按列进行翻转了，因为再按行翻转会影响到高位，分数一定不是最高的。因此我们统计第k列中1的个数和0的个数，如果0的个数多，我们就翻转该列即可，这样1的个数就多了</strong>。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int matrixScore(vector&lt;vector&lt;int&gt;&gt;&amp; A) {</span><br><span class="line">        int row = A.size(), col = A[0].size();</span><br><span class="line">        int bit = 1 &lt;&lt; (col - 1), res = 0;</span><br><span class="line">        for (int i = 0; i &lt; row; i++) {</span><br><span class="line">            if (!A[i][0]) {</span><br><span class="line">                for (int j = 0; j &lt; col; j++) {</span><br><span class="line">                    A[i][j] = 1 - A[i][j];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        for (int j = 0; j &lt; col; j++) {</span><br><span class="line">            int cnt = 0;</span><br><span class="line">            for (int i = 0; i &lt; row; i++) {</span><br><span class="line">                cnt += A[i][j];</span><br><span class="line">            }</span><br><span class="line">            res += max(cnt, row - cnt) * bit;</span><br><span class="line">            bit &gt;&gt;= 1;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  做这个题目的时候，我想了几分钟，<strong>发现将最高位都变为1和最高位都变为0然后翻转列是等价的，第一种方法次高位0的数量等于第二种方法次高位1的数量，因为在计算次高位值得时候，要取0和1的最大值，因此不会影响到次高位的结果</strong>。这一点是非常非常重要的，否则这个题就无法用贪心求解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>多次搜索(Leetcode 程序员面试金典17.17)</title>
    <url>/2021/02/18/program%20Leetcode_interview17.17/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_17.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目有趣了，看起来非常简单的题目，小伙伴们能否实现它呢？</p>
<a id="more"></a>
<h1 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a><font size="5" color="red">KMP算法</font></h1><p>对于smalls中的每一个元素，都去使用KMP算法和big进行匹配，<br>KMP算法我在Leetcode28题有详细的描述，在这里就不写算法的实现了，直接调用substr。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(m)$</strong>，其中m为big的长度，n为smalls的数量，空间复杂度的计算排除了最终答案占用的空间，只计算中间过程占用的空间。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; multiSearch(string big, vector&lt;string&gt;&amp; smalls) {</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; res(smalls.size());</span><br><span class="line">        for (int i = 0; i &lt; smalls.size(); i++) {</span><br><span class="line">            if (smalls[i] == "") { continue; }</span><br><span class="line">            int idx = big.find(smalls[i]);</span><br><span class="line">            while (idx != -1) {</span><br><span class="line">                res[i].push_back(idx);</span><br><span class="line">                idx = big.find(smalls[i], idx + 1);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="双指针-哈希表"><a href="#双指针-哈希表" class="headerlink" title="双指针+哈希表"></a><font size="5" color="red">双指针+哈希表</font></h1><p>这个算法是我比较推荐的算法，其实KMP算法是最先想到的，由于担心TLE，因此就写的这个算法，没想到直接暴力KMP居然也可以直接通过，反而时间还挺快。</p>
<p><strong>我们先建立一个哈希映射hashMap，其中键为smalls中的字符串，值为smalls中所在的索引。然后使用两层循环，双指针，i和j，如果big字符串从i到j所在的子串tmp在哈希映射中，那么就在res[hashMap[tmp]]中添加i这个索引即可。</strong></p>
<p>算法的<strong>时间复杂度为$O(m^2)$，空间复杂度为$O(m)$</strong>，其中m为big的长度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; multiSearch(string big, vector&lt;string&gt;&amp; smalls) {</span><br><span class="line">        unordered_map&lt;string, int&gt; hashMap;</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; res(smalls.size());</span><br><span class="line">        for (int i = 0; i &lt; smalls.size(); i++) { hashMap[smalls[i]] = i; }</span><br><span class="line">        for (int i = 0; i &lt; big.size(); i++) {</span><br><span class="line">            string s = "";</span><br><span class="line">            for (int j = i; j &lt; big.size(); j++) {</span><br><span class="line">                s.push_back(big[j]);</span><br><span class="line">                if (hashMap.count(s)) { res[hashMap[s]].push_back(i); }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a><font size="5" color="red">Trie树</font></h1><p>这个方法是我在查看题解的时候看到的，我们将smalls中的字符串都加入到字典树中去，以例题进行画图说明。</p>
<p><img src="/images/ALGORITHM/leetcodeinterview17_17_solve.png" alt="1"></p>
<p>算法的插入smalls字符串的时间是mn，查找big后缀的时间是nk，因此算法的<strong>时间复杂度为$O(max(mn, nk))$，空间复杂度为$O(nk)$</strong>，其中m为big的长度，n为smalls的数量，k为small中字符串的平均长度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class TrieNode {</span><br><span class="line">public:</span><br><span class="line">    int label;</span><br><span class="line">    TrieNode* child[26];</span><br><span class="line">    </span><br><span class="line">    TrieNode() {</span><br><span class="line">        label = -1;</span><br><span class="line">        for (int i = 0; i &lt; 26; i++) { child[i] = NULL; }</span><br><span class="line">    }</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    TrieNode* root = new TrieNode();</span><br><span class="line"></span><br><span class="line">    void insert(string word, int label) {</span><br><span class="line">        TrieNode* cur = root;</span><br><span class="line">        for (char c : word) {</span><br><span class="line">            if (!(cur-&gt;child[c - 'a'])) { cur-&gt;child[c - 'a'] = new TrieNode(); }</span><br><span class="line">            cur = cur-&gt;child[c - 'a'];</span><br><span class="line">        }</span><br><span class="line">        cur-&gt;label = label;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void search(string word, vector&lt;vector&lt;int&gt;&gt;&amp; res, int idx) {</span><br><span class="line">        TrieNode* cur = root;</span><br><span class="line">        for (char c : word) {</span><br><span class="line">            if (!(cur-&gt;child[c - 'a'])) { return; }</span><br><span class="line">            cur = cur-&gt;child[c - 'a'];</span><br><span class="line">            if (cur-&gt;label != -1) res[cur-&gt;label].push_back(idx);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; multiSearch(string big, vector&lt;string&gt;&amp; smalls) {</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; res(smalls.size());</span><br><span class="line">        for (int i = 0; i &lt; smalls.size(); i++) { insert(smalls[i], i); }</span><br><span class="line">        for (int i = 0; i &lt; big.size(); i++) {</span><br><span class="line">            string tmp = big.substr(i, big.size() - i);</span><br><span class="line">            search(tmp, res, i);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  Trie树在处理字符串时是一个非常方便的数据结构，尤其应用在求索引，查找等等问题上。可以实现<strong>一次建树，多次查询</strong>的效果，小伙伴们一定要会Trie树，我在博客Leetcode208题上对如何建立Trie树做了解释，有不明白的可以去参考学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>字符串</category>
        <category>哈希表</category>
        <category>特定算法</category>
        <category>双指针</category>
      </categories>
  </entry>
  <entry>
    <title>稀疏相似度(Leetcode 程序员面试金典17.26)</title>
    <url>/2021/02/16/program%20Leetcode_interview17.26/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_26.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目通俗易懂小伙伴们不要害怕困难题，先试一试将自己的想法实现出来。</p>
<a id="more"></a>
<h1 id="暴力"><a href="#暴力" class="headerlink" title="暴力"></a><font size="5" color="red">暴力</font></h1><p>暴力法是我们直观想到的一种解决方法，我们既然要比较相似度，就要求交集和并集。因此i和j两层循环，然后在循环中计算交集和并集。</p>
<p>算法的<strong>时间复杂度为$O(nm^2)$，空间复杂度为$O(1)$</strong>，其中n为每个文档的平均长度，m为文档个数。</p>
<p>但是n和m的最大值都是500，因此$nm^2 = 1.25e8$会TLE，因此这个算法无法通过所有的测试样例。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_set&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; computeSimilarities(vector&lt;vector&lt;int&gt;&gt;&amp; docs) {</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        for (int i = 0; i &lt; docs.size(); i++) {</span><br><span class="line">            for (int j = i + 1; j &lt; docs.size(); j++) {</span><br><span class="line">                int intersectionNum = 0;</span><br><span class="line">                int unionNum = 0;</span><br><span class="line">                cal(docs[i], docs[j], intersectionNum, unionNum);</span><br><span class="line">                if (intersectionNum) {</span><br><span class="line">                    char c[20];</span><br><span class="line">                    sprintf(c, "%d,%d: %.4f", i, j, double(intersectionNum) / unionNum + 1e-9);</span><br><span class="line">                    string s = c;</span><br><span class="line">                    res.push_back(s);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void cal(vector&lt;int&gt;&amp; v1, vector&lt;int&gt;&amp; v2, int&amp; intersectionNum, int&amp; unionNum) {</span><br><span class="line">        unordered_set&lt;int&gt; s;</span><br><span class="line">        for (int x : v1) {</span><br><span class="line">            s.insert(x);</span><br><span class="line">            unionNum++;</span><br><span class="line">        }</span><br><span class="line">        for (int x : v2) {</span><br><span class="line">            if (!s.count(x)) {</span><br><span class="line">                unionNum++;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                intersectionNum++;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>我们有一些隐含条件没有用到，就是题目中所说的稀疏文档。对于大部分文档来说，它们之间都是不需要计算的，没有重复元素，或者500个元素中只有很少的几个是相似的，那么我们如何节省运算呢？</p>
<p><strong>我们可以统计每个元素有哪些文档包含，因为比较稀疏，所以文档包含同一个元素的概率非常低。假如10这个元素出现在文档1，文档5，文档8中，那么我们建立一个哈希表，其中键为10，值为{1, 5, 8}的一个数组。这时我们可知1和5有一个相似的元素，1和8有一个相似的元素，5和8有一个相似的元素。这时再用一个数组intersection记录文档i和文档j的相似元素个数。即intersection[1][5]++，intersection[1][8]++，intersection[5][8]++</strong>。</p>
<script type="math/tex; mode=display">similarity = \frac{intersection[i][j]}{(docs[i].size() + docs[j].size() - intersection[i][j])}</script><p><strong>其中分子是交集元素个数，分母是并集元素个数。这里用到了一部分数学知识，交集数量+并集数量=两个集合数量之和</strong>。</p>
<p>在稀疏文档中，文档包含同一个元素的平均个数为常数量级，算法的<strong>时间复杂度为$O(nm)$，在统计每个元素有哪些文档时，用到m x n的空间，在计算文档之间相似元素个数时，用到m x m的空间。因此空间复杂度为$O(m \times max(m, n))$</strong>，其中n为每个文档的平均长度，m为文档个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; computeSimilarities(vector&lt;vector&lt;int&gt;&gt;&amp; docs) {</span><br><span class="line">        int length = docs.size();</span><br><span class="line">        unordered_map&lt;int, vector&lt;int&gt;&gt; wordsInDocs;</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; intersection(length, vector&lt;int&gt;(length));</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        for (int i = 0; i &lt; length; i++) {</span><br><span class="line">            for (int x : docs[i]) {</span><br><span class="line">                wordsInDocs[x].push_back(i);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        for (auto p : wordsInDocs) {</span><br><span class="line">            vector&lt;int&gt; idx = p.second;</span><br><span class="line">            for (int i = 0; i &lt; idx.size(); i++) {</span><br><span class="line">                for (int j = i + 1; j &lt; idx.size(); j++) {</span><br><span class="line">                    intersection[idx[i]][idx[j]]++;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        for (int i = 0; i &lt; length; i++) {</span><br><span class="line">            for (int j = i + 1; j &lt; length; j++) {</span><br><span class="line">                if (intersection[i][j]) {</span><br><span class="line">                    char c[20];</span><br><span class="line">                    sprintf(c, "%d,%d: %.4f", i, j, double(intersection[i][j]) / (docs[i].size() + docs[j].size() - intersection[i][j]) + 1e-9);</span><br><span class="line">                    string s = c;</span><br><span class="line">                    res.push_back(s);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  哈希表典型的特征是以空间换时间，我们有了哈希表，可以用额外的空间去存储数据的属性，以后查找的时候就不需要遍历数组。哈希表的题目，小伙伴要多多练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>婴儿名字(Leetcode 程序员面试金典17.07)</title>
    <url>/2021/02/13/program%20Leetcode_interview17.07/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_07.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目一看就是一个搜索类的题目，其实搜索类的题目我已经拿出来很多了。这个题目又要拿出来说一说，因为它不同于一般的图，一般的图告诉我们邻接矩阵，而这个图类似于朋友圈题目，只告诉我们两两关系，这个题目最直观的方法是并查集，但是如何使用DFS和BFS去求解呢？希望小伙伴们先尝试一下。</p>
<a id="more"></a>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>和普通的矩阵图问题不同的是，在地图搜索问题中，往往给定一个起始点，向四个方向搜索即可。但是这个问题没有邻接矩阵，我们要构造一个临界矩阵，找到某个名字和其他名字的关系。</p>
<p><strong>在DFS中，我们建立一个HashMap，其中键为某个名字，值是一个哈希表，其中存放着所有和它相同的名字的集合</strong>。</p>
<p><strong>然后建立一个visited集合，存放所有访问过的名字的集合</strong>。从第一个名字开始搜索，所有搜索过的名字都加入visited集合，搜完与第一个名字相同的所有名字，并且在搜索过程中取出最小的名字作为真实名字。然后再搜索第二个名字，如果第二个名字和第一个名字是同一个名字，则第二个名字在搜索第一个名字的时候已经加入了visited，继续搜索第三个名字。</p>
<p>算法的<strong>时间复杂度为$O(n + m)$，因为最坏情况下，每个人都和其他所有人名字相同，因此每个键对应的值都是其他所有人的名字，所以空间复杂度为$O(n^2)$</strong>，其中n为名字数量，m为相同名字的关系对数量。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;unordered_set&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; trulyMostPopular(vector&lt;string&gt;&amp; names, vector&lt;string&gt;&amp; synonyms) {</span><br><span class="line">        unordered_map&lt;string, int&gt; name;</span><br><span class="line">        for (string s : names) {</span><br><span class="line">            int l = s.find('(');</span><br><span class="line">            int r = s.size() - 1;</span><br><span class="line">            name[s.substr(0, l)] += stoi(s.substr(l + 1, r - l - 1));</span><br><span class="line">        }</span><br><span class="line">        unordered_map&lt;string, unordered_set&lt;string&gt;&gt; relationship;</span><br><span class="line">        for (string s : synonyms) {</span><br><span class="line">            int dot = s.find(',');</span><br><span class="line">            string name1 = s.substr(1, dot - 1), name2 = s.substr(dot + 1, s.size() - dot - 2);</span><br><span class="line">            if (!relationship.count(name1)) { relationship[name1] = unordered_set&lt;string&gt;(); }</span><br><span class="line">            if (!relationship.count(name2)) { relationship[name2] = unordered_set&lt;string&gt;(); }</span><br><span class="line">            relationship[name1].insert(name2);</span><br><span class="line">            relationship[name2].insert(name1);</span><br><span class="line">        }</span><br><span class="line">        unordered_set&lt;string&gt; visited;</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        for (auto x : name) {</span><br><span class="line">            if (!visited.count(x.first)) {</span><br><span class="line">                string miniName = x.first;</span><br><span class="line">                int num = dfs(miniName, miniName, name, relationship, visited);</span><br><span class="line">                res.push_back(miniName + "(" + to_string(num) + ")");</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int dfs(string curName, string&amp; miniName, unordered_map&lt;string, int&gt;&amp; name, unordered_map&lt;string, unordered_set&lt;string&gt;&gt;&amp; relationship, unordered_set&lt;string&gt;&amp; visited) {</span><br><span class="line">        if (visited.count(curName)) { return 0; }</span><br><span class="line">        visited.insert(curName);</span><br><span class="line">        int res = name[curName];</span><br><span class="line">        for (auto x : relationship[curName]) {</span><br><span class="line">            res += dfs(x, miniName, name, relationship, visited);</span><br><span class="line">            miniName = min(miniName, x);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p><strong>BFS和DFS的预处理过程完全相同，只是我们在搜索时，搜到某个名字，如果某个名字不在visited中，则将其加入visited，说明该名字已经访问过，然后同时将和它相同的所有名字都同时加入到队列中</strong>。</p>
<p>这里也不过多赘述，思路也比较简单，多写一些DFS和BFS就会发现它们都是相同的模板。</p>
<p>算法的<strong>时间复杂度为$O(n + m)$，空间复杂度为$O(n^2)$</strong>，其中n为名字数量，m为相同名字的关系对数量。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;unordered_set&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; trulyMostPopular(vector&lt;string&gt;&amp; names, vector&lt;string&gt;&amp; synonyms) {</span><br><span class="line">        unordered_map&lt;string, int&gt; name;</span><br><span class="line">        for (string s : names) {</span><br><span class="line">            int l = s.find('(');</span><br><span class="line">            int r = s.size() - 1;</span><br><span class="line">            name[s.substr(0, l)] += stoi(s.substr(l + 1, r - l - 1));</span><br><span class="line">        }</span><br><span class="line">        unordered_map&lt;string, unordered_set&lt;string&gt;&gt; relationship;</span><br><span class="line">        for (string s : synonyms) {</span><br><span class="line">            int dot = s.find(',');</span><br><span class="line">            string name1 = s.substr(1, dot - 1), name2 = s.substr(dot + 1, s.size() - dot - 2);</span><br><span class="line">            if (!relationship.count(name1)) { relationship[name1] = unordered_set&lt;string&gt;(); }</span><br><span class="line">            if (!relationship.count(name2)) { relationship[name2] = unordered_set&lt;string&gt;(); }</span><br><span class="line">            relationship[name1].insert(name2);</span><br><span class="line">            relationship[name2].insert(name1);</span><br><span class="line">        }</span><br><span class="line">        unordered_set&lt;string&gt; visited;</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        for (auto x : name) {</span><br><span class="line">            if (!visited.count(x.first)) {</span><br><span class="line">                string miniName = x.first;</span><br><span class="line">                deque&lt;string&gt; queue = { miniName };</span><br><span class="line">                int num = 0;</span><br><span class="line">                while (!queue.empty()) {</span><br><span class="line">                    string curName = queue.front();</span><br><span class="line">                    queue.pop_front();</span><br><span class="line">                    if (visited.count(curName)) { continue; }</span><br><span class="line">                    num += name[curName];</span><br><span class="line">                    visited.insert(curName);</span><br><span class="line">                    for (string neighbor : relationship[curName]) {</span><br><span class="line">                        queue.push_back(neighbor);</span><br><span class="line">                        miniName = min(miniName, neighbor);</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">                res.push_back(miniName + "(" + to_string(num) + ")");</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a><font size="5" color="red">并查集</font></h1><p>并查集也是解决这个问题的好方法，虽然并查集没有DFS和BFS那样使用范围大，但是解决朋友圈数量，岛屿个数等等这类问题，最好的方法就是使用并查集。我在数据结构和算法中的算法部分也专门提到过这个方法。</p>
<p>这里再大致说一下，<strong>要新建一个并查集UF类，要在类中实现两个最最重要的方法，一个是find，一个是union，在C++语言中不能写union方法，就用merge代替</strong>。其中find是找到带头人，merge是合并带头人。什么意思呢？这个问题就是一个合并问题，相同名字合并在一起进行计数。一开始我们让每一个名字的带头人都是自己，数量就是自己的数量。</p>
<p>然后访问合并关系，当两个名字相同时，就让其中一个带头人的带头人是另一个带头人。比如A和B是相同的名字，原本A的带头人是ARoot，ARoot的带头人就是它自己。B的带头人是BRoot，BRoot的带头人也是它自己。我们要合并A和B，就说让ARoot的带头人是BRoot，或者让BRoot的带头人是ARoot，这样我们查找A的带头人和B的带头人都是同一个人。这就相当于合并了A和B。非常类似于生活中的例子，本来有一个校长A，也有一个校长B，那么合并两个学校后，让一个校长变成副校长，听从另一个校长的管理。</p>
<p><strong>在合并时，如果两个带头人不相同，则取较小的那个名字为真正的带头人，并且让较小名字的带头人的数量加上较大名字带头人的数量即可</strong>。</p>
<p>最后合并完以后，查看所有的带头人，有多少带头人就有多少个不同的名字，再查看每个名字对应的数字，将其转换为字符串并return即可。</p>
<p>在merge时，对于每一对相同的名字，都要进行find，最坏情况下，每一次find都要向上搜索m次。因此算法的<strong>时间复杂度为$O(n + m^2)$，空间复杂度为$O(n + m)$</strong>，其中n为名字数量，m为相同名字的关系对数量。</p>
<p>因为find的过程非常简单，几乎不用花费很长时间，因此时间消耗和DFS或者BFS几乎差不多。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;unordered_set&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; trulyMostPopular(vector&lt;string&gt;&amp; names, vector&lt;string&gt;&amp; synonyms) {</span><br><span class="line">        unordered_map&lt;string, int&gt; name;</span><br><span class="line">        for (string s : names) {</span><br><span class="line">            int l = s.find('(');</span><br><span class="line">            int r = s.size() - 1;</span><br><span class="line">            name[s.substr(0, l)] += stoi(s.substr(l + 1, r - l - 1));</span><br><span class="line">        }</span><br><span class="line">        unordered_map&lt;string, unordered_set&lt;string&gt;&gt; relationship;</span><br><span class="line">        for (string s : synonyms) {</span><br><span class="line">            int dot = s.find(',');</span><br><span class="line">            string name1 = s.substr(1, dot - 1), name2 = s.substr(dot + 1, s.size() - dot - 2);</span><br><span class="line">            if (!relationship.count(name1)) { relationship[name1] = unordered_set&lt;string&gt;(); }</span><br><span class="line">            if (!relationship.count(name2)) { relationship[name2] = unordered_set&lt;string&gt;(); }</span><br><span class="line">            relationship[name1].insert(name2);</span><br><span class="line">            relationship[name2].insert(name1);</span><br><span class="line">        }</span><br><span class="line">        unordered_set&lt;string&gt; visited;</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        for (auto x : name) {</span><br><span class="line">            if (!visited.count(x.first)) {</span><br><span class="line">                string miniName = x.first;</span><br><span class="line">                deque&lt;string&gt; queue = { miniName };</span><br><span class="line">                int num = 0;</span><br><span class="line">                while (!queue.empty()) {</span><br><span class="line">                    string curName = queue.front();</span><br><span class="line">                    queue.pop_front();</span><br><span class="line">                    if (visited.count(curName)) { continue; }</span><br><span class="line">                    num += name[curName];</span><br><span class="line">                    visited.insert(curName);</span><br><span class="line">                    for (string neighbor : relationship[curName]) {</span><br><span class="line">                        queue.push_back(neighbor);</span><br><span class="line">                        miniName = min(miniName, neighbor);</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">                res.push_back(miniName + "(" + to_string(num) + ")");</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  上面三个方法都需要小伙伴们掌握，能用并查集解决的问题，使用DFS和BFS基本上都可以解决，但是并查集的思想非常好，希望小伙伴能够认真学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
        <category>并查集</category>
      </categories>
  </entry>
  <entry>
    <title>任务调度器(Leetcode 621)</title>
    <url>/2021/02/10/program%20Leetcode621/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode621.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目很奇妙，小伙伴们认真思考思考。<br><a id="more"></a></p>
<h1 id="堆-贪心"><a href="#堆-贪心" class="headerlink" title="堆+贪心"></a><font size="5" color="red">堆+贪心</font></h1><p>直观的感觉应该如何去做？是不是应该先去做出现次数最多的任务。如果先做了出现次数少的B，那么剩余出现次数多的A，每两次之间都需要等待间隔n。这其实就是一种贪心思想。想看证明的小伙伴可以去Leetcode621题官方题解中查看。</p>
<p><strong>因此我们可以建立一个最大堆，记录着每个字符的出现次数。n + 1个长度为一组，这个非常重要，因为A出现一次以后，下一次要等待n个单位时间，下一次A出现最早是在n + 1单位时间以后。我们从最大堆中连续拿出n + 1个数。然后再将它们数量都减1之后再放入最大堆中。当最大堆中拿出的第一个数只有最后一个时，并且堆为空，说明已经完全做完了，返回所用的时间</strong>。</p>
<p>算法的<strong>时间复杂度为$O(nlog(m))$，空间复杂度为$O(m)$</strong>，其中n为指令个数，m为指令种类，这里为大写字母，因此最大为26。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;queue&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int leastInterval(vector&lt;char&gt;&amp; tasks, int n) {</span><br><span class="line">        priority_queue&lt;pair&lt;int, int&gt;&gt; heap;</span><br><span class="line">        vector&lt;int&gt; alpha(26);</span><br><span class="line">        for (char c : tasks) alpha[c - 'A']++;</span><br><span class="line">        for (int i = 0; i &lt; 26; i++) heap.push({ alpha[i], i });</span><br><span class="line">        int res = 0;</span><br><span class="line">        while (heap.top().first) {</span><br><span class="line">            vector&lt;pair&lt;int, int&gt;&gt; maxiChar;</span><br><span class="line">            for (int i = 0; i &lt;= n; i++) {</span><br><span class="line">                if (!heap.empty() &amp;&amp; heap.top().first) {</span><br><span class="line">                    maxiChar.push_back({ heap.top().first, heap.top().second });</span><br><span class="line">                    heap.pop();</span><br><span class="line">                }</span><br><span class="line">                else if (maxiChar[0].first == 1) return res;</span><br><span class="line">                res++;</span><br><span class="line">            }</span><br><span class="line">            for (pair&lt;int, int&gt; p : maxiChar) heap.push({ p.first - 1, p.second });</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>数学方法太巧妙了，我这里参考了官方题解的答案。</p>
<p>我们先考虑执行次数最多的任务，记为A，执行次数为maxExec，而且具有相同执行次数的任务有maxCount个。不妨设有A，B，C三个任务都要执行maxExec次。那么n + 1个单位时间为一组。<br><img src="/images/ALGORITHM/leetcode621_solve1.png" alt="1"></p>
<p>按照贪心思路，我们每次都要首先执行这3个任务，其他的时间往空余时间里面挤。不妨设n = 5，那么我们再1，2，3时间执行A，B，C，那么在4和5执行其他的任务，一定不会产生问题。<br><img src="/images/ALGORITHM/leetcode621_solve2.png" alt="1"></p>
<p>如果按照我们的想法，那么所用的时间是</p>
<script type="math/tex; mode=display">(maxExec - 1) \times (n + 1) + maxCount</script><p><strong>但是这个前提是我们不会超过n + 1列，如果maxCount &gt; n 或者其他指令的数量nums &gt; (maxExec - 1) x (n + 1 - maxCount)，那么就不满足上面的算法</strong>。</p>
<p><strong>不满足上面的算法主要原因就是超过了n + 1列，在n + 1列中，两个相同任务之间的间隔都不少于n，因此任何两个相同操作间隔都至少为n，就是我们不需要任何待命操作，所以总执行时间就是任务总数。所以执行任务所用时间是两者的最大值</strong>。</p>
<p>代码非常短，但是很不容易想到，需要小伙伴们认真品味。</p>
<p>算法的<strong>时间复杂度为$O(n + m)$，空间复杂度为$O(m)$</strong>，其中n为指令个数，m为指令种类，这里为大写字母，因此最大为26。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int leastInterval(vector&lt;char&gt;&amp; tasks, int n) {</span><br><span class="line">        unordered_map&lt;char, int&gt; count;</span><br><span class="line">        for (char c : tasks) { count[c]++; }</span><br><span class="line">        int maxExec = 0, maxCount = 0;</span><br><span class="line">        for (auto x : count) {</span><br><span class="line">            if (x.second &gt; maxExec) { maxExec = x.second, maxCount = 1; }</span><br><span class="line">            else if (x.second == maxExec) { maxCount++; }</span><br><span class="line">        }</span><br><span class="line">        return max((maxExec - 1) * (n + 1) + maxCount, int(tasks.size()));</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目我最推荐的方法是我写的方法，堆是这类问题的通解，也是一个非常非常重要的数据结构，小伙伴们一定要会使用它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>数学</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>分割数组为连续子序列(Leetcode 659)</title>
    <url>/2021/02/07/program%20Leetcode659/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode659.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目有一定的难度，用到了贪心的思路，一般来说贪心算法的题目都是比较难的，因为很难想到为什么当前最优解一定是局部最优解，而且需要数学去证明才能够保证贪心法是正确的。<br><a id="more"></a></p>
<h1 id="堆-贪心"><a href="#堆-贪心" class="headerlink" title="堆+贪心"></a><font size="5" color="red">堆+贪心</font></h1><p>我们考虑1，2，3，3，4，5这个情况，当出现1的时候，我们发现前面没有以0结尾的数组，因此我们要单独建立一个数组以1开头，1结尾，长度为1。当出现2的时候，我们发现前面有以1结尾的数组，这时面临一个选择。<strong>是重新开辟一个以2开头，2结尾，长度为1的数组呢？还是在以1结尾的数组中添加元素2，变成以2结尾，长度为2的数组呢？我们发现添加元素一定是最优的。因为如果创建一个数组，以2为开头，如果得到了最优分配方式，那么将以2为开头的数组添加在以1结尾的数组中也一定是最优的</strong>。</p>
<p>以上面的规则我们继续看，当出现第一个3时，也是将3添加到以2为结尾的数组后面，形成了以3结尾长度为3的数组。当出现第二个3时，没有以2结尾的数组了，这时要重新开辟一个以3结尾，长度为1的数组。当出现4时，又面临选择了，<strong>有两个以3结尾的数组，是选择添加哪一个数组的尾部呢？选择添加最短的，因为添加在最长的满足最优解的情况下，添加在最短的也一定满足最优解。这也体现了一个贪心思想</strong>。</p>
<p>因此堆的思想就体现出来了，我们维护一个最小堆即可，记录以k结尾的数组的长度。每次将最短的一个拿出来。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line">#include&lt;queue&gt;</span><br><span class="line">#include&lt;functional&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool isPossible(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        unordered_map&lt;int, priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt;&gt; m;</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            if (m[x].empty()) m[x] = priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt;();</span><br><span class="line">            if (m.find(x - 1) == m.end()) {</span><br><span class="line">                m[x].push(1);</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                int length = m[x - 1].top();</span><br><span class="line">                m[x - 1].pop();</span><br><span class="line">                if (m[x - 1].empty()) m.erase(x - 1);</span><br><span class="line">                m[x].push(length + 1);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        for (auto tail : m) {</span><br><span class="line">            if (tail.second.top() &lt; 3) return false;</span><br><span class="line">        }</span><br><span class="line">        return true;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="哈希表优化-贪心"><a href="#哈希表优化-贪心" class="headerlink" title="哈希表优化+贪心"></a><font size="5" color="red">哈希表优化+贪心</font></h1><p>堆的时间复杂度log(n)，我们还可以继续优化，使用常数级的哈希表查找即可。</p>
<p><strong>用count哈希表先统计每个元素出现的次数，然后遍历整个数组，还以1，2，3，3，4，5为例，先统计1出现1次，2出现1次，3出现2次，4出现1次，5出现1次。然后遍历数组，开始遍历到1，如果1还存在，那么要看是否有以0结尾的数组，即tail[0]是否等于0，如果有，则tail[0]—, tail[1]++, count[x]—。如果没有要建立一个长度为3的数组，如果count[2]和count[3]都大于0则可以建立，否则直接return false。可以建立时，count[1]—, count[2]—,count[3]—,tail[3]++</strong>，此时说明花费了1，2，3这三个数，建立了一个以3结尾的数组。然后遍历到2的时候，因为count[2]—以后，count[2] = 0，因此直接跳过。同理，第一个3也直接跳过。到第二个3时，因为没有以2结尾的数组，因此又建立了一个以5结尾的数组。遍历到4和5时，因为创建5结尾的数组时，count[4]—, count[5]—，也都直接跳过。最终return true。</p>
<p><strong>小伙伴们想一想为什么这里时间复杂度会缩短呢？因为我们直接建立一个长度为3的数组，不需要取出最短的，哪一个都满足条件，不需要像上面一样，要优先在最短的数组中添加，满足长度条件。这里如果无法建立长度为3的数组则直接return false</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool isPossible(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        unordered_map&lt;int, int&gt; count, tail;</span><br><span class="line">        for (int x : nums) count[x]++;</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            if (count[x] &gt; 0) {</span><br><span class="line">                if (tail[x - 1] != 0) {</span><br><span class="line">                    tail[x - 1]--;</span><br><span class="line">                    tail[x]++;</span><br><span class="line">                    count[x]--;</span><br><span class="line">                }</span><br><span class="line">                else {</span><br><span class="line">                    if (count[x + 1] &amp;&amp; count[x + 2]) {</span><br><span class="line">                        count[x]--;</span><br><span class="line">                        count[x + 1]--;</span><br><span class="line">                        count[x + 2]--;</span><br><span class="line">                        tail[x + 2]++;</span><br><span class="line">                    }</span><br><span class="line">                    else return false;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return true;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  贪心题目做不出来不要灰心，多见一见题目，可能面试中就会遇到原题。在字节，滴滴等公式面试时，我就遇到了许多原题。小伙伴们想找好工作的，赶紧刷起来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>数组</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>2出现的次数(Leetcode 程序员面试金典17.06)</title>
    <url>/2021/02/04/program%20Leetcode_interview17.06/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_06.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   我做这种题目，主要是按照位数变化找规律，先看一看0~9有多少个2，0~99有多少个2，0~999有多少个2。</p>
<a id="more"></a>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p><img src="/images/ALGORITHM/leetcodeinterview17_06_solve.png" alt="1"></p>
<p>知道原理后，使用迭代实现即可。算法的<strong>时间复杂度为$O(log(n))$，空间复杂度为$O(log(n))$</strong>。</p>
<p>我们也可以节省空间复杂度，因为n位数2的个数是$n * 10^{n - 1}$，在这里为了方便说明和使用，就使用了数组进行保存。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int numberOf2sInRange(int n) {</span><br><span class="line">        vector&lt;int&gt; cnt = { 0 };</span><br><span class="line">        int length = 0, ten = 1, tmp = n, res = 0;</span><br><span class="line">        while (tmp &gt;= 10) {</span><br><span class="line">            tmp /= 10;</span><br><span class="line">            cnt.push_back(++length * ten);</span><br><span class="line">            ten *= 10;</span><br><span class="line">        }</span><br><span class="line">        for (int i = length; i &gt;= 0; i--) {</span><br><span class="line">            int high = n / ten;</span><br><span class="line">            n = n % ten;</span><br><span class="line">            if (high == 1) res += cnt[i];</span><br><span class="line">            else if (high == 2) res += cnt[i] * 2 + n + 1;</span><br><span class="line">            else if (high != 0) res += high * cnt[i] + ten;</span><br><span class="line">            ten /= 10;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  对于数学问题，我们要学习小学生的做法，这类问题往往数字很大，不能使用线性，甚至更高复杂度的代码，老老实实找规律即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>计数质数(Leetcode 204)</title>
    <url>/2021/02/02/program%20Leetcode204/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode204.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   来一道简单题给小伙伴们放松放松。<br><a id="more"></a></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>相信每个学习编程的同学们都遇到过这个题目或者类似这个题目，当时我遇到的是判断一个数是否为质数。什么是质数，质数是指在大于1的自然数中，除了1和它本身以外不再有其他因数的自然数。如7，只能分解成1和7的乘积，说明7是质数，8就不是质数，因为可以分解为2和4的乘积，9也不是质数，可以分解为3和3的乘积。</p>
<p>因此算法也非常明显，判断n是否为质数，从2遍历到$\sqrt{n}$，如果能整除，说明不是质数。如果都不能整除，说明是质数。</p>
<p>这个题目是判断小于n的质数数量，那么就逐一枚举n，如果是质数则res++即可。</p>
<p>算法的<strong>时间复杂度为$O(n\sqrt{n})$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int countPrimes(int n) {</span><br><span class="line">        int res = n &gt;= 3 ? 1 : 0;</span><br><span class="line">        for (int i = 3; i &lt; n; i++) {</span><br><span class="line">            int sq = sqrt(i) + 1;</span><br><span class="line">            for (int j = 2; j &lt;= sq; j++) {</span><br><span class="line">                if (i % j == 0) break;</span><br><span class="line">                if (j == sq) res++;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="埃氏筛"><a href="#埃氏筛" class="headerlink" title="埃氏筛"></a><font size="5" color="red">埃氏筛</font></h1><p>该算法由希腊数学家厄拉多塞（EratosthenesEratosthenes）提出，称为厄拉多塞筛法，简称埃氏筛。</p>
<p>算法的思路非常简单，有三个要点。</p>
<ol>
<li>如果一个数是质数，那么其倍数一定都是合数。如7是质数，那么14，21，28…都是合数。</li>
<li>如果一个数是合数，不需要判断其倍数，一定已经判断过了。如14是合数，因为14可以分解为2和7的乘积，那么在2中已经将14，28，42…判断过了，因此不用判断倍数了。</li>
<li>分析质数k时，直接从k x k开始判断倍数即可。如分析7时，直接判断49， 56， 63…，不需要判断14， 21， 28…，因为k x m(m &lt; k)时，已经在分析m时判断过了。14在分析2的时候已经判断过了，21在分析3的时候已经判断过了。</li>
</ol>
<p><img src="/images/ALGORITHM/leetcode204_solve.png" alt="1"></p>
<p>代码也比较简单，记住上面三个要点也很容易可以写出来。</p>
<p>算法的<strong>时间复杂度为$O(nlog(log(n)))$，空间复杂度为$O(n)$</strong>，时间复杂度的推导非常繁琐，有兴趣的小伙伴可以找度娘。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int countPrimes(int n) {</span><br><span class="line">        vector&lt;bool&gt; nums(n, true);</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 2; i &lt; n; i++) {</span><br><span class="line">            if (nums[i]) {</span><br><span class="line">                res++;</span><br><span class="line">                if (long long(i) * i &lt; n) {</span><br><span class="line">                    for (int j = i * i;j &lt; n; j += i) { nums[j] = false; }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="线性筛"><a href="#线性筛" class="headerlink" title="线性筛"></a><font size="5" color="red">线性筛</font></h1><p>这个方法就更绕人了，小伙伴们能写出埃氏筛即可，线性筛作为了解。</p>
<p>在埃氏筛中，对于45这个数，在分析3的时候进行了赋值，在分析5的时候也进行了赋值。这会浪费一部分时间复杂度，可以从中进一步优化。</p>
<p>我们想对一个数只标记一次，用最小因子和最大因子标记即可，如45，就用3和15进行标记，不需要用5和9再次标记。</p>
<p>如果一个数x可以被一个质数n整除，设x = k x n，那么对于合数y = x <em> m，其中m为另一个更大的质数，就不需要标记了，一定会被$\frac{x}{n} \cdot m$标记。例如15可以被3整除，那么对于75 = 15 </em> 5来说，75一定会被$\frac{15}{3} \cdot 5 = 25$标记。</p>
<script type="math/tex; mode=display">y = x \cdot m = k \cdot n \cdot m = k \cdot m \cdot n</script><p>其中n是最小的质数因子。</p>
<p>因此我们在分析15的时候，只用将30， 45， 60…标记即可，对于75这个数，以后有25会对其标记。</p>
<p>可以再优化的是：我们只用标记质数，在分析15的时候，其实只用标记30和45，因为15 x 2 = 30， 15 * 3 = 45，2和3都是质数。因为合数一定可以分解为最小的质数因子，所以，60可以分解为4 x 15，4是质数，可以分解为2 x 2，因此可以写成30 x 2，会被30标记，也不用在这里标记。</p>
<p>综上所述，合数不用标记，只用标记到能整除的第一个质数即可。这样每个数只用标记一次。算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int countPrimes(int n) {</span><br><span class="line">        vector&lt;int&gt; prime;</span><br><span class="line">        vector&lt;bool&gt; nums(n, true);</span><br><span class="line">        for (int i = 2; i &lt; n; i++) {</span><br><span class="line">            if (nums[i]) { prime.push_back(i); }</span><br><span class="line">            for (int j = 0; j &lt; prime.size() &amp;&amp; i * prime[j] &lt; n; j++) {</span><br><span class="line">                nums[i * prime[j]] = false;</span><br><span class="line">                if (i % prime[j] == 0) { break; }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return prime.size();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  还是埃氏筛简单易懂，而且时间复杂度很低，在1e10的数量中，log(log(1e10)) = 5，也相当于几乎线性的时间复杂度。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>特定算法</category>
      </categories>
  </entry>
  <entry>
    <title>拼接最大数(Leetcode 321)</title>
    <url>/2021/01/30/program%20Leetcode321/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode321.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目作为困难题，一点都不为过，难度确实很大，考察的知识点也很多，也都是非常非常重要的内容，明白了思路，小伙伴们会发现这个题是许多题目的融合，每一道题至少都是中等难度的。<br><a id="more"></a></p>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a><font size="5" color="red">排序</font></h1><p>我们恰巧在讲解1673题的时候，讲到过求数组长度为k的最小子序列的求法。当时那个题目使用栈来求解，是一个中等难度的题目。而这个问题是求长度为k的最大子序列，但是要从两个数组中选取。</p>
<p>两个数组选长度为k的子序列，有多少种不同的选法呢？当两个数组长度都大于等于k时，有k+1种选法。nums1选取n个，nums2选取k - n个。其中一个子函数是求解一个数组长度为k的最大子序列，在代码中对应getMaxSubsequence函数。</p>
<p>求出nums1的长度为n的子序列，nums2长度为k - n的子序列后，要对两个子序列进行合并，其中用到了双指针的知识，类似于归并排序。在代码中对应merge函数。</p>
<p>在归并排序的时候，如果从大到小排序，哪一个大则将哪一个值加入结果中，并且索引+1，这个题目也是一样，但是在相等的时候较为复杂。归并排序时，因为子序列一定是有序的，在合并的时候相等时先加入哪一个都是可以的。但是这里子序列并不是按照从大到小排列的，因为要满足长度条件，因此顺序是不能保证的。在两个值相等时要递归比较下一个值是否相等。在代码中对应compare函数。</p>
<p>等到k + 1个序列都比较完成后，最大的用res保存即可。</p>
<p>算法一共要比较k次，在每一次都需要计算两个最大子序列，时间复杂度为$O(m + n)$，两个子序列合并时，如果每一次比较都相等，最坏时间复杂度为$k^2$，因此算法的<strong>时间复杂度为$O(k(m + n + k^2))$，空间复杂度为$O(k)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; maxNumber(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2, int k) {</span><br><span class="line">        vector&lt;int&gt; res(k, 0);</span><br><span class="line">        for (int i = 0; i &lt;= k; i++) {</span><br><span class="line">            if (nums1.size() &gt;= i &amp;&amp; nums2.size() &gt;= k - i) {</span><br><span class="line">                vector&lt;int&gt; subsequence1 = getMaxSubsequence(nums1, i), subsequence2 = getMaxSubsequence(nums2, k - i);</span><br><span class="line">                vector&lt;int&gt; mergeSubsequence = merge(subsequence1, subsequence2);</span><br><span class="line">                if (compare(mergeSubsequence, 0, res, 0)) res = mergeSubsequence;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    vector&lt;int&gt; getMaxSubsequence(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) {</span><br><span class="line">            while (!res.empty() &amp;&amp; res.back() &lt; nums[i] &amp;&amp; int(nums.size() + res.size() - k - i - 1) &gt;= 0) res.pop_back();</span><br><span class="line">            if (res.size() &lt; k) res.push_back(nums[i]);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    vector&lt;int&gt; merge(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt; nums2) {</span><br><span class="line">        int idx1 = 0, idx2 = 0;</span><br><span class="line">        vector&lt;int&gt; res(nums1.size() + nums2.size());</span><br><span class="line">        for (int i = 0; i &lt; res.size(); i++) res[i] = compare(nums1, idx1, nums2, idx2) ? nums1[idx1++] : nums2[idx2++];</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool compare(vector&lt;int&gt;&amp; nums1, int idx1, vector&lt;int&gt;&amp; nums2, int idx2) {</span><br><span class="line">        if (idx1 == nums1.size()) return false;</span><br><span class="line">        if (idx2 == nums2.size()) return true;</span><br><span class="line">        if (nums1[idx1] &lt; nums2[idx2]) return false;</span><br><span class="line">        if (nums1[idx1] &gt; nums2[idx2]) return true;</span><br><span class="line">        return compare(nums1, idx1 + 1, nums2, idx2 + 1);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  最近遇到的题目难度都很大，但是非常有意义，希望小伙伴们认真做题，认真总结。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
        <category>数组</category>
        <category>递归</category>
        <category>双指针</category>
      </categories>
  </entry>
  <entry>
    <title>完全二叉树的节点个数(Leetcode 222)</title>
    <url>/2021/01/28/program%20Leetcode222/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode222.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   第222题厉害了，<strong>考察的知识点非常丰富，不但有搜索算法，DFS搜索还包含了递归的思想，BFS包含了队列数据结构，还覆盖了位运算和二分查找的思想</strong>，这有点类似于完全二叉搜索树。因为<strong>一般只有完全二叉树才可能用得到位运算的思想，也只有二叉搜索树才可能用得到二分查找的思想</strong>。这个题目将它们融合起来，小伙伴们要好好思考。<br><a id="more"></a></p>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>这个题目的重点不是DFS，而且DFS的代码非常简单，就不做过多介绍了。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(log(n))$</strong>，其中n为节点个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int countNodes(TreeNode* root) {</span><br><span class="line">        int res = 0;</span><br><span class="line">        dfs(root, res);</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void dfs(TreeNode* node, int&amp; res) {</span><br><span class="line">        if (!node) return;</span><br><span class="line">        res++;</span><br><span class="line">        dfs(node-&gt;left, res);</span><br><span class="line">        dfs(node-&gt;right, res);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>BFS也非常简单，小伙伴们直接看代码。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>，其中n为节点个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int countNodes(TreeNode* root) {</span><br><span class="line">        int res = 0;</span><br><span class="line">        deque&lt;TreeNode*&gt; queue = { root };</span><br><span class="line">        while (!queue.empty()) {</span><br><span class="line">            TreeNode* cur = queue.front();</span><br><span class="line">            queue.pop_front();</span><br><span class="line">            if (cur) {</span><br><span class="line">                res++;</span><br><span class="line">                queue.push_back(cur-&gt;left);</span><br><span class="line">                queue.push_back(cur-&gt;right);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="二分查找-位运算"><a href="#二分查找-位运算" class="headerlink" title="二分查找+位运算"></a><font size="5" color="red">二分查找+位运算</font></h1><p>本题要重点讲解二分查找+位运算的算法。<br><img src="/images/ALGORITHM/leetcode222_solve.png" alt="1"></p>
<p><strong>看了上面的图，小伙伴们发现什么规律，是不是从第0层根节点到第k层某节点经过了k个通路，然后这k个通路按照0和1的顺序排列，就是该节点的二进制表示</strong>。</p>
<p><strong>因此我们可以确定完全二叉树的层数，然后二分查找最后一层的数量。假定有k层(根节点在第0层)，那么节点数就在$2^k~2^{k + 1} - 1$个</strong>。</p>
<p>二分节点数，并且根据节点的二进制表示确定其在左子树还是右子树。</p>
<p><strong>如树有3层，节点数为1101的13号，那么我们看第二位的1，可知它是根节点的右子树中的某个节点。然后看第一位的0，可知它是右子树中的左子树的某个节点。然后看第零位的1可知它是根节点右子树的左子树的右节点。因此如果该节点存在，说明二叉树至少有13个节点，left = mid即可。否则二叉树没有13个节点，right = mid - 1</strong>。</p>
<p>因为二分节点数需要log(n)的时间复杂度，从根节点找到该节点也需要log(n)的时间复杂度，因此算法的<strong>时间复杂度为$O(log^{2}(n))$，空间复杂度为$O(1)$</strong>，其中n为节点个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int countNodes(TreeNode* root) {</span><br><span class="line">        if (!root) return 0;</span><br><span class="line">        int layer = -1;</span><br><span class="line">        TreeNode* node = root;</span><br><span class="line">        while (node) {</span><br><span class="line">            layer++;</span><br><span class="line">            node = node-&gt;left;</span><br><span class="line">        }</span><br><span class="line">        int left = 1 &lt;&lt; layer, right = (1 &lt;&lt; (layer + 1)) - 1;</span><br><span class="line">        while (left &lt; right) {</span><br><span class="line">            int mid = (left + right + 1) &gt;&gt; 1;</span><br><span class="line">            node = root;</span><br><span class="line">            for (int i = layer - 1; i &gt;= 0; i--) {</span><br><span class="line">                if (!(mid &amp; (1 &lt;&lt; i)) &amp;&amp; node-&gt;left) node = node-&gt;left;</span><br><span class="line">                else if (mid &amp; (1 &lt;&lt; i) &amp;&amp; node-&gt;right) node = node-&gt;right;</span><br><span class="line">                else {</span><br><span class="line">                    right = mid - 1;</span><br><span class="line">                    break;</span><br><span class="line">                }</span><br><span class="line">                if (i == 0) left = mid;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return left;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  树的位运算表示也非常重要，<strong>如果不用位运算，我们需要递推出节点所在的子树。如13号节点，我们可以先除以2，确定它的父亲节点是6号，因为13 = 6 * 2 + 1，因此13为6号节点的右子树。同理可知6是3号节点的左子树，3是1号根节点的右子树。然后再从根索引到13号节点，来确定13号节点是否存在。这样做时间复杂度多了一次log(n)，而且需要一个堆栈保存13， 6， 3， 1的顺序，方便索引时取出。空间复杂度也会提高到log(n)</strong>。虽然比较麻烦，但是也是一个解决方案，小伙伴们可以尝试能否实现。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>树</category>
        <category>广度优先搜索</category>
        <category>二分查找</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>搜索旋转数组(Leetcode 程序员面试金典10.03)</title>
    <url>/2021/01/25/program%20Leetcode_interview10.03/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview10_03.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目的数据量是1e7，暴力法可以直接通过，小伙伴们能否想到更优的方法？</p>
<a id="more"></a>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>题目的意图是让我们使用二分查找来解决这个题目，题意中明确说了这是一个升序排列后的数组，经过了旋转，因此打乱了原先的排列顺序。这个题目和Leetcode33题和Leetcode81题非常类似，小伙伴们可以做完这个题目之后做一些另外两道。</p>
<p>旋转后可能出现三种情况，我们分别对其讨论，如下图所示。<br><img src="/images/ALGORITHM/leetcodeinterview10_03_solve.png" alt="1"></p>
<p>因此最坏的情况下算法的<strong>时间复杂度仍是$O(n)$</strong>，正常情况下算法的<strong>时间复杂度为$O(log(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int search(vector&lt;int&gt;&amp; arr, int target) {</span><br><span class="line">        int left = 0, right = arr.size() - 1;</span><br><span class="line">        while (left &lt; right) {</span><br><span class="line">            int mid = (left + right) &gt;&gt; 1;</span><br><span class="line">            if (arr[mid] &gt; arr[left]) {</span><br><span class="line">                if (target &gt;= arr[left] &amp;&amp; target &lt;= arr[mid]) right = mid;</span><br><span class="line">                else left = mid + 1;</span><br><span class="line">            }</span><br><span class="line">            else if (arr[mid] &lt; arr[left]){</span><br><span class="line">                if (target &gt;= arr[left] || target &lt;= arr[mid]) right = mid;</span><br><span class="line">                else left = mid + 1;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                if (arr[left] == target) right = left;</span><br><span class="line">                else left++;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return arr[left] == target ? left : -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这类题目是二分查找的扩展题型，二分查找是算法的重点内容，也是面试笔试的常考知识点，希望小伙伴们能深刻理解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>汉诺塔问题(Leetcode 程序员面试金典08.06)</title>
    <url>/2021/01/23/program%20Leetcode_interview08.06/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview08_06.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  汉诺塔是一个经典的递归算法，小伙伴们在学习算法课程时应该接触过这个问题。当时我学习递归的时候，遇到的两个经典问题，一个是斐波那契数列问题，一个就是汉诺塔问题。当然这个问题难度稍微大了一些，当时只需要打印移动的过程，这个题目是要用数组模拟移动的过程。<br><a id="more"></a></p>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p><img src="/images/ALGORITHM/leetcodeinterview08_06_solve.png" alt="1"><br>思考一个问题，如果要将A通过B移动到C，我们应该怎么做？类比于将大象放进冰箱需要几步？</p>
<ol>
<li>将A中除了最后一个盘子，其他的盘子都放在B中。</li>
<li>将A中最后一个盘子放入C。</li>
<li>将B中所有盘子放入C。</li>
</ol>
<p><strong>定义：subQuestion(A, B, C, nums)指将A中的nums个盘子在B柱子的帮助下，全部放入到C中</strong>。</p>
<p>因此递归的思路就很明确了，<strong>先将A中的盘子除了最后一个，在C的帮助下都放入B，可以表示为subQuestion(A, C, B, nums - 1)。然后将A中剩余的盘子放入C，C.push_back(A.back())，A.pop_back()。最后将B中的所有盘子，在A的帮助下都放入C，此时B中盘子个数为nums - 1，可以表示为subQuestion(B, A, C, nums - 1)</strong>。</p>
<p><strong>其中出口条件是nums = 0时，当nums = 0，不需要任何操作，直接return即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(2^n)$，空间复杂度为$O(n)$</strong>。</p>
<p>其中每次操作都会分裂为两个额外的操作，因此时间复杂度为$O(2^n)$，空间复杂度是递归的栈调用消耗的空间，其中递归的深度最大为n，空间复杂度为$O(n)$<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    void hanota(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B, vector&lt;int&gt;&amp; C) {</span><br><span class="line">        subQuestion(A, B, C, A.size());</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void subQuestion(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B, vector&lt;int&gt;&amp; C, int num) {</span><br><span class="line">        if (num == 0) return;</span><br><span class="line">        subQuestion(A, C, B, num - 1);</span><br><span class="line">        C.push_back(A.back());</span><br><span class="line">        A.pop_back();</span><br><span class="line">        subQuestion(B, A, C, num - 1);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个问题时最经典的递归问题，没有接触过的小伙伴可能觉得有些困难，理清楚思想之后还是比较清晰的，希望小伙伴们可以顺利写出来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>递归</category>
      </categories>
  </entry>
  <entry>
    <title>消失的数字(Leetcode 程序员面试金典17.04)</title>
    <url>/2021/01/20/program%20Leetcode_interview17.04/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_04.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  这个题目我做过许多次了，之前是使用Python语言写的代码，这次用C++来实现一下，题目难度不大，小伙伴们能够想到多少种方法呢？<br><a id="more"></a></p>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>直接遍历查找，每一个数都从数组中进行查找，看一下是否存在。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(1)$</strong>。</p>
<p>提交时会TLE，因此不能使用这个方法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        for (int i = 0; i &lt;= nums.size(); i++) {</span><br><span class="line">            for (int j = 0; j &lt; nums.size(); j++) {</span><br><span class="line">                if (i == nums[j]) break;</span><br><span class="line">                if (j == nums.size() - 1) return i;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a><font size="5" color="red">数组</font></h1><p>使用空间来换取时间，来一个数则该索引值+1，最后遍历数组，看一下哪一个索引对应的值为0即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        vector&lt;int&gt; arr(nums.size() + 1, 0);</span><br><span class="line">        for (int x : nums) arr[x] += 1;</span><br><span class="line">        for (int i = 0; i &lt; arr.size(); i++) if (arr[i] == 0) return i;</span><br><span class="line">        return -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>使用哈希表同样的道理，可以先将0~n的所有元素都加入哈希表中，然后从nums中逐一删除，最后剩余元素就是缺失的元素。</p>
<p>也可以从nums中逐一添加进哈希表，然后查找0~n的所有元素，如果找不到说明该元素是缺失元素，</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_set&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        unordered_set&lt;int&gt; hashSet;</span><br><span class="line">        for (int i = 0; i &lt;= nums.size(); i++) hashSet.insert(i);</span><br><span class="line">        for (int x : nums) hashSet.erase(x);</span><br><span class="line">        return *hashSet.begin();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化数组"><a href="#优化数组" class="headerlink" title="优化数组"></a><font size="5" color="red">优化数组</font></h1><p>都是正数的题目可以在原数组上进行修改，不需要另外开辟数组。</p>
<p><strong>如果某个数等于k，那么我们让k对应的索引变成相反数。那么最后是正数的位置说明没有相应的k让其变化</strong>。</p>
<p>但是这个方法需要考虑很多的情况，代码量较长。</p>
<ol>
<li>最大值问题，数组长度为n，最大值为n，因此不能改变nums[n]对应的值，会数组越界。因此我们要对最大值进行特判。</li>
<li>0的问题，如果某个位置的值是0，如nums[k] = 0,那么我们修改k的时候还是0，最后查询时会出错。因此我们先判断0是否存在，如果不存在直接返回0。如果存在，我们对修改后的数组查询时，如果存在正数，则返回对应索引，如果不存在，说明恰好修改的是0，因此返回0的索引。</li>
</ol>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        pair&lt;vector&lt;int&gt;::iterator, vector&lt;int&gt;::iterator&gt; minMax = minmax_element(nums.begin(), nums.end());</span><br><span class="line">        int mini = *minMax.first, maxi = *minMax.second;</span><br><span class="line">        if (maxi &lt; nums.size()) return nums.size();</span><br><span class="line">        if (mini != 0) return 0;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) if (abs(nums[i]) &lt; maxi) nums[abs(nums[i])] *= -1;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) if (nums[i] &gt; 0) return i;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) if (nums[i] == 0) return i;</span><br><span class="line">        return -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>在优化数组中，我们遍历了数组4次，如何更快更高效呢？</p>
<p><strong>数组中的数组是从0~n的，因此和是已知的，我们计算之和，然后再减数组中的每一个元素，即可求出缺失元素</strong>。</p>
<p>在<strong>Python中不会超出数据的表示范围，但是C++中要小心</strong>，因此利用等差数列求和公式是不安全的，这里给出一种更好的处理方法。</p>
<p><strong>我们要计算0~n这n个数的和，然后减去nums数组中的和，可以减去数组中的元素，如果结果小于等于0，那么就加上一个数k，直到结果变为正数为止，其中k从0到n</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int k = 0, res = 0;</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            res -= x;</span><br><span class="line">            while (res &lt;= 0 &amp;&amp; k &lt;= nums.size()) res += k++;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>本题除了数学方法以外，也有其他巧妙的方法——位运算。</p>
<p><strong>位运算是满足交换律的，而且满足如下两个式子</strong>。<br>$x ^ x = 0 \ \ x ^ 0 = x$</p>
<p><strong>因此我们先从0异或到n，再异或数组中的所有元素，那么除了缺失的元素以外，其他的元素都异或了两次，都变成了0，0异或缺失的元素，最后得到的结果就是缺失的元素</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 1; i &lt;= nums.size(); i++) res ^= i;</span><br><span class="line">        for (int x : nums) res ^= x;</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  题目虽然简单，但是考察了许多重要的知识点，如数据的表示范围，位运算等等，希望小伙伴们能够掌握后面三种方法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
        <category>哈希表</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>数组的最小偏移量(Leetcode 217场单周赛第4题)</title>
    <url>/2021/01/18/program%20Leetcode1675/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1675.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第217场周赛的第四题，这次周赛的难度较大，都是有关数组和数学的题目，重在考察小伙伴们对数据结构的掌握程度。<br><a id="more"></a></p>
<h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a><font size="5" color="red">堆</font></h1><p><strong>这个题目的特点是偶数可以除以2，奇数可以乘2，因此数组中的值是有上限的，上限就是全部变成偶数。因此我们可以先将数组变大，然后求出最大值和最小值之间的差距。然后看最大值能否变小，如果可以，说明最大最小值之间的差异就会变小</strong>。</p>
<p>因此我们可以维护一个最大堆，我们动态维护这个堆的最大值和最小值即可。维护最大值不需要我们手动维护，但是维护最小值应该如何操作呢？</p>
<p>只需要将最大值除以2以后和最小值比较，看一看是否需要更新最小值。再将更新后的最大值放入堆中即可。</p>
<p>堆操作的时间复杂度为$O(nlog(n))$，每个数最多需要插入$log(nums[i])$次，因此算法的<strong>时间复杂度为$O(nlog(n)log(a_i))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;queue&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int minimumDeviation(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        priority_queue&lt;int&gt; q;</span><br><span class="line">        int mini = nums[0] * 2;</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            int tmp = x &amp; 1 ? x * 2 : x;</span><br><span class="line">            q.push(tmp);</span><br><span class="line">            mini = min(mini, tmp);</span><br><span class="line">        }</span><br><span class="line">        int res = q.top() - mini;</span><br><span class="line">        while ((q.top() &amp; 1) == 0) {</span><br><span class="line">            int maxi = q.top() / 2;</span><br><span class="line">            q.pop();</span><br><span class="line">            q.push(maxi);</span><br><span class="line">            mini = min(mini, maxi);</span><br><span class="line">            res = min(res, q.top() - mini);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  堆是一种非常重要的数据结构，在刷题中常常会遇到，在动态维护最值时有重要应用，小伙伴们要加强这方面的训练。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>数学</category>
        <category>模拟</category>
      </categories>
  </entry>
  <entry>
    <title>使数组互补的最少操作次数(Leetcode 217场单周赛第3题)</title>
    <url>/2021/01/15/program%20Leetcode1674/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1674.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第217场周赛的第三题，这个题目难度较大，思路也非常奇特，小伙伴们之前应该都没有遇到过类似的题目，拿出来给小伙伴们看一看。<br><a id="more"></a></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>这个题目我没有求解出来，参考了北大吴自华大佬的题解。</p>
<p>我们最终要让nums[i]+nums[n - 1 - i]等于同一个数target，那么不妨设</p>
<script type="math/tex; mode=display">nums[i] = a, nums[n - 1 - i] = b，a \le b</script><p>如果 a &gt; b则可以交换a和b，不会影响结果。如[1, 2, 3, 4]和[4, 2, 3, 1]的结果是相同的。</p>
<p>我们让target从2开始移动，因为nums[i]都大于等于1。因此操作次数是2n。即target &lt; 2的时候，在移动之前每一个操作数都需要改变。</p>
<p><strong>发现如果$target = 1 + nums[k]$的时候，操作次数就会减少一次，只需要将nums[n - 1 - k]改成1即可，nums[k]不用变化</strong>。</p>
<p><strong>发现如果$target = nums[k] + nums[n - 1 - k]$的时候，操作次数又会减少一次，因为两个都不需要变化</strong>。</p>
<p><strong>发现如果$target = nums[k] + nums[n - 1 - k] + 1$的时候，操作次数会增加一次，因为需要将a改为a + 1</strong>。</p>
<p><strong>发现如果$target = nums[n - 1 - k] + limit + 1$的时候，操作次数又会增加一次，因为需要将a变为limit，b变为b + 1</strong>。</p>
<p>只要从2到2*limit遍历target，求出最小的操作次数即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int minMoves(vector&lt;int&gt;&amp; nums, int limit) {</span><br><span class="line">        vector&lt;int&gt; delta(limit * 2 + 2);</span><br><span class="line">        int length = nums.size();</span><br><span class="line">        for (int i = 0; i &lt; length / 2; i++) {</span><br><span class="line">            int low = 1 + min(nums[i], nums[length - i - 1]);</span><br><span class="line">            int high = limit + max(nums[i], nums[length - i - 1]);</span><br><span class="line">            int sum = nums[i] + nums[length - i - 1];</span><br><span class="line">            delta[low]--;</span><br><span class="line">            delta[sum]--;</span><br><span class="line">            delta[sum + 1]++;</span><br><span class="line">            delta[high + 1]++;</span><br><span class="line">        }</span><br><span class="line">        int res = length, cur = length;</span><br><span class="line">        for (int i = 2; i &lt;= limit * 2; i++) {</span><br><span class="line">            cur += delta[i];</span><br><span class="line">            res = min(res, cur);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目太奇妙了，如果遇到了这个题目，我相信小伙伴们也是非常困扰的，因此刷题的目的除了熟练代码，练习算法以外还能够拓展思维，开阔视野，非常nice。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>数组</category>
        <category>模拟</category>
      </categories>
  </entry>
  <entry>
    <title>找出最具竞争力的子序列(Leetcode 217场单周赛第2题)</title>
    <url>/2021/01/11/program%20Leetcode1673/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1673.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第217场周赛的第二题，题目有一定的难度，希望小伙伴们能认真思考。<br><a id="more"></a></p>
<h1 id="递归算法"><a href="#递归算法" class="headerlink" title="递归算法"></a><font size="5" color="red">递归算法</font></h1><p>这个题目可以使用递归进行求解，<strong>每次判断剩余的元素数目是否等于k，如果等于则将其全部加入结果，判断k是否等于0，如果是也可以作为递归出口</strong>。</p>
<p>否则<strong>我们要保留k - 1个数，找到之前所有元素的最小值加入结果序列中</strong>。这里要说明的是保留k - 1个数的目的防止后面元素不满足k个。如[3,4,2,5,1]序列，k = 2，我们先选出序列的第一个元素，我们要保留2 - 1 = 1个元素，即保留1，从3，4，2，5中选择最小的作为序列的第一个元素，如果不保留，我们选择了1，那么后面就没有序列了，因此是不正确的。</p>
<p>为什么要找最小值呢？这也很容易理解，1，9，9，9的竞争力也大于2，0，0，0，因此我们有一种贪心的思想，能选最小的一定先选最小的。</p>
<p>每次递归都需要计算从当前元素到倒数第k个元素的最小值，算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; mostCompetitive(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        subQuestion(nums, res, 0, k);</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void subQuestion(vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; res, int left, int k) {</span><br><span class="line">        if (k == 0) return;</span><br><span class="line">        if (nums.size() - left == k) {</span><br><span class="line">            for (int i = left; i &lt; nums.size(); i++) res.push_back(nums[i]);</span><br><span class="line">            return;</span><br><span class="line">        }</span><br><span class="line">        int mini = nums[left], idx = left;</span><br><span class="line">        for (int i = left + 1; i &lt; nums.size() - k + 1; i++) {</span><br><span class="line">            if (nums[i] &lt; mini) mini = nums[i], idx = i;</span><br><span class="line">        }</span><br><span class="line">        res.push_back(mini);</span><br><span class="line">        subQuestion(nums, res, idx + 1, k - 1);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="队列优化的迭代算法"><a href="#队列优化的迭代算法" class="headerlink" title="队列优化的迭代算法"></a><font size="5" color="red">队列优化的迭代算法</font></h1><p>能用递归求解的问题，很多都可以迭代求解，这个题目也一样，小伙伴们可以尝试一下如何将上面的递归改写为迭代算法。</p>
<p>上面的算法提交会TLE，因为数据量是1e5，因此不能使用$O(n^2)$的算法求解。我们想一下超时的问题出现在什么地方？</p>
<p><strong>因为我们每次都要重新求解数组的最小值，浪费了大量的操作。这个题目类似于Leetcode239题，滑动窗口的相关题目，我们要求的最小值也是在滑动的，因此我们可以使用一个单调递增的队列保存滑动窗口的最小值。第一次从0到nums.size() - k + 1这个位置中计算单调递增队列。然后队头元素一定是最小值，因此将队头元素取出加入结果序列res中，然后窗口向下滑动</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; mostCompetitive(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        deque&lt;pair&lt;int, int&gt;&gt; queue;</span><br><span class="line">        int begin = 0, end = nums.size() - k + 1;</span><br><span class="line">        while (k) {</span><br><span class="line">            for (int i = begin; i &lt; end; i++) {</span><br><span class="line">                while (!queue.empty() &amp;&amp; nums[i] &lt; queue.back().first) queue.pop_back();</span><br><span class="line">                queue.push_back({ nums[i], i });</span><br><span class="line">            }</span><br><span class="line">            int val = queue.front().first, idx = queue.front().second;</span><br><span class="line">            res.push_back(val);</span><br><span class="line">            begin = end;</span><br><span class="line">            queue.pop_front();</span><br><span class="line">            k--;</span><br><span class="line">            end++;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p>本题的最妙解法是单调栈求解，时间复杂度和使用单调队列相同，但是代码非常简单。</p>
<p><strong>我们不需要建立额外的单调队列保存最小值，可以直接将结果序列看成一个单调栈。向结果序列中添加元素，如果新加入的元素小于栈顶元素，则栈顶元素出栈，新元素入栈。维护一个单调递增的栈即可。前提是我们要保证剩余元素+栈内元素要大于等于k</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; mostCompetitive(vector&lt;int&gt;&amp; nums, int k) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        for (int i = 0; i &lt; nums.size(); i++) {</span><br><span class="line">            while (!res.empty() &amp;&amp; res.back() &gt; nums[i] &amp;&amp; nums.size() - i - 1 + res.size() &gt;= k) res.pop_back();</span><br><span class="line">            if (res.size() &lt; k) res.push_back(nums[i]);</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目是典型的数据结构相关的算法题，难度适中，代码量不多不少，非常适合在面试中考察大家，因此小伙伴们一定要多多练习，自己实现一遍。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
        <category>数组</category>
        <category>递归</category>
        <category>队列</category>
        <category>迭代</category>
      </categories>
  </entry>
  <entry>
    <title>Java异常</title>
    <url>/2021/01/07/Java_exception/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java75.png" alt="2"></p>
<h1 id="Java异常"><a href="#Java异常" class="headerlink" title="Java异常"></a><font size="5" color="red">Java异常</font></h1><p>  异常是指程序在执行过程中出现的非正常情况，最终导致JVM非正常停止。在Java语言中，异常的产生就是创建异常对象并抛出了一个异常对象，依次向上寻找是否有处理逻辑，如果到main方法仍然没有try…catch语句，则会继续抛出给JVM处理，JVM收到后会将异常信息以红色字体打印在控制台，并且终止程序，<br><a id="more"></a></p>
<h1 id="throw-throws关键字"><a href="#throw-throws关键字" class="headerlink" title="throw/throws关键字"></a><font size="5">throw/throws关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.io.FileNotFoundException;</span><br><span class="line"></span><br><span class="line">public class ExceptionClass {</span><br><span class="line">    //throws是异常处理的第一种方式，交给其他人处理。注意throws关键字必须写在方法声明处，throws关键字后声明的异常必须是Exception或子类，如果内部抛出了多个对象，则必须也声明多个异常，如果抛出的异常有子父类关系，则直接抛出父类异常即可。</span><br><span class="line">    public static void main(String[] args) throws FileNotFoundException {</span><br><span class="line">        test();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void test() throws FileNotFoundException {</span><br><span class="line">        //可以使用throw关键字在指定的方法中抛出指定的异常，注意throw关键字抛出的异常必须是Exception的子类对象，如果是RuntimeException或子类，我们可以不处理，如果是编译异常，则必须处理，要不继续throws，要不try...catch处理</span><br><span class="line">        throw new FileNotFoundException("没有找到文件异常！");</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java76.png" alt="1"></p>
<h1 id="try…catch关键字"><a href="#try…catch关键字" class="headerlink" title="try…catch关键字"></a><font size="5">try…catch关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class ExceptionClass {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        System.out.println("测试try...catch语句");</span><br><span class="line">        System.out.println("--------------------");</span><br><span class="line">        System.out.println(test1(10, 2));</span><br><span class="line">        System.out.println(test1(10, 0));</span><br><span class="line">        System.out.println("测试try...catch...finally语句");</span><br><span class="line">        System.out.println("--------------------");</span><br><span class="line">        System.out.println(test2(10, 2));</span><br><span class="line">        System.out.println(test2(10, 0));</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //在try...catch语句中，可能会抛出多个异常，那么就可以使用多个catch进行捕获。</span><br><span class="line">    //如果try中产生了异常，则会执行catch中的语句，执行完毕后执行try...catch语句后的代码；如果try中没有产生异常，则会执行完try中的语句，然后继续执行try...catch语句后的代码。</span><br><span class="line">    //如果有多个异常时，有三种解决方案，可以写多个try...catch语句进行分别处理，也可以写一个try语句，多个catch语句，但是子类异常的catch要写在前面，或者写一个try语句一个catch语句，在catch语句中写所有异常的父类，即可一次性抛出所有异常。</span><br><span class="line">    public static int test1(int a, int b){</span><br><span class="line">        int res;</span><br><span class="line">        try {</span><br><span class="line">            res = a / b;</span><br><span class="line">            System.out.println("执行try之后的语句");</span><br><span class="line">        }catch (ArithmeticException e) {</span><br><span class="line">            res = 0;</span><br><span class="line">            System.out.println("执行catch之后的语句");</span><br><span class="line">        }</span><br><span class="line">        System.out.println("执行try...catch之后的语句");</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //在try...catch...finally语句中，finally中的语句无论异常是否出现都会执行，常常用于资源回收和释放。</span><br><span class="line">    public static int test2(int a, int b){</span><br><span class="line">        int res;</span><br><span class="line">        try {</span><br><span class="line">            res = a / b;</span><br><span class="line">            System.out.println("执行try之后的语句");</span><br><span class="line">        }catch (ArithmeticException e) {</span><br><span class="line">            res = 0;</span><br><span class="line">            System.out.println("执行catch之后的语句");</span><br><span class="line">        }finally {</span><br><span class="line">            System.out.println("执行finally之后的语句");</span><br><span class="line">        }</span><br><span class="line">        System.out.println("执行try...catch之后的语句");</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java77.png" alt="1"></p>
<h1 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a><font size="5">自定义异常</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//自定义异常类必须继承Exception或RuntimeException</span><br><span class="line">//继承Exception：则自定义异常是编译期异常，如果抛出异常则必须处理。</span><br><span class="line">public class MyException1 extends Exception {</span><br><span class="line">    public MyException1(String message) {</span><br><span class="line">        super(message);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//继承RuntimeException：则自定义异常是运行期异常，无需处理，交给JVM也可。</span><br><span class="line">public class MyException2 extends RuntimeException {</span><br><span class="line">    public MyException2(String message) {</span><br><span class="line">        super(message);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class ExceptionClass {</span><br><span class="line">    public static void main(String[] args) throws MyException1 {</span><br><span class="line">        try{</span><br><span class="line">            test1();</span><br><span class="line">            test2();</span><br><span class="line">        }catch (Exception e){</span><br><span class="line">            System.out.println("我解决了继承Exception类的异常");</span><br><span class="line">            System.out.println("我解决了继承RuntimeException类的异常");</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void test1() throws MyException1 {</span><br><span class="line">        throw new MyException1("这是一个继承Exception类的异常");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void test2() {</span><br><span class="line">        throw new MyException2("这是一个继承RuntimeException类的异常");</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java78.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  红色的异常语句是每一个程序员都遇到过的，在这里我们对异常进行了揭秘，可能在平时的做题或者工程中很难用到，我们还是要了解它的机制，当我们需要的时候可以及时回忆起来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>Java常用类(HashMap)</title>
    <url>/2021/01/05/Java_hashMap/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java72.png" alt="2"></p>
<h1 id="Java常用类-HashMap"><a href="#Java常用类-HashMap" class="headerlink" title="Java常用类(HashMap)"></a><font size="5" color="red">Java常用类(HashMap)</font></h1><p>  今天给小伙伴们介绍HashMap类，HashMap是Java专门用于处理字典的类，和C++中的map，或者Python中的dict相同。其特点是双列集合，一个元素包含两个值，一个称为key，一个称为value，key的底层是哈希表，不允许存储重复元素，无序，无法索引，因此无法使用普通的for循环，通常的使用场景是根据key得到value对应的值。在Java中也内置了许多常用的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="HashMap类"><a href="#HashMap类" class="headerlink" title="HashMap类"></a><font size="5">HashMap类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.util.Collection;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line">import java.util.Set;</span><br><span class="line"></span><br><span class="line">public class HashMapClass {</span><br><span class="line">    public static void print(HashMap&lt;Integer, String&gt; h) {</span><br><span class="line">        for (Map.Entry&lt;Integer, String&gt; e: h.entrySet()) {</span><br><span class="line">            //Map.Entry&lt;K,V&gt;类型的getKey()方法可以取出对象的key，getValue()方法可以取出对象的value</span><br><span class="line">            System.out.println(e.getKey() + ": " + e.getValue());</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //注意：如果想用HashMap中的key存储自定义类型，和HashSet中存储自定义类型相同，需要重写对象中的hashCode方法和equals方法。</span><br><span class="line">        //还可以创建LinkedHashMap类型，和HashMap几乎相同，但是LinkedHashMap底层是一个链表和一个哈希表，链表的作用是记录元素第一次出现的位置，因此元素是有序的。</span><br><span class="line">        HashMap&lt;Integer, String&gt; h = new HashMap&lt;&gt;();</span><br><span class="line">        //public V put(K key, V value) 给key:value放入字典中</span><br><span class="line">        h.put(1, "Momday");</span><br><span class="line">        h.put(2, "Tuesday");</span><br><span class="line">        h.put(3, "Wenesday");</span><br><span class="line"></span><br><span class="line">        System.out.println("初始时字典h：");</span><br><span class="line">        print(h);</span><br><span class="line"></span><br><span class="line">        //public int size() 查看字典的大小</span><br><span class="line">        System.out.println("字典h的大小为：" + h.size());</span><br><span class="line"></span><br><span class="line">        //当插入的键值对的key已经存在于字典中，如果值不同，则会覆盖之前的值。</span><br><span class="line">        h.put(1, "Monday");</span><br><span class="line">        //public V replace(K key, V value) 将键对应的值进行修改。</span><br><span class="line">        h.replace(3, "wednesday");</span><br><span class="line">        System.out.print("修改后字典h：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public boolean containsKey(Object key) 查看字典中是否包含key</span><br><span class="line">        System.out.println("字典h的key是否包含4：" + h.containsKey(4));</span><br><span class="line"></span><br><span class="line">        //public boolean containsValue(Object value) 查看字典中是否包含value</span><br><span class="line">        System.out.println("字典h的value是否包含星期二：" + h.containsValue("Tuesday"));</span><br><span class="line"></span><br><span class="line">        //public V get(Object key) 获取字典中key对应的value</span><br><span class="line">        System.out.print("星期三的英文单词是：" + h.get(3));</span><br><span class="line"></span><br><span class="line">        //public V getOrDefault(Object key, V defaultValue) 获取字典中key对应的value，如果没有则返回默认value</span><br><span class="line">        System.out.print("星期四的英文单词是：" + h.getOrDefault(4, "Thursday"));</span><br><span class="line"></span><br><span class="line">        //public boolean remove(Object key, Object value) 移除字典中键值对，如果不存在则不移除。</span><br><span class="line">        System.out.print("字典h删除3:Wenesday是否成功：" + h.remove(3, "Wenesday"));</span><br><span class="line">        </span><br><span class="line">        //public V remove(Object key) 移除字典中key对应的键值对，如果不存在则不移除。</span><br><span class="line">        h.remove(3);</span><br><span class="line">        System.out.print("删除星期三的单词后字典h：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public Set&lt;K&gt; keySet() 获取字典中key的Set集合</span><br><span class="line">        Set&lt;Integer&gt; hKey = h.keySet();</span><br><span class="line">        System.out.print("字典h的key：");</span><br><span class="line">        System.out.println(hKey);</span><br><span class="line"></span><br><span class="line">        //public Collection&lt;V&gt; values() 获取字典中value的Collection集合</span><br><span class="line">        Collection&lt;String&gt; hValue = h.values();</span><br><span class="line">        System.out.print("字典h的value：");</span><br><span class="line">        System.out.println(hValue);</span><br><span class="line"></span><br><span class="line">        //public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() 获取字典中的键值对的Set集合，其中每一个对象是一个Map.Entry&lt;K,V&gt;类型</span><br><span class="line">        Set&lt;Map.Entry&lt;Integer, String&gt;&gt; e = h.entrySet();</span><br><span class="line">        System.out.print("字典h的key &amp; value：");</span><br><span class="line">        System.out.println(e);</span><br><span class="line">        </span><br><span class="line">        HashMap&lt;Integer, String&gt; h1 = new HashMap&lt;&gt;();</span><br><span class="line">        h1.put(3, "Wednesday");</span><br><span class="line">        h1.put(4, "Thursday");</span><br><span class="line">        h1.put(5, "Friday");</span><br><span class="line">        System.out.print("初始时字典h1：");</span><br><span class="line">        System.out.println(h1);</span><br><span class="line">        </span><br><span class="line">        //public void putAll(Map&lt;? extends K, ? extends V&gt; m) 将字典m合并到当前字典中，重复key对应的value会被替换</span><br><span class="line">        h.putAll(h1);</span><br><span class="line">        System.out.print("h合并h1后：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public void clear()  清空字典</span><br><span class="line">        h.clear();</span><br><span class="line">        System.out.print("移除所有元素后，字典h：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public boolean isEmpty() 判断字典是否为空</span><br><span class="line">        System.out.println("字典h是否为空：" + h.isEmpty());</span><br><span class="line">        System.out.println("字典h的大小为：" + h.size());</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java74.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  字典无法通过索引下标进行遍历。使用字典时，只要记住4个重要的函数put，remove，containsKey，get即可。常常在数组中出现，如统计每一个元素出现的次数，遇到新元素时加入字典中，遇到旧元素，则对应的value加1即可，非常方便。到目前位置Java中常用的一些集合类就讲完了，一些特定场景使用的类需要小伙伴们在刷题的时候多多总结和积累，再次强调的是，编程是一门实践课程而不是理论课，要想真正的提高，一定要多加训练。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>最大间距(Leetcode 164)</title>
    <url>/2021/01/04/program%20Leetcode164/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode164.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   本题的难点在于如何在线性的时间复杂度和空间复杂度下完成此题。<br><a id="more"></a></p>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a><font size="5" color="red">排序</font></h1><p>最朴素的方法是将数组进行排序，然后遍历一次数组，求出最大间距</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int maximumGap(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        sort(nums.begin(), nums.end());</span><br><span class="line">        int res = 0;</span><br><span class="line">        for (int i = 1; i &lt; nums.size(); i++) res = max(res, nums[i] - nums[i - 1]);</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="桶排序思想"><a href="#桶排序思想" class="headerlink" title="桶排序思想"></a><font size="5" color="red">桶排序思想</font></h1><p>上面的排序算法可以用其他的任意排序方法代替，相关的知识可以参考Leetcode912题相关博客。</p>
<p>这里直接介绍一种不用排序，只利用桶排序思想的一种解题技巧。</p>
<p>我们先明白一个数学原理，n个数，最大值为maxi，最小值为mini，且n个数都为整数，那么它们之间的最大间距至少为</p>
<script type="math/tex; mode=display">\frac{maxi - mini}{n}</script><p><strong>因此我们可以建立n + 1个桶，桶的间距为$\frac{maxi - mini}{n}$，多出的一个桶是保证边缘的安全性。那么间距最大的两个数一定位于两个不同的桶之中。这样每个桶就不需要存放所有的元素，只需要记录每个桶元素的最大值和最小值。那么间距一定是第m个桶的最大值和第n个桶的最小值之差，其中n&gt;m，并且n和m之间有且仅有空桶</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int maximumGap(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        if (nums.size() &lt; 2) return 0;</span><br><span class="line">        pair&lt;vector&lt;int&gt;::iterator, vector&lt;int&gt;::iterator&gt; minMax = minmax_element(nums.begin(), nums.end());</span><br><span class="line">        int mini = *minMax.first, maxi = *minMax.second;</span><br><span class="line">        if (mini == maxi) return 0;</span><br><span class="line">        int bucketsNum = nums.size() + 1;</span><br><span class="line">        double bucketsSize = double(maxi - mini) / (bucketsNum - 1);</span><br><span class="line">        vector&lt;pair&lt;int, int&gt;&gt; buckets(bucketsNum, {-1, -1});</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            int idx = (x - mini) / bucketsSize;</span><br><span class="line">            if (buckets[idx].first == -1) {</span><br><span class="line">                buckets[idx] = { x, x };</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                buckets[idx].first = min(buckets[idx].first, x);</span><br><span class="line">                buckets[idx].second = max(buckets[idx].second, x);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        int pre = -1, res = 0;</span><br><span class="line">        for (auto x : buckets) {</span><br><span class="line">            if (x.first == -1) continue;</span><br><span class="line">            if (pre != -1) res = max(res, x.first - pre);</span><br><span class="line">            pre = x.second;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目的思想非常好，按照桶排序来求解，思路非常相似，但是桶排序需要对每个桶进行单独排序，在这个算法中我们不需要知道桶内元素的具体顺序，而是只考虑桶和桶之间的差异即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>排序</category>
      </categories>
  </entry>
  <entry>
    <title>Java常用类(HashSet)</title>
    <url>/2021/01/03/Java_hashSet/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java71.png" alt="2"></p>
<h1 id="Java常用类-HashSet"><a href="#Java常用类-HashSet" class="headerlink" title="Java常用类(HashSet)"></a><font size="5" color="red">Java常用类(HashSet)</font></h1><p>  今天给小伙伴们介绍HashSet类，HashSet是Java专门用于处理哈希表的类，和C++或者Python中的set相同。其特点是不允许存储重复元素，无序，无法索引，因此无法使用普通的for循环，查询速度特别快。在Java中也内置了许多常用的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="HashSet类"><a href="#HashSet类" class="headerlink" title="HashSet类"></a><font size="5">HashSet类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.util.HashSet;</span><br><span class="line"></span><br><span class="line">public class HashSetClass {</span><br><span class="line"></span><br><span class="line">    public static void print(HashSet&lt;Integer&gt; h) {</span><br><span class="line">        for (int i: h) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //注意：如果想用HashSet存储自定义类型，需要重写对象中的hashCode方法和equals方法。</span><br><span class="line">        //因为HashSet的存储过程是先比较HashCode是否已经存在，如果没有存在则可以将元素加入，否则发生了哈希冲突，即多个不同的元素具有相同的HashCode，这样将这些元素和要加入的元素进行equals比较，如果不相同，则可以加入，否则不能将元素加入。</span><br><span class="line">        //还可以创建LinkedHashSet类型，和HashSet几乎相同，但是LinkedHashSet底层是一个链表和一个哈希表，链表的作用是记录元素第一次出现的位置，因此元素是有序的。</span><br><span class="line">        HashSet&lt;Integer&gt; h = new HashSet&lt;&gt;();</span><br><span class="line">        //boolean addAll(Collection&lt;? extends E&gt; c) 将集合中的元素添加到哈希表中</span><br><span class="line">        //public boolean add(E e) 向哈希表中添加元素，因为无序，所以没有public void add(int index, E element)方法。</span><br><span class="line">        h.add(10);</span><br><span class="line">        h.add(20);</span><br><span class="line"></span><br><span class="line">        System.out.print("初始时哈希表h：");</span><br><span class="line">        print(h);</span><br><span class="line"></span><br><span class="line">        //public int size() 查看哈希表的大小</span><br><span class="line">        System.out.println("哈希表h的大小为：" + h.size());</span><br><span class="line"></span><br><span class="line">        h.add(10);</span><br><span class="line">        h.add(30);</span><br><span class="line">        System.out.print("添加10和30两个元素时哈希表h：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public boolean contains(Object o) 查看哈希表中是否存在元素</span><br><span class="line">        System.out.println("哈希表h是否包含元素20：" + h.contains(20));</span><br><span class="line">        System.out.println("哈希表h是否包含元素40：" + h.contains(40));</span><br><span class="line"></span><br><span class="line">        //public Object[] toArray()  将哈希表元素转换为数组</span><br><span class="line">        Object[] array = h.toArray();</span><br><span class="line">        System.out.print("将哈希表转换为普通数组array：");</span><br><span class="line">        for (Object i: array) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        //public boolean remove(Object o) 从哈希表中移除指定元素</span><br><span class="line">        h.remove(20);</span><br><span class="line">        System.out.print("移除20，哈希表h：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public void clear()  清空哈希表</span><br><span class="line">        h.clear();</span><br><span class="line">        System.out.print("移除所有元素后，哈希表h：");</span><br><span class="line">        System.out.println(h);</span><br><span class="line"></span><br><span class="line">        //public boolean isEmpty() 判断哈希表是否为空</span><br><span class="line">        System.out.println("哈希表h是否为空：" + h.isEmpty());</span><br><span class="line">        System.out.println("哈希表h的大小为：" + h.size());</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java73.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  哈希表没有getFirst和getLast方法，也无法通过索引进行遍历。使用哈希表时，只要记住4个重要的函数即可，add，remove，size，foreach(增强for)。常常在BFS或者DFS或者数组中出现，如搜索时，该点已经搜索完成，则可以将其加入哈希表，下次查到该点时则可以不再进行查找，节约大量的时间，因此小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>Java常用类(LinkedList)</title>
    <url>/2021/01/01/Java_linkedList/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java69.png" alt="2"></p>
<h1 id="Java常用类-LinkedList"><a href="#Java常用类-LinkedList" class="headerlink" title="Java常用类(LinkedList)"></a><font size="5" color="red">Java常用类(LinkedList)</font></h1><p>  今天给小伙伴们介绍LinkedList类，LinkedList是Java专门用于处理链表的类，和前面说的ArrayList都是List的实现类，但是ArrayList的底层存储方式是数组，因此查询快，可以通过地址移动直接进行查找，但是要增删元素就很慢，需要大量的移动元素。而LinkedList的底层存储方式是链表，因此查询很慢，需要一个一个比较查找，但是增删元素非常快，只需要修改链表的指向即可。因此模拟队列时常常使用，也是小伙伴们必须掌握的数据结构。<br><a id="more"></a></p>
<h1 id="LinkedList类"><a href="#LinkedList类" class="headerlink" title="LinkedList类"></a><font size="5">LinkedList类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.Comparator;</span><br><span class="line">import java.util.LinkedList;</span><br><span class="line">import java.util.function.Predicate;</span><br><span class="line"></span><br><span class="line">public class LinkedListClass {</span><br><span class="line">    public static void print(LinkedList&lt;Integer&gt; l) {</span><br><span class="line">        for (int i: l) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line">    }</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        LinkedList&lt;Integer&gt; l = new LinkedList&lt;&gt;();</span><br><span class="line">        //public boolean addAll(Collection&lt;? extends E&gt; c) 将集合c中的元素加入到原集合中</span><br><span class="line">        //public boolean addAll(int index, Collection&lt;? extends E&gt; c) 在指定位置处将集合c中的元素加入到原集合中</span><br><span class="line">        //public boolean add(E e) 向链表尾部添加元素</span><br><span class="line">        //public void add(int index, E element) 在指定位置处添加元素</span><br><span class="line">        l.add(20);</span><br><span class="line">        l.add(0, 10);</span><br><span class="line">        l.add(30);</span><br><span class="line"></span><br><span class="line">        System.out.print("初始时链表l：");</span><br><span class="line">        print(l);</span><br><span class="line"></span><br><span class="line">        //public int size() 查看链表的大小</span><br><span class="line">        System.out.println("链表l的大小为：" + l.size());</span><br><span class="line"></span><br><span class="line">        //public boolean contains(Object o) 查看链表中是否存在元素</span><br><span class="line">        System.out.println("链表l是否包含元素20：" + l.contains(20));</span><br><span class="line">        System.out.println("链表l是否包含元素40：" + l.contains(40));</span><br><span class="line"></span><br><span class="line">        //public E get(int index)  获取链表对应索引元素</span><br><span class="line">        System.out.println("链表l中索引为1的元素是：" + l.get(1));</span><br><span class="line"></span><br><span class="line">        //public int indexOf(Object o) 从初始位置开始查找元素对应的索引</span><br><span class="line">        System.out.println("链表l中第一个元素10的索引为：" + l.indexOf(10));</span><br><span class="line">        //public int lastIndexOf(Object o)  从最后位置开始向前查找元素对应的索引</span><br><span class="line">        System.out.println("链表l中最后一个元素20的索引为：" + l.lastIndexOf(20));</span><br><span class="line"></span><br><span class="line">        //public void addFirst(E e)   向链表头部添加元素</span><br><span class="line">        l.addFirst(0);</span><br><span class="line">        System.out.print("在链表l头部添加元素0：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public void addLast(E e)    向链表尾部添加元素</span><br><span class="line">        l.addLast(40);</span><br><span class="line">        System.out.print("在链表l尾部添加元素40：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public E getFirst() 获取链表头部元素</span><br><span class="line">        System.out.println("查看链表l的头部元素：" + l.getFirst());</span><br><span class="line"></span><br><span class="line">        //public E getLast() 获取链表尾部元素</span><br><span class="line">        System.out.println("查看链表l的尾部元素：" + l.getLast());</span><br><span class="line"></span><br><span class="line">        //public E removeFirst()     移除链表头部元素</span><br><span class="line">        l.removeFirst();</span><br><span class="line">        System.out.print("移除链表l头部元素：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public E removeLast()     移除链表尾部元素</span><br><span class="line">        l.removeLast();</span><br><span class="line">        System.out.print("移除链表l尾部元素：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public E set(int index, E element)  修改链表指定位置元素</span><br><span class="line">        l.set(1, 15);</span><br><span class="line">        System.out.print("将索引1处改为15时，链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public Object[] toArray()  将链表元素转换为数组</span><br><span class="line">        Object[] array = l.toArray();</span><br><span class="line">        System.out.print("将链表转换为普通数组array：");</span><br><span class="line">        for (Object i: array) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        //default boolean removeIf(Predicate&lt;? super E&gt; filter) 移除所有符合条件的元素，需要创建谓词对象</span><br><span class="line">        l.removeIf(new Predicate&lt;Integer&gt;() {</span><br><span class="line">            @Override</span><br><span class="line">            public boolean test(Integer integer) {</span><br><span class="line">                return integer == 10;</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line">        System.out.print("移除10时，链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public E remove(int index) 移除链表指定索引元素</span><br><span class="line">        l.remove(1);</span><br><span class="line">        System.out.print("移除索引1的元素，链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public void clear()  清空链表</span><br><span class="line">        l.clear();</span><br><span class="line">        System.out.print("移除所有元素后，链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public boolean isEmpty() 判断链表是否为空</span><br><span class="line">        System.out.println("链表l是否为空：" + l.isEmpty());</span><br><span class="line">        System.out.println("链表l的大小为：" + l.size());</span><br><span class="line"></span><br><span class="line">        //public static &lt;T&gt; boolean addAll(Collection&lt;? super T&gt; c, T... elements) Collections静态方法，向集合中添加元素</span><br><span class="line">        Collections.addAll(l, 20, 10, 40, 30);</span><br><span class="line">        System.out.print("添加元素后链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public synchronized void sort(Comparator&lt;? super E&gt; c) 对链表进行排序，排序规则要创建比较器对象</span><br><span class="line">        l.sort(new Comparator&lt;Integer&gt;() {</span><br><span class="line">            @Override</span><br><span class="line">            public int compare(Integer o1, Integer o2) {</span><br><span class="line">                return o1 - o2;</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line">        System.out.print("从小到大排序后链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line"></span><br><span class="line">        //public static void shuffle(List&lt;?&gt; list)  打乱链表中的元素</span><br><span class="line">        Collections.shuffle(l);</span><br><span class="line">        System.out.print("打乱元素后链表l：");</span><br><span class="line">        System.out.println(l);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java70.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  当然了LinkedList的相关操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是addFirst，addLast，getFirst，getLast，removeFirst，removeLast这些操作，是区别于ArrayList类的关键，希望小伙伴们可以牢记。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>Java常用类(ArrayList)</title>
    <url>/2020/12/31/Java_arrayList/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java67.png" alt="2"></p>
<h1 id="Java常用类-ArrayList"><a href="#Java常用类-ArrayList" class="headerlink" title="Java常用类(ArrayList)"></a><font size="5" color="red">Java常用类(ArrayList)</font></h1><p>  今天给小伙伴们介绍ArrayList类，ArrayList也是Java专门用于处理动态数组的类，和Vector基本相同，都是List接口的实现类，具有大量相似的成员方法。但是区别是Vector是同步单线程的，而ArrayList是多线程的，推荐使用ArrayList。<br><a id="more"></a></p>
<h1 id="ArrayList类"><a href="#ArrayList类" class="headerlink" title="ArrayList类"></a><font size="5">ArrayList类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.Comparator;</span><br><span class="line">import java.util.function.Predicate;</span><br><span class="line"></span><br><span class="line">public class ArrayListClass {</span><br><span class="line"></span><br><span class="line">    public static void print(ArrayList&lt;Integer&gt; a) {</span><br><span class="line">        for (int i: a) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line">    }</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        ArrayList&lt;Integer&gt; a = new ArrayList&lt;&gt;();</span><br><span class="line">        //public boolean addAll(Collection&lt;? extends E&gt; c) 将集合c中的元素加入到原集合中</span><br><span class="line">        //public boolean addAll(int index, Collection&lt;? extends E&gt; c) 在指定位置处将集合c中的元素加入到原集合中</span><br><span class="line">        //public boolean add(E e) 向动态数组尾部添加元素</span><br><span class="line">        //public void add(int index, E element) 在指定位置处添加元素</span><br><span class="line">        a.add(20);</span><br><span class="line">        a.add(0, 10);</span><br><span class="line">        a.add(30);</span><br><span class="line"></span><br><span class="line">        System.out.print("初始时动态数组a：");</span><br><span class="line">        print(a);</span><br><span class="line"></span><br><span class="line">        //public int size() 查看动态数组的大小</span><br><span class="line">        System.out.println("动态数组a的大小为：" + a.size());</span><br><span class="line"></span><br><span class="line">        //public boolean contains(Object o) 查看动态数组中是否存在元素</span><br><span class="line">        System.out.println("动态数组a是否包含元素20：" + a.contains(20));</span><br><span class="line">        System.out.println("动态数组a是否包含元素40：" + a.contains(40));</span><br><span class="line"></span><br><span class="line">        //public E get(int index)  获取动态数组对应索引元素</span><br><span class="line">        System.out.println("动态数组a中索引为1的元素是：" + a.get(1));</span><br><span class="line"></span><br><span class="line">        //public int indexOf(Object o) 从初始位置开始查找元素对应的索引</span><br><span class="line">        System.out.println("动态数组a中第一个元素10的索引为：" + a.indexOf(10));</span><br><span class="line">        //public int lastIndexOf(Object o)  从最后位置开始向前查找元素对应的索引</span><br><span class="line">        System.out.println("动态数组a中最后一个元素20的索引为：" + a.lastIndexOf(20));</span><br><span class="line"></span><br><span class="line">        //public E set(int index, E element)  修改动态数组指定位置元素</span><br><span class="line">        a.set(1, 15);</span><br><span class="line">        System.out.print("将索引1处改为15时，动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line"></span><br><span class="line">        //public Object[] toArray()  将动态数组元素转换为数组</span><br><span class="line">        Object[] array = a.toArray();</span><br><span class="line">        System.out.print("将动态数组转换为普通数组array：");</span><br><span class="line">        for (Object i: array) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        //public boolean removeIf(Predicate&lt;? super E&gt; filter) 移除所有符合条件的元素，需要创建谓词对象</span><br><span class="line">        a.removeIf(new Predicate&lt;Integer&gt;() {</span><br><span class="line">            @Override</span><br><span class="line">            public boolean test(Integer integer) {</span><br><span class="line">                return integer == 10;</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line">        System.out.print("移除10时，动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line"></span><br><span class="line">        //public E remove(int index) 移除动态数组指定索引元素</span><br><span class="line">        a.remove(1);</span><br><span class="line">        System.out.print("移除索引1的元素，动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line"></span><br><span class="line">        //public void clear()  清空动态数组</span><br><span class="line">        a.clear();</span><br><span class="line">        System.out.print("移除所有元素后，动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line"></span><br><span class="line">        //public boolean isEmpty() 判断动态数组是否为空</span><br><span class="line">        System.out.println("动态数组a是否为空：" + a.isEmpty());</span><br><span class="line">        System.out.println("动态数组a的大小为：" + a.size());</span><br><span class="line"></span><br><span class="line">        //public static &lt;T&gt; boolean addAll(Collection&lt;? super T&gt; c, T... elements) Collections静态方法，向集合中添加元素</span><br><span class="line">        Collections.addAll(a, 20, 10, 40, 30);</span><br><span class="line">        System.out.print("添加元素后动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line"></span><br><span class="line">        //public synchronized void sort(Comparator&lt;? super E&gt; c) 对动态数组进行排序，排序规则要创建比较器对象</span><br><span class="line">        a.sort(new Comparator&lt;Integer&gt;() {</span><br><span class="line">            @Override</span><br><span class="line">            public int compare(Integer o1, Integer o2) {</span><br><span class="line">                return o1 - o2;</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line">        System.out.print("从小到大排序后动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line"></span><br><span class="line">        //public static void shuffle(List&lt;?&gt; list)  打乱动态数组中的元素</span><br><span class="line">        Collections.shuffle(a);</span><br><span class="line">        System.out.print("打乱元素后动态数组a：");</span><br><span class="line">        System.out.println(a);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java68.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  当然了ArrayList的相关操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是isEmpty，size，add，contains，get，indexOf索引和遍历这些操作，是笔试，面试中的重中之重，因为Vector是同步的，在Vector方法中有synchronized关键字，因此会影响性能，我们尽量使用ArrayList类，更加高效。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>计算器(Leetcode 程序员面试金典16.26)</title>
    <url>/2020/12/30/program%20Leetcode_interview16.26/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview16_26.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   计算器这个题目是经典的栈问题，在学习数据结构时，堆栈的重要应用场景就是实现复杂的数学运算。<br><a id="more"></a></p>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p><strong>在本题没有括号的情况下，出现符号时记录运算操作，出现数字时，查看运算操作，如果是乘除法，则优先级最高，需要立即运算，因此从栈中弹出栈顶元素，与该数字进行操作，并将运算的结果作为新数字压入栈中。如果是加法则直接入栈，如果是减法则取相反数后入栈。最后按照顺序将栈中的所有元素相加即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int calculate(string s) {</span><br><span class="line">        vector&lt;int&gt; stack;</span><br><span class="line">        int length = s.size(), idx = 0, sign = 0, res = 0;</span><br><span class="line">        while (idx &lt; length) {</span><br><span class="line">            if (s[idx] &gt;= '0' &amp;&amp; s[idx] &lt;= '9') {</span><br><span class="line">                int tmp = s[idx] - '0';</span><br><span class="line">                while (idx + 1 &lt; length &amp;&amp; s[idx + 1] &gt;= '0' &amp;&amp; s[idx + 1] &lt;= '9') tmp = tmp * 10 + (s[++idx] - '0');</span><br><span class="line">                if (sign == 0) stack.push_back(tmp);</span><br><span class="line">                else if (sign == 1) stack.push_back(-tmp);</span><br><span class="line">                else if (sign == 2) stack[stack.size() - 1] *= tmp;</span><br><span class="line">                else stack[stack.size() - 1] /= tmp;</span><br><span class="line">            }</span><br><span class="line">            else if (s[idx] != ' ') {</span><br><span class="line">                if (s[idx] == '+') sign = 0;</span><br><span class="line">                else if (s[idx] == '-') sign = 1;</span><br><span class="line">                else if (s[idx] == '*') sign = 2;</span><br><span class="line">                else sign = 3;</span><br><span class="line">            }</span><br><span class="line">            idx++;</span><br><span class="line">        }</span><br><span class="line">        for (auto x : stack) res += x;</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  栈类型的题目是非常经典的，栈也是应用非常广泛的数据结构，在笔试面试中都经常出现，希望大家能够注意类似的题目。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
      </categories>
  </entry>
  <entry>
    <title>Java常用类(Vector)</title>
    <url>/2020/12/29/Java_vector/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java66.png" alt="2"></p>
<h1 id="Java常用类-Vector"><a href="#Java常用类-Vector" class="headerlink" title="Java常用类(Vector)"></a><font size="5" color="red">Java常用类(Vector)</font></h1><p>  今天给小伙伴们介绍Vector类，Vector是Java专门用于处理动态数组的类，和C++中的vector容器相同。里面也内置了许多常用的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="Vector类"><a href="#Vector类" class="headerlink" title="Vector类"></a><font size="5">Vector类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.Comparator;</span><br><span class="line">import java.util.Vector;</span><br><span class="line"></span><br><span class="line">public class VectorClass {</span><br><span class="line"></span><br><span class="line">    //foreach循环，是一种简单的增强for循环，格式是for(类型名 变量名: 数组/集合)，意思是逐一从数组或者集合中取出元素赋值给变量</span><br><span class="line">    public static void print(Vector&lt;Integer&gt; v) {</span><br><span class="line">        for (int i: v) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line">    }</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Vector&lt;Integer&gt; v = new Vector&lt;&gt;();</span><br><span class="line">        //public boolean addAll(Collection&lt;? extends E&gt; c) 将集合c中的元素加入到原集合中</span><br><span class="line">        //public boolean addAll(int index, Collection&lt;? extends E&gt; c) 在指定位置处将集合c中的元素加入到原集合中</span><br><span class="line">        //public synchronized boolean add(E e) 向动态数组尾部添加元素</span><br><span class="line">        //public void add(int index, E element)  在指定位置处添加元素</span><br><span class="line">        v.add(20);</span><br><span class="line">        v.add(0, 10);</span><br><span class="line">        v.add(30);</span><br><span class="line">        System.out.print("初始时动态数组v：");</span><br><span class="line">        print(v);</span><br><span class="line"></span><br><span class="line">        //public synchronized int capacity() 查看动态数组的容量</span><br><span class="line">        System.out.println("动态数组v的容量为：" + v.capacity());</span><br><span class="line">        //public synchronized int size()  查看动态数组的大小</span><br><span class="line">        System.out.println("动态数组v的大小为：" + v.size());</span><br><span class="line"></span><br><span class="line">        //public boolean contains(Object o)  查看动态数组中是否存在元素</span><br><span class="line">        System.out.println("动态数组v是否包含元素20：" + v.contains(20));</span><br><span class="line">        System.out.println("动态数组v是否包含元素40：" + v.contains(40));</span><br><span class="line"></span><br><span class="line">        //public synchronized E get(int index)  获取动态数组对应索引元素</span><br><span class="line">        System.out.println("动态数组v中索引为1的元素是：" + v.get(1));</span><br><span class="line"></span><br><span class="line">        //public int indexOf(Object o) 从初始位置开始查找元素对应的索引</span><br><span class="line">        System.out.println("动态数组v中第一个元素10的索引为：" + v.indexOf(10));</span><br><span class="line">        //public synchronized int indexOf(Object o, int index) 从指定位置开始查找元素对应的索引</span><br><span class="line">        System.out.println("动态数组v中从索引1开始查找的第一个元素10的索引为：" + v.indexOf(10, 1));</span><br><span class="line"></span><br><span class="line">        //public synchronized int lastIndexOf(Object o) 从最后位置开始向前查找元素对应的索引</span><br><span class="line">        System.out.println("动态数组v中最后一个元素20的索引为：" + v.lastIndexOf(20));</span><br><span class="line">        //public synchronized int lastIndexOf(Object o, int index) 从指定位置开始向前查找元素对应的索引</span><br><span class="line">        System.out.println("动态数组v中从索引0开始查找最后一个元素20的索引为：" + v.lastIndexOf(20, 0));</span><br><span class="line"></span><br><span class="line">        //public synchronized E firstElement() 获取动态数组第一个元素</span><br><span class="line">        System.out.println("动态数组v中第一个元素是：" + v.firstElement());</span><br><span class="line">        //public synchronized E lastElement()  获取动态数组最后一个元素</span><br><span class="line">        System.out.println("动态数组v中最后一个元素是：" + v.lastElement());</span><br><span class="line"></span><br><span class="line">        //public synchronized E set(int index, E element) 修改动态数组指定位置元素</span><br><span class="line">        v.set(1, 15);</span><br><span class="line">        System.out.print("将索引1处改为15时，动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line"></span><br><span class="line">        //public synchronized Object[] toArray()  将动态数组元素转换为数组</span><br><span class="line">        Object[] array = v.toArray();</span><br><span class="line">        System.out.print("将动态数组转换为普通数组array：");</span><br><span class="line">        for (Object i: array) {</span><br><span class="line">            System.out.print(i + " ");</span><br><span class="line">        }</span><br><span class="line">        System.out.println();</span><br><span class="line"></span><br><span class="line">        //public synchronized boolean removeElement(Object obj) 移除动态数组指定元素</span><br><span class="line">        v.removeElement(10);</span><br><span class="line">        System.out.print("移除10时，动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line"></span><br><span class="line">        //public synchronized E remove(int index)  移除动态数组指定索引元素</span><br><span class="line">        v.remove(1);</span><br><span class="line">        System.out.print("移除索引1的元素，动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line"></span><br><span class="line">        //public void clear()  清空动态数组</span><br><span class="line">        v.clear();</span><br><span class="line">        System.out.print("移除所有元素后，动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line"></span><br><span class="line">        //public synchronized boolean isEmpty()  判断动态数组是否为空</span><br><span class="line">        System.out.println("动态数组v是否为空：" + v.isEmpty());</span><br><span class="line">        System.out.println("动态数组v的容量为：" + v.capacity());</span><br><span class="line">        System.out.println("动态数组v的大小为：" + v.size());</span><br><span class="line"></span><br><span class="line">        //public static &lt;T&gt; boolean addAll(Collection&lt;? super T&gt; c, T... elements) Collections静态方法，向集合中添加元素</span><br><span class="line">        Collections.addAll(v, 20, 10, 40, 30);</span><br><span class="line">        System.out.print("添加元素后动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line"></span><br><span class="line">        //public synchronized void sort(Comparator&lt;? super E&gt; c) 对动态数组进行排序，排序规则要创建比较器对象</span><br><span class="line">        v.sort(new Comparator&lt;Integer&gt;() {</span><br><span class="line">            @Override</span><br><span class="line">            public int compare(Integer o1, Integer o2) {</span><br><span class="line">                return o1 - o2;</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line">        System.out.print("从小到大排序后动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line"></span><br><span class="line">        //public static void shuffle(List&lt;?&gt; list)  打乱动态数组中的元素</span><br><span class="line">        Collections.shuffle(v);</span><br><span class="line">        System.out.print("打乱元素后动态数组v：");</span><br><span class="line">        System.out.println(v);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java65.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  当然了Vector的相关操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是isEmpty，size，add，contains，get，indexOf索引和遍历这些操作，是笔试，面试中的重中之重，有了Vector容器，使得我们写代码时更加方便，请小伙伴们务必放在心上。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>单词转换(Leetcode 程序员面试金典17.22)</title>
    <url>/2020/12/28/program%20Leetcode_interview17.22/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_22.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目在前几天讲解过，是Leetcode126和Leetcode127题的姐妹题，当时讲解的是第127题求最短的转换序列长度，当时的最优算法是BFS，原因也经常叙述了，找到最近的一条就是BFS，找到任意一条就是DFS，在这里是求任意一条，因此最优解也非常明显，小伙伴们先尝试去做。<br><a id="more"></a></p>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>当列表单词很多的时候，我们可以枚举单词的位置，枚举每个位置的字符，假如有字典中10000个单词，每个单词长度为10。如果我们逐一和所有单词比较是否相差一个字符，就需要10000次比较，如果只是枚举长度和可能出现的单词，只需要枚举10*26=260次。这个技巧在处理字符串问题时非常重要，希望小伙伴们务必掌握它。</p>
<p>我们对单词列表进行深搜，当搜索到了则返回true，否则将该点加入visited并且返回false。加入visited的目的是剪枝，防止通过其他的路径再次到达该点进行搜索。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(mn)$，其中n为字典中单词的个数，m为每个单词的长度</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;set&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; findLadders(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) {</span><br><span class="line">        vector&lt;string&gt; cur = { beginWord };</span><br><span class="line">        set&lt;string&gt; path = {beginWord}, newWords, visited;</span><br><span class="line">        for (string s : wordList) if (s.size() == beginWord.size()) newWords.insert(s);</span><br><span class="line">        if (dfs(cur, path, newWords, endWord, visited)) return cur;</span><br><span class="line">        return vector&lt;string&gt;();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool dfs(vector&lt;string&gt;&amp; cur, set&lt;string&gt;&amp; path, set&lt;string&gt;&amp; newWords, string endWord, set&lt;string&gt;&amp; visited) {</span><br><span class="line">        if (cur.back() == endWord) {</span><br><span class="line">            return true;</span><br><span class="line">        }</span><br><span class="line">        if (visited.count(cur.back())) return false;</span><br><span class="line">        for (int i = 0; i &lt; cur[0].size(); i++) {</span><br><span class="line">            string curString = cur.back();</span><br><span class="line">            for (int j = 0; j &lt; 26; j++) {</span><br><span class="line">                curString[i] = 'a' + j;</span><br><span class="line">                if (newWords.count(curString) &amp;&amp; !path.count(curString)) {</span><br><span class="line">                    cur.push_back(curString);</span><br><span class="line">                    path.insert(curString);</span><br><span class="line">                    if (dfs(cur, path, newWords, endWord, visited)) return true;</span><br><span class="line">                    visited.insert(curString);</span><br><span class="line">                    cur.pop_back();</span><br><span class="line">                    path.erase(curString);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>我们对单词列表进行广搜，当搜索到了直接return即可，否则将该点加入visited并且继续搜索。加入visited的目的也是剪枝，防止通过其他的路径再次到达该点进行搜索。</p>
<p>我在这个算法中每一次搜索都保存了所有的路径，因此空间复杂度为$O(mn^2)$。</p>
<p>可以使用哈希表记录最先到达某点的路径，这样可以追溯求出路径，这样只适合于求最短路径，并不是这类问题的通解。如果要求出所有路径，就无法做到了。所有有兴趣的小伙伴可以尝试去做。</p>
<p>算法的<strong>时间复杂度为$O(mn^2)$，空间复杂度为$O(mn)$，其中n为字典中单词的个数，m为每个单词的长度</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line">#include&lt;set&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; findLadders(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) {</span><br><span class="line">        deque&lt;vector&lt;string&gt;&gt; queue = { { beginWord } };</span><br><span class="line">        set&lt;string&gt; visited = { beginWord }, newWords;</span><br><span class="line">        for (string s : wordList) if (s.size() == beginWord.size()) newWords.insert(s);</span><br><span class="line">        while (!queue.empty()) {</span><br><span class="line">            vector&lt;string&gt; cur = queue.front();</span><br><span class="line">            queue.pop_front();</span><br><span class="line">            for (int i = 0; i &lt; cur[0].size(); i++) {</span><br><span class="line">                string curString = cur.back();</span><br><span class="line">                for (int j = 0; j &lt; 26; j++) {</span><br><span class="line">                    curString[i] = 'a' + j;</span><br><span class="line">                    if (newWords.count(curString) &amp;&amp; !visited.count(curString)) {</span><br><span class="line">                        cur.push_back(curString);</span><br><span class="line">                        visited.insert(curString);</span><br><span class="line">                        if (curString == endWord) return cur;</span><br><span class="line">                        queue.push_back(cur);</span><br><span class="line">                        cur.pop_back();</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return vector&lt;string&gt;();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  搜索类的题目在面试中遇到的并不多，但是在笔试中是非常非常重要的考点，希望小伙伴们可以加强练习，认真准备，争取笔试全AC。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>字符串</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>Java常用类(String)</title>
    <url>/2020/12/27/Java_string/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java63.png" alt="2"></p>
<h1 id="Java常用类-String"><a href="#Java常用类-String" class="headerlink" title="Java常用类(String)"></a><font size="5" color="red">Java常用类(String)</font></h1><p>  今天给小伙伴们介绍String类，String库是Java专门用于处理字符串的类，里面内置了许多字符串的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="String类"><a href="#String类" class="headerlink" title="String类"></a><font size="5">String类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class StringClass {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //String类型创建可以通过字符数组进行创建</span><br><span class="line">        char[] chars = new char[] {'h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd', '!'};</span><br><span class="line">        String s1 = new String(chars);</span><br><span class="line">        //String类型创建可以通过字节数组进行创建</span><br><span class="line">        byte[] bytes = new byte[] {104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33};</span><br><span class="line">        String s2 = new String(bytes);</span><br><span class="line">        //String类型创建可以通过双引号直接创建</span><br><span class="line">        String s3 = "Hello world!";</span><br><span class="line"></span><br><span class="line">        System.out.println("s1:" + s1);</span><br><span class="line">        System.out.println("s2:" + s2);</span><br><span class="line">        System.out.println("s3:" + s3);</span><br><span class="line"></span><br><span class="line">        //int length() 返回字符串长度</span><br><span class="line">        System.out.println("s1的长度：" + s1.length());</span><br><span class="line"></span><br><span class="line">        //boolean equals(Object anObject) 比较两个字符串是否相等</span><br><span class="line">        System.out.println("s1=s2? " + s1.equals(s2));</span><br><span class="line">        System.out.println("s1=s3? " + s1.equals(s3));</span><br><span class="line"></span><br><span class="line">        //boolean equalsIgnoreCase(String anotherString) 忽略大小写比较两个字符串是否相等</span><br><span class="line">        System.out.println("忽略大小写时，s1=s3? " + s1.equalsIgnoreCase(s3));</span><br><span class="line"></span><br><span class="line">        //int compareTo(String anotherString) 比较两个字符串的大小，如果两个字符串相同返回0，否则返回第一个不同的字符ASCII码的差值</span><br><span class="line">        System.out.println("s1&gt;s2? " + s1.compareTo(s2));</span><br><span class="line">        System.out.println("s1&gt;s3? " + s1.compareTo(s3));</span><br><span class="line"></span><br><span class="line">        //String concat(String str) 字符串拼接，等价于字符串相加</span><br><span class="line">        System.out.println("s1+s3: " + s1.concat(s3));</span><br><span class="line"></span><br><span class="line">        //char charAt(int index) 查找索引位置的字符</span><br><span class="line">        System.out.println("s1的第2个字符：" + s1.charAt(1));</span><br><span class="line"></span><br><span class="line">        //int indexOf(String str) 查找字符串首次出现的位置</span><br><span class="line">        System.out.println("s1中o字符串首次出现的位置" + s1.indexOf("o"));</span><br><span class="line"></span><br><span class="line">        //int lastIndexOf(String str) 查找字符串最后出现的位置</span><br><span class="line">        System.out.println("s1中o字符串最后出现的位置" + s1.lastIndexOf("o"));</span><br><span class="line"></span><br><span class="line">        //String substring(int beginIndex) 从字符串起始位置截取到字符串末尾</span><br><span class="line">        System.out.println("s1中从第2个字符截取到末尾：" + s1.substring(1));</span><br><span class="line"></span><br><span class="line">        //String substring(int beginIndex, int endIndex) 从字符串起始位置截取到指定位置</span><br><span class="line">        System.out.println("s1中从第2个字符截取到第7个字符：" + s1.substring(1, 7));</span><br><span class="line"></span><br><span class="line">        //String replace(CharSequence target, CharSequence replacement) 用指定字符串替代目标字符串</span><br><span class="line">        System.out.println("s1中的小写l变为大写L：" + s1.replace("l", "L"));</span><br><span class="line"></span><br><span class="line">        //boolean startsWith(String prefix) 判断字符串是否以指定字符串开头</span><br><span class="line">        System.out.println("s1是否以he开头：" + s1.startsWith("he"));</span><br><span class="line"></span><br><span class="line">        //boolean endsWith(String suffix) 判断字符串是否以指定字符串结尾</span><br><span class="line">        System.out.println("s1是否以!结束：" + s1.endsWith("!"));</span><br><span class="line"></span><br><span class="line">        //String toUpperCase() 将字符串变为大写</span><br><span class="line">        System.out.println("s1全变为大写：" + s1.toUpperCase());</span><br><span class="line"></span><br><span class="line">        //String toLowerCase() 将字符串变为小写</span><br><span class="line">        System.out.println("s3全变为小写：" + s3.toLowerCase());</span><br><span class="line"></span><br><span class="line">        //char[] toCharArray() 将字符串转换为字符数组</span><br><span class="line">        System.out.println("s1转换为字符数组");</span><br><span class="line">        char[] chars1 = s1.toCharArray();</span><br><span class="line">        for (char c: chars1) {</span><br><span class="line">            System.out.print(c + " ");</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        //String[] split(String regex) 将字符串按照指定字符串进行分隔，如果要按照英文"."分割，需要加两个反斜杠变为"\\."</span><br><span class="line">        System.out.println("\ns1按照小写字符l进行拆分");</span><br><span class="line">        String[] strings = s1.split("l");</span><br><span class="line">        for (String s: strings) {</span><br><span class="line">            System.out.println(s);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java64.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  当然了Java字符串处理操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是截取，增加，查找，比较，插入，删除，替换这些操作，是笔试，面试中一旦考察字符串一定会用到的函数，请小伙伴们务必放在心上。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>主要元素(Leetcode 程序员面试金典17.10)</title>
    <url>/2020/12/26/program%20Leetcode_interview17.10/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_10.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   来一道简单题目给小伙伴们放松放松，小伙伴们能优化到什么程度呢？能否在$O(n)$的时间复杂度内完成？能否在$O(1)$的空间复杂度完成？如果可以能否同时满足两个要求呢？<br><a id="more"></a></p>
<h1 id="排序求解"><a href="#排序求解" class="headerlink" title="排序求解"></a><font size="5" color="red">排序求解</font></h1><p><strong>因为数组中主要元素超过一半，因此我们将数组进行排序后，连续长度一定超过数组长度的一半。我们从0号元素遍历到nums.size() - num.size() / 2，如果存在nums[i] == nums[i + num.size() / 2]说明该元素是主要元素，否则返回-1</strong>。</p>
<p>主要时间在数组的排序，算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int majorityElement(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        sort(nums.begin(), nums.end());</span><br><span class="line">        for (int i = 0; i + nums.size() / 2 &lt; nums.size(); i++) if (nums[i] == nums[i + nums.size() / 2]) return nums[i];</span><br><span class="line">        return -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p><strong>最简单的方法是哈希表求解，我们将元素都存放在哈希表中，然后遍历哈希表，如果存在某个元素的个数大于数组长度的一半，那么说明该元素是主要元素</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;unordered_map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int majorityElement(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        unordered_map&lt;int, int&gt; m;</span><br><span class="line">        for (int x : nums) m[x]++;</span><br><span class="line">        for (auto p : m) if (p.second &gt; nums.size() / 2) return p.first;</span><br><span class="line">        return -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="摩尔投票法"><a href="#摩尔投票法" class="headerlink" title="摩尔投票法"></a><font size="5" color="red">摩尔投票法</font></h1><p>这个题目的最优解是摩尔投票法，是一种特殊算法，其思想是主要元素的个数超过其他所有元素之和，因此用一个计数器记录当前获胜者的票数。</p>
<p>如果当前获胜者是A，票数是k，如果下一个选票是B，那么k—，如果下一个选票是A，那么k++。一旦k=0，就没有获胜者。最后投票完成后，如果存在主要元素，那么获胜者一定是主要元素。如果不存在主要元素，获胜者可能是其他元素。</p>
<p>如何理解呢？假设A是主要元素，那么A的选票足以大于其他的所有人，因此无论如何抵消，A都会在最后胜出。因此我们可以用一次遍历确定获胜者，然后再用一次遍历统计获胜者的票数即可。如果票数大于数组长度的一半则为主要元素，否则没有主要元素。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int majorityElement(vector&lt;int&gt;&amp; nums) {</span><br><span class="line">        int major, cnt = 0;</span><br><span class="line">        for (int x : nums) {</span><br><span class="line">            if (cnt == 0) {</span><br><span class="line">                major = x;</span><br><span class="line">                cnt++;</span><br><span class="line">            }</span><br><span class="line">            else cnt += major == x ? 1 : -1;</span><br><span class="line">        }</span><br><span class="line">        cnt = 0;</span><br><span class="line">        for (int x : nums) if (x == major) cnt++;</span><br><span class="line">        return cnt &gt; nums.size() / 2 ? major : -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目难度很小，想给小伙伴们多科普一些特殊算法，拓展视野。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>哈希表</category>
        <category>特定算法</category>
      </categories>
  </entry>
  <entry>
    <title>Java包装类和泛型</title>
    <url>/2020/12/25/Java_wrapper_genericity/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java56.png" alt="2"></p>
<h1 id="Java包装类和泛型"><a href="#Java包装类和泛型" class="headerlink" title="Java包装类和泛型"></a><font size="5" color="red">Java包装类和泛型</font></h1><p>  在Java中基本类型使用方便，但是没有对应的方法操作这些基本的数据类型。因此可以使用一个类把基本类型数据装起来，在这个类中定义一些方法，这个类称为包装类。<br><a id="more"></a></p>
<h1 id="包装类"><a href="#包装类" class="headerlink" title="包装类"></a><font size="5">包装类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Wrapper {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //装箱：从基本类型转换为对应的包装类对象</span><br><span class="line">        //拆箱：从包装类型转换为对应的基本类对象</span><br><span class="line">        //通过自动装箱获取包装类对象</span><br><span class="line">        Integer integer1 = 10;</span><br><span class="line">        //通过Integer类构造函数创建就包装类对象</span><br><span class="line">        Integer integer2 = new Integer(15);</span><br><span class="line">        Integer integet3 = new Integer("20");</span><br><span class="line">        //通过Integer静态方法创建包装类对象</span><br><span class="line">        Integer integer4 = Integer.valueOf(25);</span><br><span class="line">        Integer integet5 = Integer.valueOf("30");</span><br><span class="line"></span><br><span class="line">        //JDK1.5后出现了自动装箱和自动拆箱的过程，首先进行自动拆箱先将Integer对象进行自动拆箱变为int基本类型，然后进行自加5，最后进行自动装箱，从int基本类型变为Integer包装类对象。</span><br><span class="line">        integer1 += 5;</span><br><span class="line"></span><br><span class="line">        //从基本类型到String类型的转换</span><br><span class="line">        //通过+""变成String类型</span><br><span class="line">        String s1 = integer1 + "";</span><br><span class="line">        //通过包装类对象的toString方法</span><br><span class="line">        String s2 = integer1.toString();</span><br><span class="line">        //通过包装类的静态toString方法</span><br><span class="line">        String s3 = Integer.toString(integer1);</span><br><span class="line">        //通过String类的静态valueOf方法</span><br><span class="line">        String s4 = String.valueOf(integer1);</span><br><span class="line"></span><br><span class="line">        //从String类型到基本类型的转换</span><br><span class="line">        //通过包装类的parseInt/parseFloat等静态方法</span><br><span class="line">        Integer integer6 = Integer.parseInt(s1);</span><br><span class="line">        //通过包装类的valueOf</span><br><span class="line">        Integer integer7 = Integer.valueOf(s1);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java57.png" alt="1"></p>
<h1 id="泛型和迭代器"><a href="#泛型和迭代器" class="headerlink" title="泛型和迭代器"></a><font size="5">泛型和迭代器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">import java.util.Iterator;</span><br><span class="line">import java.util.Vector;</span><br><span class="line"></span><br><span class="line">//泛型是一种未知的数据类型，当我们不知道需要哪种数据类型时，可以使用泛型，当使用时再确定。</span><br><span class="line">//泛型类的定义：修饰符 + class + 类名&lt;代表泛型的变量&gt;</span><br><span class="line">//泛型接口的定义和泛型类相同，只是将class改成interface即可。</span><br><span class="line">//写子类或者实现类时，有两种方式，可以指定父类或者接口的类型，这样子类或者实现类就是确定的类型，也可以将定义子类或者实现类仍然是泛型类。</span><br><span class="line">public class Generics&lt;E&gt; {</span><br><span class="line">    E e;</span><br><span class="line"></span><br><span class="line">    public Generics(E e) {</span><br><span class="line">        this.e = e;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        System.out.println("----------测试泛型类----------");</span><br><span class="line">        //使用泛型时：类名&lt;类型&gt; 对象名 = new 类名&lt;&gt;(参数列表);</span><br><span class="line">        Generics&lt;Integer&gt; generics1 = new Generics&lt;&gt;(1);</span><br><span class="line">        Generics&lt;String&gt; generics2 = new Generics&lt;&gt;("hello world!");</span><br><span class="line">        Generics&lt;Double&gt; generics3 = new Generics&lt;&gt;(3.14);</span><br><span class="line">        Generics&lt;Object&gt; generics4 = new Generics&lt;&gt;("Object");</span><br><span class="line">        generics1.print("Integer");</span><br><span class="line">        generics2.print("String");</span><br><span class="line">        generics3.print("Double");</span><br><span class="line"></span><br><span class="line">        System.out.println("----------测试泛型方法----------");</span><br><span class="line">        Generics.print(1, "Integer");</span><br><span class="line">        Generics.print("hello world!", "String");</span><br><span class="line">        Generics.print(3.14, "Double");</span><br><span class="line"></span><br><span class="line">        System.out.println("----------测试泛型通配符----------");</span><br><span class="line">        Vector&lt;Integer&gt; integerVector = new Vector&lt;&gt;();</span><br><span class="line">        integerVector.add(1);</span><br><span class="line">        integerVector.add(2);</span><br><span class="line">        integerVector.add(3);</span><br><span class="line">        Vector&lt;Double&gt; doubleVector = new Vector&lt;&gt;();</span><br><span class="line">        doubleVector.add(1.1);</span><br><span class="line">        doubleVector.add(2.2);</span><br><span class="line">        doubleVector.add(3.3);</span><br><span class="line">        Vector&lt;String&gt; stringVector = new Vector&lt;&gt;();</span><br><span class="line">        stringVector.add("hello");</span><br><span class="line">        stringVector.add("world");</span><br><span class="line">        stringVector.add("java");</span><br><span class="line">        Generics.print(integerVector);</span><br><span class="line">        Generics.print(doubleVector);</span><br><span class="line">        Generics.print(stringVector);</span><br><span class="line"></span><br><span class="line">        System.out.println("----------测试受限泛型----------");</span><br><span class="line">        test1(generics1);</span><br><span class="line">        test1(generics3);</span><br><span class="line">        test2(generics4);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void print(String s) {</span><br><span class="line">        System.out.println("我的类型是：" + s + " 值为：" +  e);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //泛型方法的定义：修饰符 &lt;泛型&gt; + 返回值类型 + 方法名(参数列表)</span><br><span class="line">    //泛型方法更能说明泛型的用处，print函数不能确定打印什么样的数据，因此传入int，float，double，String等类型时，就需要进行函数重载，当写了泛型方法时，在参数列表中不指定类型，而在调用方法时确定泛型的数据类型。</span><br><span class="line">    public static &lt;T&gt; void print(T t, String s) {</span><br><span class="line">        System.out.println("我的类型是：" + s + " 值为：" +  t);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //泛型通配符：在参数传递的数据中，泛型类型不确定时，可以通过通配符&lt;?&gt;表示，一旦使用泛型的通配符后，不能进行类型转换，只能使用object中的共性方法，自身方法无法使用。</span><br><span class="line">    //注意：只能在参数传递时使用，不能创建&lt;?&gt;类型的数据。</span><br><span class="line">    public static void print(Vector&lt;?&gt; v) {</span><br><span class="line">        //Iterator接口：import java.util.Iterator</span><br><span class="line">        //用于集合操作之中，关于集合操作我会在后面的博客中进行讲解，因为数组增删元素特别繁琐，因此Java给我们提供了一些接口和类可以非常方便的操作元素，这就是集合。</span><br><span class="line">        //集合元素操作时有迭代器的概念，在C++和Python中也有迭代器，就相当于一个指针指向某个元素，迭代器对象有两个非常重要的方法，一个是hasNext()方法，可以判断是否已经迭代完成，另一个是next()方法，当没有迭代完成时，可以指向下一个元素。</span><br><span class="line">        Iterator&lt;?&gt; iterator = v.iterator();</span><br><span class="line">        while (iterator.hasNext()) {</span><br><span class="line">            System.out.println(iterator.next());</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //泛型的上限：此时的泛型？必须是Number类型的同类或子类，因此generics1和generics3可以调用</span><br><span class="line">    public static void test1(Generics&lt;? extends Number&gt; g) {</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //泛型的下限：此时的泛型？必须是Number类型的同类或父类，因此generics4可以调用</span><br><span class="line">    public static void test2(Generics&lt;? super Number&gt; g) {</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java58.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  今天介绍的是Java的包装类和泛型的概念，现在使用包装类时，因为提供了自动装箱和自动拆箱的功能，因此和基本数据类型非常相似，泛型的概念不常使用，常常用于集合的一些操作之中，类似于C++中的模板概念，作为了解，见到的时候能够辨别即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>迷路的机器人(Leetcode 程序员面试金典08.02)</title>
    <url>/2020/12/24/program%20Leetcode_interview08.02/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview08_02.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目可以说是非常经典了，<strong>这一系列题目有很多的问法，有路径的长度，有所有路径，有最短路径，有两个方向，有四个方向，有障碍等等</strong>，小伙伴们可以进行集中训练。<br><a id="more"></a></p>
<h1 id="深度优先搜索"><a href="#深度优先搜索" class="headerlink" title="深度优先搜索"></a><font size="5" color="red">深度优先搜索</font></h1><p>DFS是可以解决这类问题的，但是要进行优化，因为DFS的时间复杂度是指数量级的，因此要进行剪枝。</p>
<p><strong>DFS的剪枝也可以称为记忆化，当搜索过的路径，我们可以将其置为0，在这里因为只要找到一条路径即可，可以直接return true。如果某点无法走到，可以将其置为1，因此就可以在原数据上直接进行操作。在原始数据上，1代表障碍物，这样可以节省开辟visited的内存消耗</strong>。</p>
<p>优化后算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(mn)$</strong>，其中m和n分别为数据的宽和高。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; pathWithObstacles(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) {</span><br><span class="line">        if (obstacleGrid.empty() || obstacleGrid[0][0] || obstacleGrid[obstacleGrid.size() - 1][obstacleGrid[0].size() - 1]) return vector&lt;vector&lt;int&gt;&gt;();</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; direction = { {0, 1}, {1, 0} };</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; path = { {0, 0} };</span><br><span class="line">        if (dfs(obstacleGrid, direction, path)) return path;</span><br><span class="line">        return vector&lt;vector&lt;int&gt;&gt;();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool dfs(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid, vector&lt;vector&lt;int&gt;&gt;&amp; direction, vector&lt;vector&lt;int&gt;&gt;&amp; path) {</span><br><span class="line">        int r = path.back()[0], c = path.back()[1];</span><br><span class="line">        if (r == obstacleGrid.size() - 1 &amp;&amp; c == obstacleGrid[0].size() - 1) return true;</span><br><span class="line">        for (auto direct : direction) {</span><br><span class="line">            int newR = r + direct[0], newC = c + direct[1];</span><br><span class="line">            if (0 &lt;= newR &amp;&amp; newR &lt; obstacleGrid.size() &amp;&amp; 0 &lt;= newC &amp;&amp; newC &lt; obstacleGrid[0].size() &amp;&amp; !obstacleGrid[newR][newC]) {</span><br><span class="line">                obstacleGrid[newR][newC] = 1;</span><br><span class="line">                path.push_back({ newR, newC });</span><br><span class="line">                if (dfs(obstacleGrid, direction, path)) return true;</span><br><span class="line">                path.pop_back();</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a><font size="5" color="red">广度优先搜索</font></h1><p>BFS也是可以解决这类问题的，而且在求最短路径时非常好用，但是同样要进行优化，因为BFS的时间复杂度是也是指数量级的，因此要进行剪枝。</p>
<p><strong>BFS和DFS的区别在于，BFS是同时搜索，在求最短路径时非常方便，找到的第一个路径一定是最短路径。而DFS是沿着一条路走到黑，不行再调头，因此在求任意一条路径时非常方便</strong>。</p>
<p><strong>BFS的剪枝主要目的是去重，如本题中，(1, 1)这个点，可以由(0, 1)走到，也可以由(1, 0)走到，因此不需要重复计算。如果某点可以已经由其他点走到，可以将其置为1，这里同样可以在原数据上直接进行操作</strong>。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(mn)$</strong>，其中m和n分别为数据的宽和高。</p>
<p>我在这个算法中每一次搜索都保存了所有的路径，因此空间复杂度为$O(mn \cdot max(m, n))$，因为有去重，队列中最多只有max(m, n)条不同的路径。</p>
<p>可以使用哈希表记录最先到达某点的路径，这样可以追溯求出路径，这样只适合于求最短路径，并不是这类问题的通解。如果要求出所有路径，就无法做到了。所有有兴趣的小伙伴可以尝试去做。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; pathWithObstacles(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) {</span><br><span class="line">        if (obstacleGrid.empty() || obstacleGrid[0][0] || obstacleGrid[obstacleGrid.size() - 1][obstacleGrid[0].size() - 1]) return vector&lt;vector&lt;int&gt;&gt;();</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; direction = { {0, 1}, {1, 0} };</span><br><span class="line">        deque&lt;vector&lt;vector&lt;int&gt;&gt;&gt; queue = { { {0, 0} } };</span><br><span class="line">        int row = obstacleGrid.size(), col = obstacleGrid[0].size();</span><br><span class="line">        while (!queue.empty()) {</span><br><span class="line">            vector&lt;vector&lt;int&gt;&gt; path = queue.front();</span><br><span class="line">            int r = path.back()[0], c = path.back()[1];</span><br><span class="line">            queue.pop_front();</span><br><span class="line">            if (r == row - 1 &amp;&amp; c == col - 1) return path;</span><br><span class="line">            for (auto direct : direction) {</span><br><span class="line">                int newR = r + direct[0], newC = c + direct[1];</span><br><span class="line">                if (0 &lt;= newR &amp;&amp; newR &lt; obstacleGrid.size() &amp;&amp; 0 &lt;= newC &amp;&amp; newC &lt; obstacleGrid[0].size() &amp;&amp; !obstacleGrid[newR][newC]) {</span><br><span class="line">                    obstacleGrid[newR][newC] = 1;</span><br><span class="line">                    path.push_back({ newR, newC });</span><br><span class="line">                    queue.push_back(path);</span><br><span class="line">                    path.pop_back();</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return vector&lt;vector&lt;int&gt;&gt;();</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>DP也是可以解决这个问题的，在这里用词要小心，只是这个问题，而不是这类问题，如果移动方向是四个，或者求出所有路径，或者求出最长路径都不方便使用。</p>
<p>我们想一想为什么可以使用动态规划进行求解？<strong>因为这个问题具有最优子问题的特点，如走到(5, 5)这个点，可以先走到(4, 5)或者走到(5, 4)这两个点，而这两个点都是已经知道的。因此如果移动方向是4个，那么也可能从(5, 6)或者(6, 5)走到，但是(5, 6)和(6, 5)就说没有求得的，所以不能使用DP</strong>。</p>
<p><strong>在求路径的时候，利用回溯的原理，走到(x, y)一定是x + y步，那么如果(x, y - 1)或者(x - 1, y)是x + y - 1，那么就可以从(x, y - 1)或者(x - 1, y)走到(x, y)，一直递推到(0, 0)即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(mn)$</strong>，其中m和n分别为数据的宽和高。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; pathWithObstacles(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) {</span><br><span class="line">        if (obstacleGrid.empty() || obstacleGrid[0][0] || obstacleGrid[obstacleGrid.size() - 1][obstacleGrid[0].size() - 1]) return vector&lt;vector&lt;int&gt;&gt;();</span><br><span class="line">        int row = obstacleGrid.size(), col = obstacleGrid[0].size();</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; dp(row, vector&lt;int&gt;(col, -1)), path;</span><br><span class="line">        for (int i = 0; i &lt; row; i++) {</span><br><span class="line">            if (obstacleGrid[i][0]) break;</span><br><span class="line">            else dp[i][0] = i;</span><br><span class="line">        }</span><br><span class="line">        for (int j = 1; j &lt; col; j++) {</span><br><span class="line">            if (obstacleGrid[0][j]) break;</span><br><span class="line">            else dp[0][j] = j;</span><br><span class="line">        }</span><br><span class="line">        for (int i = 1; i &lt; row; i++) {</span><br><span class="line">            for (int j = 1; j &lt; col; j++) {</span><br><span class="line">                dp[i][j] = obstacleGrid[i][j] ? -1 : max(dp[i - 1][j], dp[i][j - 1]) + 1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        if (dp[row - 1][col - 1] != row + col - 2) return path;</span><br><span class="line">        path.push_back({ row - 1, col - 1 });</span><br><span class="line">        int i = row - 1, j = col - 1;</span><br><span class="line">        while (i || j) {</span><br><span class="line">            if (i &gt; 0 &amp;&amp; dp[i - 1][j] == dp[i][j] - 1) path.push_back({ --i, j });</span><br><span class="line">            else path.push_back({ i, --j });</span><br><span class="line">        }</span><br><span class="line">        reverse(path.begin(), path.end());</span><br><span class="line">        return path;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这类题目非常重要，面试中考察较少，但是笔试中DFS和BFS是考察的重点，尤其是美团招聘的时候，我记得4道题目都是搜索，这可能和美团的业务相关，需要求各种最短的优化路径。但是考察的难度都很大，如果没有剪枝只能通过30%-40%，而且方法一定要用正确，什么时候该用DFS，什么时候该用BFS，小伙伴们还有很长的路要走，加油吧！</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>Java面向对象完结</title>
    <url>/2020/12/23/Java_oop_5/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++52.png" alt="2"></p>
<h1 id="Java面向对象完结"><a href="#Java面向对象完结" class="headerlink" title="Java面向对象完结"></a><font size="5" color="red">Java面向对象完结</font></h1><p>  Java面向对象终于来到了完结篇，最后剩下的内容是面向对象中最难理解的一个特性——多态，虽然在自己写代码时很少用到，但是在企业级开发中是必不可少的部分，还会把剩余的一些内部类的知识给小伙伴们介绍。<br><a id="more"></a></p>
<h1 id="多态"><a href="#多态" class="headerlink" title="多态"></a><font size="5">多态</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public abstract class Animal {</span><br><span class="line">    String name;</span><br><span class="line"></span><br><span class="line">    public Animal(String name) {</span><br><span class="line">        this.name = name;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public abstract void eat();</span><br><span class="line"></span><br><span class="line">    public abstract void speak();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Cat extends Animal{</span><br><span class="line">    public Cat(String name) {</span><br><span class="line">        super(name);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void eat() {</span><br><span class="line">        System.out.println("我是" + name + "，我喜欢吃鱼");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void speak() {</span><br><span class="line">        System.out.println("我是" + name + "，我会喵喵喵");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void climb() {</span><br><span class="line">        System.out.println("我是" + name + "，我会爬树");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Dog extends Animal{</span><br><span class="line">    public Dog(String name) {</span><br><span class="line">        super(name);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void eat() {</span><br><span class="line">        System.out.println("我是" + name + "，我喜欢吃骨头");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void speak() {</span><br><span class="line">        System.out.println("我是" + name + "，我会汪汪汪");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void watch() {</span><br><span class="line">        System.out.println("我是" + name + "，我会看家");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop5 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //多态的本质：父类或接口引用子类对象，调用时会调用子类的成员方法。</span><br><span class="line">        //编译看左，运行看右。因为编译时看左边，父类对象没有子类的特有方法，因此在animal_cat中无法调用Cat类的climb方法。运行时是按照右边创建的子类进行调用，调用的是子类的方法。</span><br><span class="line">        //向上转型：父类名 对象名 = new 子类名，即创建子类对象，当作父类看待，这是安全的。例如猫是子类，看做一个动物，这是合理的。缺陷是无法调用子类特有的方法，编译不通过。</span><br><span class="line">        //向下转型：子类名 对象名 = (子类名) 父类对象 即将父类对象还原成子类对象，这时不安全的。例如你不能说动物就是猫，还可能是狗，因此必须保证它确实就是一只猫。所以必须保证对象本来创建的时候就是子类A，才能从父类转型为子类A，如果对象创建的时候是子类B，则向下转型为子类A，会在运行时报错。</span><br><span class="line">        Animal animalCat = new Cat("小猫");</span><br><span class="line">        Animal animalDog = new Dog("小狗");</span><br><span class="line">        //在这里animalCat无法调用到子类的climb属性，编译就会报错。</span><br><span class="line">        animalCat.eat();</span><br><span class="line">        animalCat.speak();</span><br><span class="line">        animalDog.eat();</span><br><span class="line">        animalDog.speak();</span><br><span class="line">        //在这里可以将父类对象animalCat转型为Dog，编译不会报错，但是运行时会报错。只能将其向下转型为Cat类对象，因为在创建时animalCat就是Cat类型。</span><br><span class="line">        Cat cat = (Cat) animalCat;</span><br><span class="line">        cat.eat();</span><br><span class="line">        cat.speak();</span><br><span class="line">        cat.climb();</span><br><span class="line">        Dog dog = (Dog) animalDog;</span><br><span class="line">        dog.eat();</span><br><span class="line">        dog.speak();</span><br><span class="line">        dog.watch();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java54.png" alt="1"></p>
<h1 id="Java内部类"><a href="#Java内部类" class="headerlink" title="Java内部类"></a><font size="5">Java内部类</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//外部类：可以使用public和默认权限修饰符修饰。如果使用默认权限修饰符则包外不可导入该类。</span><br><span class="line">//成员内部类：可以使用四种权限修饰符，和成员变量类似。</span><br><span class="line">//局部内部类：只能在方法内使用，因此不可以写权限修饰符。</span><br><span class="line"></span><br><span class="line">public class OuterClass {</span><br><span class="line">    //成员内部类的定义方式，定义在外部类的成员变量中</span><br><span class="line">    public static class InnerClass {</span><br><span class="line">        public void speak() {</span><br><span class="line">            System.out.println("我是InnerClass内部类中的speak方法");</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void localInnerClass() {</span><br><span class="line">        //局部内部类的定义方式，定义在一个方法的内部</span><br><span class="line">        class LocalInnerClass {</span><br><span class="line">            public void speak() {</span><br><span class="line">                System.out.println("我是OuterClass外部类中localInnerClass方法中的LocalInnerClass局部内部类中的speak方法");</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        //使用局部内部类，仅仅在当前所属的方法中才能使用它，超出这个方法外面就不可以使用了</span><br><span class="line">        LocalInnerClass localInnerClass = new LocalInnerClass();</span><br><span class="line">        localInnerClass.speak();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void speak() {</span><br><span class="line">        System.out.println("我是OuterClass外部类中的speak方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop5 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //使用外部类</span><br><span class="line">        OuterClass outerClass = new OuterClass();</span><br><span class="line">        //使用成员内部类，需要外部类名.内部类名 对象名 = new 外部类名.内部类名()</span><br><span class="line">        OuterClass.InnerClass innerClass = new OuterClass.InnerClass();</span><br><span class="line">        //使用匿名内部类，如果接口的实现类或者父类的子类只使用一次，可以省略该类的定义，直接重写方法即可。</span><br><span class="line">        OuterClass anonymous = new OuterClass() {</span><br><span class="line">          @Override</span><br><span class="line">          public void speak() {</span><br><span class="line">              System.out.println("我是匿名内部类中的speak方法");</span><br><span class="line">          }</span><br><span class="line">        };</span><br><span class="line">        outerClass.speak();</span><br><span class="line">        outerClass.localInnerClass();</span><br><span class="line">        innerClass.speak();</span><br><span class="line">        anonymous.speak();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java55.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  到今天为止，面向对象的所有内容都已经给小伙伴们分享完了，至于其中包含的奇技淫巧，需要小伙伴们慢慢磨砺，多态是设计模式的基础，以后会给小伙伴们详细介绍设计模式，在这里一定要掌握多态的用法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>字母与数字(Leetcode 程序员面试金典17.05)</title>
    <url>/2020/12/22/program%20Leetcode_interview17.05/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview17_05.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目的数据范围是数组长度小于等于1e5，因此我们不能使用$O(n^2)$或者以上时间复杂度的算法进行求解。<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p><strong>这个题目和Leetcode第一题非常相似。我们可以设定一个计数器val，当数字出现时，val++，否则val—。一开始val=0。当两次val相同时，说明这中间的字符满足数字和字母相同</strong>。</p>
<p>因此我们将计数器第一次出现的位置保存下来，如0号字符是数字，val = 1，那么我们将用map记录一个pair{1, 0}，当第8个字符遍历后，发现val = 1。因此我们查看map中已经有了key=1的键值对，我们就可以知道从1号到8号这8个字符中数字和字母是相同的。因为从1号开始val++和val—次数相同。如果长度大于之前保存的最大长度，则替换，如果长度相等，比较起始的字符串的大小。如果小于之前的则替换即可。</p>
<p><strong>此题要注意要给哈希表赋初值，当一个字符都没有时，索引为-1。即map = { {0, -1} }，否则在特殊情况下会得到错误结果。如[“A”, “1”]，当遍历到第二个元素时，val = 0，发现并没有key = 0的键值对，因此会创建一个{0, 1}的键值对，这就是不正确的</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    vector&lt;string&gt; findLongestSubarray(vector&lt;string&gt;&amp; array) {</span><br><span class="line">        int val = 0, begin = 0, length = 0;</span><br><span class="line">        map&lt;int, int&gt; m = { {0, -1} };</span><br><span class="line">        for (int i = 0; i &lt; array.size(); i++) {</span><br><span class="line">            if (array[i][0] &gt;= '0' &amp;&amp; array[i][0] &lt;= '9') val++;</span><br><span class="line">            else val--;</span><br><span class="line">            if (!m.count(val)) m[val] = i;</span><br><span class="line">            else if(i - m[val] &gt; length || (i - m[val] == length &amp;&amp; array[m[val] + 1] &lt; array[begin + 1])) begin = m[val] + 1, length = i - m[val];</span><br><span class="line">        }</span><br><span class="line">        return vector&lt;string&gt;(array.begin() + begin, array.begin() + begin + length);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  两数之和是Leetcode的入坑题，其中包含了非常重要的思想，在今后的做题过程中会反复用到，小伙伴们务必理解它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>Java面向对象拓展</title>
    <url>/2020/12/21/Java_oop_4/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++47.png" alt="2"></p>
<h1 id="Java面向对象拓展"><a href="#Java面向对象拓展" class="headerlink" title="Java面向对象拓展"></a><font size="5" color="red">Java面向对象拓展</font></h1><p>  Java面向对象还有最最重要的部分知识，接口的问题，C++中允许多继承，而Java中不提供多继承，而是提供了接口的概念，在这里给大家做简单的介绍。<br><a id="more"></a></p>
<h1 id="Java抽象方法"><a href="#Java抽象方法" class="headerlink" title="Java抽象方法"></a><font size="5">Java抽象方法</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//如果父类中的方法不确定如何进行方法体的实现，则该方法是抽象方法，该类是抽象类。如动物类，无法确定他们吃什么东西，只有具体到某一个动物才可以确定，因此动物类就是一个抽象类。</span><br><span class="line">//抽象类在public和class之间加上abstract关键字，抽象方法在权限修饰符和返回值之间加上abstract关键字。而且抽象方法不能写实现，直接在参数列表后面加分号即可。</span><br><span class="line">//抽象类中不一定包含抽象方法，但是有抽象方法的一定是抽象类。</span><br><span class="line">public abstract class Animal {</span><br><span class="line">    String name;</span><br><span class="line"></span><br><span class="line">    public Animal(String name) {</span><br><span class="line">        this.name = name;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public abstract void eat();</span><br><span class="line"></span><br><span class="line">    public abstract void speak();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//抽象类必须用一个子类继承抽象类，并且重写父类中所有的抽象方法才可以创建子类对象进行使用。如果没有重写父类的所有抽象方法，那么子类也是一个抽象类。</span><br><span class="line">public class Cat extends Animal{</span><br><span class="line">    public Cat(String name) {</span><br><span class="line">        super(name);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //在重写父类的抽象方法中，可以在方法的上面一行加上@Override表示重写。</span><br><span class="line">    //注意重写是在继承关系中，方法的名称一样，参数列表也一样，和函数的重载是不同的。</span><br><span class="line">    //重写时子类方法的返回值范围必须小于等于父类方法的返回值范围，子类方法的访问权限必须大于等于父类方法的权限。</span><br><span class="line">    @Override</span><br><span class="line">    public void eat() {</span><br><span class="line">        System.out.println("我是" + name + "，我喜欢吃鱼");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void speak() {</span><br><span class="line">        System.out.println("我是" + name + "，我会喵喵喵");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Dog extends Animal{</span><br><span class="line">    public Dog(String name) {</span><br><span class="line">        super(name);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void eat() {</span><br><span class="line">        System.out.println("我是" + name + "，我喜欢吃骨头");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void speak() {</span><br><span class="line">        System.out.println("我是" + name + "，我会汪汪汪");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop4 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Cat cat = new Cat("小猫");</span><br><span class="line">        Dog dog = new Dog("小狗");</span><br><span class="line">        cat.eat();</span><br><span class="line">        cat.speak();</span><br><span class="line">        dog.eat();</span><br><span class="line">        dog.speak();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java53.png" alt="1"></p>
<h1 id="Java接口"><a href="#Java接口" class="headerlink" title="Java接口"></a><font size="5">Java接口</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//接口是一种公共的规范标准，接口中最重要的内容就是抽象方法。</span><br><span class="line">//接口中可以包含常量，抽象方法，默认方法(Java8)，静态方法(Java8)，私有方法(Java9)</span><br><span class="line">//接口的定义是public + interface + 接口名称</span><br><span class="line">//接口中不允许出现静态代码块和构造方法。</span><br><span class="line">// 类和接口的关系：类与类之间是单继承的，类与接口之间是多实现的，接口与接口之间是多继承的。</span><br><span class="line">public interface A {</span><br><span class="line">    //接口中可以定义成员变量，也是属于接口，必须使用public static final修饰，也可以省略，但是最好不要省略。</span><br><span class="line">    //接口常量必须在定义时赋值，否则会报错，而且名称最好用完全大写的字母，并且用下划线分隔。</span><br><span class="line">    public static final String NAME = "A";</span><br><span class="line"></span><br><span class="line">    //接口中的抽象方法和抽象类中的抽象方法相同。</span><br><span class="line">    public abstract void aMethod();</span><br><span class="line"></span><br><span class="line">    //从Java8开始，接口中允许定义默认方法，可以通过接口实现类对象进行调用，也可以在接口实现类中进行重写。</span><br><span class="line">    public default void defaultMethod() {</span><br><span class="line">        System.out.println("我是接口A的默认方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //从Java8开始，接口中允许定义静态方法，不能通过接口实现类进行调用，和类中的静态方法不同，只能通过接口名.静态方法名进行调用。</span><br><span class="line">    public static void staticMethod() {</span><br><span class="line">        System.out.println("我是接口A的静态方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //从Java9开始，接口中允许定义私有方法，用于解决代码冗余问题，但是又不能暴露给实现类，因此需要私有化。包括普通私有方法和静态私有方法。</span><br><span class="line">    private void privateMethod() {</span><br><span class="line">        System.out.println("我是接口A的私有方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public interface B {</span><br><span class="line">    public static final String NAME = "B";</span><br><span class="line"></span><br><span class="line">    public abstract void bMethod();</span><br><span class="line"></span><br><span class="line">    public default void defaultMethod() {</span><br><span class="line">        System.out.println("我是接口B的默认方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void staticMethod() {</span><br><span class="line">        System.out.println("我是接口B的静态方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    private void privateMethod() {</span><br><span class="line">        System.out.println("我是接口B的私有方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//定义类实现多个接口时，格式是public class 类名 implements 多个接口名，并用逗号分隔。</span><br><span class="line">public class C implements A, B{</span><br><span class="line"></span><br><span class="line">    //接口中的默认方法重复，必须进行重写，如果抽象方法重复，只需要覆盖重写一次即可。</span><br><span class="line">    //如果实现类没有覆盖重写所有抽象方法，那么该类就是一个抽象类。</span><br><span class="line">    //如果父类的方法和接口中的默认方法冲突，则优先使用父类中的方法。</span><br><span class="line">    @Override</span><br><span class="line">    public void defaultMethod() {</span><br><span class="line">        System.out.println("我是C重写接口A和B的共同默认方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void aMethod() {</span><br><span class="line">        System.out.println("我是C重写接口A的特有方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void bMethod() {</span><br><span class="line">        System.out.println("我是C重写接口B的特有方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop4 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        C c = new C();</span><br><span class="line">        c.aMethod();</span><br><span class="line">        c.bMethod();</span><br><span class="line">        c.defaultMethod();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java51.png" alt="1"></p>
<h1 id="Java中final关键字"><a href="#Java中final关键字" class="headerlink" title="Java中final关键字"></a><font size="5">Java中final关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">//final修饰类名：代表当前类没有子类，无法被继承，而且该类的方法不能写成抽象类。</span><br><span class="line">public final class FinalClassA {</span><br><span class="line">    public void methodA() {</span><br><span class="line">        System.out.println("我是ClassA中的methodA方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class ClassB {</span><br><span class="line">    //final修饰方法名：代表该方法不能被子类覆盖重写，因此也不能写成抽象方法。</span><br><span class="line">    public final void finalMethodB() {</span><br><span class="line">        System.out.println("我是ClassB中的finalMethodA方法");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void methodB() {</span><br><span class="line">        System.out.println("我是ClassB中的methodB方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class ClassC extends ClassB{</span><br><span class="line">    @Override</span><br><span class="line">    public void methodB() {</span><br><span class="line">        System.out.println("我是ClassC中重写的methodB方法");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop4 {</span><br><span class="line">    //final修饰成员变量，代表成员变量不可变，要么在定义时赋值要么在构造方法中赋值。</span><br><span class="line">    public static final double PI = 3.14;</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //final修饰局部变量，代表局部变量不可变</span><br><span class="line">        final int R = 10;</span><br><span class="line">        FinalClassA finalClassA = new FinalClassA();</span><br><span class="line">        ClassB classB = new ClassB();</span><br><span class="line">        ClassC classC = new ClassC();</span><br><span class="line">        finalClassA.methodA();</span><br><span class="line">        classB.finalMethodB();</span><br><span class="line">        classB.methodB();</span><br><span class="line">        classC.finalMethodB();</span><br><span class="line">        classC.methodB();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java52.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  今天的内容是Java面向对象的拓展部分，也是Java中最最重要的部分，是和C++最核心的区别之一，小伙伴在今后的工作中肯定会和接口有很多交集，因此需要深刻理解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>Java面向对象进阶</title>
    <url>/2020/12/19/Java_oop_3/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java43.png" alt="2"></p>
<h1 id="Java面向对象进阶"><a href="#Java面向对象进阶" class="headerlink" title="Java面向对象进阶"></a><font size="5" color="red">Java面向对象进阶</font></h1><p>  前面介绍了面向对象的四种访问控制权限。今天带小伙们看一看Java面向对象中的static关键字。<br><a id="more"></a></p>
<h1 id="static关键字"><a href="#static关键字" class="headerlink" title="static关键字"></a><font size="5">static关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class JavaProgrammer {</span><br><span class="line">    //static修饰的成员变量称为静态成员变量，其特点是所有对象共享一份数据，也可称为类成员变量，说明这个成员变量不属于某一个对象，而是属于这个类。</span><br><span class="line">    static String language = "Java";</span><br><span class="line">    String name = "xxx";</span><br><span class="line"></span><br><span class="line">    public JavaProgrammer(String name) {</span><br><span class="line">        this.name = name;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //static修饰的成员方法称为静态成员方法，其特点是所有对象共享一个函数，也可称为类成员函数，注意类成员函数只能访问类成员变量，不可以访问普通成员变量。</span><br><span class="line">    static String getLanguage() {</span><br><span class="line">        return language;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    String getName() {</span><br><span class="line">        return name;</span><br><span class="line">    }</span><br><span class="line">}	</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop3 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //使用静态成员方法时可以通过对象名.静态成员变量名，也可以通过类名.静态成员变量名，因为所有对象都拥有同一份数据，因此为了区分推荐使用类名.静态成员变量名</span><br><span class="line">        JavaProgrammer programmer1 = new JavaProgrammer("Alice");</span><br><span class="line">        System.out.println("程序员1号的名字是：" + programmer1.name + " 我会用的语言是：" + JavaProgrammer.language);</span><br><span class="line">        JavaProgrammer programmer2 = new JavaProgrammer("Bob");</span><br><span class="line">        System.out.println("程序员2号的名字是：" + programmer2.name + " 我会用的语言是：" + JavaProgrammer.language);</span><br><span class="line">        JavaProgrammer.language = "C++";</span><br><span class="line">        System.out.println("程序员1号的名字是：" + programmer1.name + " 我会用的语言是：" + JavaProgrammer.language);</span><br><span class="line">        System.out.println("程序员2号的名字是：" + programmer2.name + " 我会用的语言是：" + JavaProgrammer.language);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java44.png" alt="1"></p>
<h1 id="static代码块"><a href="#static代码块" class="headerlink" title="static代码块"></a><font size="5">static代码块</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Need {</span><br><span class="line">    String language;</span><br><span class="line">    int maxAge, minAge;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Person {</span><br><span class="line"></span><br><span class="line">    public Programmer programmer;</span><br><span class="line">    public static Need need = new Need();</span><br><span class="line">    //使用静态代码块，简单方便，易于修改，适合于特定场景的类当中。</span><br><span class="line">    static {</span><br><span class="line">        need.language = "Java";</span><br><span class="line">        need.minAge = 25;</span><br><span class="line">        need.maxAge = 35;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public Person(Programmer programmer) {</span><br><span class="line">        this.programmer = programmer;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String isFit() {</span><br><span class="line">        return programmer.language.equals(need.language) &amp;&amp; programmer.age &gt;= need.minAge &amp;&amp; programmer.age &lt;= need.maxAge ? "符合条件" : "不符合条件";</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop3 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Person p1 = new Person(new Programmer("C++", 28));</span><br><span class="line">        Person p2 = new Person(new Programmer("Java", 26));</span><br><span class="line">        Person p3 = new Person(new Programmer("Java", 24));</span><br><span class="line"></span><br><span class="line">        System.out.println("本次招聘的需求是使用" + Person.need.language + " 年龄是" + Person.need.minAge + "~" + Person.need.maxAge + "岁");</span><br><span class="line">        System.out.println("我是程序员1，我使用的语言是：" + p1.programmer.language + "我的年龄是：" + p1.programmer.age + " " + p1.isFit());</span><br><span class="line">        System.out.println("我是程序员2，我使用的语言是：" + p2.programmer.language + "我的年龄是：" + p2.programmer.age + " " + p2.isFit());</span><br><span class="line">        System.out.println("我是程序员3，我使用的语言是：" + p3.programmer.language + "我的年龄是：" + p3.programmer.age + " " + p3.isFit());</span><br><span class="line"></span><br><span class="line">        Person.need.language = "C++";</span><br><span class="line"></span><br><span class="line">        System.out.println("本次招聘的需求是使用" + Person.need.language + " 年龄是" + Person.need.minAge + "~" + Person.need.maxAge + "岁");</span><br><span class="line">        System.out.println("我是程序员1，我使用的语言是：" + p1.programmer.language + "我的年龄是：" + p1.programmer.age + " " + p1.isFit());</span><br><span class="line">        System.out.println("我是程序员2，我使用的语言是：" + p2.programmer.language + "我的年龄是：" + p2.programmer.age + " " + p2.isFit());</span><br><span class="line">        System.out.println("我是程序员3，我使用的语言是：" + p3.programmer.language + "我的年龄是：" + p3.programmer.age + " " + p3.isFit());</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java45.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  今天的内容也非常重要，static关键字，要记得它不属于某一个对象，而是属于整个类，因此在以后的访问中尽量使用类名的方式进行访问。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>稀疏数组搜索(Leetcode 程序员面试金典10.05)</title>
    <url>/2020/12/18/program%20Leetcode_interview10.05/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview10_05.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   第一眼看上去，直接brute暴力搜索，结果直接通过了，然后好奇心驱使我看了一下其他解法，竟然有更加巧妙的方法。小伙伴们能想得到吗？</p>
<a id="more"></a>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>暴力法在这里我就不叙述了，一个一个比较，相等返回索引，最后返回-1即可。</p>
<p><strong>为什么我一开始想不到二分查找呢？主要是因为一般我们认为要查找的是有序的序列。但是这里存在着一些空串，因此序列并不是有序的</strong>。</p>
<p><strong>看了方法之后，我了解到，虽然空串导致序列并不是有序的，但是我们可以忽略空串，当mid所在的字符串为空时，我们可以顺序向下搜索第一个不是空串的位置，用这个位置进行比较</strong>。</p>
<p>当仅有words[0]不为空，这时需要遍历所有的情况，因此最坏的情况下算法的<strong>时间复杂度仍是$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int findString(vector&lt;string&gt;&amp; words, string s) {</span><br><span class="line">        int left = 0, right = words.size();</span><br><span class="line">        while (left &lt; right) {</span><br><span class="line">            int mid = (left + right) &gt;&gt; 1;</span><br><span class="line">            if (words[mid] == s) return mid;</span><br><span class="line">            if (words[mid] == "") {</span><br><span class="line">                int cur = mid + 1;</span><br><span class="line">                while (cur &lt; right &amp;&amp; words[cur] == "") cur++;</span><br><span class="line">                if (cur == right || words[cur] &gt; s) right = mid;</span><br><span class="line">                else if (words[cur] == s) return cur;</span><br><span class="line">                else left = cur + 1;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                if (words[mid] &gt; s) right = mid;</span><br><span class="line">                else left = mid + 1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return -1;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目给我的启发是非常大的，<strong>只要数据满足满足除了某些特定元素之外，其他都是有序的，那么我们也可以使用二分进行查找，在大部分数据下时间复杂度都会大大降低</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>Java面向对象提高</title>
    <url>/2020/12/17/Java_oop_2/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java41.png" alt="2"></p>
<h1 id="Java面向对象提高"><a href="#Java面向对象提高" class="headerlink" title="Java面向对象提高"></a><font size="5" color="red">Java面向对象提高</font></h1><p>  之前介绍了Java面向对象的基础内容，其中引入了public关键字，这时Java面向对象的一种访问控制权限，这非常重要，可以更灵活的使用我们创建的类和对象，保护类中的内容，不被其他人调用。今天带小伙们看一看Java中的四种访问控制权限。<br><a id="more"></a></p>
<h1 id="访问控制权限"><a href="#访问控制权限" class="headerlink" title="访问控制权限"></a><font size="5">访问控制权限</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//这个文件在demo01包下，考察类内是否可以访问</span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Father {</span><br><span class="line">    //public关键字：类内，同一包内，子类，不同包非子类均可以访问</span><br><span class="line">    public String name;</span><br><span class="line">    //protected关键字：类内，同一包内，子类可以访问</span><br><span class="line">    protected int age;</span><br><span class="line">    //默认(没有访问控制权限)：类内，同一包内可以访问</span><br><span class="line">    String id;</span><br><span class="line">    //private：类内可以访问</span><br><span class="line">    private int money;</span><br><span class="line"></span><br><span class="line">    public Father() {</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public Father(String name, int age, String id, int money) {</span><br><span class="line">        this.name = name;</span><br><span class="line">        this.age = age;</span><br><span class="line">        this.id = id;</span><br><span class="line">        this.money = money;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String getName() {</span><br><span class="line">        return name;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public int getAge() {</span><br><span class="line">        return age;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String getId() {</span><br><span class="line">        return id;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public int getMoney() {</span><br><span class="line">        return money;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">//这个文件在demo02包下，考察不同包的子类是否可以访问</span><br><span class="line">package demo02;</span><br><span class="line">import demo01.Father;</span><br><span class="line"></span><br><span class="line">//继承：面向对象的第二大特点，可以获取父类的部分成员，实现代码的复用。</span><br><span class="line">//语法是public + class + 子类名 + extends + 父类名</span><br><span class="line">//super关键字，获取父类的成员变量，成员方法或者构造函数。</span><br><span class="line">public class Son extends Father{</span><br><span class="line">    public Son() {</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public Son(String name, int age, String id, int money) {</span><br><span class="line">        super(name, age, id, money);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">//这个文件在demo01包下，考察同一包下是否可以访问</span><br><span class="line">package demo01;</span><br><span class="line">import demo02.Son;</span><br><span class="line"></span><br><span class="line">public class Oop2 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Father father = new Father("父类", 30, "123456", 1000000);</span><br><span class="line">        //同一包下，private不能直接访问，其他的三种都可以直接访问。</span><br><span class="line">        System.out.println("我的名字是：" + father.name + " 我的年龄是：" + father.age + " 我的id是：" + father.id + " 我的存款是：" + father.getMoney());</span><br><span class="line">        Son son = new Son("子类", 3, "234567", 100);</span><br><span class="line">        //不同包子类中，private和默认权限不能直接访问，其他的两种都可以直接访问。</span><br><span class="line">        System.out.println("我的名字是：" + son.name + " 我的年龄是：" + son.age + " 我的id是：" + son.getId() + " 我的存款是：" + son.getMoney());</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">//这个文件在demo02包下，考察不同包非子类是否可以访问</span><br><span class="line">package demo02;</span><br><span class="line">import demo01.Father;</span><br><span class="line"></span><br><span class="line">public class Stranger {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Father father = new Father("父类", 30, "123456", 1000000);</span><br><span class="line">        //不同包非子类中，private，默认和protected都不能直接访问，只有public可以直接访问。</span><br><span class="line">        System.out.println("我的名字是：" + father.name + " 我的年龄是：" + father.getAge() + " 我的id是：" + father.getId() + " 我的存款是：" + father.getMoney());</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java42.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  今天给大家介绍四种Java的访问控制权限以及继承的基本概念，这对于Java的学习非常重要，因此小伙伴们务必掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>翻转数位(Leetcode 程序员面试金典05.03)</title>
    <url>/2020/12/16/program%20Leetcode_interview5.3/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview05_03.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   位运算的题目难度都不大，但是有一些技巧和陷阱需要小伙伴们在做题中发现，做完这个题目，希望小伙伴们可以去Leetcode官网做面试题05.06进行知识点巩固。</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p><strong>负数右移，符号位不变，这是需要小伙伴们注意的，如果我们想让负数右移符号位补0，可以让结果异或0x8000000(1 &lt;&lt; 31)，或者让结果与(0x7fffffff)</strong>。</p>
<p>本题中，我们从低位到高位统计连续的1出现的次数，如果某一位是0，则right统计右边1出现的个数，left统计左边1出现的个数。left + right + 1就是将该位改为1时连续的1出现的次数。然后再统计下一位，此时right = 0，left = right。</p>
<p>我写的版本是先找到最先出现的第一个0，统计右边1的个数记为right作为初始条件，然后开始统计left的个数。代码有些冗余，因此在下面提供一个其他人写的版本。</p>
<p>算法的<strong>时间复杂度为$O(1)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int reverseBits(int num) {</span><br><span class="line">        int left = 0, right = 0, maxLens = 0;</span><br><span class="line">        while (num &amp;&amp; num % 2) {</span><br><span class="line">            right++;</span><br><span class="line">            num &gt;&gt;= 1;</span><br><span class="line">            num = num &gt;= 0 ? num : num ^ (1 &lt;&lt; 31);</span><br><span class="line">        }</span><br><span class="line">        num &gt;&gt;= 1;</span><br><span class="line">        num = num &gt;= 0 ? num : num ^ (1 &lt;&lt; 31);</span><br><span class="line">        while (num) {</span><br><span class="line">            if (num % 2) {</span><br><span class="line">                left++;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                maxLens = max(maxLens, left + right + 1);</span><br><span class="line">                right = left;</span><br><span class="line">                left = 0;</span><br><span class="line">            }</span><br><span class="line">            num = num &gt;&gt; 1;</span><br><span class="line">        }</span><br><span class="line">        return min(max(maxLens, left + right + 1), 32);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化位运算"><a href="#优化位运算" class="headerlink" title="优化位运算"></a><font size="5" color="red">优化位运算</font></h1><p>其实并没有优化时间复杂度和空间复杂度，但是美观了我们的代码，让我们的代码可读性大大提高了。</p>
<p>思想是：<strong>不管移位以后最高位补的是0还是1，我们只关心int的32位数据，因此使用for循环进行遍历，而且不需要找到第一个0产生的位置，统计右边1的个数赋值给right，将初始值right设0即可。</strong></p>
<p>算法的<strong>时间复杂度为$O(1)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int reverseBits(int num) {</span><br><span class="line">        if (~num == 0) return 32;</span><br><span class="line">    </span><br><span class="line">        int previous = 0;</span><br><span class="line">        int current = 0;</span><br><span class="line">        int length = 0;</span><br><span class="line">        for (int i = 0; i &lt; 32; i++) {</span><br><span class="line">            if (num &amp; 1) {</span><br><span class="line">                current++;</span><br><span class="line">            } else {</span><br><span class="line">                previous = current;</span><br><span class="line">                current = 0;</span><br><span class="line">            }</span><br><span class="line">            length = max(length, previous + current + 1);</span><br><span class="line">            num &gt;&gt;= 1;</span><br><span class="line">        }</span><br><span class="line">        return length;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  位运算是小伙伴们必须掌握的技能，这是我们软件程序员的基本知识，从计算机为什么要用二进制表示，到数值的二进制保存方法，这都是需要我们熟记的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>Java面向对象基础</title>
    <url>/2020/12/15/Java_oop_1/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++37.png" alt="2"></p>
<h1 id="Java面向对象基础"><a href="#Java面向对象基础" class="headerlink" title="Java面向对象基础"></a><font size="5" color="red">Java面向对象基础</font></h1><p>  面向对象的编程思想(Object Oriented Programming, OOP)是程序设计发展的必然阶段，在70年代初，人们使用面向过程的编程思想解决问题，但是随着时代的进步，人们发现这种编程思想非常繁琐，尤其是定义多个相同或相似的变量，需要进行非常冗余的代码编写。这就引入了OOP的观念，面向对象的思想是Java语言的核心内容，因此我们分成多个篇章进行叙述，今天主要给大家介绍类的创建和使用，以及封装，构造析构函数等内容。<br><a id="more"></a></p>
<h1 id="类的定义及使用"><a href="#类的定义及使用" class="headerlink" title="类的定义及使用"></a><font size="5">类的定义及使用</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//定义类时，需要使用public + class关键字 + 类名，然后在花括号中定义成员变量和成员方法。</span><br><span class="line">//这种将成员变量和成员方法写在一个类中，创建对象时，所有对象都具有这些成员变量，也可以使用成员方法，这种思想称为封装。</span><br><span class="line">//要注意的是在Java中每一个类就是一个单独的文件，因此我们不能把多个类写入同一个.java文件中。</span><br><span class="line">//导包是一个非常重要的工具，当我们要使用其他开发者定义的类时，我们就需要导包，如果要使用的类和本类在同一个包下，可以省略导包语句，否则需要import 包名.类名进行导入才可以使用。</span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Person {</span><br><span class="line">    String name;</span><br><span class="line">    int age;</span><br><span class="line"></span><br><span class="line">    public void eat() {</span><br><span class="line">        System.out.println("I am hungry!");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void sleep() {</span><br><span class="line">        System.out.println("I am sleepy!");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">	</span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop1 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //对象的创建，可以通过类名 变量名 = new 类名(参数列表)进行创建，和C++不同的是如果没有参数也不能省略括号。</span><br><span class="line">        Person p1 = new Person();</span><br><span class="line">        //对象的使用，如果想访问对象的成员变量或者成员方法和结构体相同，使用小数点进行访问。</span><br><span class="line">        p1.name = "睡神";</span><br><span class="line">        p1.age = 24;</span><br><span class="line">        System.out.println("我的名字是：" + p1.name);</span><br><span class="line">        System.out.println("我的年龄是：" + p1.age);</span><br><span class="line">        p1.eat();</span><br><span class="line">        p1.sleep();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java38.png" alt="1"></p>
<h1 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a><font size="5">构造函数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Person {</span><br><span class="line">    String name = "xxx";</span><br><span class="line">    int age = 0;</span><br><span class="line"></span><br><span class="line">    //构造函数是和类名同名的一种特殊的成员函数，当创建对象时会自动调用类的构造函数。</span><br><span class="line">    //如果没有自定义构造函数，编译器会自动帮你创建一个无参的构造函数，里面是空实现，如果自定义了构造函数，则编译器不会再帮你创建无参构造函数。</span><br><span class="line">    //构造函数的出现帮我们省去了每个成员变量重新赋值的操作，而且构造函数可以发生函数重载。</span><br><span class="line">    //注意构造函数的写法，没有返回值。</span><br><span class="line">    //和C++不同的地方还在于Java中存在GC垃圾回收机制，不需要程序员进行手动清理，因此没有析构函数，关于GC会在以后的课程中进行相关的介绍。</span><br><span class="line">    public Person(String name, int age) {</span><br><span class="line">        this.name = name;</span><br><span class="line">        this.age = age;</span><br><span class="line">        System.out.println("我是" + this.name + "我有两个参数的构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public Person(String name) {</span><br><span class="line">        this.name = name;</span><br><span class="line">        System.out.println("我是" + this.name + "我有一个参数的构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public Person() {</span><br><span class="line">        System.out.println("我是" + this.name + "无参的构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop1 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Person p1 = new Person();</span><br><span class="line">        Person p2 = new Person("婴儿");</span><br><span class="line">        Person p3 = new Person("程序员", 24);</span><br><span class="line"></span><br><span class="line">        System.out.println(p1.name + "的年龄是：" + p1.age);</span><br><span class="line">        System.out.println(p2.name + "的年龄是：" + p2.age);</span><br><span class="line">        System.out.println(p3.name + "的年龄是：" + p3.age);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java39.png" alt="2"></p>
<h1 id="拷贝构造函数"><a href="#拷贝构造函数" class="headerlink" title="拷贝构造函数"></a><font size="5">拷贝构造函数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Person {</span><br><span class="line">    String name = "xxx";</span><br><span class="line">    int age = 0;</span><br><span class="line">    int[] score;</span><br><span class="line"></span><br><span class="line">    public Person(String name, int age, int[] score) {</span><br><span class="line">        this.name = name;</span><br><span class="line">        this.age = age;</span><br><span class="line">        this.score = score;</span><br><span class="line">        System.out.println("我是" + this.name + "我有三个参数的构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //拷贝构造函数的参数是一个同类型的对象，可以根据传入的对象创建一个相同的对象。</span><br><span class="line">    //与C++不同的是，默认情况下编译器不会提供拷贝构造函数，需要程序员自己定义。</span><br><span class="line">    public Person(Person p) {</span><br><span class="line">        this.name = p.name;</span><br><span class="line">        this.age = p.age;</span><br><span class="line">        this.score = p.score;</span><br><span class="line">        System.out.println("我是" + this.name + "拷贝构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop1 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Person p1 = new Person("程序员1", 24, new int[]{80});</span><br><span class="line">        Person p2 = new Person(p1);</span><br><span class="line">        p2.name = "程序员2";</span><br><span class="line">        System.out.println("程序员1的成绩为：" + p1.score[0]);</span><br><span class="line">        System.out.println("程序员2的成绩为：" + p2.score[0]);</span><br><span class="line">        p1.score[0] = 90;</span><br><span class="line">        System.out.println("程序员1的成绩为：" + p1.score[0]);</span><br><span class="line">        System.out.println("程序员2的成绩为：" + p2.score[0]);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java40.png" alt="2"></p>
<h1 id="深拷贝和浅拷贝"><a href="#深拷贝和浅拷贝" class="headerlink" title="深拷贝和浅拷贝"></a><font size="5">深拷贝和浅拷贝</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Person {</span><br><span class="line">    String name = "xxx";</span><br><span class="line">    int age = 0;</span><br><span class="line">    int[] score;</span><br><span class="line"></span><br><span class="line">    public Person(String name, int age, int[] score) {</span><br><span class="line">        this.name = name;</span><br><span class="line">        this.age = age;</span><br><span class="line">        this.score = score;</span><br><span class="line">        System.out.println("我是" + this.name + "我有三个参数的构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line">    //深拷贝：指当对象或者变量复制时，不是简单的赋值操作，而是内存的重新分配，即两个对象或者变量中的地址是不重复的。修改了原对象，拷贝构造对象不会发生改变。</span><br><span class="line">    //浅拷贝：指当对象或者变量复制时，通过简单的赋值号，完成拷贝，两个对象或者变量可能指向同一块内存地址。修改了原对象，拷贝构造对象也会发生改变。</span><br><span class="line">    //在上面的例子中使用的是浅拷贝，因此修改了程序员1的成绩，程序员2的成绩也会发生改变。因为两个程序员的成员变量指向了同一块内存地址。在本例中重新进行了内存的申请，两个成员变量的地址是不同的。</span><br><span class="line">    public Person(Person p) {</span><br><span class="line">        this.name = p.name;</span><br><span class="line">        this.age = p.age;</span><br><span class="line">        this.score = new int[1];</span><br><span class="line">        this.score[0] = p.score[0];</span><br><span class="line">        System.out.println("我是" + this.name + "拷贝构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop1 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Person p1 = new Person("程序员1", 24, new int[]{80});</span><br><span class="line">        Person p2 = new Person(p1);</span><br><span class="line">        p2.name = "程序员2";</span><br><span class="line">        System.out.println("程序员1的成绩为：" + p1.score[0]);</span><br><span class="line">        System.out.println("程序员2的成绩为：" + p2.score[0]);</span><br><span class="line">        p1.score[0] = 90;</span><br><span class="line">        System.out.println("程序员1的成绩为：" + p1.score[0]);</span><br><span class="line">        System.out.println("程序员2的成绩为：" + p2.score[0]);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java37.png" alt="2"></p>
<h1 id="this指针"><a href="#this指针" class="headerlink" title="this指针"></a><font size="5">this指针</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Person {</span><br><span class="line">    String name = "xxx";</span><br><span class="line">    int age = 0;</span><br><span class="line">    //this指针是隐含在每一个非静态成员函数中的一个指针，使用时无需定义，指代当前对象，其本质是一个指针常量，指针的指向是该对象，不可以修改，但是指针指向的值可以修改。</span><br><span class="line">    //this指针的作用是指代该对象的成员变量或者成员函数，在构造函数中常有体现，当进行赋值时，由于作用域的原因，参数列表中的参数如果和成员变量同名，则会隐藏成员函数，如果想访问可以通过this指针。</span><br><span class="line">    public Person(String name, int age) {</span><br><span class="line">        this.name = name;</span><br><span class="line">        this.age = age;</span><br><span class="line">        System.out.println("我是" + this.name + "我有两个参数的构造函数，我被执行了~");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //当要返回当前对象时，可以使用return this，返回值仍是一个对象，因此还可以继续调用成员变量或者成员方法，体现出链式编程的思想。</span><br><span class="line">    public Person print() {</span><br><span class="line">        System.out.println("我被执行了~");</span><br><span class="line">        return this;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">package demo01;</span><br><span class="line"></span><br><span class="line">public class Oop1 {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        Person p = new Person("程序员", 24);</span><br><span class="line">        p.print().print().print();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java36.png" alt="2"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  在这里给小伙伴们介绍了Java的基本面向对象的概念，虽然不是很难，但是非常重要，在这里为了方便起见，使用了public关键字，下一节会为大家详细介绍几种访问权限关键字。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>合法二叉搜索树(Leetcode 程序员面试金典04.05)</title>
    <url>/2020/12/14/program%20Leetcode_interview4.5/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview04_05.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   合法的二叉搜索树，这个题目非常简单，并不是想为难大家，只是希望小伙伴们能够用不同的方法解决此题。<br><a id="more"></a></p>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p><strong>最简单的方法是进行中序遍历，用一个容器接收数据，然后看这个容器中的元素是否满足严格递增的关系</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool isValidBST(TreeNode* root) {</span><br><span class="line">        vector&lt;int&gt; v;</span><br><span class="line">        subQuestion(root, v);</span><br><span class="line">        for (int i = 1; i &lt; v.size(); i++) if (v[i] &lt;= v[i - 1]) return false;</span><br><span class="line">        return true;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void subQuestion(TreeNode* root, vector&lt;int&gt;&amp; v) {</span><br><span class="line">        if (root) {</span><br><span class="line">            subQuestion(root-&gt;left, v);</span><br><span class="line">            v.push_back(root-&gt;val);</span><br><span class="line">            subQuestion(root-&gt;right, v);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化递归"><a href="#优化递归" class="headerlink" title="优化递归"></a><font size="5" color="red">优化递归</font></h1><p><strong>因为我们每次只要记录前一个数字即可，因此我们设定一个指针pre指向前一个节点</strong>。判断一个树是否为搜索树，就是根节点的左子树是搜索树，并且根节点的值大于pre指向的节点的值，再让pre指向根节点，最后判断右子树即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    TreeNode* pre = NULL;</span><br><span class="line"></span><br><span class="line">    bool isValidBST(TreeNode* root) {</span><br><span class="line">        if (!root) return true;</span><br><span class="line">        bool left = isValidBST(root-&gt;left);</span><br><span class="line">        if (pre &amp;&amp; pre-&gt;val &gt;= root-&gt;val) return false;</span><br><span class="line">        pre = root;</span><br><span class="line">        return left &amp;&amp; isValidBST(root-&gt;right);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a><font size="5" color="red">迭代</font></h1><p>中序遍历是可以通过迭代进行的，先访问左子树，在访问左子树之前将根节点加入容器，然后容器的尾部就是最左端的节点，取出该节点，访问其右子树，在访问右子树的过程中也是先访问其左子树。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    bool isValidBST(TreeNode* root) {</span><br><span class="line">        vector&lt;TreeNode*&gt; v;</span><br><span class="line">        TreeNode* cur = root, * pre = NULL;</span><br><span class="line">        while (cur || !v.empty()) {</span><br><span class="line">            while (cur) {</span><br><span class="line">                v.push_back(cur);</span><br><span class="line">                cur = cur-&gt;left;</span><br><span class="line">            }</span><br><span class="line">            cur = v.back();</span><br><span class="line">            v.pop_back();</span><br><span class="line">            if (pre &amp;&amp; pre-&gt;val &gt;= cur-&gt;val) return false;</span><br><span class="line">            pre = cur;</span><br><span class="line">            cur = cur-&gt;right;</span><br><span class="line">        }</span><br><span class="line">        return true;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  在几天前给小伙伴们介绍了二叉搜索树的第k大节点这个题目，和本题非常类似，希望小伙伴们可以学习不同的解法，在面试中也能给自己加分。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
        <category>迭代</category>
      </categories>
  </entry>
  <entry>
    <title>Java函数</title>
    <url>/2020/12/13/Java_function/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++18.png" alt="2"></p>
<h1 id="Java函数"><a href="#Java函数" class="headerlink" title="Java函数"></a><font size="5" color="red">Java函数</font></h1><p>  函数是面向过程的程序设计精髓，也是所有语言中最重要的一个内容，学好函数，可以设计出优雅的程序，下面给小伙伴们介绍Java函数的定义，调用，参数传递，声明，默认参数，占位参数和函数的重载。<br><a id="more"></a></p>
<h1 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a><font size="5">函数定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//函数小伙伴们其实并不陌生，在第一行Java代码中就用到了函数的知识，main函数，main函数是程序运行的起始位置，程序必须要有main函数才可以运行</span><br><span class="line">//和C++不同的是，C++不是一个完全面向对象的语言，而Java是完全面向对象的语言，因此函数的定义包括权限修饰符，返回值类型，函数名，参数列表和函数体，C++中普通函数没有权限修饰符这个概念。关于函数的权限修饰符会在面向对象中进行详细介绍。</span><br><span class="line">//这里单独强调返回值，返回值代表函数运行结束后返回到调用处时产生的数据，如果没有返回值，类型要写void，可以不写return，如果有返回值，一定要写return</span><br><span class="line">//C++中可以对函数进行声明，Java中不能对函数进行声明，写在上面的函数也可以直接调用写在下面的函数。</span><br><span class="line">//函数的参数列表要写清楚参数的类型，而且不能在一个函数内部定义另一个函数，这和Python有很大的区别。</span><br><span class="line">public class Function {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 5;</span><br><span class="line">        int b = 3;</span><br><span class="line"></span><br><span class="line">        //函数的调用使用函数名(参数)，如果有返回值可以用变量接收</span><br><span class="line">        int c = add(a, b);</span><br><span class="line">        int d = add(c, b);</span><br><span class="line"></span><br><span class="line">        System.out.println("c = a + b = " + c);</span><br><span class="line">        System.out.println("d = c + b = " + d);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static int add(int a, int b) {</span><br><span class="line">        int c = a + b;</span><br><span class="line">        return c;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java19.png" alt="1"></p>
<h1 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a><font size="5">函数重载</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//占位参数意义不大，使用频率也不高，但是默认参数却经常使用。但是Java中没有默认参数和占位参数的概念，因此无法定义默认参数。</span><br><span class="line">//函数重载是指，一个函数名有不同的功能实现，当传入的参数个数不同，类型不同或者顺序不同时，函数可以发生重载，调用时，根据和哪一个函数更匹配则调用相应的函数。</span><br><span class="line">//特别注意，参数名和返回值不同不能成为函数重载的发生条件，编译器会报错。</span><br><span class="line">public class Function {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        double c = calcArea(3, 3.14);</span><br><span class="line">        System.out.println("圆c的面积为 " + c);</span><br><span class="line"></span><br><span class="line">        double e = calcArea(3.0, 3.14);</span><br><span class="line">        System.out.println("圆e的面积为 " + e);</span><br><span class="line"></span><br><span class="line">        double f = calcArea(3.14, 3);</span><br><span class="line">        System.out.println("圆f的面积为 " + f);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static double calcArea(int r, double pi) {</span><br><span class="line">        System.out.println("调用了int + double类型的函数");</span><br><span class="line">        return r * r * pi;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static double calcArea(double r, double pi) {</span><br><span class="line">        System.out.println("调用了double + double类型的函数");</span><br><span class="line">        return r * r * pi;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static double calcArea(double pi, int r) {</span><br><span class="line">        System.out.println("调用了double + int类型的函数");</span><br><span class="line">        return r * r * pi;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java21.png" alt="4"></p>
<h1 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a><font size="5">参数传递</font></h1><p><img src="/images/LANGUAGE/Java25.png" alt="1"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//Java语言只有值传递参数。当一个对象实例作为一个参数被传递到方法中时，参数就是该对象的一个副本。指向同一个对象,对象的内容可以在被调用的方法中改变，但原对象是永远不会改变的</span><br><span class="line">//如果传递了两个值并进行交换，a'和b'是a和b值的拷贝，a'和b'进行了改变，原始数据a和b并没有改变。如果传递了一个数组a，则会创建一个副本a'指向a，(对a地址的拷贝)，对a'指向的内容进行两个值的交换(对象的内容进行了改变)，因为a和a'指向同一个内容，因此a中的内容也发生了改变，但是原对象a本身并没有发生改变。</span><br><span class="line">//这里注意a的内容发生改变和a本身发生改变是两回事。如一个人吃了饭，肚子里的东西改变了，但是这个人并没有变换。</span><br><span class="line">public class Function {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 1;</span><br><span class="line">        int b = 2;</span><br><span class="line">        System.out.println("交换前 a = " + a + " b = " + b);</span><br><span class="line">        swap(a, b);</span><br><span class="line">        System.out.println("交换后 a = " + a + " b = " + b);</span><br><span class="line"></span><br><span class="line">        int[] c = {1, 2};</span><br><span class="line">        System.out.println("交换前 c[0] = " + c[0] + " c[1] = " + c[1]);</span><br><span class="line">        swap(c);</span><br><span class="line">        System.out.println("交换后 c[0] = " + c[0] + " c[1] = " + c[1]);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void swap(int a, int b) {</span><br><span class="line">        int tmp = a;</span><br><span class="line">        a = b;</span><br><span class="line">        b = tmp;</span><br><span class="line">        System.out.println("交换时 a = " + a + " b = " + b);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void swap(int[] c) {</span><br><span class="line">        int tmp = c[0];</span><br><span class="line">        c[0] = c[1];</span><br><span class="line">        c[1] = tmp;</span><br><span class="line">        System.out.println("交换时 c[0] = " + c[0] + " c[1] = " + c[1]);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/Java26.png" alt="1"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  函数是我们面向过程编程的重要思想，同时也是面向对象中封装特性的体现，有了函数我们可以节约大量的时间和空间管理我们的代码，提高了代码的复用率，但是我们要注意编程习惯，尽量一个函数实现一个功能，不要将多个功能写在同一个函数之中。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>阶乘尾数(Leetcode 程序员面试金典16.05)</title>
    <url>/2020/12/12/program%20Leetcode_interview16_05/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeinterview16_05.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是一个数学问题，如果数字很小的话可以迭代求解，但是一旦超过20以上，就变得较为复杂，因为阶乘的数值比指数还要爆炸，在n较大的时候，long类型都无法表示，即使Python语言也会计算的非常慢，小伙伴们能够想到不用计算的好办法吗？</p>
<a id="more"></a>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p><strong>阶乘尾数为0，说明这个数是一个偶数和5相乘的结果，这里也可以看成2和5相乘的结果，因为偶数都可以写成2k。如12!，当乘5的时候，会在尾部增加一个0，是因为有偶数的积累在5之前有2和4，可以积累出3个2相乘，在乘5的时候会消耗一个2，得到一个0，这是这个问题的精髓所在</strong>。</p>
<p>因此可以设置一个偶数计数器和一个尾数计数器，当一个数有因子2时，偶数计数器+1，然后继续分解因子，直到无法分解时，继续分解下一个数。当这个数有因子5时，偶数计数器-1，尾数计数器+1，同样继续分解。迭代到n时，如果偶数计数器大于等于0，说明有多余的2，所有的5都匹配成了10，返回尾数计数器的个数。如果偶数计数器小于0，说明5的个数大于2的个数，返回尾数计数器 + 偶数计数器即可。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int trailingZeroes(int n) {</span><br><span class="line">        int res = 0, evenCnt = 0;</span><br><span class="line">        for (int i = 1; i &lt;= n; i++) {</span><br><span class="line">            int tmp = i;</span><br><span class="line">            while (!(tmp &amp; 1)) {</span><br><span class="line">                evenCnt++;</span><br><span class="line">                tmp &gt;&gt;= 1;</span><br><span class="line">            }</span><br><span class="line">            while (!(tmp % 5)) {</span><br><span class="line">                evenCnt--;</span><br><span class="line">                res++;</span><br><span class="line">                tmp /= 5;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return res + min(evenCnt, 0);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化数学"><a href="#优化数学" class="headerlink" title="优化数学"></a><font size="5" color="red">优化数学</font></h1><p>上面的写法虽然能得到正确结果，但是会TLE，主要原因是样例的数据太大，有1e8量级的数据，只能使用log(n)的算法进行求解。</p>
<p><strong>我们发现了一个规律，偶数出现的次数是一定大于5出现的次数的。因为间隔1个数就会出现一个偶数，间隔4个数才会出现1个5的倍数。因此我们只需要统计5出现的次数，尾数就有多少个0</strong>。</p>
<p>如果我们仍然使用上面的方法，一个数一个数进行枚举，这也是没用的，复杂度没有发生变化。我们想n!中有多少个5，以32为例，5，10，15，20，25，30中至少含有一个5，因此有32 / 5 = 6个元素含有一个5，那么这些数除以5以后变为1，2，3，4，5，6，这里面又会有一个5，因此6 / 5 = 1个元素含有5。</p>
<p>小伙伴们是不是已经知道了如何求解。</p>
<p>算法的<strong>时间复杂度为$O(log(n))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int trailingZeroes(int n) {</span><br><span class="line">        int res = 0;</span><br><span class="line">        while (n) {</span><br><span class="line">            n /= 5;</span><br><span class="line">            res += n;</span><br><span class="line">        }</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这种题目基本上已经不会出现在面试中，因为过于简单，也不能排除有些公司特别喜欢考察算法题，先来一些简单题目预热，题目不难，如果之前没有遇到过还是可能做不出来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>Java数组</title>
    <url>/2020/12/11/Java_array/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++17.png" alt="2"></p>
<h1 id="Java数组"><a href="#Java数组" class="headerlink" title="Java数组"></a><font size="5" color="red">Java数组</font></h1><p>  在前面已经介绍了Java的运算符和流程控制语句，这里主要介绍Java的数组，建议大家在学习Java数组之前先去学习C++中的数组，可以更好的理解数组的存放方式和地址的概念。<br><a id="more"></a></p>
<h1 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a><font size="5">创建数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//Java创建数组有三种常见方式，可以先定义然后赋初值，也可以定义的时候赋初值</span><br><span class="line">//创建时数组的大小必须要固定，和C++不同的是可以使用变量作为数组的长度，在C++中int a[b]是错误的语法，在Java中new int[b]是合法的。虽然第二种和第三种方式没有指定数组大小，但是编译器会根据值的个数自动确定。</span><br><span class="line">//和C++不同点还在于初始化的问题，Java中整型默认为0，浮点型默认为0.0，字符型默认为"\u0000"，布尔默认false，引用类型默认为null。C++中一般需要先赋值再使用，否则容易出错。</span><br><span class="line">//C++中打印数组名是数组的首个元素的地址，Java中打印数组名得到的是内存地址的哈希值。</span><br><span class="line">//C++中计算数组长度，需要用总的空间大小除以每一个元素的大小，但是Java中可有使用数组名.length获取数组长度，是一个常用的操作。</span><br><span class="line">public class Array {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int[] a = new int[5];</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; 5; i++) {</span><br><span class="line">            a[i] = i;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        int[] b = new int[]{ 1, 2, 3, 4, 5 };</span><br><span class="line">        int[] c = { 1, 2, 3, 4, 5 };</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; 5; i++) {</span><br><span class="line">            System.out.printf("a[%d] = %d ", i, a[i]);</span><br><span class="line">            System.out.printf("b[%d] = %d ", i, b[i]);</span><br><span class="line">            System.out.printf("c[%d] = %d\n", i, c[i]);</span><br><span class="line">        }</span><br><span class="line">        System.out.println("a的长度为: " + a.length + " a的哈希值为: " + a);</span><br><span class="line">        System.out.println("b的长度为: " + b.length + " b的哈希值为: " + b);</span><br><span class="line">        System.out.println("c的长度为: " + c.length + " c的哈希值为: " + c);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java15.png" alt="1"></p>
<h1 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a><font size="5">二维数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Array {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        //二维数组和一维数组类似，有相似的创建方法，但是和C++不同点在于创建二维数组不能省略第二个维度，而且静态初始化时必须写成二维的形式。不可以写成int[][4] c = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 };但是C++这么写是合法的。</span><br><span class="line">        int[][] a = new int[3][4];</span><br><span class="line">        int[][] b = new int[][]{{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}};</span><br><span class="line">        int[][] c = { {1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12} };</span><br><span class="line"></span><br><span class="line">        //和C++不同的是，Java二维数组中每一个一维数组的长度可以不相同。</span><br><span class="line">        int[][] d = new int[3][];</span><br><span class="line">        d[0] = new int[]{1, 2, 3};</span><br><span class="line">        d[1] = new int[]{1, 2, 3, 4};</span><br><span class="line">        d[2] = new int[]{1, 2, 3, 4, 5};</span><br><span class="line">        for (int[] x: d){</span><br><span class="line">            for (int xx: x){</span><br><span class="line">                System.out.print(xx + " ");</span><br><span class="line">            }</span><br><span class="line">            System.out.println();</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        System.out.println("二维数组d的长度为: " + d.length + " 二维数组d的哈希值为: " + d);</span><br><span class="line">        System.out.println("一维数组d[0]的长度为: " + d[0].length + " 一维数组d[0]的哈希值为: " + d[0]);</span><br><span class="line">        System.out.println("一维数组d[1]的长度为: " + d[1].length + " 一维数组d[1]的哈希值为: " + d[1]);</span><br><span class="line">        System.out.println("一维数组d[2]的长度为: " + d[2].length + " 一维数组d[2]的哈希值为: " + d[2]);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java16.png" alt="4"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  数组是我们存放数据的好方法，就如同抽屉一样，每一个抽屉都放置同样的物品，数组的学习非常重要，无论以后从事什么样的研究，数组的使用都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>二叉搜索树的第k大节点(Leetcode 剑指Offer54)</title>
    <url>/2020/12/10/program%20Leetcode_offer54/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer54.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   二叉搜索树第k大的节点，这个题目还是非常简单的，除了常规解法还给小伙伴们推荐一个奇妙的方法，小伙伴先尝试如何求解。</p>
<a id="more"></a>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>根据二叉搜索树的规律，使用中序遍历访问所有节点，将节点存放在容器中，然后取出容器倒数第k个值即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int kthLargest(TreeNode* root, int k) {</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        inorder(root, res);</span><br><span class="line">        return res[res.size() - k];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void inorder(TreeNode* node, vector&lt;int&gt;&amp; v) {</span><br><span class="line">        if (!node) {</span><br><span class="line">            return;</span><br><span class="line">        }</span><br><span class="line">        inorder(node-&gt;left, v);</span><br><span class="line">        v.push_back(node-&gt;val);</span><br><span class="line">        inorder(node-&gt;right, v);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化递归"><a href="#优化递归" class="headerlink" title="优化递归"></a><font size="5" color="red">优化递归</font></h1><p>本题还有一个更加巧妙的方法，我们要求第k大的元素，如果按照中序遍历的方法，需要遍历所有节点，如果k=1，我们也需要访问所有的节点，这样是不划算的。虽然最坏情况的时间复杂度都是$O(n)$，但是我们不希望这么做。</p>
<p>我们可以逆中序遍历进行访问，使用一个计数器cnt，访问一个节点cnt++，当cnt=k的时候停止递归。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int kthLargest(TreeNode* root, int k) {</span><br><span class="line">        int res = 0, cnt = 0;</span><br><span class="line">        inorder(root, res, cnt, k);</span><br><span class="line">        return res;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    void inorder(TreeNode* node, int&amp; res, int &amp;cnt, int k) {</span><br><span class="line">        if (!node) {</span><br><span class="line">            return;</span><br><span class="line">        }</span><br><span class="line">        inorder(node-&gt;right, res, cnt, k);</span><br><span class="line">        if (++cnt == k) res = node-&gt;val;</span><br><span class="line">        if (cnt &gt;= k) return;</span><br><span class="line">        inorder(node-&gt;left, res, cnt, k);</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a><font size="5" color="red">迭代</font></h1><p>中序遍历是可以通过迭代进行的，先访问左子树，在访问左子树之前将根节点加入容器，然后容器的尾部就是最左端的节点，取出该节点，访问其右子树，在访问右子树的过程中也是先访问其左子树。</p>
<p>在这里也是按照一个逆中序遍历的顺序进行的，代码也比较简单，小伙伴直接看代码即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    int kthLargest(TreeNode* root, int k) {</span><br><span class="line">        vector&lt;TreeNode*&gt; v;</span><br><span class="line">        TreeNode* cur = root;</span><br><span class="line">        while (cur || v.size()) {</span><br><span class="line">            while (cur) {</span><br><span class="line">                v.push_back(cur);</span><br><span class="line">                cur = cur-&gt;right;</span><br><span class="line">            }</span><br><span class="line">            cur = v.back();</span><br><span class="line">            v.pop_back();</span><br><span class="line">            if (--k == 0) return cur-&gt;val;</span><br><span class="line">            cur = cur-&gt;left;</span><br><span class="line">        }</span><br><span class="line">        return root-&gt;val;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  中序遍历的递归求解是大家都比较清楚的，但是如何迭代求解是大多数人都没有了解过的，迭代求解思路奇妙，代码量相对递归求解较长，作为拓展知识。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
        <category>迭代</category>
      </categories>
  </entry>
  <entry>
    <title>Java流程控制</title>
    <url>/2020/12/09/Java_control/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python4.jpg" alt="2"></p>
<h1 id="Java流程控制"><a href="#Java流程控制" class="headerlink" title="Java流程控制"></a><font size="5" color="red">Java流程控制</font></h1><p>  在前面已经介绍了Java的运算符，这里主要介绍Java的流程控制，包括if条件语句，switch条件语句，while循环，do…while循环，for循环，以及continue和break跳转语句，但是和C++不同的是Java中没有goto语句，避免了逻辑隐患。<br><a id="more"></a></p>
<h1 id="Java条件语句"><a href="#Java条件语句" class="headerlink" title="Java条件语句"></a><font size="5" color="red">Java条件语句</font></h1><h2 id="if条件语句"><a href="#if条件语句" class="headerlink" title="if条件语句"></a><font size="4">if条件语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 10;</span><br><span class="line"></span><br><span class="line">        //if单分支语句</span><br><span class="line">        if (a &gt; 5) {</span><br><span class="line">            System.out.println("a &gt; 5");</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        //if...else双分支语句</span><br><span class="line">        if (a &gt; 20) {</span><br><span class="line">            System.out.println("a &gt; 20");</span><br><span class="line">        }else{</span><br><span class="line">            System.out.println("a &lt;= 20");</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        //if...else if...else多分支语句</span><br><span class="line">        if (a &gt; 20) {</span><br><span class="line">            System.out.println("a &gt; 20");</span><br><span class="line">        }else if (a &lt; 0) {</span><br><span class="line">            System.out.println("a &lt; 0");</span><br><span class="line">        }else{</span><br><span class="line">            System.out.println("0 &lt;= a &lt;= 20");</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java10.png" alt="1"></p>
<h2 id="switch-case语句"><a href="#switch-case语句" class="headerlink" title="switch case语句"></a><font size="4">switch case语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 6;</span><br><span class="line"></span><br><span class="line">        //switch中的表达式可以为整型，字符型或者字符串型，不能为浮点型，或者一段区间。而且switch语句具有穿透效果，直至遇到break才会跳出。功能和C++相同，但是C++不支持字符串类型。</span><br><span class="line">        switch (a){</span><br><span class="line"></span><br><span class="line">            case 1:</span><br><span class="line">                System.out.println("Monday");</span><br><span class="line">                break;</span><br><span class="line">            case 2:</span><br><span class="line">                System.out.println("Tuesday");</span><br><span class="line">                break;</span><br><span class="line">            case 3:</span><br><span class="line">                System.out.println("Wednesday");</span><br><span class="line">                break;</span><br><span class="line">            case 4:</span><br><span class="line">                System.out.println("Thursday");</span><br><span class="line">                break;</span><br><span class="line">            case 5:</span><br><span class="line">                System.out.println("Friday");</span><br><span class="line">                break;</span><br><span class="line">            case 6:</span><br><span class="line">                System.out.println("Saturday is free");</span><br><span class="line">            case 7:</span><br><span class="line">                System.out.println("Sunday is free");</span><br><span class="line">                break;</span><br><span class="line">            default:</span><br><span class="line">                System.out.println("Wrong");</span><br><span class="line">                break;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java11.png" alt="2"></p>
<h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a><font size="4">while循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int i = 1;</span><br><span class="line">        int sum = 0;</span><br><span class="line"></span><br><span class="line">        //while循环，每次循环开始时，判断表达式的内容，为真时执行循环体，否则跳出循环</span><br><span class="line">        while (i &lt; 10) {</span><br><span class="line">            sum += i++;</span><br><span class="line">        }</span><br><span class="line">        System.out.println("1 + 2 + 3 + ... + 9 = " + sum);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java12.png" alt="4"></p>
<h2 id="do…while循环"><a href="#do…while循环" class="headerlink" title="do…while循环"></a><font size="4">do…while循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int i = 1;</span><br><span class="line">        int sum = 0;</span><br><span class="line"></span><br><span class="line">        //do...while循环，每次循环结束后，判断表达式的内容，为真时执行下一次循环体，否则跳出循环</span><br><span class="line">        //注意do...while语句，一定会执行一次，而且最后有分号。而while语句，可能一次都不会执行。</span><br><span class="line">        do{</span><br><span class="line">            sum += i++;</span><br><span class="line">        } while (i &lt; 10);</span><br><span class="line">        System.out.println("1 + 2 + 3 + ... + 9 = " + sum);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java12.png" alt="5"></p>
<h2 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a><font size="4">for循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int sum = 0;</span><br><span class="line"></span><br><span class="line">        //for循环，括号中有三个表达式，分别为初始化表达式1，布尔表达式2，步进表达式3，循环体内容记为4</span><br><span class="line">        //for循环的执行过程为1-&gt;2-&gt;4-&gt;3-&gt;2-&gt;4-&gt;3-&gt;...-&gt;2，注意表达式1，2，3都可以省略，但是分号不可以省略。</span><br><span class="line">        //三种循环往往可以得到相同的结果，如果确定执行次数一般使用for循环，如果不确定执行次数则可以使用while循环</span><br><span class="line">        for (int i = 1; i &lt; 10; i++) {</span><br><span class="line">            sum += i;</span><br><span class="line">        }</span><br><span class="line">        System.out.println("1 + 2 + 3 + ... + 9 = " + sum);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java12.png" alt="6"></p>
<h2 id="continue关键字"><a href="#continue关键字" class="headerlink" title="continue关键字"></a><font size="4">continue关键字</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int sum = 0;</span><br><span class="line"></span><br><span class="line">        //continue关键字，立即结束本次循环体中的内容，继续进行下一次循环</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) {</span><br><span class="line">            if (i == 5) {</span><br><span class="line">                continue;</span><br><span class="line">            }</span><br><span class="line">            sum += i;</span><br><span class="line">        }</span><br><span class="line">        System.out.println("1 + 2 + 3 + 4 + 6 + 7 + 8 + 9 = " + sum);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java13.png" alt="4"></p>
<h2 id="break关键字"><a href="#break关键字" class="headerlink" title="break关键字"></a><font size="4">break关键字</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">public class Control {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int sum = 0;</span><br><span class="line"></span><br><span class="line">        //break关键字，立即结束该层循环，如果是多层循环嵌套，则进行上一层循环的下一次循环</span><br><span class="line">        //break语句除了用于循环结构，还可以用于switch语句中，跳出选择结构</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) {</span><br><span class="line">            if (i == 5) {</span><br><span class="line">                break;</span><br><span class="line">            }</span><br><span class="line">            sum += i;</span><br><span class="line">        }</span><br><span class="line">        System.out.println("1 + 2 + 3 + 4 = " + sum);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java14.png" alt="5"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  流程控制每种语言都大同小异，因为流程控制是所有语言的基础，只有掌握不同的流程控制语句，才能达到我们想要的目的，虽然难度较小，但是非常重要，无论以后从事什么样的研究，流程控制都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>二叉树的最近公共祖先(Leetcode 剑指Offer68-Ⅱ)</title>
    <url>/2020/12/08/program%20Leetcode_offer68-%E2%85%A1/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer68-Ⅱ.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   有关树的题目，小伙伴们就要想到递归，这个要深深的印在脑海里面。本题和Leetcode 剑指Offer68-Ⅰ是姐妹类型，这个题目难度稍微大一些，上一题我没有拿出来讲解是因为过于简单。在二叉搜索树中查找，因为是搜索树，我们可以根据节点的大小选择固定的路，不用进行回溯，所以通过迭代即可，不用递归进行查找，<strong>时间复杂度为$O(log(n))$</strong>。这个题目我们不知道树中节点的大小关系，因此需要进行递归查找，<strong>时间复杂度为$O(n)$</strong>。</p>
<a id="more"></a>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>在这里先给出我的笨方法，虽然时间复杂度和空间复杂度并不高，但是代码长度大，不美观。</p>
<p>我的思路是自底向上进行查找，当找到p或者q时，数量加1，当数量等于2时，说明该节点是最近的公共祖先。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {</span><br><span class="line">        int nums = 0;</span><br><span class="line">        return subQuestion(root, p, q, nums);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    TreeNode* subQuestion(TreeNode* root, TreeNode* p, TreeNode* q, int&amp; nums) {</span><br><span class="line">        if (!root) {</span><br><span class="line">            return NULL;</span><br><span class="line">        }</span><br><span class="line">        int left = 0, right = 0;</span><br><span class="line">        TreeNode* leftChild = subQuestion(root-&gt;left, p, q, left);</span><br><span class="line">        TreeNode* rightChild = subQuestion(root-&gt;right, p, q, right);</span><br><span class="line">        nums = left + right;</span><br><span class="line">        if (root == p || root == q) {</span><br><span class="line">            nums++;</span><br><span class="line">        }</span><br><span class="line">        if (left == 2) {</span><br><span class="line">            return leftChild;</span><br><span class="line">        }</span><br><span class="line">        else if (right == 2) {</span><br><span class="line">            return rightChild;</span><br><span class="line">        }</span><br><span class="line">        else {</span><br><span class="line">            if (nums == 2) {</span><br><span class="line">                return root;</span><br><span class="line">            }</span><br><span class="line">            else {</span><br><span class="line">                return NULL;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化递归"><a href="#优化递归" class="headerlink" title="优化递归"></a><font size="5" color="red">优化递归</font></h1><p>要找两个节点的最近公共祖先，<strong>现在有三种情况，一个是两个节点都在某个节点的左孩子中，第二个是两个节点都存在于某个节点的右孩子中，第三个是两个节点一左一右分别存在于左孩子和右孩子中。</strong></p>
<p>我们自底向上进行查找，当找到p或者q时返回p和q，p和q一定在某个节点的左右子树上，一个在左，一个在右，如果没有找到该节点，那么左右子树一定有一个是NULL，如果left = NULL，则return right，如果right = NULL，则return left，如果左右都不是NULL，说明找到了最近的公共祖先，返回root即可。</p>
<p>这个思路是比较难想的，代码却非常简单，也非常漂亮。算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {</span><br><span class="line">        if (!root || root == p || root == q) return root;</span><br><span class="line">        TreeNode* left = lowestCommonAncestor(root-&gt;left, p, q);</span><br><span class="line">        TreeNode* right = lowestCommonAncestor(root-&gt;right, p, q);</span><br><span class="line">        if (!left) return right;</span><br><span class="line">        if (!right) return left;</span><br><span class="line">        return root;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目作为简单题，我不能接受，我想了很久，用了一种很笨的方法，虽然也是自底向上，但是代码不优美，这里提醒小伙伴们在刷题的时候，不能提交没有问题就进行下一题，一定要看一看别人的思路和方法，多多学习，这样才可以更好的提升自己。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
      </categories>
  </entry>
  <entry>
    <title>Java运算符</title>
    <url>/2020/12/07/Java_operator/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python3.jpg" alt="2"></p>
<h1 id="Java运算符"><a href="#Java运算符" class="headerlink" title="Java运算符"></a><font size="5" color="red">Java运算符</font></h1><p>  在前面已经介绍了Java的由来，这里主要介绍Java的运算符，包括赋值运算符，算术运算符，关系运算符，逻辑运算符，三目运算符。<br><a id="more"></a></p>
<h1 id="Java创建变量"><a href="#Java创建变量" class="headerlink" title="Java创建变量"></a><font size="4">Java创建变量</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// Java中的变量创建时必须写清楚数据类型，也可以先定义，然后在其他地方赋初始值</span><br><span class="line">// 注意在C++中的char类型是占用1个字节，在Java中char类型占用2个字节</span><br><span class="line">// C++中的布尔类型是bool，Java中的布尔类型是boolean</span><br><span class="line">// 在Java中所有类型都是继承自Object基类，对每一个类无法直接像C++一样通过typeid()获得类型，也无法通过sizeof()获得大小。</span><br><span class="line"></span><br><span class="line">public class Operator {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        short s = 1;</span><br><span class="line">        int i = 20;</span><br><span class="line">        long l = 300;</span><br><span class="line">        char c = 'A';</span><br><span class="line">        float f = 3.14f;</span><br><span class="line">        double d = 1.234567;</span><br><span class="line">        boolean b;</span><br><span class="line">        b = true;</span><br><span class="line">        System.out.println("s的类型为：" + getType(s) + " 所占的空间为：" + "2Bit");</span><br><span class="line">        System.out.println("i的类型为：" + getType(i) + " 所占的空间为：" + "4Bit");</span><br><span class="line">        System.out.println("l的类型为：" + getType(l) + " 所占的空间为：" + "8Bit");</span><br><span class="line">        System.out.println("c的类型为：" + getType(c) + " 所占的空间为：" + "2Bit");</span><br><span class="line">        System.out.println("f的类型为：" + getType(f) + " 所占的空间为：" + "4Bit");</span><br><span class="line">        System.out.println("d的类型为：" + getType(d) + " 所占的空间为：" + "8Bit");</span><br><span class="line">        System.out.println("b的类型为：" + getType(b) + " 所占的空间为：" + "1Bit");</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static String getType(Object o) {</span><br><span class="line">        return o.getClass().toString();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java4.png" alt="1"></p>
<h1 id="Java算术运算"><a href="#Java算术运算" class="headerlink" title="Java算术运算"></a><font size="4">Java算术运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// +(加)，-(减)，*(乘)，/(除)，%(求余)，整数除法结果只能得到整数，注意字符型可以参与运算，字符型的值为ASCII码对应的值，但是布尔型不可以参与算术运算。</span><br><span class="line">//进行计算时要注意数据的范围，以及低范围和高范围数据类型进行运算时，数据会发生自动类型转换到高范围，高范围数据向低范围数据要强制类型转换</span><br><span class="line">public class Operator {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 2;</span><br><span class="line">        long l = 999;</span><br><span class="line">        char c = 'A';</span><br><span class="line">        double d = 3.14159;</span><br><span class="line"></span><br><span class="line">        System.out.println("a + c =" + " " + (a + c));</span><br><span class="line">        System.out.println("l / a =" + " " + (l / a));</span><br><span class="line">        System.out.println("l % a =" + " " + (l % a));</span><br><span class="line">        System.out.println("a * a * d =" + " " + (a * a * d));</span><br><span class="line">        System.out.println("a * a * d =" + " " + (int)(a * a * d));</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java5.png" alt="2"></p>
<h1 id="Java关系运算"><a href="#Java关系运算" class="headerlink" title="Java关系运算"></a><font size="4">Java关系运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// &gt;(大于)，&lt;(小于)，&gt;=(大于等于)，&lt;=(小于等于)，==(等于)，!=(不等于)</span><br><span class="line">public class Operator {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 99;</span><br><span class="line">        int b = 'b';</span><br><span class="line">        char c = 'c';</span><br><span class="line">        boolean d = a == c;</span><br><span class="line">        boolean e = b &gt; c;</span><br><span class="line"></span><br><span class="line">        System.out.println("99是否等于c？ " + d);</span><br><span class="line">        System.out.println("b是否大于c " + e);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java6.png" alt="4"></p>
<h1 id="Java自增自减运算符"><a href="#Java自增自减运算符" class="headerlink" title="Java自增自减运算符"></a><font size="4">Java自增自减运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// ++(自增运算符)，--(自减运算符)，++在前代表先进行加1，然后将值代入表达式，++在后代表先将值代入表达式，然后再进行加1，自减操作符同理。</span><br><span class="line">public class Operator {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 1;</span><br><span class="line"></span><br><span class="line">        System.out.println(a + " 此时a=1");</span><br><span class="line">        System.out.println(a++ + " ++在后，先打印a=1，然后a=a+1");</span><br><span class="line">        System.out.println(a + " 此时a=2");</span><br><span class="line">        System.out.println(++a + " ++在前，先计算a=a+1，然后再打印a=3");</span><br><span class="line">        System.out.println(a + " 此时a=3");</span><br><span class="line">        System.out.println(a-- + " --在后，先打印a=3，然后a=a-1");</span><br><span class="line">        System.out.println(a + " 此时a=2");</span><br><span class="line">        System.out.println(--a + " --在前，先计算a=a-1，然后再打印a=1");</span><br><span class="line">        System.out.println(a + " 此时a=1");</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java7.png" alt="5"></p>
<h1 id="Java逻辑运算"><a href="#Java逻辑运算" class="headerlink" title="Java逻辑运算"></a><font size="4">Java逻辑运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// &amp;&amp;(与)，||(或)，!(非)，注意与或操作只要可以判断出最后结果则停止，具有短路效果。</span><br><span class="line">//如果与操作的第一个条件为假，则不执行第二个条件，如果或操作的第一个条件为真，则不执行第二个条件。</span><br><span class="line">public class Operator {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 5;</span><br><span class="line">        int b = 6;</span><br><span class="line">        int i = 0;</span><br><span class="line">        boolean d = a &gt; b || ++i &gt; 0; //此时或操作的第一个表达式为假，需要执行++i，因此i=1</span><br><span class="line">        System.out.println("i = " + i);</span><br><span class="line">        System.out.println("d = " + d);</span><br><span class="line">        boolean e = a &gt; b &amp;&amp; ++i &gt; 0; //此时与操作的第一个表达式为假，不需要执行++i，因此i=1</span><br><span class="line">        System.out.println("i = " + i);</span><br><span class="line">        System.out.println("e = " + e);</span><br><span class="line">        boolean f = !d;</span><br><span class="line">        System.out.println("f = " + f);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java8.png" alt="6"></p>
<h1 id="Java三目运算符"><a href="#Java三目运算符" class="headerlink" title="Java三目运算符"></a><font size="4">Java三目运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 条件?表达式1:表达式2，当条件成立时，执行表达式1的内容，否则执行表达式2的内容。</span><br><span class="line">public class Operator {</span><br><span class="line">    public static void main(String[] args) {</span><br><span class="line">        int a = 5 &gt; 3 ? 2 : 1; // 5 &gt; 3成立，因此a = 2</span><br><span class="line">        System.out.println("a = " + a);</span><br><span class="line">        int b = ++a &gt;= a++ ? ++a : a++; // ++a中a的值先计算为3，再赋值为a，a++中a的值为3，此时++a &gt;= a++等价于3 &gt;= 3成立，当条件判断结束后，a又自增一次，变为4，然后b = ++a，a先自增为5，并且赋值给b</span><br><span class="line">        System.out.println("a = " + a);</span><br><span class="line">        System.out.println("b = " + b);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/Java9.png" alt="7"></p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  运算符操作每种语言都大同小异，因为运算符是所有语言的基础，学习每一种语言都离不开运算操作，虽然难度较小，但是非常重要，无论以后从事什么样的研究，都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>平衡二叉树(Leetcode 剑指Offer55-Ⅱ)</title>
    <url>/2020/12/06/program%20Leetcode_offer55-%E2%85%A1/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer55-Ⅱ.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   平衡二叉树指的是左右孩子的深度相差最多为1，这个条件就告诉了我们解法。为了练习C++语言，在今后一段时间内我就用C++写代码，小伙伴要做的事情不是关注于语言，而是关注算法本身，要深刻理解语言只是一门表达方式，只要思路正确，哪一种语言都可以解答。</p>
<a id="more"></a>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>我们可以<strong>求得每一个节点的高度放在哈希表中，然后再次遍历这棵树，求每个节点的左右孩子高度之差是否都小于等于1即可</strong>。</p>
<p>代码难度较小，也容易想到，算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;map&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    map&lt;TreeNode*, int&gt; m;</span><br><span class="line"></span><br><span class="line">    bool isBalanced(TreeNode* root) {</span><br><span class="line">        m.clear();</span><br><span class="line">        subQuestion(root);</span><br><span class="line">        for (auto au : m) {</span><br><span class="line">            if (abs(subQuestion(au.first-&gt;left) - subQuestion(au.first-&gt;right)) &gt; 1) {</span><br><span class="line">                return false;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return true;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    int subQuestion(TreeNode* node) {</span><br><span class="line">        if (!node) {</span><br><span class="line">            return 0;</span><br><span class="line">        }</span><br><span class="line">        if (!m.count(node)) {</span><br><span class="line">            int left = subQuestion(node-&gt;left) + 1;</span><br><span class="line">            int right = subQuestion(node-&gt;right) + 1;</span><br><span class="line">            m[node] = max(left, right);</span><br><span class="line">        }</span><br><span class="line">        return m[node];</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>在哈希表的方法中，我们使用了哈希表，而且遍历了树结构两次。虽然时间复杂度仍是$O(n)$没有变化，但是可不可以寻找一种更优的解决方案呢？</p>
<p><strong>我们可以自底向上进行递归，如果左右孩子的高度已知，那么就可以判断该节点是否满足条件。我们如何通过函数得到int类型的左右孩子高度和bool类型的该节点是否是平衡树呢？</strong>在我们的认识中，Python语言可以一次性返回多个不同类型的对象，但是其他语言怎么做呢？</p>
<p><strong>在C++语言中，有一个其他语言无法比拟的优势——引用，我们将左右孩子的高度作为引用传入函数中，在函数中进行修改，那么就不需要返回int类型</strong>。</p>
<p>思路是：我们先定义根节点的高度为depth，然后传入函数subQuestion中，在函数中创建左右孩子的高度left和right，在判断左右孩子是否是平衡树时进行赋值。当左右孩子都是平衡树的时候，left和right已经被赋值了，计算left和right是否满足之差小于等于1，如果是则根节点的高度depth = max(left, right) + 1。</p>
<p>这种方法是这个题目的最优解，思路巧妙，代码难度较大，算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct TreeNode {</span><br><span class="line">    int val;</span><br><span class="line">    TreeNode *left;</span><br><span class="line">    TreeNode *right;</span><br><span class="line">    TreeNode(int x) : val(x), left(NULL), right(NULL) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class Solution {</span><br><span class="line">public:</span><br><span class="line">    map&lt;TreeNode*, int&gt; m;</span><br><span class="line"></span><br><span class="line">    bool isBalanced(TreeNode* root) {</span><br><span class="line">        if (!root) return true;</span><br><span class="line">        int depth = 0;</span><br><span class="line">        return subQuestion(root, depth);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    bool subQuestion(TreeNode* node, int&amp; pDepth) {</span><br><span class="line">        if (!node) {</span><br><span class="line">            pDepth = 0;</span><br><span class="line">            return true;</span><br><span class="line">        }</span><br><span class="line">        int left = 0, right = 0;</span><br><span class="line">        if (subQuestion(node-&gt;left, left) &amp;&amp; subQuestion(node-&gt;right, right)) {</span><br><span class="line">            if (abs(left - right) &lt;= 1) {</span><br><span class="line">                pDepth = max(left, right) + 1;</span><br><span class="line">                return true;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目虽然标记为简单题，但是做起来并不简单，希望小伙伴们多加练习。而且我的建议是小伙伴们不能仅仅局限于一门语言之中，对于程序员来说，必须要掌握一门编译型语言和一门脚本语言，不能认为算法就不用关心语言本身，我认为这是不正确的，在编译型语言中，我首推C++，这是一门永远不会过时的语言，在学校中觉得Python就足够了，但是一旦进入到真正的工作中去，尤其是一些开发岗位，Python的需求还是很少的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>Java介绍</title>
    <url>/2020/12/05/Java_introduction/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/Java1.png" alt="0"></p>
<h1 id="Java由来"><a href="#Java由来" class="headerlink" title="Java由来"></a><font size="5" color="red">Java由来</font></h1><p>  等了好久，最近闲下来了，接下来的一段时间给大家介绍Java的一些基本语法，因为没有多年的Java开发经验，在这里只能点到为止，带着大家入门，如何提升代码能力和实际开发能力，还需要小伙伴们多多刷题，多多进行工程实践。Java的创始人为加拿大人詹姆斯·高斯林(James Gosling)和他的小组成员。其开发的主要目的是解决C++语言的复杂性和无法跨平台运行的问题。对C++语言进行了改造，去除了C++中一些不太实用及影响安全的成分，创建了一种完全面向对象的语言。<br><a id="more"></a></p>
<p><img src="/images/LANGUAGE/Java.png" alt="0"></p>
<h1 id="语言的比较"><a href="#语言的比较" class="headerlink" title="语言的比较"></a><font size="5" color="red">语言的比较</font></h1><p>  <font size="3">将其他语言翻译成机器语言的工具称为编译器，编译的方式有两种，一种是编译，一种是解释</font><br>  <font size="3">编译型语言：C/C++，Pascal等语言都属于编译型语言，先由编译器生成可执行文件，运行时不需要重新编译，直接使用编译的结果即可，因此程序执行效率高，跨平台能力差。</font><br>  <font size="3">解释型语言：Java，Python等语言都属于解释型语言，运行时由解释器逐行解释每一句源代码，每次运行都需要解释一次，因此程序执行效率低，跨平台能力强。</font><br><img src="/images/LANGUAGE/python1.jpg" alt="1"></p>
<h1 id="Java语言的特点"><a href="#Java语言的特点" class="headerlink" title="Java语言的特点"></a><font size="5" color="red">Java语言的特点</font></h1><p>  <font size="3">简单性：Java的简单性是相对于C++语言来说的，省去了最难的两个问题，指针和内存管理。</font><br>  <font size="3">跨平台性：Java语言借助于JVM(Java Virtual Machine, Java虚拟机)，使我们的代码都运行于JVM之上，不依赖于操作系统。</font><br>  <font size="3">面向对象：Java的面向对象和其他语言完全不同，是完全面向对象的语言，哪怕打印一行字也要在一个类中实现。</font></p>
<h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a><font size="5" color="red">JVM</font></h1><p><img src="/images/LANGUAGE/Java2.png" alt="0"><br>在这里先简单介绍一下JVM，后面有时间会专门介绍JVM这个重要的机制。<br>JVM(Java Virtual Machine, Java虚拟机)是运行在所有Java程序上的假想计算机，是Java程序的运行环境，是Java最具有吸引力的特性之一，具有跨平台的特性。任何的软件都要运行在操作系统指上，而我们使用的Java程序之所以可以跨平台，就是因为我们写的程序都是运行在JVM上，JVM运行在各个版本的操作系统之上。</p>
<h1 id="JRE和JDK"><a href="#JRE和JDK" class="headerlink" title="JRE和JDK"></a><font size="5" color="red">JRE和JDK</font></h1><p><img src="/images/LANGUAGE/Java3.png" alt="0"><br>我们在学习Java时常常听别人说什么JRE，JDK等，但是新手往往不知道它们在说啥，这里给小伙伴们科普一下。<br>JRE(Java Runtime Environment, Java运行环境)：其中包含JVM和运行时包含的一些核心类库。<br>JDK(Java Development Kit, Java开发工具包)：其中包含了JRE和一些编译开发工具。<br>如果想要运行一个已有的Java程序，那么仅仅需要安装JRE即可，如果想开发一个Java程序，那么就需要安装JDK。</p>
<h1 id="Java的开发步骤"><a href="#Java的开发步骤" class="headerlink" title="Java的开发步骤"></a><font size="5" color="red">Java的开发步骤</font></h1><p>首先编写一个.java后缀的源程序，然后通过编译获得.class后缀的字节码文件，最后由JVM解释运行.class文件即可。</p>
<h1 id="Java小结"><a href="#Java小结" class="headerlink" title="Java小结"></a><font size="5" color="red">Java小结</font></h1><p>  Java的完全面向对象和跨平台的特性，使得在企业中受到了广泛的应用，在各个软件排行榜中，Java基本上都是在第一的位置，现在很多小伙伴都使用Python作为自己的擅长，他们就会问为什么我们还要学习Java呢？我不做Java开发工程师是不是可以不用学习Java了呢？我认为无论在什么时候，只要是程序员，都需要和C++,Java等语言打交道，因为你的项目总要落地，总要应用在不同的场景之中(大型网站，游戏，安卓开发等等)，所以了解其他的语言可以更好的和其他部门的同事合作。想要在程序员的道路上越走越远，那么你就需要掌握多种语言，少年，你渴望力量吗<del>~</del>~</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title>单词接龙(Leetcode 127)</title>
    <url>/2020/12/04/program%20Leetcode127/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode127.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目一看就是使用广度优先算法，如何一看就知道，这个分析很重要。原因有两个，其一是搜索过程很简单，已知当前状态，从字典中搜索下一个匹配的状态。其二是要求最短的转换序列长度，这就说明了BFS是优于DFS的。<br><a id="more"></a></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>BFS大家也已经非常熟悉了，在这里我就介绍两个重要的点。<br>一个是当列表单词很多的时候，我们可以枚举单词的位置，枚举每个位置的字符，假如有字典中10000个单词，每个单词长度为10。如果我们逐一和所有单词比较是否相差一个字符，就需要10000次比较，如果只是枚举长度和可能出现的单词，只需要枚举10*26=260次。</p>
<p>二是如果某个单词a首先变换到了b，那么可以将b添加到passed集合中，说明最先到达了b，后面所有到达b的长度一定不小于本次，所有以后到达b的都不需要在进行查找。</p>
<p>算法的<strong>时间复杂度为$O(nm)$，空间复杂度为$O(nm)$，其中n为字典中单词的个数，m为每个单词的长度</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def ladderLength(self, beginWord, endWord, wordList):</span><br><span class="line">        """</span><br><span class="line">        :type beginWord: str</span><br><span class="line">        :type endWord: str</span><br><span class="line">        :type wordList: List[str]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        if endWord not in wordList:</span><br><span class="line">            return 0</span><br><span class="line">        queue, word_lens, wordList, passed = deque([[beginWord, 1]]), len(beginWord), set(wordList), set()</span><br><span class="line">        while queue:</span><br><span class="line">            cur, n = queue.popleft()</span><br><span class="line">            if cur == endWord:</span><br><span class="line">                return n</span><br><span class="line">            for i in range(len(beginWord)):</span><br><span class="line">                for c in range(97, 123):</span><br><span class="line">                    next_ = cur[:i] + chr(c) + cur[i + 1:]</span><br><span class="line">                    if next_ in wordList and next_ not in passed:</span><br><span class="line">                        queue.append([next_, n + 1])</span><br><span class="line">                        passed.add(next_)</span><br><span class="line">        return 0</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化BFS"><a href="#优化BFS" class="headerlink" title="优化BFS"></a><font size="5" color="red">优化BFS</font></h1><p>看了题解中powcai大佬的解答，才发现BFS还是可以进一步优化的。我们可以从首尾双向开始查找，当它们有交集的时候，说明找到了一条通路。就类似于两个人见面，上面的做法是一个人在原地等待，一个人去找。而现在介绍的算法是两个人都向中间走。</p>
<p>代码很好理解，我们来看一看大神的思路。</p>
<p>算法的<strong>时间复杂度为$O(nm)$，空间复杂度为$O(nm)$，其中n为字典中单词的个数，m为每个单词的长度</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def ladderLength(self, beginWord: str, endWord: str, wordList: List[str]) -&gt; int:</span><br><span class="line">        if endWord not in wordList:</span><br><span class="line">            return 0</span><br><span class="line">        wordict = set(wordList)</span><br><span class="line">        s1 = {beginWord}</span><br><span class="line">        s2 = {endWord}</span><br><span class="line">        n = len(beginWord)</span><br><span class="line">        step = 0</span><br><span class="line">        wordict.remove(endWord)</span><br><span class="line">        while s1 and s2:</span><br><span class="line">            step += 1</span><br><span class="line">            if len(s1) &gt; len(s2): s1, s2 = s2, s1</span><br><span class="line">            s = set()</span><br><span class="line">            for word in s1:</span><br><span class="line">                nextword = [word[:i] + chr(j) + word[i + 1:] for j in range(97, 123) for i in range(n)]</span><br><span class="line">                for w in nextword:</span><br><span class="line">                    if w in s2:</span><br><span class="line">                        return step + 1</span><br><span class="line">                    if w not in wordict: continue</span><br><span class="line">                    wordict.remove(w)</span><br><span class="line">                    s.add(w)</span><br><span class="line">            s1 = s</span><br><span class="line">        return 0</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  小伙伴们认真刷题，现在刷题是软件岗位的必备技能，即使小伙伴们已经找到了工作，但也不能放弃刷题提升自己。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>字符串</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>不用加减乘除做加法(Leetcode 剑指Offer65)</title>
    <url>/2020/12/02/program%20Leetcode_offer65/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer65.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目很有趣，虽然是一个简单题目，但是做起来是非常有难度的，对于理解计算机数据存储有重要的意义，我认为难度应该是中等以上，小伙伴们也不能轻视它。</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>我们先考虑正数的相加问题，用下图进行说明。<br><img src="/images/ALGORITHM/leetcodeoffer65_solve.png" alt="q"></p>
<p>那么负数如何计算呢，首先要明白负数为了计算的方便在计算机中是以补码的形式保存起来的。相关内容可以参考<a href="https://ustccoder.github.io/2019/08/02/algorithm%20bit%20operation/">位运算(Bit Operation)</a>。计算过程也用一张图进行说明。<br><img src="/images/ALGORITHM/leetcodeoffer65_solve1.png" alt="q"></p>
<p>诡异的事情发生了，<strong>在Python中没有位的概念</strong>，因此负数的补码需要通过其他手段获得。如C++中，对于8位的有符号整型，首位是符号位，将其他的位取反加1可以得到补码，但是Python没有位的概念，也就没有首位，更无法将其他位取反。这应该怎么考虑呢？</p>
<p>因为题目中数据的范围不会超出32位，因此我们<strong>将a和b都和0xffffffff做与运算，这样就可以保证超过32位的位都是0</strong>，但是此时正数数k与0xffffffff还是原始k，而负数k就会得到0xffffffff + k - 1。在Python中k = -1，k &amp; 0xffffffff的结果是0xffffffff + (-1) - 1。这是因为-1代表全1，做与运算后，得到前32个1，会认为一个正数，因此等于0xffffffff。</p>
<p>上面这段话是说明我们只要和0xffffffff做与操作即可，不需要过分关注于与后的结果。我一开始就出现了这个错误，当我计算-28的时候，结果是4294967268，我一直在纠结为什么要用这个结果参与计算。其实这一步的操作只是为了取负数的前32位，这时Python的特性，会导致将前32位的数当作一个正数来计算，对于位运算来说并没有影响。</p>
<p>然后<strong>最终的结果res我们要判断首尾是否位1</strong>，$res \le 0xffffffff$说明首位为0，代表正数，直接输出即可，否则说明首位为1，代表负数，但是此时res为32位的，在Python中一定为正数，我们需要在首位加1，并且在高位也都补上1。举个例子，<strong>假如最终的结果为15，则res = 0000 0000 0000 0000 0000 0000 0000 1111，在Python中的15也是这样的表达。但是如果最终的结果为-15，则res = 1111 1111 1111 1111 1111 1111 1111 0001，但是Python中的-15不是这样的，Python没有位的概念，可以认为在前面还有无数个1。因此res在Python中的值为4294967281。我们要保留前32位的值，并且给前面都加上1，这样才能得到正确结果。异或1能达到取反的效果，因此我们可以异或0xffffffff然后再取反操作，这样就可以实现高于32位的数据只取反，低于32位数据不变，达到我们想要的效果</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def add(self, a, b):</span><br><span class="line">        """</span><br><span class="line">        :type a: int</span><br><span class="line">        :type b: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        x = 0xffffffff</span><br><span class="line">        a, b = a &amp; x, b &amp; x</span><br><span class="line">        while b != 0:</span><br><span class="line">            a, b = (a ^ b), (a &amp; b) &lt;&lt; 1 &amp; x</span><br><span class="line">        return a if a &lt;= 0x7fffffff else ~(a ^ x)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目太有意思了，也是我遇到的第一题Python比C++和Java都要复杂的一题。这道题目推荐大家使用C++去写，没必要在Python的思路中绕来绕去。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>串联所有单词的子串(Leetcode 30)</title>
    <url>/2020/11/30/program%20Leetcode30/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode30.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目难度不大，还要小伙伴们仔细思考，不能因为难度是困难而放弃，有时候想一想也会豁然开朗。<br><a id="more"></a></p>
<h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a><font size="5" color="red">滑动窗口</font></h1><p><strong>单词列表中的单词都已经告诉了，假设共有k个单词，每个单词长度为m，因此总长度mk也是已知的，所以我们可以维护一个滑动窗口，让窗口的长度等于单词的总长度，然后将其中的所有字符按照单词长度分成k份，看一看是否等于单词列表中的k个单词。如果相等则说明从该索引处可以完全匹配，否则窗口滑动到下一个索引</strong>。</p>
<p>假设字符串长度为n，算法需要滑动n次，每次滑动时要进行匹配，每次匹配最多要比较k次，每次比较的时间为m，只需要一个字典保存k个单词，因为k一般小于n，因此算法的<strong>时间复杂度为$O(nmk)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findSubstring(self, s, words):</span><br><span class="line">        """</span><br><span class="line">        :s: str</span><br><span class="line">        :words: List[str]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        if not words:</span><br><span class="line">            return []</span><br><span class="line">        len_word, len_num = len(words[0]), len(words)</span><br><span class="line">        length, res, dic = len_word * len_num, [], Counter(words)</span><br><span class="line">        for i in range(len(s) - length + 1):</span><br><span class="line">            if Counter([s[i + len_word * j: i + len_word * (j + 1)] for j in range(len_num)]) == dic:</span><br><span class="line">                res.append(i)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化滑动窗口"><a href="#优化滑动窗口" class="headerlink" title="优化滑动窗口"></a><font size="5" color="red">优化滑动窗口</font></h1><p>上面那种做法是可以的，但是没有充分利用长度相等这个条件。在上面的方法中，每次滑窗都需要统计单词出现的个数并且进行对比，对于如下情况s=”abcaababcaacabc”，word=[“abc”, “aab”]，当滑动窗口从索引0到索引5时，单词为”abcaab”是有效答案，如果按照上面的思路，下一步进行索引1到索引6，单词为”bcaaba”，不匹配，直到索引3到索引8才能再一次匹配，”aababc”是有效答案，在统计时，索引0到索引5有”aab”这个单词，索引3到索引8也有这个单词，我们没有利用到这个信息。</p>
<p><strong>出现这个问题的缘故是我们每次只移动一个位置，如果我们能每次移动单词长度m的位置，那么下一个单词滑进窗口，滑窗中的第一个单词就会滑出窗口。那么中间的单词就可以进行充分利用</strong>。</p>
<p>因此需要两层循环，第一层循环单词的长度，作为滑窗的起始位置。还以刚刚的例子进行说明，word中的单词长度为3，因此第一层为0，1，2。当i=0时，将s分成[“abc”, “aab”, “abc”, “aac”, “abc”]，当i=1时，将s分成[“bca”, “aba”, “bca”. “aca”]，当i=2时，将s分成[“caa”, “bab”, “caa”, “cab”]。在第二层循环中，我们依次加入滑窗，当滑窗中单词个数为k时，进行比较。</p>
<p>算法第一层循环的次数为m，第二层循环的次数为n / k，每次要比较长度为k的字符是否相等，因此<strong>时间复杂度为$O(nm)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findSubstring(self, s, words):</span><br><span class="line">        """</span><br><span class="line">        :s: str</span><br><span class="line">        :words: List[str]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        if not words:</span><br><span class="line">            return []</span><br><span class="line">        lens, word_lens, words_lens = len(s), len(words[0]), len(words)</span><br><span class="line">        str_lens, res = word_lens * words_lens, []</span><br><span class="line">        for i in range(word_lens):</span><br><span class="line">            left = right = i</span><br><span class="line">            cur_dic = Counter(words)</span><br><span class="line">            while right + word_lens &lt;= lens:</span><br><span class="line">                if right - left &lt; str_lens:</span><br><span class="line">                    cur_dic[s[right: right + word_lens]] -= 1</span><br><span class="line">                    right += word_lens</span><br><span class="line">                    if right - left == str_lens and list(set(cur_dic.values())) == [0]:</span><br><span class="line">                        res.append(left)</span><br><span class="line">                else:</span><br><span class="line">                    cur_dic[s[left: left + word_lens]] += 1</span><br><span class="line">                    cur_dic[s[right: right + word_lens]] -= 1</span><br><span class="line">                    left += word_lens</span><br><span class="line">                    right += word_lens</span><br><span class="line">                    if list(set(cur_dic.values())) == [0]:</span><br><span class="line">                        res.append(left)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  滑动窗口也是非常有趣的题目，小伙伴们要打破瓶颈，不要局限于滑窗的步长为1，要充分利用题目中隐藏的信息。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>字符串</category>
        <category>滑动窗口</category>
      </categories>
  </entry>
  <entry>
    <title>分割回文串(Leetcode 131)</title>
    <url>/2020/11/28/program%20Leetcode131/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode131.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和Leetcode 140题非常类似，在140题中是判断分割字符是否出现在字典中，这个题目是判断分割字符是否为回文，两个题目的解法是几乎相同的，小伙伴们可以做一题，用另一题练习。<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p><strong>这种题目可以先尝试使用动态规划进行求解。dp[i]代表前i个字符组成的结果。因此计算dp[i]时，j要遍历从0到i - 1的所有情况，如果从j到i的单词为回文字符串中，那么dp[i]可以由dp[j]中的所有结果后面添加该单词组成</strong>。</p>
<p>如”abb”字符串，当i=3时，求解dp[i]，j从0遍历到i - 1，j=1时，dp[1]=[[“a”]]是已知的，而且从第二个字符到第三个字符为”bb”是回文字符串，因此dp[3]可以由dp[1]在后面添加”bb”组成，此时dp[3]=[[“a”,  “bb”]]。j=2时，dp[2]=[“ab”]是已知的，而且从第三个字符到第三个字符为”b”是回文字符串，因此dp[3]可以由dp[2]在后面添加”b”组成，此时dp[3]=[[“a”, “bb”], [“ab”, “b”]]。</p>
<p>算法的<strong>时间复杂度为$O(n^n)$，空间复杂度为$O(n^n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line">from copy import deepcopy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def partition(self, s):</span><br><span class="line">        """</span><br><span class="line">        :type s: str</span><br><span class="line">        :rtype: List[List[str]]</span><br><span class="line">        """</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def is_para(i, j):</span><br><span class="line">            return True if i &gt;= j else s[i] == s[j] and is_para(i + 1, j - 1)</span><br><span class="line"></span><br><span class="line">        if not s:</span><br><span class="line">            return []</span><br><span class="line">        lens = len(s)</span><br><span class="line">        dp = [[] for _ in range(lens + 1)]</span><br><span class="line">        dp[0] = [[]]</span><br><span class="line">        for i in range(1, len(s) + 1):</span><br><span class="line">            for j in range(1, i + 1):</span><br><span class="line">                if is_para(j - 1, i - 1):</span><br><span class="line">                    tmp = deepcopy(dp[j - 1])</span><br><span class="line">                    for x in tmp:</span><br><span class="line">                        x.append(s[j - 1: i])</span><br><span class="line">                    dp[i].extend(tmp)</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p><strong>DFS的思想和DP基本相同，也是判断前面的字符是否为回文字符串，如果是则加入字符串中，并且继续寻找接下来的字符是否为回文字符串</strong>，代码非常简单，因为dp[i]需要用到dp[j]的数据，因此<strong>动态规划需要进行数据拷贝，而DFS不需要数据拷贝，只需要进入下一层栈空间即可，因此代码量相对较少，思路也比较清晰</strong>。</p>
<p>上面是求回文串的记忆化搜索方法，在这里给出了一种求回文串的DP方法。</p>
<p>算法的<strong>时间复杂度为$O(n^n)$，空间复杂度为$O(2^n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def partition(self, s):</span><br><span class="line">        n = len(s)</span><br><span class="line">        dp = [[False] * n for _ in range(n)]</span><br><span class="line">        for i in range(n):</span><br><span class="line">            for j in range(i + 1):</span><br><span class="line">                if (s[i] == s[j]) and (i - j &lt;= 2 or dp[j + 1][i - 1]):</span><br><span class="line">                    dp[j][i] = True</span><br><span class="line">        res = []</span><br><span class="line"></span><br><span class="line">        def helper(i, tmp):</span><br><span class="line">            if i == n:</span><br><span class="line">                res.append(tmp)</span><br><span class="line">            for j in range(i, n):</span><br><span class="line">                if dp[i][j]:</span><br><span class="line">                    helper(j + 1, tmp + [s[i: j + 1]])</span><br><span class="line"></span><br><span class="line">        helper(0, [])</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DFS"><a href="#优化DFS" class="headerlink" title="优化DFS"></a><font size="5" color="red">优化DFS</font></h1><p>虽然DFS更加简单，但是本质上并没有降低算法的时间复杂度，仍然存在着大量的冗余计算过程。</p>
<p>那么如何进行优化呢？我们发现DFS算法在一个极端的例子。字符串为”aaaaaa”，cur=[“a a a”]，s=”aaa”和cur=[“a”, “aa”]，s=”aaa”的时候，都需要迭代计算s。其实无论是哪种情况，迭代s返回的结果都一样，因此不需要重复计算。</p>
<p><strong>这时我们就要利用记忆化的思路，保存计算的中间结果。传递的参数为字符串的位置，当传入相同的位置时，只需要计算一次即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(2^n)$，空间复杂度为$O(2^n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def partition(self, s):</span><br><span class="line">        """</span><br><span class="line">        :type s: str</span><br><span class="line">        :rtype: List[List[str]]</span><br><span class="line">        """</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def dfs(idx):</span><br><span class="line">            if idx &gt;= lens:</span><br><span class="line">                return [[]]</span><br><span class="line">            cur = []</span><br><span class="line">            for i in range(idx, lens):</span><br><span class="line">                if is_para(idx, i):</span><br><span class="line">                    cur += [[s[idx: i + 1]] + x for x in dfs(i + 1)]</span><br><span class="line">            return cur</span><br><span class="line"></span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def is_para(i, j):</span><br><span class="line">            return True if i &gt;= j else s[i] == s[j] and is_para(i + 1, j - 1)</span><br><span class="line"></span><br><span class="line">        lens = len(s)</span><br><span class="line">        return dfs(0)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  记忆化是非常重要的考察内容之一，在DFS中十分常见，普通的DFS难度较小，因此增加记忆化提高难度，也符合现在笔试面试的要求。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
        <category>字符串</category>
        <category>记忆化</category>
      </categories>
  </entry>
  <entry>
    <title>从中序与后序遍历序列构造二叉树(Leetcode 106)</title>
    <url>/2020/11/26/program%20Leetcode106/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode106.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和上一题异曲同工，一个是通过前序和中序构造二叉树，一个是通过中序和后序构造二叉树，小伙伴们可以学习两道题目中的一个，然后用另一个题目练手，看看自己能否解答出来。<br><a id="more"></a></p>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>我们已知了后序遍历，因此后序遍历的最后一个节点就是当前二叉树的根节点，我们再从中序遍历中找到该节点，那么中序遍历左边的节点都是左子树，中序遍历右边的节点都是右子树。然后根据左子树的节点个数，确定左子树和右子树的后序遍历，递归建树即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def buildTree(self, inorder, postorder):</span><br><span class="line">        """</span><br><span class="line">        :type inorder: List[int]</span><br><span class="line">        :type postorder: List[int]</span><br><span class="line">        :rtype: TreeNode</span><br><span class="line">        """</span><br><span class="line">        def sub_question(in_left, in_right, post_left, post_right):</span><br><span class="line">            if post_left &gt; post_right:</span><br><span class="line">                return None</span><br><span class="line">            root_val = postorder[post_right]</span><br><span class="line">            root_idx = dic[root_val]</span><br><span class="line">            left_size = root_idx - in_left</span><br><span class="line">            root = TreeNode(root_val)</span><br><span class="line">            root.left = sub_question(in_left, root_idx - 1, post_left, post_left + left_size - 1) </span><br><span class="line">            root.right = sub_question(root_idx + 1, in_right, post_left + left_size, post_right - 1) </span><br><span class="line">            return root</span><br><span class="line"></span><br><span class="line">        dic = {v: i for i, v in enumerate(inorder)}</span><br><span class="line">        return sub_question(0, len(postorder) - 1, 0, len(inorder) - 1)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  题目的难点在于如何根据根节点确定左右子树的中序和后序遍历，难度不大，需要仔细想一想其中的逻辑关系。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
      </categories>
  </entry>
  <entry>
    <title>从前序与中序遍历序列构造二叉树(Leetcode 105)</title>
    <url>/2020/11/24/program%20Leetcode105/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode105.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   二叉树的遍历是笔试中常考的题型，经常出现在选择或者填空题之中，相关的知识可以参考二叉树的遍历相关博客，这个题目是根据前序和中序遍历如何反推出一颗树，我认为很有价值，因此推荐给小伙伴们学习。<br><a id="more"></a></p>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>我们已知了前序遍历，因此前序遍历的第一个节点就是当前二叉树的根节点，我们再从中序遍历中找到该节点，那么中序遍历左边的节点都是左子树，中序遍历右边的节点都是右子树。然后根据左子树的节点个数，确定左子树和右子树的前序遍历，递归建树即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def buildTree(self, preorder, inorder):</span><br><span class="line">        """</span><br><span class="line">        :type preorder: List[int]</span><br><span class="line">        :type inorder: List[int]</span><br><span class="line">        :rtype: TreeNode</span><br><span class="line">        """</span><br><span class="line">        def sub_question(pre_left, pre_right, in_left, in_right):</span><br><span class="line">            if pre_left &gt; pre_right:</span><br><span class="line">                return None</span><br><span class="line">            root_val = preorder[pre_left]</span><br><span class="line">            root_idx = dic[root_val]</span><br><span class="line">            left_size = root_idx - in_left</span><br><span class="line">            root = TreeNode(root_val)</span><br><span class="line">            root.left = sub_question(pre_left + 1, pre_left + left_size, in_left, root_idx - 1) </span><br><span class="line">            root.right = sub_question(pre_left + left_size + 1, pre_right, root_idx + 1, in_right) </span><br><span class="line">            return root</span><br><span class="line"></span><br><span class="line">        dic = {v: i for i, v in enumerate(inorder)}</span><br><span class="line">        return sub_question(0, len(preorder) - 1, 0, len(inorder) - 1)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  题目的难点在于如何根据根节点确定左右子树的前序和中序遍历，难度不大，需要仔细想一想其中的逻辑关系。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
      </categories>
  </entry>
  <entry>
    <title>二叉搜索树与双向链表(Leetcode 剑指Offer36)</title>
    <url>/2020/11/22/program%20Leetcode_offer36/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer36.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目虽然标签为中等，实际上却是一个简单题。主要考察二叉树的中序遍历，小伙伴们先想一想如何求解？</p>
<a id="more"></a>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>我们要将BST转化为双向循环列表，<strong>可以进行中序遍历，将遍历到的节点都存放起来，然后在数组中将这些节点相互连接</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def treeToDoublyList(self, root):</span><br><span class="line">        """</span><br><span class="line">        :type root: Node</span><br><span class="line">        :rtype: Node</span><br><span class="line">        """</span><br><span class="line">        def inorder(node):</span><br><span class="line">            if not node:</span><br><span class="line">                return</span><br><span class="line">            inorder(node.left)</span><br><span class="line">            array.append(node)</span><br><span class="line">            inorder(node.right)</span><br><span class="line"></span><br><span class="line">        array = []</span><br><span class="line">        inorder(root)</span><br><span class="line">        lens = len(array)</span><br><span class="line">        for i in range(lens):</span><br><span class="line">            array[i].right = array[(i + 1) % lens]</span><br><span class="line">            array[i].left = array[(i - 1) % lens]</span><br><span class="line">        return array[0] if lens else root</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化递归"><a href="#优化递归" class="headerlink" title="优化递归"></a><font size="5" color="red">优化递归</font></h1><p>我们<strong>将这些节点都保存在数组中，其实是一种投机取巧的方法，除了栈空间外还用到了额外的数组空间，而且每个节点也遍历了两次，递归时访问了一次，遍历数组时又访问了一次，虽然时间复杂度和空间复杂度都是$O(n)$，但是相对复杂了一些</strong>。</p>
<p>我们能否在递归的时候就完成链表操作呢？答案是可以的，<strong>只需要添加一个pre变量，指向上一个节点，当前节点执行时，pre.right = node, node.left = pre即可，最后pre = node，就可以实现递归时完成双向链表操作</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def treeToDoublyList(self, root):</span><br><span class="line">        """</span><br><span class="line">        :type root: Node</span><br><span class="line">        :rtype: Node</span><br><span class="line">        """</span><br><span class="line">        def inorder(node):</span><br><span class="line">            if not node:</span><br><span class="line">                return</span><br><span class="line">            nonlocal pre, head</span><br><span class="line">            inorder(node.left)</span><br><span class="line">            if pre:</span><br><span class="line">                node.left, pre.right = pre, node</span><br><span class="line">            else:</span><br><span class="line">                head = node</span><br><span class="line">            pre = node</span><br><span class="line">            inorder(node.right)</span><br><span class="line"></span><br><span class="line">        if not root:</span><br><span class="line">            return None</span><br><span class="line">        pre, head = None, None</span><br><span class="line">        inorder(root)</span><br><span class="line">        head.left, pre.right = pre, head</span><br><span class="line">        return head</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  许多小伙伴们说我为什么博客更新的慢或者刷题数量好少，几天才刷一道题目。其实不是这样的，博客里的题目都是我在笔试面试中遇到的题目，或者刷题时不会做的题目或者是有意义的题目才会给大家分享，有时也会遇到一些简单的题目，就没有必要去写，因此写在博客里的题目更值得小伙伴们去思考。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
        <category>链表</category>
      </categories>
  </entry>
  <entry>
    <title>第 K 条最小指令(Leetcode 213场单周赛第4题)</title>
    <url>/2020/11/20/program%20Leetcode1643/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1643.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是231场周赛的第四题，题目难度并不大，需要小伙伴们仔细思考。</p>
<a id="more"></a>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>要按照指令进行排序，可以想到的方法是遍历所有指令，使用DFS进行搜索，题目的row和column都是小于等于15的，在不剪枝的情况下有$2^{30}=1073741824$量级的计算量，在剪枝的情况下有$C_{30}^{15}=155117520$量级的计算量，一般在1e8以上时就会TLE，因此DFS无法求解。有兴趣的小伙伴们可以练习一下。</p>
<p><strong>我们发现在一个row，column的地图中，一共有<script type="math/tex">C_{row+col}^{row}</script>种方案。前<script type="math/tex">C_{row+col-1}^{col-1}</script>种方案的第一个字符都是”H”，因为H的字典序排在前面，因此第一步一定是水平方向。因此我们每次只要判断一步该如何走，如果指令数小于等于<script type="math/tex">C_{row+col-1}^{col-1}</script>，那么第一步是水平方向，否则第一步为垂直方向，然后变成另一个更小地图的子问题即可</strong>。</p>
<p>在这里我又做了一些优化，如果小于等于<script type="math/tex">C_{row+col-1}^{col-1}</script>，我们再判断是否小于等于<script type="math/tex">C_{row+col-i}^{col-i}</script>，如果是，则一次可以向水平方向走i步。</p>
<p>算法的时间主要浪费在组合数的计算中，因此可以记忆化存储累积的结果，这样时间复杂度就会大大降低，<strong>时间复杂度为$O(row+column)$，空间复杂度为$O(row+column)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def kthSmallestPath(self, destination, k):</span><br><span class="line">        """</span><br><span class="line">        :type destination: List[int]</span><br><span class="line">        :type k: int</span><br><span class="line">        :rtype: str</span><br><span class="line">        """</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def prod(x):</span><br><span class="line">            if x &lt;= 1:</span><br><span class="line">                return 1</span><br><span class="line">            return x * prod(x - 1)</span><br><span class="line"></span><br><span class="line">        row, col = destination</span><br><span class="line">        if k == 1:</span><br><span class="line">            return 'H' * col + 'V' * row</span><br><span class="line">        for i in range(col + row):</span><br><span class="line">            c = prod(col - 1 - i + row) // prod(row) // prod(col - 1 - i)</span><br><span class="line">            if k - 1 &gt;= c:</span><br><span class="line">                return 'H' * i + 'V' + self.kthSmallestPath([row - 1, col - i], k - c)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  小伙伴们也可以经常打一打周赛，给定时间进行练习，代码功力不是看懂思路这么简单的，<strong>将自己的思路用代码的方式表达出来是一种更加重要的能力</strong>，希望小伙伴们不要眼高手低，一定要多写多练。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>递归</category>
      </categories>
  </entry>
  <entry>
    <title>可以到达的最远建筑(Leetcode 213场单周赛第3题)</title>
    <url>/2020/11/18/program%20Leetcode1642/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1642.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第213场周赛的第三题，我觉得这个题目很好，因此拿出来和小伙伴们分享。<br><a id="more"></a></p>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>贪心思路非常明显，<strong>从0开始到最远的建筑这段距离中，我们的梯子使用在差距最大的楼层一定是最优解</strong>。<br>我们只需要关注后面楼层高于前面楼层的这些位置即可，我们的梯子个数为n，那么我们要把所经过的差距最大的n个楼层使用梯子。因此我们要维护一个大小为n的最小堆，当某个楼层后面的楼层高于它时，如果此时堆的元素小于梯子数，那么可以直接加入，不使用砖块。如果此时堆的元素大于梯子数，此时如果楼层差距delta大于堆顶元素heap[0]，说明堆顶使用砖块会更少一些，因此，已使用砖块个数要加上堆顶元素heap[0]。否则当前楼层使用砖块个数会更少，已使用砖块个数要加上当前delta。</p>
<p>算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import heapq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def furthestBuilding(self, heights, bricks, ladders):</span><br><span class="line">        """</span><br><span class="line">        :type heights: List[int]</span><br><span class="line">        :type bricks: int</span><br><span class="line">        :type ladders: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        heap, cur_brick = [], 0</span><br><span class="line">        for i in range(len(heights) - 1):</span><br><span class="line">            delta = heights[i + 1] - heights[i]</span><br><span class="line">            if delta &gt; 0:</span><br><span class="line">                if len(heap) &lt; ladders:</span><br><span class="line">                    heapq.heappush(heap, delta)</span><br><span class="line">                else:</span><br><span class="line">                    cur_brick += heapq.heappushpop(heap, delta)</span><br><span class="line">                    if cur_brick &gt; bricks:</span><br><span class="line">                        return i</span><br><span class="line">        return len(heights) - 1</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>二分查找也是一个很好的思路，小伙伴们一定要学会，二分查找中点，如果满足条件，则二分查找后半段，如果不满足条件，则二分查找前半段。</p>
<p>判断条件时也是采用贪心的思路，在差异最大的楼层之间使用梯子。非常好理解，直接看代码即可。</p>
<p>二分的时间复杂度为log(n)，在每次判断时要对楼层差异进行排序，因此算法的<strong>时间复杂度为$O(nlog(n)log(n))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def furthestBuilding(self, heights, bricks, ladders):</span><br><span class="line">        """</span><br><span class="line">        :type heights: List[int]</span><br><span class="line">        :type bricks: int</span><br><span class="line">        :type ladders: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        def judge(mid):</span><br><span class="line">            tmp = sorted(diff[:mid + 1])</span><br><span class="line">            return bricks &gt;= sum(tmp[:max(0, len(tmp) - ladders)])</span><br><span class="line"></span><br><span class="line">        diff = [max(0, heights[i + 1] - heights[i]) for i in range(len(heights) - 1)]</span><br><span class="line">        left, right = 0, len(diff) - 1</span><br><span class="line">        while left &lt; right:</span><br><span class="line">            mid = (left + right) // 2</span><br><span class="line">            if judge(mid):</span><br><span class="line">                left = mid + 1</span><br><span class="line">            else:</span><br><span class="line">                right = mid</span><br><span class="line">        return left + 1 if left == len(diff) - 1 and judge(left) else left</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  二分查找是一个非常好的思路，这类题型往往都可以考虑这个方法，但是<strong>二分查找的难点在于如何写判断函数和控制边界条件</strong>，希望小伙伴们可以自己实现一遍，巩固记忆。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>贪心</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>单词拆分 II(Leetcode 140)</title>
    <url>/2020/11/16/program%20Leetcode140/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode140.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目求解有一定的难度，能算作中等难度的题型。但是这个题目列为困难主要是在于如何在满足时间的要求下解答出来。小伙伴们先思考如何如何求解，然后再去优化它。<br><a id="more"></a></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p><strong>这种题目可以先尝试使用动态规划进行求解。dp[i]代表前i个字符使用字典中的单词组成的结果。因此计算dp[i]时，j要遍历从0到i - 1的所有情况，如果从j到i的单词在字典中，那么dp[i]可以由dp[j]中的所有结果后面添加该单词组成</strong>。</p>
<p>如示例中”catsanddog”字符串，当i=7时，求解dp[7]，j从0遍历到i - 1，j=3时，dp[3]=[“cat”]是已知的，而且从第四个字符到第七个字符为”sand”在字典中，因此dp[7]可以由dp[3]在后面添加”sand”组成，此时dp[7]=[“cat sand”]。j=4时，dp[4]=[“cats”]是已知的，而且从第五个字符到第七个字符为”and”在字典中，因此dp[7]可以由dp[4]在后面添加”and”组成，此时dp[7]=[“cat sand”, “cats and”]。</p>
<p>这样求解是没有问题的，但是这个题目会TLE，主要问题在于浪费了大量的计算时间。举一个极端的例子。<br>字符串为”aaaaaa”，字典为[“a”, “aa”, “aaa”, “aaaa”, “aaaaa”, “aaaaaa”]。时间会浪费在什么地方呢？</p>
<p>以”aaa”结尾的只需要计算一次即可，因为以”aaa”结尾的可以是[“a aa”，”aa a”，”a a a”]，直接获取即可。但是计算dp[3]，dp[4]，dp[5]，dp[6]都没有利用到这个性质，因此不是最优解。</p>
<p>算法的<strong>时间复杂度为$O(n^n)$，空间复杂度为$O(n^n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wordBreak(self, s, wordDict):</span><br><span class="line">        """</span><br><span class="line">        :type s: str</span><br><span class="line">        :type wordDict: List[str]</span><br><span class="line">        :rtype: List[str]</span><br><span class="line">        """</span><br><span class="line">        lens = len(s)</span><br><span class="line">        wordDict = set(wordDict)</span><br><span class="line">        dp = [[] for _ in range(lens + 1)]</span><br><span class="line">        dp[0].append('')</span><br><span class="line">        for i in range(1, lens + 1):</span><br><span class="line">            for j in range(i):</span><br><span class="line">                if s[j: i] in wordDict:</span><br><span class="line">                    tmp = dp[j][:]</span><br><span class="line">                    for k in range(len(tmp)):</span><br><span class="line">                        tmp[k] += ' ' + s[j: i] if tmp[k] else s[j: i]</span><br><span class="line">                    dp[i] += tmp</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p><strong>DFS的思想和DP基本相同，也是判断前面的字符是否存在于字典中，如果存在则加入字符串中，并且继续寻找接下来的字符是否存在于字典中</strong>，代码非常简单，因为dp[7]需要用到dp[3]的数据，因此<strong>动态规划需要进行数据拷贝，而DFS不需要数据拷贝，只需要进入下一层栈空间即可，因此代码量相对较少，思路也比较清晰</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n^n)$，空间复杂度为$O(2^n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wordBreak(self, s, wordDict):</span><br><span class="line">        """</span><br><span class="line">        :type s: str</span><br><span class="line">        :type wordDict: List[str]</span><br><span class="line">        :rtype: List[str]</span><br><span class="line">        """</span><br><span class="line">        def dfs(s, cur):</span><br><span class="line">            if not s:</span><br><span class="line">                res.append(cur[1:])</span><br><span class="line">                return</span><br><span class="line">            for word in wordDict:</span><br><span class="line">                if s[:len(word)] == word:</span><br><span class="line">                    dfs(s[len(word):], cur + ' ' + word)</span><br><span class="line">        res = []</span><br><span class="line">        dfs(s, '')</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DFS"><a href="#优化DFS" class="headerlink" title="优化DFS"></a><font size="5" color="red">优化DFS</font></h1><p>虽然DFS更加简单，但是本质上并没有降低算法的时间复杂度，仍然存在着大量的冗余计算过程。</p>
<p>那么如何进行优化呢？我们发现DFS算法在一个极端的例子。字符串为”aaaaaa”，字典为[“a”, “aa”, “aaa”, “aaaa”, “aaaaa”, “aaaaaa”]时。cur=[“a a a”]，s=”aaa”和cur=[“a”, “aa”]，s=”aaa”的时候，都需要迭代计算s。其实无论是哪种情况，迭代s返回的结果都一样，因此不需要重复计算。</p>
<p><strong>这时我们就要利用记忆化的思路，保存计算的中间结果。传递的参数为字符串的位置，当传入相同的位置时，只需要计算一次即可</strong>。</p>
<p>算法的<strong>时间复杂度为$O(2^n)$，空间复杂度为$O(2^n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def wordBreak(self, s, wordDict):</span><br><span class="line">        """</span><br><span class="line">        :type s: str</span><br><span class="line">        :type wordDict: List[str]</span><br><span class="line">        :rtype: List[str]</span><br><span class="line">        """</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def dfs(index):</span><br><span class="line">            if index &gt;= len(s):</span><br><span class="line">                return ['']</span><br><span class="line">            cur = []</span><br><span class="line">            for word in wordDict:</span><br><span class="line">                if s[index: index + len(word)] == word:</span><br><span class="line">                    next = dfs(index + len(word))</span><br><span class="line">                    cur += [word + ' ' + x for x in next]</span><br><span class="line">            return cur</span><br><span class="line"></span><br><span class="line">        return [x[:-1] for x in dfs(0)]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  记忆化是非常重要的考察内容之一，在DFS中十分常见，普通的DFS难度较小，因此增加记忆化提高难度，也符合现在笔试面试的要求。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
        <category>字符串</category>
        <category>记忆化</category>
      </categories>
  </entry>
  <entry>
    <title>O(1) 时间插入、删除和获取随机元素 - 允许重复(Leetcode 381)</title>
    <url>/2020/11/14/program%20Leetcode381/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode381.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   设计题目也是面试的重点，这不仅仅考察小伙伴们的算法能力，思为能力，还考察小伙伴们对数据结构的掌握能力。这种题目难度往往不大，通过已有的一些数据结构加以变化，那么采用哪些已有的数据结构是这种题型的难点。<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>这里要求我们以$O(1)$的时间复杂度完成插入，移除和随机获取操作。</p>
<p>首先分析题目的意思，<strong>如果要以$O(1)$插入和获取，可以通过列表完成，题目不要求集合中元素的顺序，因此直接尾插元素即可，获取时可以随机索引获得元素。但是移除时，时间复杂度是$O(n)$的</strong>。</p>
<p><strong>如果要以$O(1)$插入和移除，可以通过哈希表完成，但是随机获取元素时，因为哈希表中的元素只能出现一次，所以无法保证返回元素的概率与其数量线性相关</strong>。</p>
<p><strong>发现列表移除元素时间复杂度过高，是因为移除的元素并不一定在末尾，如果每次移除的元素都在末尾，那么可以实现以$O(1)$移除元素</strong>。如何保证每次移除的元素都在列表末尾？我们可以通过交换该元素与最后一个元素出现的位置，使用一个字典记录每个元素出现的位置。如列表为[1, 2, 3, 4, 5]，我们要移除3这个元素，我们先将3和5进行调换，然后移除最后的元素3即可。</p>
<p><strong>要注意如果要移除的元素已经在末尾，则不需要调换，直接移除最后一个元素即可。如果要移除的元素不在末尾，要将末尾的元素的索引改为要移除元素的索引，将列标中对应位置的元素改为末尾元素</strong>。</p>
<p><strong>还要注意，使用字典记录每个元素出现的位置时，字典中的键为元素值，字典中的值是一个哈希表，为什么要使用哈希表？是因为修改末尾元素的索引时，通过移除和添加操作的时间复杂度为$O(1)$，如果使用列表，那么要查找末尾元素的索引，然后进行修改，时间复杂度为$O(n)$</strong></p>
<p>这个题目的关键是移除操作，代码并不难理解，小伙伴们认真想一想其中的逻辑关系。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line">from random import choice</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RandomizedCollection:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        """</span><br><span class="line">        Initialize your data structure here.</span><br><span class="line">        """</span><br><span class="line">        self.lis = []</span><br><span class="line">        self.dic = defaultdict(set)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def insert(self, val: int) -&gt; bool:</span><br><span class="line">        """</span><br><span class="line">        Inserts a value to the collection. Returns true if the collection did not already contain the specified element.</span><br><span class="line">        """</span><br><span class="line">        self.dic[val].add(len(self.lis))</span><br><span class="line">        self.lis.append(val)</span><br><span class="line">        return len(self.dic[val]) == 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def remove(self, val: int) -&gt; bool:</span><br><span class="line">        """</span><br><span class="line">        Removes a value from the collection. Returns true if the collection contained the specified element.</span><br><span class="line">        """</span><br><span class="line">        if len(self.dic[val]) &gt; 0:</span><br><span class="line">            idx = self.dic[val].pop()</span><br><span class="line">            if idx == len(self.lis) - 1:</span><br><span class="line">                self.lis.pop()</span><br><span class="line">            else:</span><br><span class="line">                val1 = self.lis.pop()</span><br><span class="line">                self.lis[idx] = val1</span><br><span class="line">                self.dic[val1].remove(len(self.lis))</span><br><span class="line">                self.dic[val1].add(idx)</span><br><span class="line">            return True</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def getRandom(self) -&gt; int:</span><br><span class="line">        """</span><br><span class="line">        Get a random element from the collection.</span><br><span class="line">        """</span><br><span class="line">        return choice(self.lis)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  设计题是非常有趣的，也比较贴近于生活的实际应用，也许刚刚开始接触这种题型不太适应，多见识一些题目就会变得越来越强。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>实现 Trie (前缀树)(Leetcode 208)</title>
    <url>/2020/11/12/program%20Leetcode208/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode208.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   在三面字节的时候撕过这个算法，之前没有遇到这个题目，虽然撕出来了，但是效率相对较低，在第一种解法中列举了我当时的代码，然后会给出一个更优化的版本提供小伙伴们学习。<br><a id="more"></a></p>
<h1 id="前缀树"><a href="#前缀树" class="headerlink" title="前缀树"></a><font size="5" color="red">前缀树</font></h1><p>我们按照题目的思路进行思考，以示例为参考，画一个Trie树。<br><img src="/images/ALGORITHM/leetcode208_trie.png" alt="1"><br><strong>每一个节点都有两个属性，一个是该节点代表的字符，一个是该节点的孩子。因此一个简单的想法就是创建一个数据结构，其中包括val和child两个属性。val是字符串，child是孩子的集合</strong>。</p>
<p><strong>插入时</strong>：看当前节点的孩子中，有没有val等于该字符的，如果有则递归寻找下一个字符，如果没有，则需要递归创建一条新的路径。注意在最后要加入终止字符，说明有这个单词出现。如apple单词，这时查找app也可以查到，但是加入了终止位以后，查到app时还要判断后面是否有终止位，就无法查到app单词了。<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。</p>
<p><strong>查找单词时</strong>：看当前节点的孩子中，有没有val等于该字符的，如果有则递归寻找下一个字符，如果没有，则直接返回False。当所有字符都找到后，还需要查找终止位，如果有终止位，则说明查到了，否则没有查到。<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。</p>
<p><strong>查找前缀时</strong>：和查找单词类似，只不过不用查找终止位，如果所有字符都查到则返回True即可。<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class TreeNode:</span><br><span class="line">    def __init__(self, val):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.child = set()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Trie:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        """</span><br><span class="line">        Initialize your data structure here.</span><br><span class="line">        """</span><br><span class="line">        self.dic = TreeNode(None)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def insert(self, word: str) -&gt; None:</span><br><span class="line">        """</span><br><span class="line">        Inserts a word into the trie.</span><br><span class="line">        """</span><br><span class="line">        cur = self.dic</span><br><span class="line">        for c in word:</span><br><span class="line">            for node in cur.child:</span><br><span class="line">                if node and c == node.val:</span><br><span class="line">                    cur = node</span><br><span class="line">                    break</span><br><span class="line">            else:</span><br><span class="line">                new_node = TreeNode(c)</span><br><span class="line">                cur.child.add(new_node)</span><br><span class="line">                cur = new_node</span><br><span class="line">        cur.child.add(None)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def search(self, word: str) -&gt; bool:</span><br><span class="line">        """</span><br><span class="line">        Returns if the word is in the trie.</span><br><span class="line">        """</span><br><span class="line">        cur = self.dic</span><br><span class="line">        for c in word:</span><br><span class="line">            for node in cur.child:</span><br><span class="line">                if node and c == node.val:</span><br><span class="line">                    cur = node</span><br><span class="line">                    break</span><br><span class="line">            else:</span><br><span class="line">                return False</span><br><span class="line">        return None in cur.child</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def startsWith(self, prefix: str) -&gt; bool:</span><br><span class="line">        """</span><br><span class="line">        Returns if there is any word in the trie that starts with the given prefix.</span><br><span class="line">        """</span><br><span class="line">        cur = self.dic</span><br><span class="line">        for c in prefix:</span><br><span class="line">            for node in cur.child:</span><br><span class="line">                if node and c == node.val:</span><br><span class="line">                    cur = node</span><br><span class="line">                    break</span><br><span class="line">            else:</span><br><span class="line">                return False</span><br><span class="line">        return True</span><br></pre></td></tr></tbody></table></figure>
<h1 id="优化前缀树"><a href="#优化前缀树" class="headerlink" title="优化前缀树"></a><font size="5" color="red">优化前缀树</font></h1><p>优化前缀树思路也非常简单，介绍一下就可以知道。<strong>Trie树可以看成一个字典，键就是节点的字符，值就是节点的孩子</strong>。因此不需要创建额外的类型，直接使用字典即可。</p>
<p>插入，查找的思路和前缀树相同，但是在字典中查找速度比遍历孩子节点更加迅速，代码量也更加简洁，这里就不过多介绍，直接看代码即可。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Trie:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        """</span><br><span class="line">        Initialize your data structure here.</span><br><span class="line">        """</span><br><span class="line">        self.dic = dict()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def insert(self, word: str) -&gt; None:</span><br><span class="line">        """</span><br><span class="line">        Inserts a word into the trie.</span><br><span class="line">        """</span><br><span class="line">        cur = self.dic</span><br><span class="line">        for c in word:</span><br><span class="line">            if c not in cur:</span><br><span class="line">                cur[c] = {}</span><br><span class="line">            cur = cur[c]</span><br><span class="line">        cur['#'] = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def search(self, word: str) -&gt; bool:</span><br><span class="line">        """</span><br><span class="line">        Returns if the word is in the trie.</span><br><span class="line">        """</span><br><span class="line">        cur = self.dic</span><br><span class="line">        for c in word:</span><br><span class="line">            if c not in cur:</span><br><span class="line">                return False</span><br><span class="line">            cur = cur[c]</span><br><span class="line">        return True if '#' in cur else False</span><br><span class="line"></span><br><span class="line">    def startsWith(self, prefix: str) -&gt; bool:</span><br><span class="line">        """</span><br><span class="line">        Returns if there is any word in the trie that starts with the given prefix.</span><br><span class="line">        """</span><br><span class="line">        cur = self.dic</span><br><span class="line">        for c in prefix:</span><br><span class="line">            if c not in cur:</span><br><span class="line">                return False</span><br><span class="line">            cur = cur[c]</span><br><span class="line">        return True</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  Trie树有很多经典的应用，如<strong>搜索引擎的自动补全机制，word中的拼写检查机制，手机九宫格打字预测</strong>等等。在许多算法题中<strong>trie树也称为前缀树，字典树</strong>，对于字符串匹配等问题可能有巧妙求解方法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>字符串</category>
        <category>前缀树</category>
      </categories>
  </entry>
  <entry>
    <title>最长连续序列(Leetcode 128)</title>
    <url>/2020/11/10/program%20Leetcode128/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode128.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   思路并不是十分困难，不要想的太复杂，原始想法会给你提供一些思路。<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>拿到题目先想一想有什么方法能够求解，然后再去思考有没有优化方案。不能直接追求极致的时空复杂度。</p>
<p>我来分析一下第一次遇到这个题目时我的一些想法。用题目中的例子进行说明。<br>[100, 4, 200, 1, 3, 2]，我们要求最长序列，我们首先看到的是100这个元素，如果有101这个元素，那么长度肯定要+1，如果有102这个元素，长度还要再+1，因此我们<strong>要循环查找有没有比当前元素大1的数</strong>。而且<strong>要注意有没有比当前元素小1的数</strong>，假如有99，我们就不需要考虑100这个元素，因为99也会循环查找到100，101，102等等。<strong>因此如果有比当前元素小1的数，我们就不进行查找。当没有比当前元素小1的数，说明当前元素就是某段连续序列中最小的一个数，我们开始循环查找</strong>。</p>
<p>算法中每个元素的外层循环需要遍历一次，找到某段连续序列最小值时内层循环遍历一次，因此<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def longestConsecutive(self, nums):</span><br><span class="line">        s = set(nums)</span><br><span class="line">        max_len = 0</span><br><span class="line">        for x in nums:</span><br><span class="line">            if x - 1 not in s:</span><br><span class="line">                cur_val, cur_len = x + 1, 1</span><br><span class="line">                while cur_val in s:</span><br><span class="line">                    cur_val, cur_len = cur_val + 1, cur_len + 1</span><br><span class="line">                max_len = max(max_len, cur_len)</span><br><span class="line">        return max_len</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目是字节跳动公司的算法题之一，有的小伙伴们在面试时遇到了这个问题。其实算法面试的时候代码量一般都不会特别大，但是算法的思想往往困惑了很多小伙伴，要想在面试中取得好成绩，一定要多多练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>寻找重复的子树(Leetcode 652)</title>
    <url>/2020/11/08/program%20Leetcode652/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode652.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目还是比较复杂的，能想到的方法是记录所有子树的结构，然后将结构序列化存入字典中，并记录每个结构出现的次数，当次数大于1说明有重复的结构。<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>通过递归获取子树结构，并将其结构保存为一个三元组，这样可以存放入字典中作为键。</p>
<p>算法需要遍历所有的节点，对于每一个节点要进行键的对比，因此<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n^2)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class TreeNode:</span><br><span class="line">    def __init__(self, val=0, left=None, right=None):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findDuplicateSubtrees(self, root):</span><br><span class="line">        def sub_question(node):</span><br><span class="line">            if not node:</span><br><span class="line">                return None</span><br><span class="line">            uid = (node.val, sub_question(node.left), sub_question(node.right))</span><br><span class="line">            dic[uid] += 1</span><br><span class="line">            if dic[uid] == 2:</span><br><span class="line">                res.append(node)</span><br><span class="line">            return uid</span><br><span class="line"></span><br><span class="line">        dic = defaultdict(int)</span><br><span class="line">        res = []</span><br><span class="line">        sub_question(root)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化哈希表"><a href="#优化哈希表" class="headerlink" title="优化哈希表"></a><font size="5" color="red">优化哈希表</font></h1><p>上面的算法如果树结构过大，运行效率非常慢，因为三元组记录着树的层次关系，因此在深层次的树形结构中，比较两个三元组是否相等需要浪费太多的时间。我们可以对三元组进行编号，字典中第一次出现的三元组记为0号，第二次出现的三元组记为1号，一次向下编号。那么我们就不需要比较三元组是否相等，只需要比较编号是否相等即可。</p>
<p>python3中defaultdict类，有default<em>factory成员变量，其控制着返回值的默认类型，如果为int，则新加入的元素值为0，如果为dic.<em>_len</em></em>，则新加入的元素值为dic中元素的个数，那么就相当于对元素进行编号。因为第一个元素加入前，dic中的元素个数为0，记为0号，第二个元素加入前，dic中的元素个数为1，记为1号。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class TreeNode:</span><br><span class="line">    def __init__(self, val=0, left=None, right=None):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def findDuplicateSubtrees(self, root):</span><br><span class="line">        def sub_question(node):</span><br><span class="line">            if node:</span><br><span class="line">                uid = dic[node.val, sub_question(node.left), sub_question(node.right)]</span><br><span class="line">                count[uid] += 1</span><br><span class="line">                if count[uid] == 2:</span><br><span class="line">                    res.append(node)</span><br><span class="line">                return uid</span><br><span class="line"></span><br><span class="line">        dic, count = defaultdict(), defaultdict(int)</span><br><span class="line">        dic.default_factory = dic.__len__</span><br><span class="line">        res = []</span><br><span class="line">        sub_question(root)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  优化版本的算法思想希望小伙伴能够掌握，尤其是python3中的写法，小伙伴们要加强联系。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>树</category>
        <category>递归</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>设计哈希映射(Leetcode 706)</title>
    <url>/2020/11/06/program%20Leetcode706/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode706.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目非常有价值，小伙伴们包括我也常常会出现一些问题，就是非常清楚哈希表的使用方法，但是让自己定义哈希表时就两眼抹黑，不知道如何下手。这也是年轻人普遍存在的问题，就像被制裁一样，为什么被制裁？就是因为我们拿到了一些上层的技术，直接使用非常方便，不去研究底层的原理，一旦不提供给我们上层技术，那么我们建造的大楼就会摇摇欲坠。这里也不过多深入讨论这个社会现象，<strong>因此小伙伴们在享受胜利果实的时候，一定要清楚底层的原理，这样才能在这个行业走得更远</strong>。<br><a id="more"></a></p>
<h1 id="投机取巧法"><a href="#投机取巧法" class="headerlink" title="投机取巧法"></a><font size="5" color="red">投机取巧法</font></h1><p>这个题目定义为简单题，可能是使用投机取巧法，<strong>因为所有值都是在[0, 1000000]以内，而且全都是整型，因此我们直接建立一个长度为1000001的数组，键就是索引，值就是索引对应的值即可</strong>。</p>
<p>这个方法只能解决这个问题，<strong>如果键的范围特别大则无法使用这种方法</strong>。因此这个方法不是一个通用解法。</p>
<p>算法每次操作的<strong>时间复杂度为$O(1)$，空间复杂度为$O(m)$</strong>，m为数据范围。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class MyHashMap(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        """</span><br><span class="line">        Initialize your data structure here.</span><br><span class="line">        """</span><br><span class="line">        self.dic = [-1] * 1000000</span><br><span class="line"></span><br><span class="line">    def put(self, key, value):</span><br><span class="line">        """</span><br><span class="line">        value will always be non-negative.</span><br><span class="line">        :type key: int</span><br><span class="line">        :type value: int</span><br><span class="line">        :rtype: None</span><br><span class="line">        """</span><br><span class="line">        self.dic[key] = value</span><br><span class="line"></span><br><span class="line">    def get(self, key):</span><br><span class="line">        """</span><br><span class="line">        Returns the value to which the specified key is mapped, or -1 if this map contains no mapping for the key</span><br><span class="line">        :type key: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        return self.dic[key]</span><br><span class="line"></span><br><span class="line">    def remove(self, key):</span><br><span class="line">        """</span><br><span class="line">        Removes the mapping of the specified value key if this map contains a mapping for the key</span><br><span class="line">        :type key: int</span><br><span class="line">        :rtype: None</span><br><span class="line">        """</span><br><span class="line">        self.dic[key] = -1</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="开放寻址法"><a href="#开放寻址法" class="headerlink" title="开放寻址法"></a><font size="5" color="red">开放寻址法</font></h1><p><strong>一个较好的方法是开放寻址法，就像办理业务一样，每一个键都对应一个服务台，如果有两个键对应同一个服务台，即发生了冲突，则顺次寻找下一个服务台</strong>。</p>
<p>初始时都默认为一个不会被取到的值，在这里就默认为-1，说明没有人占用该服务台。</p>
<p><strong>插入键值对时</strong>：如果某个哈希值为k，则k服务台被占用，当下一次某个哈希值为k时，依次向下寻找，如果该键不是-1，说明被占用，比较两个键是否相等，如果相等则替换值即可，如果不相等继续向下寻找。找到第一个空位置-1时，将该位置放入键值对即可。</p>
<p><strong>获取值时</strong>：当键对应的哈希值为k时，依次向下寻找，如果该键不是-1，说明被占用，比较两个键是否相等，如果相等则返回值即可，如果不相等继续向下寻找。找到第一个空位置-1时，说明没有找到该元素，返回-1。</p>
<p><strong>删除键值对时</strong>：这个要特别注意，当键对应的哈希值为k时，依次向下寻找，如果该键不是-1，说明被占用，比较两个键是否相等，<strong>如果相等则将键值对改为-2，不能改成-1</strong>，小伙伴们想一想为什么？如果不相等继续向下寻找，找到第一个空位置-1时，说明没有找到该元素，不用删除操作，直接return即可。</p>
<p>如果改成-1，那么后面的就会被切断了，举个例子，(2, 2)，(5, 5)，(8, 8)中的键都对应哈希值10，那么插入时，dic[10] = (2, 2)，dic[11] = (5, 5), dic[12] = (8, 8)，如果删除了(5, 5)，则先检查dic[10]，发现键不相等，则继续寻找dic[11]，发现匹配，则将dic[11]改成[-1, -1]，那么下一次查找(8, 8)时，也是先检查dic[10]，发现不相等，继续寻找dic[11]，发现-1，则不继续寻找了。这就会产生问题。因此要改成-2。</p>
<p>因此这种方法的局限性也很容易的看出，就是会浪费大量内存，需要内存数量大于操作次数。</p>
<p>算法最坏情况下<strong>时间复杂度为$O(n)$，均摊每次操作的</strong>时间复杂度为$O(1)$，空间复杂度为$O(n)$**，其中n为操作次数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def my_hash(key):</span><br><span class="line">    return key % 10007</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyHashMap(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        """</span><br><span class="line">        Initialize your data structure here.</span><br><span class="line">        """</span><br><span class="line">        self.dic = [[-1, -1] for _ in range(10007)]</span><br><span class="line"></span><br><span class="line">    def put(self, key, value):</span><br><span class="line">        """</span><br><span class="line">        value will always be non-negative.</span><br><span class="line">        :type key: int</span><br><span class="line">        :type value: int</span><br><span class="line">        :rtype: None</span><br><span class="line">        """</span><br><span class="line">        hash_key = my_hash(key)</span><br><span class="line">        while self.dic[hash_key][0] != -1:</span><br><span class="line">            if self.dic[hash_key][0] == key:</span><br><span class="line">                self.dic[hash_key][1] = value</span><br><span class="line">                return </span><br><span class="line">            hash_key = (hash_key + 1) % len(self.dic)</span><br><span class="line">        self.dic[hash_key] = [key, value]</span><br><span class="line"></span><br><span class="line">    def get(self, key):</span><br><span class="line">        """</span><br><span class="line">        Returns the value to which the specified key is mapped, or -1 if this map contains no mapping for the key</span><br><span class="line">        :type key: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        hash_key = my_hash(key)</span><br><span class="line">        while self.dic[hash_key][0] != -1:</span><br><span class="line">            if self.dic[hash_key][0] == key:</span><br><span class="line">                return self.dic[hash_key][1]</span><br><span class="line">            hash_key = (hash_key + 1) % len(self.dic)</span><br><span class="line">        return -1</span><br><span class="line"></span><br><span class="line">    def remove(self, key):</span><br><span class="line">        """</span><br><span class="line">        Removes the mapping of the specified value key if this map contains a mapping for the key</span><br><span class="line">        :type key: int</span><br><span class="line">        :rtype: None</span><br><span class="line">        """</span><br><span class="line">        hash_key = my_hash(key)</span><br><span class="line">        while self.dic[hash_key][0] != -1:</span><br><span class="line">            if self.dic[hash_key][0] == key:</span><br><span class="line">                self.dic[hash_key] = [-2, -2] </span><br><span class="line">            hash_key = (hash_key + 1) % len(self.dic)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="拉链法"><a href="#拉链法" class="headerlink" title="拉链法"></a><font size="5" color="red">拉链法</font></h1><p>拉链法是我认为最优的解法，不会浪费大量内存，但是需要用链表保存，需要额外的空间存放指针，而且代码写起来较为繁琐。</p>
<p>其解决冲突的思想是，将每一个哈希值对应一个链表，节点的值为一个二元组，第一个元素为键，第二个元素为值。</p>
<p><strong>插入键值对时</strong>：如果某个哈希值为k，寻找第k个链表，从头到尾进行遍历，如果链表某个节点的第一个元素等于键，则直接将第二个元素修改为值即可，如果遍历到链表尾部，则在尾部插入一个节点，该节点的值为键值对即可。</p>
<p><strong>获取值时</strong>：如果某个哈希值为k，寻找第k个链表，从头到尾进行遍历，如果链表某个节点的第一个元素等于键，则直接将第二个元素返回即可，如果遍历到链表尾部，则返回-1。</p>
<p><strong>删除键值对时</strong>：如果某个哈希值为k，寻找第k个链表，从头到尾进行遍历，如果链表某个节点的第一个元素等于键，则直接将该节点的上一个节点指向该节点的下一个节点即可，如果遍历到链表尾部，则没有找到该键值对，不需要进行任何操作。</p>
<p>算法最坏情况下<strong>时间复杂度为$O(n)$，均摊每次操作的</strong>时间复杂度为$O(1)$，空间复杂度为$O(n)$**，其中n为操作次数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Linklist:</span><br><span class="line">    def __init__(self, val=None, next=None):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.next = next</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def my_hash(key):</span><br><span class="line">    return key % 10007</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyHashMap(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        """</span><br><span class="line">        Initialize your data structure here.</span><br><span class="line">        """</span><br><span class="line">        self.dic = [Linklist([None, None]) for _ in range(10007)]</span><br><span class="line"></span><br><span class="line">    def put(self, key, value):</span><br><span class="line">        """</span><br><span class="line">        value will always be non-negative.</span><br><span class="line">        :type key: int</span><br><span class="line">        :type value: int</span><br><span class="line">        :rtype: None</span><br><span class="line">        """</span><br><span class="line">        hash_key = my_hash(key)</span><br><span class="line">        p = self.dic[hash_key]</span><br><span class="line">        while p.next:</span><br><span class="line">            if p.next.val[0] == key:</span><br><span class="line">                p.next.val[1] = value</span><br><span class="line">                return</span><br><span class="line">            else:</span><br><span class="line">                p = p.next</span><br><span class="line">        p.next = Linklist([key, value])</span><br><span class="line"></span><br><span class="line">    def get(self, key):</span><br><span class="line">        """</span><br><span class="line">        Returns the value to which the specified key is mapped, or -1 if this map contains no mapping for the key</span><br><span class="line">        :type key: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        hash_key = my_hash(key)</span><br><span class="line">        p = self.dic[hash_key]</span><br><span class="line">        while p:</span><br><span class="line">            if p.val[0] == key:</span><br><span class="line">                return p.val[1]</span><br><span class="line">            else:</span><br><span class="line">                p = p.next</span><br><span class="line">        return -1</span><br><span class="line"></span><br><span class="line">    def remove(self, key):</span><br><span class="line">        """</span><br><span class="line">        Removes the mapping of the specified value key if this map contains a mapping for the key</span><br><span class="line">        :type key: int</span><br><span class="line">        :rtype: None</span><br><span class="line">        """</span><br><span class="line">        hash_key = my_hash(key)</span><br><span class="line">        p = self.dic[hash_key]</span><br><span class="line">        pre, cur = p, p.next</span><br><span class="line">        while cur:</span><br><span class="line">            if cur.val[0] == key:</span><br><span class="line">                pre.next = cur.next</span><br><span class="line">                return</span><br><span class="line">            else:</span><br><span class="line">                pre, cur = cur, cur.next</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目真是太妙了，考察了常用数据结构的创建，也许今后小伙伴们可以直接使用dict数据结构，不需要手动创建，但是<strong>摆脱拿过来直接用的思维惰性是非常非常重要的</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>连续数组(Leetcode 525)</title>
    <url>/2020/11/04/program%20Leetcode525/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode525.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最近的题目是哈希表专题，希望小伙伴能够坚持练习，这个问题难度不大，先认真思考5分钟，看一看能够想出多少种解法。<br><a id="more"></a></p>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p><strong>枚举起点和终点，计算区间内0和1的个数是否相等</strong>。这个思路最容易想到，但是时间复杂度最高。</p>
<p>此题可以进行稍微优化，因为要求最长的连续子数组，因此可以按照长度从大到小进行遍历。</p>
<p>算法的<strong>时间复杂度为$O(n^3)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findMaxLength(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        for interval in range(len(nums), -1, -1):</span><br><span class="line">            if not interval % 2:</span><br><span class="line">                for i in range(len(nums) - interval + 1):</span><br><span class="line">                    if len([1 for j in range(i, i + interval) if nums[j] == 0]) == interval / 2:</span><br><span class="line">                        return interval</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化暴力法"><a href="#优化暴力法" class="headerlink" title="优化暴力法"></a><font size="5" color="red">优化暴力法</font></h1><p><strong>利用前缀和的特点，计算区间内0和1个数时，节省一层循环。但是要牺牲一些空间复杂度用于存放前缀和</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findMaxLength(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        cursum = [0]</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            cursum.append(cursum[-1] + nums[i])</span><br><span class="line">        for interval in range(len(nums), -1, -1):</span><br><span class="line">            if not interval % 2:</span><br><span class="line">                for i in range(len(nums) - interval + 1):</span><br><span class="line">                    if cursum[i + interval] - cursum[i] == interval / 2:</span><br><span class="line">                        return interval</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p>根据一般性规律，我们可以从题目中寻找一些提示。<strong>算法一般能够接受的时间复杂度再1e8以内，而这个题目的长度可以达到50000，因此使用$O(n^2)$的时间复杂度都会TLE。因此我们要想出一些$O(n)$或者$O(nlog(n))$的算法进行求解</strong>。</p>
<p>数量相同的0和1是包含着一些规律的，如果出现0则计数加1，出现1则计数减1，那么这个计数代表着0和1的相对差。如果i处和j处的相对差相等，说明从i+1到j的序列中0和1的个数是相同的。</p>
<p>我们只需要记录每个绝对差第一次出现的索引i，如果出现相等的绝对差，则记录长度，求出最大的长度即可。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findMaxLength(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        cur, dic, max_val = 0, {0: -1}, 0</span><br><span class="line">        for i, v in enumerate(nums):</span><br><span class="line">            if v == 0:</span><br><span class="line">                cur += 1</span><br><span class="line">            else:</span><br><span class="line">                cur -= 1</span><br><span class="line">            if cur in dic:</span><br><span class="line">                max_val = max(max_val, i - dic[cur])</span><br><span class="line">            else:</span><br><span class="line">                dic[cur] = i</span><br><span class="line">        return max_val</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  有感而发~，随着内卷越来越严重，公司对人才的要求也越来越苛刻，小伙伴们如果想要大的平台和更多的机遇，一定要加强代码能力，有些人就会说这有什么用？当你做的题目足够多的时候，就会慢慢的察觉到它的作用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>和为K的子数组(Leetcode 560)</title>
    <url>/2020/11/02/program%20Leetcode560/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode560.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   连续子数组的和，一定会用得到前缀和概念，可以节省大量的计算。cursum数组表示前缀和，cursum[i]表示前i个元素的和。cursum[0] = 0，那么从第m个元素到第n个元素的连续子数组的和为cursum[n] - cursum[m - 1]。<br><a id="more"></a></p>
<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a><font size="5" color="red">哈希表</font></h1><p><strong>首先计算数组的前缀和，如果前缀和cursum[j] - cursum[i] = k，那么说明从第i + 1个元素到第j个元素组成的子序列之和为k。因此题目转换为遍历j，寻找满足cursum[i] = cursum[j] - k公式中i的个数</strong>。</p>
<p>将遍历过的数都加入哈希表，这样寻找满足公式中i的个数时直接取出即可。</p>
<p><strong>注意此题是有顺序的，即i是小于j的，因此不能将所有cursum的值都存入哈希表，只能遍历过的点存入，这样才能保证取出的点都是小于j的。而有的题目是需要将cursum的值先全部存入哈希表，然后再进行遍历。</strong></p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def subarraySum(self, nums, k):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :type k: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        cursum, res, dic = 0, 0, defaultdict(int)</span><br><span class="line">        dic[0] = 1</span><br><span class="line">        for x in nums:</span><br><span class="line">            cursum += x</span><br><span class="line">            res += dic[cursum - k]</span><br><span class="line">            dic[cursum] += 1</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  有趣的数组题，数组是笔试面试中的常考题型，表述简单，思路清晰，是小伙伴们需要加强的重点题型。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>四数相加 II(Leetcode 454)</title>
    <url>/2020/10/31/program%20Leetcode454/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode454.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   第一次见到这个题目是在2年前了，当初的我比现在还要菜得多，拿到题目想了10秒，4个for循环嘛~，然后TLE，随着刷的题目越来越多，时间复杂度逐渐降低。<br><a id="more"></a></p>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>4个for循环，没啥好说的。</p>
<p>算法的<strong>时间复杂度为$O(n^4)$，空间复杂度为$O(1)$</strong>。用Python3的列表表达式可以简化代码，但是空间复杂度会变高，在这里就采用简化写法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def fourSumCount(self, A, B, C, D):</span><br><span class="line">        """</span><br><span class="line">        :type A: List[int]</span><br><span class="line">        :type B: List[int]</span><br><span class="line">        :type C: List[int]</span><br><span class="line">        :type D: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        return len([0 for a in A for b in B for c in C for d in D if a + b + c + d == 0])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化暴力法"><a href="#优化暴力法" class="headerlink" title="优化暴力法"></a><font size="5" color="red">优化暴力法</font></h1><p><strong>第4个for循环可以改成哈希表，进行查询即可，如前3层循环得到了k，则查找D列表中-k的个数即可。这样时间复杂度可以降低一个维度</strong>。</p>
<p>而且<strong>遇到重复元素，可以保存在该层的哈希表中，如A中存在多个a元素，那么只需要计算第一次出现的a，当下次遍历到a时，直接查表取出数值即可</strong>。但是要注意这个哈希表是该层的，如B中存在多个b元素，那么对于每一个A中的元素，B都要重新创建该层的哈希表。</p>
<p>算法的<strong>时间复杂度为$O(n^3)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def fourSumCount(self, A, B, C, D):</span><br><span class="line">        """</span><br><span class="line">        :type A: List[int]</span><br><span class="line">        :type B: List[int]</span><br><span class="line">        :type C: List[int]</span><br><span class="line">        :type D: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        res = 0</span><br><span class="line">        dic_d = Counter(D)</span><br><span class="line">        dic_a = dict()</span><br><span class="line">        for a in A:</span><br><span class="line">            if a in dic_a:</span><br><span class="line">                res += dic_a[a]</span><br><span class="line">            else:</span><br><span class="line">                dic_b = dict()</span><br><span class="line">                for b in B:</span><br><span class="line">                    if b in dic_b:</span><br><span class="line">                        res += dic_b[b]</span><br><span class="line">                    else:</span><br><span class="line">                        dic_c = dict()</span><br><span class="line">                        for c in C:</span><br><span class="line">                            if c in dic_c:</span><br><span class="line">                                res += dic_c[c]</span><br><span class="line">                            else:</span><br><span class="line">                                res += dic_d[-a - b - c]</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="分治法"><a href="#分治法" class="headerlink" title="分治法"></a><font size="5" color="red">分治法</font></h1><p>这里的分治法只是意义上的将一个问题转换为两个子问题的表述。其实优化的暴力版本已经使用了分治法的思想。我们将a+b+c+d=0的问题看成了a+b+c=-d，因此将d放入哈希表中进行查找。那么如果将a+b+c+d=0看成a+b=-c-d如何呢？</p>
<p><strong>我们计算a+b的值，存放在哈希表中，计算c+d的值也存放在哈希表中。那么又会减少一层循环，但是空间复杂度会高，因为不是存放d的值，而是存放c+d的值</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n^2)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def fourSumCount(self, A, B, C, D):</span><br><span class="line">        """</span><br><span class="line">        :type A: List[int]</span><br><span class="line">        :type B: List[int]</span><br><span class="line">        :type C: List[int]</span><br><span class="line">        :type D: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        dic_ab, dic_cd = Counter([a + b for a in A for b in B]), Counter([-c - d for c in C for d in D])</span><br><span class="line">        return sum([dic_ab[x] * dic_cd[x] for x in dic_ab])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这种题型并不难，和其他题型不同的是，其他类型的变种很复杂，可能这个题目会做，换一个题目就不会了，而该题型只要见过一次，一定会想起来如何求解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>哈希表</category>
      </categories>
  </entry>
  <entry>
    <title>132模式(Leetcode 456)</title>
    <url>/2020/10/29/program%20Leetcode456/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode456.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目非常有趣，而且题意清晰，考察单调栈的思路，单调栈的题目时间复杂度往往是<strong>$O(n)$</strong>量级，小伙伴们先思考应该如何求解，如果不是$O(n)$的时间复杂度，再去想一想如何优化。<br><a id="more"></a></p>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>我们先分析这个题目，要求是132模式，因此<strong>对于$a_i, a_j, a_k, \ i &lt; j &lt; k$来说，$a_i$应当越小越好，所以若$a_i$满足条件，则取前j个数的最小值一定也满足条件</strong>。</p>
<p>首先我们记录最小的前缀，然后我们遍历所有的元素，将每一个元素作为$a_j$，然后寻找在j索引之后，小于$a_j$的最大值$a_k$即可。若找到$a_k$大于$a_i$则返回True，如果遍历所有元素都没有找到则返回False。</p>
<p>算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def find132pattern(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: bool</span><br><span class="line">        """</span><br><span class="line">        mini = [nums[0]]</span><br><span class="line">        for x in nums[1:]:</span><br><span class="line">            mini.append(min(mini[-1], x))</span><br><span class="line">        for j in range(1, len(nums) - 1):</span><br><span class="line">            if nums[j] &gt; mini[j]:</span><br><span class="line">                maxi = -float('inf')</span><br><span class="line">                for k in range(j + 1, len(nums)):</span><br><span class="line">                    if maxi &lt; nums[k] &lt; nums[j]:</span><br><span class="line">                        maxi = nums[k]</span><br><span class="line">                if maxi &gt; mini[j]:</span><br><span class="line">                    return True</span><br><span class="line">        return False</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a><font size="5" color="red">单调栈</font></h1><p>单调栈的思路是维护一个单调递减的栈，栈内元素的含义是，当前元素之后的备选方案，是132模式中的2，最小前缀的含义是当前元素之前的备选方案，是132模式中的1。</p>
<p><strong>如果栈顶元素小于等于最小前缀，说明$a_k$较小，应当弹出，当某个元素$a_k$大于最小前缀时，说明满足了$a_k &gt; a_i$的条件，再判断$a_k$和$a_j$的大小关系即可。如果$a_k &lt; a_j$则找到了符合132模式的序列，返回True，如果遍历所有的j都没有找到，则返回False</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def find132pattern(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: bool</span><br><span class="line">        """</span><br><span class="line">        mini, stack = [nums[0]], []</span><br><span class="line">        for x in nums[1:]:</span><br><span class="line">            mini.append(min(mini[-1], x))</span><br><span class="line">        for i in range(len(nums) - 1, -1, -1):</span><br><span class="line">            if nums[i] &gt; mini[i]:</span><br><span class="line">                while stack and stack[-1] &lt;= mini[i]:</span><br><span class="line">                    stack.pop()</span><br><span class="line">                if stack and stack[-1] &lt; nums[i]:</span><br><span class="line">                    return True</span><br><span class="line">                stack.append(nums[i])</span><br><span class="line">        return False</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  对于数组题目来说，有一些常用的算法，如单调栈，单调队列，二分查找，动态规划等等，小伙伴们一定要多多练手，才能迅速求解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>单调栈/单调队列</category>
      </categories>
  </entry>
  <entry>
    <title>滑动窗口最大值(Leetcode 239)</title>
    <url>/2020/10/27/program%20Leetcode239/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode239.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个问题也是经典的算法之一了，也是图像处理或者信号处理中常常需要处理的问题。解法并不困难，能否找到最好的求解方法是这个题目的关键，小伙伴们先想一想如何解答。<br><a id="more"></a></p>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>暴力法不需要过多解释，代码也非常简单。把每一个区间都遍历一下，求出最大值即可，但是对于本题来说，数据量较大会超时。</p>
<p>算法的<strong>时间复杂度为$O(nk)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxSlidingWindow(self, nums, k):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :type k: int</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        return [max(nums[i:i + k]) for i in range(len(nums) - k + 1)]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="单调队列"><a href="#单调队列" class="headerlink" title="单调队列"></a><font size="5" color="red">单调队列</font></h1><p>思考这个问题，<strong>滑动窗口出现一个很大的数字M时，那么滑动窗口中小于等于该数字的都是无意义的，因为如果取得这些数，一定不如取M</strong>。因此我们需要维护一个单调递减的队列。</p>
<p><strong>要注意和单调栈的区别，单调递减的栈中，最大元素是永远不会被弹出的，而滑动窗口中的最大元素可能会弹出</strong>。因此我们<strong>在滑动窗口中保存元素的索引位置，当第一个元素的索引已经不在窗口中时，将该元素弹出</strong>。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def maxSlidingWindow(self, nums, k):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :type k: int</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        queue = deque()</span><br><span class="line">        res = []</span><br><span class="line">        for i, x in enumerate(nums):</span><br><span class="line">            if queue and queue[0] + k &lt;= i:</span><br><span class="line">                queue.popleft()</span><br><span class="line">            while queue and nums[queue[-1]] &lt;= x:</span><br><span class="line">                queue.pop()</span><br><span class="line">            queue.append(i)</span><br><span class="line">            res.append(nums[queue[0]])</span><br><span class="line">        return res[k - 1:]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  小伙伴们遇到这个题目，一定不要用暴力法求解，一旦用了，基本上是挂了。现在招聘的难度越来越大，内卷越来越严重。因此算法题基本上都是力扣mid以上，所以小伙伴们要多刷mid和hard题，提高自身的实力。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>单调栈/单调队列</category>
      </categories>
  </entry>
  <entry>
    <title>供暖器(Leetcode 475)</title>
    <url>/2020/10/25/program%20Leetcode475/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode475.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最近忙于论文，停更了一段时间，现在继续我们的刷题之旅。我们要寻找最小的加热半径，因为每一个房屋都需要加热到，因此我们<strong>找到距离每个房屋最近的供暖器到该房屋之间的距离，并求所有距离的最大值</strong>即可。<br><a id="more"></a></p>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>这个题目有一个小技巧，为了方便二分查找对于边界值的讨论，我们可以<strong>在正无穷和负无穷远处加上两个供暖器，这样就不会超出边界，也不用对特殊值进行分类讨论</strong>。</p>
<p>算法的<strong>时间复杂度为$O(mlog(n))$，空间复杂度为$O(1)$</strong>，其中m为房屋个数，n为供暖器个数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findRadius(self, houses, heaters):</span><br><span class="line">        """</span><br><span class="line">        :type houses: List[int]</span><br><span class="line">        :type heaters: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        heaters.append(float('inf'))</span><br><span class="line">        heaters.append(-float('inf'))</span><br><span class="line">        heaters.sort()</span><br><span class="line">        max_dis = 0</span><br><span class="line">        for h in houses:</span><br><span class="line">            left, right = 0, len(heaters)</span><br><span class="line">            while left &lt; right:</span><br><span class="line">                mid = (left + right) // 2</span><br><span class="line">                if heaters[mid] &gt;= h:</span><br><span class="line">                    right = mid</span><br><span class="line">                else:</span><br><span class="line">                    left = mid + 1</span><br><span class="line">            max_dis = max(max_dis, min(h - heaters[left - 1], heaters[left] - h))</span><br><span class="line">        return max_dis</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目难度不大，但是往往第一眼看上去并没有思路，小伙伴们需要多见一些题目，这样才能迅速反应过来如何求解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>出界的路径数(Leetcode 576)</title>
    <url>/2020/10/10/program%20Leetcode576/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode576.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   还是老规矩，小伙伴们先思考题解，然后参考下面的代码，如果直接看答案，可能当时会了，下次遇到还是不会的情况，因此做题之前思考是我们必须要经历的过程。<br><a id="more"></a></p>
<h1 id="记忆化"><a href="#记忆化" class="headerlink" title="记忆化"></a><font size="5" color="red">记忆化</font></h1><p>因为路径是可以来回走的，如N是4步，那么我向上走，再向下走回到了原点，还剩余2步。如果我向下走再向上走也回到了原点，也剩余两步。同理左右方向也是一样。则相当于从原点出发N为2步，需要计算4次，其实我们只需要计算一次即可，那么就需要记住从原点出发N为2所需要的步骤。</p>
<p>因此一种自顶向下的方法呼之欲出，在某一点(i, j)处，可以走N步，第一步可以向四周前进，剩下可以走N - 1步。因此可得递推关系式和边界条件。</p>
<script type="math/tex; mode=display">f(i, j, N) = \begin{cases} 0 & N = 0 \\ 1 & i < 0 || i \ge m || j < 0 || j \ge n \\ f(i - 1, j, N - 1) + f(i + 1, j, N - 1) + f(i, j - 1, N - 1) + f(i, j + 1, N - 1) & else \end{cases}</script><p><strong>在Python中，可以使用lru_cache保存函数运行的结果，其他语言需要写一个字典，其中键为i, j和N，值为f(i, j, N)的结果。运行后将结果保存在字典中，下次运行时直接进行查找，如果在字典中则将其取出</strong>。算法的<strong>时间复杂度为$O(mnN)$，空间复杂度为$O(mnN)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def findPaths(self, m, n, N, i, j):</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def dfs(i, j, N):</span><br><span class="line">            if N == 0:</span><br><span class="line">                return 0</span><br><span class="line">            tmp = 0</span><br><span class="line">            for di, dj in direction:</span><br><span class="line">                new_i, new_j = i + di, j + dj</span><br><span class="line">                if 0 &lt;= new_i &lt; m and 0 &lt;= new_j &lt; n:</span><br><span class="line">                    tmp += dfs(new_i, new_j, N - 1)</span><br><span class="line">                else:</span><br><span class="line">                    tmp += 1</span><br><span class="line">            return tmp</span><br><span class="line">        direction = [[1, 0], [-1, 0], [0, 1], [0, -1]]</span><br><span class="line">        return dfs(i, j, N) % 1000000007</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="记忆化Python实现"><a href="#记忆化Python实现" class="headerlink" title="记忆化Python实现"></a><font size="5" color="red">记忆化Python实现</font></h1><p>这里给出了一种记忆化的实现方案，算法的思路和上面完全相同，不用lru_cache，而是手动维护一个字典，保存了每一次的计算结果。算法的<strong>时间复杂度为$O(mnN)$，空间复杂度为$O(mnN)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findPaths(self, m, n, N, i, j):</span><br><span class="line">        def dfs(i, j, N):</span><br><span class="line">            if N == 0:</span><br><span class="line">                return 0</span><br><span class="line">            if (i, j, N) in dic:</span><br><span class="line">                return dic[(i, j, N)]</span><br><span class="line">            tmp = 0</span><br><span class="line">            for di, dj in direction:</span><br><span class="line">                new_i, new_j = i + di, j + dj</span><br><span class="line">                if 0 &lt;= new_i &lt; m and 0 &lt;= new_j &lt; n:</span><br><span class="line">                    tmp += dfs(new_i, new_j, N - 1)</span><br><span class="line">                else:</span><br><span class="line">                    tmp += 1</span><br><span class="line">            dic[(i, j, N)] = tmp</span><br><span class="line">            return tmp</span><br><span class="line">        dic = {}</span><br><span class="line">        direction = [[1, 0], [-1, 0], [0, 1], [0, -1]]</span><br><span class="line">        return dfs(i, j, N) % 1000000007</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>动态规划其实也是一种记忆化的方式，动态规划就是保存了之前运行产生的状态，通过状态的传递快速求解出结果。因此这个题目也可以通过动态规划进行求解。</p>
<p>用dp[k][i][j]表示到花费k步，到达(i, j)一共有多少种不同的方法，可以通过dp[k - 1][i - 1][j]向下一步，可以通过dp[k - 1][i + 1][j]向上一步，可以通过dp[k - 1][i][j - 1]向右一步，可以通过dp[k - 1][i][j + 1]向左一步到达。</p>
<p>如果在向上，向下，向左或者向右到达了边界，说明这一步可以通过某个方向到达边界，因此在最终的结果上加上dp[k - 1][i][j]即可。算法的<strong>时间复杂度为$O(mnN)$，空间复杂度为$O(mnN)$</strong>。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findPaths(self, m, n, N, i, j):</span><br><span class="line">        direction = [[1, 0], [-1, 0], [0, 1], [0, -1]]</span><br><span class="line">        dp = [[[0 for _ in range(n)] for _ in range(m)] for _ in range(N + 1)]</span><br><span class="line">        dp[0][i][j] = 1</span><br><span class="line">        res = 0</span><br><span class="line">        for k in range(1, N + 1):</span><br><span class="line">            for x in range(m):</span><br><span class="line">                for y in range(n):</span><br><span class="line">                    for dx, dy in direction:</span><br><span class="line">                        new_x, new_y = x + dx, y + dy</span><br><span class="line">                        if 0 &lt;= new_x &lt; m and 0 &lt;= new_y &lt; n:</span><br><span class="line">                            dp[k][new_x][new_y] += dp[k - 1][x][y]</span><br><span class="line">                        else:</span><br><span class="line">                            res += dp[k - 1][x][y]</span><br><span class="line">        return res % 1000000007</span><br></pre></td></tr></tbody></table></figure>
<h1 id="逆向思维DP"><a href="#逆向思维DP" class="headerlink" title="逆向思维DP"></a><font size="5" color="red">逆向思维DP</font></h1><p>这种动态规划方法是一种<strong>农村包围城市</strong>的思想。<br><strong>上面的算法是通过初始的某个位置，每次向周围进行扩散，如果扩散到边界则加上相应的值。<br>而这个算法是通过边界向内部进行扩散</strong>。</p>
<ul>
<li><strong>up代表从上向下进行扩散，当i = 0时，说明是从上边界点扩散而来，此时有1种方案，否则，说明不是从上边界点扩散而来，此时有dp[k - 1][i - 1][j]种方案</strong>。</li>
<li><strong>down代表从下向上进行扩散，当i = m - 1时，说明是从下边界点扩散而来，此时有1种方案，否则，说明不是从下边界点扩散而来，此时有dp[k - 1][i + 1][j]种方案</strong>。</li>
<li><strong>left代表从左向右进行扩散，当j = 0时，说明是从左边界点扩散而来，此时有1种方案，否则，说明不是从左边界点扩散而来，此时有dp[k - 1][i][j - 1]种方案</strong>。</li>
<li><strong>right代表从右向左进行扩散，当j = n - 1时，说明是从右边界点扩散而来，此时有1种方案，否则，说明不是从右边界点扩散而来，此时有dp[k - 1][i][j + 1]种方案</strong>。</li>
</ul>
<p>当迭代N次以后，dp[N][i][j]就是在(i, j)这一点，通过N步能够到达边界的方案数。算法的<strong>时间复杂度为$O(mnN)$，空间复杂度为$O(mnN)$</strong>。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findPaths(self, m, n, N, i, j):</span><br><span class="line">        dp = [[[0 for _ in range(n)] for _ in range(m)] for _ in range(N + 1)]</span><br><span class="line">        for k in range(1, N + 1):</span><br><span class="line">            for x in range(m):</span><br><span class="line">                for y in range(n):</span><br><span class="line">                    up = 1 if x == 0 else dp[k - 1][x - 1][y]</span><br><span class="line">                    down = 1 if x == m - 1 else dp[k - 1][x + 1][y]</span><br><span class="line">                    left = 1 if y == 0 else dp[k - 1][x][y - 1]</span><br><span class="line">                    right = 1 if y == n - 1 else dp[k - 1][x][y + 1]</span><br><span class="line">                    dp[k][x][y] = (up + down + left + right)</span><br><span class="line">        return dp[N][i][j] % 1000000007</span><br></pre></td></tr></tbody></table></figure>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  虽然这个题目有很多种解法，<strong>我最喜欢的还是记忆化的方法，因为在DP中会浪费很多的空间和时间，虽然时空复杂度都是$O(mnN)$，但是记忆化是需要哪些点搜索哪些点，而DP就需要遍历所有的点。如N=1，记忆化只需要搜索当前位置的上下左右四个方向，而DP需要遍历地图上的所有点，i从0遍历到m - 1，j从0遍历到n - 1，对于每个点搜索四个方向。所以时空复杂度相对较高</strong>。不过DP方法的思路也是非常好的，可以作为本题的延申算法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>记忆化</category>
      </categories>
  </entry>
  <entry>
    <title>解码方法(Leetcode 91)</title>
    <url>/2020/10/09/program%20Leetcode91/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode91.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  在做这个题目之前，可以先去做Leetcode 70题或者经典的斐波那契数列，那两个题目是这类最简单的问题，然后再回来思考本题，就可能茅塞顿开。</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>这种题目是最经典的动态规划问题，<strong>和爬楼梯相同，要想爬前n阶楼梯，可以有两种方法，一个是通过n - 1阶爬1阶到n，也可以通过n - 2阶爬2阶到n</strong>。因此爬楼梯的状态转移方程是</p>
<script type="math/tex; mode=display">f[i] = \begin{cases} f[i - 1] + f[i - 2] & i \ge 2 \\ 1 & i < 2 \end{cases}</script><p><strong>这个题目相同，只是加了一些限制条件，当计算前n个数字有多少编码方式，可以通过前n - 1个数字的编码方式加上第n个数字的编码方式，也可以通过前n - 2个数字的编码方式加上n - 1和第n两个数字组成的编码方式</strong>。</p>
<p><strong>当第n个数字为0时，无法编码，即无法通过前n - 1个数字加上第n个数字的编码方式。<br>当第n -1和n两个组成的数字小于10或者大于26时，无法编码，即无法通过前n - 2个数字的编码方式加上n - 1和第n个数字组成的编码方式</strong>。</p>
<p><strong>用dp[i + 2]数组保存前i个数字的编码方式，并给初始值dp[0]和dp[1]都赋值为1</strong>。DP算法的<strong>时间复杂度为$O(n)，空间复杂度为$O(n)$</strong><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def numDecodings(self, s):</span><br><span class="line">        dp = [1, 1] + [0] * len(s)</span><br><span class="line">        for i in range(2, len(s) + 2):</span><br><span class="line">            if s[i - 2] != '0':</span><br><span class="line">                dp[i] += dp[i - 1]</span><br><span class="line">            if i - 3 &gt;= 0 and 10 &lt;= int(s[i - 3] + s[i - 2]) &lt;= 26:</span><br><span class="line">                dp[i] += dp[i - 2]</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DP"><a href="#优化DP" class="headerlink" title="优化DP"></a><font size="5" color="red">优化DP</font></h1><p>优化DP思路相同，只是我们<strong>不需要使用dp数组存放所有的编码个数，算法只用到了前一个和前两个字符的编码个数，因此我们只需要使用n_2和n_1表示前n - 2个和前n - 1个字符的编码个数</strong>。就像斐波那契数列一样使用a和b就可以求出f(n)。优化DP算法的<strong>时间复杂度为$O(n)，空间复杂度为$O(1)$</strong><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def numDecodings(self, s):</span><br><span class="line">        n_2, n_1 = [1, 1]</span><br><span class="line">        for i in range(2, len(s) + 2):</span><br><span class="line">            tmp = 0</span><br><span class="line">            if s[i - 2] != '0':</span><br><span class="line">                tmp = n_1</span><br><span class="line">            if i - 3 &gt;= 0 and 10 &lt;= int(s[i - 3] + s[i - 2]) &lt;= 26:</span><br><span class="line">                tmp += n_2</span><br><span class="line">            n_2, n_1 = n_1, tmp</span><br><span class="line">        return n_1</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这是动态规划题目中最最简单的问题了，笔试基本上不会遇到，面试可能会遇到，如果遇到了就太幸运了。但是如果这个题目做不出来的话，基本上就没后续了，小伙伴们一定要警惕。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>巧克力棒(某大厂手撕笔试题)</title>
    <url>/2020/10/07/program%20Interview8/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview8.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   太有趣了，某厂特别喜欢考数学题，基本上每次都有2题数学。数学是程序员的重要法宝，很多优化算法，人工智能都是建立在数学的基础上，因此学好数学才能在计算机的领域走的更好。小伙伴们不要害怕，下面看一看如何求解。</p>
<a id="more"></a>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>我们考虑两种情况：</p>
<ol>
<li>当L小于等于d时，不需要切割，因此输出为0</li>
<li>当L大于d时，则一定需要切割一次，设长度为x的木棒的切割期望为$f(x)$<ul>
<li>如果切割时剩余的长度t小于等于d时，则不需要下一次切割。</li>
<li>对于切割时剩余长度t大于d小于x时，则需要以$\frac{1}{x}$的概率下一次切割，切割期望为$f(t)$</li>
</ul>
</li>
</ol>
<p>因此可以得到下面这个方程</p>
<script type="math/tex; mode=display">f(x) = 1 + \frac{1}{x} \int_d^x f(t)dt \ \ \textcircled{1}</script><p>将等式两边同时求导</p>
<script type="math/tex; mode=display">f'(x) = -\frac{1}{x^2} \int_d^x f(t)dt + \frac{f(x)}{x} \ \ \textcircled{2}</script><p>将$\textcircled{1}$式进行变换</p>
<script type="math/tex; mode=display">-\frac{1}{x^2} \int_d^x f(t)dt = -\frac{1}{x}(f(x) - 1)</script><p>然后代入$\textcircled{2}$式，可得</p>
<script type="math/tex; mode=display">f'(x) = \frac{1}{x}</script><p>则有</p>
<script type="math/tex; mode=display">f(x) = ln(x) + C</script><p>将边界点$f(d) = 1$代入，可得</p>
<script type="math/tex; mode=display">1 = ln(d) + C</script><p>因此$C = 1 - ln(d)$，所以期望可以写为</p>
<script type="math/tex; mode=display">f(x) = \begin{cases} 0 & x \le d \\ ln(\frac{x}{d}) + 1 & x > d \end{cases}</script><p>得到公式以后，求解就迎刃而解了。算法的<strong>时间复杂度为$O(1)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    L, d = [int(x) for x in line.strip().split()]</span><br><span class="line">    print('0.0000') if L &lt;= d else print('%.4f' % (math.log(L / d) + 1))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  <strong>这类题目往往有两个思路，一个是代入公式进行推导计算，例如本题，求出最后的表达式，因为不涉及算法层面，只是考察数学运用能力，所以这种题型较少。更多题型的是使用递归的思路进行迭代计算，当满足一定条件，通常是误差小于指定精度停止计算，得到最后的结果</strong>。这两种题型不难，但是如果没有见过可能很难想到，因此小伙伴们需要掌握几道这种类型的题目。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>求最长的山谷序列(某大厂手撕笔试题)</title>
    <url>/2020/10/05/program%20Interview7/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview7.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目有一些难度，有些类似于LIS(最长上升子序列)问题，但是难度比它大，因为不单单是上升问题，还要下降，并且两部分长度要相等，且中间的元素值相等。这应该如何求解呢？能否仍然利用上升子序列的思想去做呢？</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们需要找到从初始位置到i的最长下降子序列lds_array，然后找到从j到最后位置的最长上升子序列lis_array。然后当array[i] = array[j]时，看最长下降子序列lds_array[i]的值，然后看最长上升子序列lis_array[j]的值，因为两个长度要相等，因此只能选择两者的较小值乘2作为有效的长度。</p>
<p>要强调的是，这个问题不需要写两种，虽然既要使用LIS，也要使用LDS。但是我们发现从初始位置到i是LDS问题，从j到最后位置是LIS问题，但是从最后位置到j位置是一个LDS问题，因此将数组逆序，再传入最长下降子序列函数，最后将得到的最长下降子序列长度再逆序即可。</p>
<p>这就是这个题目的思路，其实说到底还是LIS问题。有关LIS的解法可以参考Leetcode 300博客，里面有详细的说明。这里就不过多赘述，给出LDS的写法。</p>
<p>这个标题是使用动态规划求解LIS问题，求解LIS的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。因为要遍历i和j，因此整体<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def LDS(array):</span><br><span class="line">    dp = [1] * n</span><br><span class="line">    for i in range(n):</span><br><span class="line">        for j in range(i):</span><br><span class="line">            if array[j] &gt; array[i]:</span><br><span class="line">                dp[i] = max(dp[i], dp[j] + 1)</span><br><span class="line">    return dp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n = int(line.strip())</span><br><span class="line">    array = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    lds_array = LDS(array)</span><br><span class="line">    lis_array = LDS(array[::-1])[::-1]</span><br><span class="line">    res = 0</span><br><span class="line">    for i in range(n):</span><br><span class="line">        for j in range(i + 1, n):</span><br><span class="line">            if array[i] == array[j]:</span><br><span class="line">                res = max(res, 2 * min(lds_array[i], lis_array[j]))</span><br><span class="line">    print(res)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>整体的分析过程和动态规划方法完全相同。</p>
<p>这个标题是使用二分查找求解LIS问题，求解LIS的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong>。因为要遍历i和j，因此整体<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def LDS(array):</span><br><span class="line">    tmp = []</span><br><span class="line">    res = []</span><br><span class="line">    for x in array:</span><br><span class="line">        if not tmp or tmp[-1] &gt; x:</span><br><span class="line">            tmp.append(x)</span><br><span class="line">        else:</span><br><span class="line">            left, right = 0, len(tmp)</span><br><span class="line">            while left &lt; right:</span><br><span class="line">                mid = (left + right) // 2</span><br><span class="line">                if tmp[mid] &lt;= x:</span><br><span class="line">                    right = mid</span><br><span class="line">                else:</span><br><span class="line">                    left = mid + 1</span><br><span class="line">            tmp[left] = x</span><br><span class="line">        res.append(len(tmp))</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n = int(line.strip())</span><br><span class="line">    array = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    lds_array = LDS(array)</span><br><span class="line">    lis_array = LDS(array[::-1])[::-1]</span><br><span class="line">    res = 0</span><br><span class="line">    for i in range(n):</span><br><span class="line">        for j in range(i + 1, n):</span><br><span class="line">            if array[i] == array[j]:</span><br><span class="line">                res = max(res, 2 * min(lds_array[i], lis_array[j]))</span><br><span class="line">    print(res)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  最长上升子序列问题太经典了，在面试笔试中会经常遇到它，因此小伙伴们一定，一定，一定要掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>求一元n次方程的根(某大厂手撕笔试题)</title>
    <url>/2020/10/03/program%20Interview6/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview6.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是一个典型的数学问题，如果是一元一次方程，一元二次方程，我们可以很容易的求出根的值，这个题目是一元n次方程，因此无法获得根的表达式，这应该如何求解呢？</p>
<a id="more"></a>
<h1 id="暴力"><a href="#暴力" class="headerlink" title="暴力"></a><font size="5" color="red">暴力</font></h1><p>我们可以使用暴力法进行求解，设定一个解的区间，枚举这个区间的所有数据，因为答案要求保留两位小数，所以数字间隔$\epsilon$设为0.005即可。</p>
<ul>
<li>如果某个x代入后，其结果非常接近0，那么则可以认为某个根约等于x，将x保留两位小数代替这个根。</li>
<li>如果某个x代入后不接近0，但是将$x + \epslion$代入与将x代入的结果异号，说明根处于$(x, \ x + \epslion]$，这时可以认为某个根约等于$x + \frac{\epslion}{2}$，并将其加入最后的结果之中。</li>
</ul>
<p>这个方法无法得到全局的解，但是这种算法题不会出特别大的样例让小伙伴们计算，所以是可以通过的。<br>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(1)$</strong>，其中m为自己设定的范围，n为精度的倒数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f(x):</span><br><span class="line">    res = 0</span><br><span class="line">    base = 1</span><br><span class="line">    for i in range(len(a) - 1, -1, -1):</span><br><span class="line">        res += base * a[i]</span><br><span class="line">        base *= x</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n = int(line.strip())</span><br><span class="line">    a = [float(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    res = []</span><br><span class="line">    range_x = [-1000, 1000]</span><br><span class="line">    epsilon = 5e-3</span><br><span class="line">    x = range_x[0]</span><br><span class="line">    while x &lt;= range_x[1]:</span><br><span class="line">        v = f(x)</span><br><span class="line">        if abs(v) &lt; 1e-8:</span><br><span class="line">            tmp = '%.2f' % x</span><br><span class="line">            if tmp == '-0.00':</span><br><span class="line">                tmp = '0.00'</span><br><span class="line">            if tmp not in res:</span><br><span class="line">                res.append(tmp)</span><br><span class="line">        elif v * (f(x + epsilon)) &lt; 0:</span><br><span class="line">            tmp = '%.2f' % (x + epsilon / 2)</span><br><span class="line">            if tmp == '-0.00':</span><br><span class="line">                tmp = '0.00'</span><br><span class="line">            if tmp not in res:</span><br><span class="line">                res.append(tmp)</span><br><span class="line">        x += epsilon</span><br><span class="line">    print("NO") if not res else print(' '.join(res))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a><font size="5" color="red">牛顿法</font></h1><p>啊，牛顿，永远滴神。</p>
<p><img src="/images/ALGORITHM/interview6_solve1.png" alt="1"><br>假设$f(x)$为凸函数，且处处可导，如果我们要求$f(x) = 0$的根，我们假设初始值位于$x_0$处。<br>那么在$x_0$处的导数为$f’(x_0)$。所以过$(x_0, f(x_0))$，斜率为$f’(x_0)$的直线会与x轴交于一点$x_1$，这个点更接近于我们要求的根。我们只要求出这个根，并且重复这个迭代过程就可以无限逼近于真实的根。<br>我们观察$\triangle x_1x_0f(x_0)$，可以知道</p>
<script type="math/tex; mode=display">\frac{f(x_0)}{x0 - x1} = f'(x_0)</script><p>通过上面这个式子，将$x_1$用$x_0$表示为</p>
<script type="math/tex; mode=display">x_1 = x_0 - \frac{f(x_0)}{f'(x_0)}</script><p>这就是牛顿法，可以通过初始点不断进行迭代逼近方程的根。</p>
<p>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(1)$</strong>，其中m为自己设定的范围，n为精度的倒数。</p>
<p>其实牛顿法做这个题目并不是很适合，牛顿法适合于求解单根问题，对于多根问题，尤其是不定根，也需要进行迭代。但是对于大多数问题来说，牛顿法可以跨度较大，如$epsilon$的值可以设置的较大，因为根在大部分情况下是散落的，但是根为0.01, 0.02, 0.03时，如果跨度较大$\epsilon = 1$，那么就可能只能得到0.01和0.03的解，在小于0时，会得到0.01的根，大于1时会得到0.03的根。如果想得到正确的结果，需要设置$\epsilon \le 0.01$。那么这种做法反而慢于暴力法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f(x):</span><br><span class="line">    res = 0</span><br><span class="line">    base = 1</span><br><span class="line">    for i in range(len(a) - 1, -1, -1):</span><br><span class="line">        res += base * a[i]</span><br><span class="line">        base *= x</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def df(x):</span><br><span class="line">    res = 0</span><br><span class="line">    base = 1</span><br><span class="line">    for i in range(len(a) - 2, -1, -1):</span><br><span class="line">        res += base * a[i] * (len(a) - 1 - i)</span><br><span class="line">        base *= x</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n = int(line.strip())</span><br><span class="line">    a = [float(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    res = []</span><br><span class="line">    range_x = [-1000, 1000]</span><br><span class="line">    epsilon = 0.01</span><br><span class="line">    acc = 1e-8</span><br><span class="line">    max_it = 100</span><br><span class="line">    x = range_x[0]</span><br><span class="line">    while x &lt;= range_x[1]:</span><br><span class="line">        cur_x = x</span><br><span class="line">        f_cur = f(cur_x)</span><br><span class="line">        df_cur = df(cur_x)</span><br><span class="line">        if df_cur != 0:</span><br><span class="line">            times = 0</span><br><span class="line">            while abs(f_cur) &gt;= acc and times &lt; max_it:</span><br><span class="line">                cur_x = cur_x - f_cur / df_cur</span><br><span class="line">                f_cur = f(cur_x)</span><br><span class="line">                df_cur = df(cur_x)</span><br><span class="line">                times += 1</span><br><span class="line">        cur_x = "%.2f" % cur_x</span><br><span class="line">        if cur_x == '-0.00':</span><br><span class="line">            cur_x = '0.00'</span><br><span class="line">        if abs(f_cur) &lt; acc and cur_x not in res:</span><br><span class="line">            res.append(cur_x)</span><br><span class="line">        x += epsilon</span><br><span class="line">    print("NO") if not res else print(' '.join(res))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目并不是非常重要，也没有太多的技巧性，但是牛顿法是通过题目让小伙伴们学习的内容。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>检查字符串是否可以通过排序子字符串得到另一个字符串(Leetcode 206场单周赛第4题)</title>
    <url>/2020/10/02/program%20Leetcode1585/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1585.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目难度较大，代码量很少，主要考察思路，如何寻找一种合适的数据结构表达这种关系非常重要。</p>
<a id="more"></a>
<h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a><font size="5" color="red">队列</font></h1><p><strong>某个数前面比它小的数在变换后必须也要在它前面</strong>，这句话非常重要。<br>如s = “84532” t = “34852”<br>看t的第一个数字3，s的3前面没有比他小的数字，因此可以。<br>看t的第二个数字4，s的4前面没有比他小的数字，因此可以。<br>看t的第一个数字8，s的8前面没有比他小的数字，因此可以。<br>看t的第二个数字5，s的5前面有比他小的数字4，而t中5前面也有4，因此可以。<br>看t的第一个数字2，s的2前面没有比他小的数字，因此可以，输出True</p>
<p>下面看一个反例<br>如s = “12345” t = “12435”<br>看t的第一个数字1，s的1前面没有比他小的数字，因此可以。<br>看t的第二个数字2，s的2前面有比他小的数字1，而t中2前面也有1，因此可以。<br>看t的第一个数字4，s的3前面有比他小的数字1, 2和3，而t中2前面只有1和2，因此不可以，输出False</p>
<p><strong>因此我们使用一个字典，其中键为0到9，值为队列，记录s每个数字出现的位置，然后遍历t。<br>对于t中的每一个数字k，如果k不存在于s中，则返回False。<br>如果存在s中，则寻找小于k的所有元素第一次出现的位置，如果在k前面，则输出False。<br>如果小于k的所有数字都不在k的前面，则说明这个元素可以移动到当前位置，则字典中对应的队列弹出队头元素。<br>当所有数字都比较完成后，则返回True</strong>。</p>
<p><strong>每个数字最多比较10次，且要保存每个元素出现的索引</strong>，所以算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def isTransformable(self, s, t):</span><br><span class="line">        dic = {i: deque() for i in range(10)}</span><br><span class="line">        for idx, val in enumerate(s):</span><br><span class="line">            d = int(val)</span><br><span class="line">            dic[d].append(idx)</span><br><span class="line">        for idx, val in enumerate(t):</span><br><span class="line">            d = int(val)</span><br><span class="line">            if not dic[d]:</span><br><span class="line">                return False</span><br><span class="line">            if any(dic[j] and dic[j][0] &lt; dic[d][0] for j in range(d)):</span><br><span class="line">                return False</span><br><span class="line">            dic[d].popleft()</span><br><span class="line">        return True</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这道题的代码就这么简短，但是思路难以想到。通过记录数字最早出现的位置，判断在某个数字前面是否有比它小的数字出现，通过队列保存数字出现的索引，方便从队头进行删除，太精彩了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>字符串</category>
        <category>队列</category>
      </categories>
  </entry>
  <entry>
    <title>连接所有点的最小费用(Leetcode 206场单周赛第3题)</title>
    <url>/2020/09/30/program%20Leetcode1584/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1584.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是一个最小生成树问题，可以通过prim算法或者kurskal算法进行求解。</p>
<a id="more"></a>
<h1 id="prim"><a href="#prim" class="headerlink" title="prim"></a><font size="5" color="red">prim</font></h1><p>prim算法是通过节点合并实现的，其步骤为：</p>
<ol>
<li>首先任意选择一个节点，常常选择第1个节点，然后放入passed集合中。</li>
<li>计算剩余的所有点可以直接到达1号节点的距离</li>
<li>选择一个最小的点k加入到passed集合中。</li>
<li>从剩余节点中如果通过k到达passed集合比之前的更近，则更新该距离。</li>
<li>重复步骤3和4，直到所有的点都在passed集合中为止。</li>
<li>此时距离数组的和就是最小生成树的距离</li>
</ol>
<p>prim算法时间方面，<strong>对于每一个新加入的节点，要计算其他节点通过该节点到达passed集合的距离，空间方面只需要保存passed集合和剩余点到passed集合的最近距离</strong>。因此算法的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def minCostConnectPoints(self, points):</span><br><span class="line">        def prim(points):</span><br><span class="line">            no_passed = set(range(1, n))</span><br><span class="line">            close_distance = [distance(points[0], points[i]) for i in range(n)]</span><br><span class="line">            while no_passed:</span><br><span class="line">                mini_distance, idx = float('inf'), -1</span><br><span class="line">                for node in no_passed:</span><br><span class="line">                    if mini_distance &gt; close_distance[node]:</span><br><span class="line">                        mini_distance, idx = close_distance[node], node</span><br><span class="line">                no_passed.remove(idx)</span><br><span class="line">                for node in no_passed:</span><br><span class="line">                    close_distance[node] = min(close_distance[node], distance(points[node], points[idx]))</span><br><span class="line">            return sum(close_distance)</span><br><span class="line"></span><br><span class="line">        distance = lambda x, y: abs(x[0] - y[0]) + abs(x[1] - y[1])</span><br><span class="line">        n = len(points)</span><br><span class="line">        return prim(points)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="kurskal"><a href="#kurskal" class="headerlink" title="kurskal"></a><font size="5" color="red">kurskal</font></h1><p>kurskal算法是通过边合并实现的，其步骤为：<br>1.首先给每个节点定义一个编号，通常i节点的编号为i，结果res赋值为0</p>
<ol>
<li>选择距离最近的两个节点，如果两个节点的编号不同，假设为i和j，则将所有等于i的节点的编号改为j相同，说明生成树的结果存在这条边，结果res加上这条边的距离。如果节点相同则说明两个节点已存在一个通路，继续寻找下一个距离最近的边。</li>
<li>重复步骤2，直到所有的点的编号都相同为止。</li>
<li>返回结果res即可。</li>
</ol>
<p>kurskal算法时间方面，<strong>要对每一条边进行排序，假设边数为e，当e很大时，排序的过程非常耗时，当e很小时，网络最少合并n次，每次要判断每个编号是否需要更新</strong>，因此<strong>时间复杂度为$O(max(elog(e), n^2))，空间复杂度为$O(e)$</strong>。</p>
<p><strong>在全连接网络中，$e = (n - 1)!$，所以kurskal的时间复杂度和空间复杂度都非常大，如本题，每两个点都有距离定义，因此适合于prim算法，不适合于kurskal算法</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def minCostConnectPoints(self, points):</span><br><span class="line">        def kurskal(points):</span><br><span class="line">            distance_map = [[distance(points[i], points[j]), i, j] for i in range(n) for j in range(i)]</span><br><span class="line">            distance_map.sort(reverse=True)</span><br><span class="line">            label = list(range(n))</span><br><span class="line">            combine_times = 0</span><br><span class="line">            res = 0</span><br><span class="line">            while combine_times != n - 1:</span><br><span class="line">                mini_distance, i, j = distance_map.pop()</span><br><span class="line">                if label[i] != label[j]:</span><br><span class="line">                    label = [label[j] if label[k] == label[i] else label[k] for k in range(n)]</span><br><span class="line">                    combine_times += 1</span><br><span class="line">                    res += mini_distance</span><br><span class="line">            return res</span><br><span class="line"></span><br><span class="line">        distance = lambda x, y: abs(x[0] - y[0]) + abs(x[1] - y[1])</span><br><span class="line">        n = len(points)</span><br><span class="line">        return kurskal(points)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  最小生成树问题时经典的贪心问题，其实难度并不大，记住思路就可以很容易的写出来，这时一个非常重要的算法，小伙伴们务必掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>贪心</category>
        <category>特定算法</category>
      </categories>
  </entry>
  <entry>
    <title>特殊编辑距离(某大厂手撕笔试题)</title>
    <url>/2020/09/29/program%20Interview5/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview5.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   编辑距离是一个非常经典的问题了，这是小伙伴们必须掌握的算法，这个题目在编辑距离的基础上加以修改，其思路并没有变换，先用20分钟动手尝试一下如何求解。</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>用二维数组dp[i][j]表示a的前i个单词与b的前j个单词的编辑距离。</p>
<ul>
<li>当a[i]与b[j]相同时<script type="math/tex; mode=display">dp[i][j] = dp[i - 1][j - 1]</script></li>
<li>当a[i]与b[j]不相同时，又可以分成4种情况<ul>
<li>当a[i]和b[j]都是s中的元素时<script type="math/tex; mode=display">dp[i][j] = min(dp[i - 1][j - 1], dp[i][j - 1], dp[i - 1][j])</script>其中第一项为a[i]与b[j]都跳过，第二项为跳过a[i]，第三项为跳过b[j]</li>
<li>当a[i]是s中的元素时<script type="math/tex; mode=display">dp[i][j] = min(dp[i - 1][j - 1] + 1, dp[i - 1][j], dp[i][j - 1] + 1)</script>其中第一项为将a[i]替换为b[j]，第二项为跳过a[i]，第三项为删除b[j]</li>
<li>当b[j]是s中的元素时<script type="math/tex; mode=display">dp[i][j] = min(dp[i - 1][j - 1] + 1, dp[i - 1][j] + 1, dp[i][j])</script>其中第一项为将a[i]替换为b[j]，第二项为删除a[i]，第三项为跳过b[j]</li>
<li>当a[i]和b[j]都不是s中的元素时<script type="math/tex; mode=display">dp[i][j] = min(dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1]) + 1</script>其中第一项为将a[i]替换为b[j]，第二项为删除a[i]，第三项为删除b[j]</li>
</ul>
</li>
</ul>
<p>状态转移方程较为复杂，小伙伴们好好理解。算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(mn)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    stop_word = line.strip().split()</span><br><span class="line">    a = sys.stdin.readline().strip().split()</span><br><span class="line">    b = sys.stdin.readline().strip().split()</span><br><span class="line">    lena, lenb = len(a), len(b)</span><br><span class="line">    dp = [[0 for _ in range(lenb + 1)] for _ in range(lena + 1)]</span><br><span class="line">    for i in range(1, lena + 1):</span><br><span class="line">        dp[i][0] = dp[i - 1][0]</span><br><span class="line">        dp[i][0] += 1 if a[i - 1] not in stop_word else 0</span><br><span class="line">    for i in range(1, lenb + 1):</span><br><span class="line">        dp[0][i] = dp[0][i - 1]</span><br><span class="line">        dp[0][i] += 1 if b[i - 1] not in stop_word else 0</span><br><span class="line">    for i in range(1, lena + 1):</span><br><span class="line">        for j in range(1, lenb + 1):</span><br><span class="line">            if a[i - 1] == b[j - 1]:</span><br><span class="line">                dp[i][j] = dp[i - 1][j - 1]</span><br><span class="line">            else:</span><br><span class="line">                if a[i - 1] in stop_word and b[j - 1] in stop_word:</span><br><span class="line">                    dp[i][j] = min(dp[i - 1][j - 1], dp[i][j - 1], dp[i - 1][j])</span><br><span class="line">                elif a[i - 1] in stop_word:</span><br><span class="line">                    dp[i][j] = min(dp[i - 1][j], dp[i - 1][j - 1] + 1, dp[i][j - 1] + 1)</span><br><span class="line">                elif b[j - 1] in stop_word:</span><br><span class="line">                    dp[i][j] = min(dp[i][j - 1], dp[i - 1][j - 1] + 1, dp[i - 1][j] + 1)</span><br><span class="line">                else:</span><br><span class="line">                    dp[i][j] = min(dp[i - 1][j - 1], dp[i][j - 1], dp[i - 1][j]) + 1</span><br><span class="line">    print(dp[-1][-1])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DP"><a href="#优化DP" class="headerlink" title="优化DP"></a><font size="5" color="red">优化DP</font></h1><p>这个题目有趣的地方在于，我们可以将a和b中的所有出现在s中的字符都跳过，进行普通的编辑距离即可。<br>假设a[i]在s中，那么a[i]会被保留或者跳过，如果选择保留，那么一定和某个单词进行了匹配，则进行修改操作。那么等价于将其忽略，然后增加一个单词。<br>如A是s中的单词，字符串a为BAC，字符串b为BBC，此时a想变为b，可以将a中的A保留，并且进行修改，将A改成B，那么两个字符串相同，此时编辑距离为1，这个操作等价于将A忽略，然后插入一个单词B。<br>用公式进行说明，当a[i]是s中的元素时</p>
<script type="math/tex; mode=display">dp[i][j] = min(dp[i - 1][j - 1] + 1, dp[i - 1][j], dp[i][j - 1] + 1)</script><p>其中第一项为将a[i]替换为b[j]，第二项为跳过a[i]，第三项为删除b[j]<br>第一项一定大于等于第二项，我们可以认为dp[i - 1][j - 1]在插入了一个b[j]单词，因此</p>
<script type="math/tex; mode=display">dp[i - 1][j - 1] + 1 \ge dp[i - 1][j]</script><p>所以上面的式子可以转换为</p>
<script type="math/tex; mode=display">dp[i][j] = min(dp[i - 1][j], dp[i][j - 1] + 1)</script><p>这个状态还可以继续简化</p>
<script type="math/tex; mode=display">dp[i][0] = dp[i - 1][0] \ \ if \ \ j = 0</script><script type="math/tex; mode=display">\begin{align} dp[i][1] & = min(dp[i - 1][1], dp[i][0] + 1) \ \ if \ \ j = 0 \\ & = min(dp[i - 1][1], dp[i - 1][0] + 1)\\ \end{align}</script><p>上面已经说明了</p>
<script type="math/tex; mode=display">dp[i - 1][j - 1] + 1 \ge dp[i - 1][j]</script><script type="math/tex; mode=display">dp[i][1] = dp[i - 1][1] \ \ if \ \ j = 0</script><p>利用数学归纳法可以轻易求得</p>
<script type="math/tex; mode=display">dp[i][j] = dp[i - 1][j]</script><p>因此当a[i]出现在单词列表s中，可以将a[i]直接忽略，不会对结果产生影响。<br>算法的<strong>时间复杂度为$O(mn)$，空间复杂度为$O(mn)$</strong>。在很多单词出现在单词列表中，时间复杂度和空间复杂度比第一种算法低得多。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    stop_word = line.strip().split()</span><br><span class="line">    a = sys.stdin.readline().strip().split()</span><br><span class="line">    b = sys.stdin.readline().strip().split()</span><br><span class="line">    a = [x for x in a if x not in stop_word]</span><br><span class="line">    b = [x for x in b if x not in stop_word]</span><br><span class="line">    lena, lenb = len(a), len(b)</span><br><span class="line">    dp = [[0 for _ in range(lenb + 1)] for _ in range(lena + 1)]</span><br><span class="line">    for i in range(1, lena + 1):</span><br><span class="line">        dp[i][0] = i</span><br><span class="line">    for i in range(1, lenb + 1):</span><br><span class="line">        dp[0][i] = i</span><br><span class="line">    for i in range(1, lena + 1):</span><br><span class="line">        for j in range(1, lenb + 1):</span><br><span class="line">            if a[i - 1] == b[j - 1]:</span><br><span class="line">                dp[i][j] = dp[i - 1][j - 1]</span><br><span class="line">            else:</span><br><span class="line">                dp[i][j] = min(dp[i - 1][j - 1], dp[i][j - 1], dp[i - 1][j]) + 1</span><br><span class="line">    print(dp[-1][-1])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  编辑距离的问题，小伙伴们一定要掌握它，肯定是通过动态规划来解决的，当题目变化时，我们的状态转移方程可能也会发生改动，一定要开动脑筋，思考如何去修改。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>寻找符合条件的节点数(某大厂手撕笔试题)</title>
    <url>/2020/09/27/program%20Interview4/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview4.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   遇到树形的问题，肯定要想到深搜和广搜，但是这个题目并不是一个树，只是一些邻接关系，没有left和right节点。如何转换到树的思想？当然可以创建树，但是还需要写递归创建树结构，思路不是非常好，小伙伴们能否使用数组容器实现呢？</p>
<a id="more"></a>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>我们可以<strong>使用二维数组保存，第一个维度大小是101，代表最多101个结点，第二个维度大小是2，分别代表左孩子和右孩子。因为节点从1开始，因此我们初始值设为0，进行DFS，当某个节点的两个孩子都不为0，并且每个孩子的两个孩子都为0，则计数器+1</strong>。算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dfs(current):</span><br><span class="line">    global res</span><br><span class="line">    if dic[current][0] and dic[dic[current][0]] == leaf and dic[current][1] and dic[dic[current][1]] == leaf:</span><br><span class="line">        res += 1</span><br><span class="line">        return</span><br><span class="line">    for child in dic[current]:</span><br><span class="line">        if child:</span><br><span class="line">            dfs(child)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    m, n = [int(x) for x in line.strip().split()]</span><br><span class="line">    leaf = [0, 0]</span><br><span class="line">    dic = [[0, 0] for _ in range(101)]</span><br><span class="line">    for _ in range(n):</span><br><span class="line">        p, relation, c = sys.stdin.readline().strip().split()</span><br><span class="line">        p, c = int(p), int(c)</span><br><span class="line">        if relation == 'left':</span><br><span class="line">            dic[p][0] = c</span><br><span class="line">        else:</span><br><span class="line">            dic[p][1] = c</span><br><span class="line">    res = 0</span><br><span class="line">    dfs(1)</span><br><span class="line">    print(res)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>思路和DFS相同，只是搜索方式是按层搜索，直接看代码即可。算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    m, n = [int(x) for x in line.strip().split()]</span><br><span class="line">    leaf = [0, 0]</span><br><span class="line">    dic = [[0, 0] for _ in range(101)]</span><br><span class="line">    for _ in range(n):</span><br><span class="line">        p, relation, c = sys.stdin.readline().strip().split()</span><br><span class="line">        p, c = int(p), int(c)</span><br><span class="line">        if relation == 'left':</span><br><span class="line">            dic[p][0] = c</span><br><span class="line">        else:</span><br><span class="line">            dic[p][1] = c</span><br><span class="line">    res = 0</span><br><span class="line"></span><br><span class="line">    queue = deque([1])</span><br><span class="line">    while queue:</span><br><span class="line">        current = queue.popleft()</span><br><span class="line">        if dic[current][0] and dic[dic[current][0]] == leaf and dic[current][1] and dic[dic[current][1]] == leaf:</span><br><span class="line">            res += 1</span><br><span class="line">            continue</span><br><span class="line">        for child in dic[current]:</span><br><span class="line">            if child:</span><br><span class="line">                queue.append(child)</span><br><span class="line">    print(res)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>严格意义来说不是一种数学推导，但是又具有数学的逆向思维思路，勉强归为数学部分吧。<br>我们<strong>将每一个关系读入，将父节点保存在父节点哈希表中，将子节点加入到子节点哈希表中，让子节点哈希表减父节点哈希表，则可以得到叶子节点的哈希表。并且在读入时维护一个从子节点指向父节点的字典。我们对每个叶子节点寻找其父节点，如果某个父节点出现两次，说明该父节点有两个叶子节点，给计数器+1即可</strong>。在Python中可以from collections import Counter，这时一个计数器，当某个父节点的计数器值为2时，说明该父节点是满足条件的。算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    m, n = [int(x) for x in line.strip().split()]</span><br><span class="line">    dic = dict()</span><br><span class="line">    node = set()</span><br><span class="line">    not_leaf = set()</span><br><span class="line">    for _ in range(n):</span><br><span class="line">        p, relation, c = sys.stdin.readline().strip().split()</span><br><span class="line">        p, c = int(p), int(c)</span><br><span class="line">        node.add(c)</span><br><span class="line">        not_leaf.add(p)</span><br><span class="line">        dic[c] = p</span><br><span class="line">    leaf = node - not_leaf</span><br><span class="line">    res = len(list(filter(lambda x: x == 2, Counter([dic[leaf_node] for leaf_node in leaf]).values())))</span><br><span class="line">    print(res)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这时一种BFS和DFS的变形题目，通过数组记录父子关系，这种题和leetcode的题型不同，因为<strong>leetcode是只需要写函数实现，因此输入输出已经定义好了树形结构</strong>，直接搜索即可。而<strong>牛客网的题型需要自己读入数据，如果需要创建树结构，则需要自己定义构造函数，所以并不是很方便，这时候通过其他方式保存树结构就非常重要</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>数学</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>打印数组的形状(某大厂手撕面试题)</title>
    <url>/2020/09/25/program%20Interview3/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview3.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目是我在面试时遇到的一个手撕代码题，题目意思非常简单，可以利用栈的思想，小伙伴们使用20分钟，看一看能否实现。</p>
<a id="more"></a>
<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a><font size="5" color="red">栈</font></h1><p>这道题有如下三点说明：</p>
<ol>
<li><p>在N层括号中，数据的个数就是数组的N维的维度。<br>如[[1, 2, 3], [4, 5, 6]]，在第一层括号中，有两个数据，分别是[1, 2, 3]和[4, 5, 6]，在第二层括号中有3个数据，为[1, 2, 3]，计算[4, 5, 6]也一样。判断层数时，根据右括号进行判断，栈中存在多少个左括号说明在多少层中。</p>
</li>
<li><p>给定的数组都是正确的，假设第k维的尺寸为K，计算k维所有数字是计算k - 1维所有数字的K倍，因为对于k - 1维的每一个数据，都时一个长度维K的数组。<br>如[[1, 2, 3], [4, 5, 6]]，第2维的所有数字为6，第1维的所有数字为3，说明第二维的长度为2。</p>
</li>
<li><p>可以通过检查逗号判断数据个数，遇到左括号或者逗号，可以将相应层数的数字加1。</p>
</li>
</ol>
<p>对于上面这个例子，用一个图进行说明。<br><img src="/images/ALGORITHM/interview3_solve.png" alt="1"></p>
<p>算法只需要遍历一次字符串即可，且只需要一个数组保存前k维的数据个数，因此<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    s = line.strip()</span><br><span class="line">    stack = []</span><br><span class="line">    res = []</span><br><span class="line">    for c in s:</span><br><span class="line">        if c == '[':</span><br><span class="line">            stack.append('[')</span><br><span class="line">            if len(res) &lt; len(stack):</span><br><span class="line">                res.append(1)</span><br><span class="line">            else:</span><br><span class="line">                res[len(stack) - 1] += 1</span><br><span class="line">        elif c == ',':</span><br><span class="line">            res[len(stack) - 1] += 1</span><br><span class="line">        elif c == ']':</span><br><span class="line">            stack.pop()</span><br><span class="line">    for i in range(len(res) - 1, 0, -1):</span><br><span class="line">        res[i] //= res[i - 1]</span><br><span class="line">    print(res)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="思维拓展"><a href="#思维拓展" class="headerlink" title="思维拓展"></a><font size="5" color="red">思维拓展</font></h1><p>如果要判断数组是否合法，合法输出shape，不合法输出-1，则该如何求解呢？</p>
<p>其实只需要再加一个数组，每次遇到右括号，将当前维度的大小保存到数组中，下次再遇到相同维度的右括号时，进行比较，如果大小不一致，则返回-1即可。</p>
<p>用一个图进行说明，与上面那种算法思想类似，但是实现有所区别，小伙伴们可以比较一下两种算法。<br><img src="/images/ALGORITHM/interview3_solve2.png" alt="1"></p>
<p>算法也只需要遍历一次字符串即可，需要两个数组，temp保存当前第k维的数据个数，res保存之前第k维的数据个数，因此<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    s = line.strip()</span><br><span class="line">    stack = []</span><br><span class="line">    res = []</span><br><span class="line">    temp = []</span><br><span class="line">    for idx, c in enumerate(s):</span><br><span class="line">        if c == '[':</span><br><span class="line">            stack.append('[')</span><br><span class="line">            if len(temp) &lt; len(stack):</span><br><span class="line">                temp.append(1)</span><br><span class="line">                res.append(0)</span><br><span class="line">            else:</span><br><span class="line">                temp[len(stack) - 1] = 1</span><br><span class="line">        elif c == ',':</span><br><span class="line">            temp[len(stack) - 1] += 1</span><br><span class="line">        elif c == ']':</span><br><span class="line">            if not stack or s[idx - 1] == '[':</span><br><span class="line">                res = -1</span><br><span class="line">                break</span><br><span class="line">            if not res[len(stack) - 1]:</span><br><span class="line">                res[len(stack) - 1] = temp[len(stack) - 1]</span><br><span class="line">            elif res[len(stack) - 1] != temp[len(stack) - 1]:</span><br><span class="line">                res = -1</span><br><span class="line">                break</span><br><span class="line">            stack.pop()</span><br><span class="line">    print(res) if not stack and s else print(-1)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  两种栈的做法都可以解决这个问题，我更推荐第二种做法，不但提高了代码的鲁棒性而且思路非常好，符合人的思考方式，小伙伴们如何认为呢？</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>栈</category>
      </categories>
  </entry>
  <entry>
    <title>比特位计数(Leetcode 338)</title>
    <url>/2020/09/24/program%20Leetcode338/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode338.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   一个简单的题目，正是因为思路简单，所以会忽略一些技巧。先提示一下，可以通过动态规划进行求解，小伙伴们先尝试一下如何实现。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>对每一个元素都求二进制表示，然后统计1的个数，因为求二进制表示需要log(n)的时间。所以算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def countBits(self, num):</span><br><span class="line">        return [bin(x).count('1') for x in range(num + 1)]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p><strong>动态规划并不一定需要有固定的写法，同学们可能存在一种思维定势，如一维DP，就是i从0到n，找i和i - 1的关系，二维DP，就是i从0到n，j从0到n或者从0到i，找i和j的关系</strong>。其实<strong>动态规划只是记忆化的搜索过程，只要是以前保存的结果，都可以在$O(1)$的复杂度将其取出</strong>。</p>
<p>我们已知前k - 1个数二进制表示中1的个数，要计算第k个数的二进制表示中1的个数，如何可以通过$O(1)$的时间复杂度计算呢？</p>
<p>在大于0的数中，至少有一位为1，而且在<strong>位运算中有一个操作可以删除最后一位的1，这个操作就是x &amp; (x - 1)</strong>，小伙伴们可以想一想为什么可以这样做？将k的最后一位的1删除以后，必然比k小，一定在记录之中，而且只少了一个1，因此状态转移方程为</p>
<script type="math/tex; mode=display">dp[i] = dp[i & (i - 1)] + 1</script><p>算法的<strong>时间复杂度为O(n)，空间复杂度为O(n)</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def countBits(self, num):</span><br><span class="line">        dp = [0] * (num + 1)</span><br><span class="line">        for i in range(1, num + 1):</span><br><span class="line">            dp[i] = dp[i &amp; (i - 1)] + 1</span><br><span class="line">        return dp</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  有没有写出来呢？小伙伴们要打破思维定势，寻找更加精妙的解法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>俄罗斯套娃信封问题(Leetcode 354)</title>
    <url>/2020/09/22/program%20Leetcode354/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode354.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题目的名字起得非常有意思哈，禁止套娃。这个题目在某厂的笔试题中遇到过，当时太菜了，没有想出来该如何求解，当时的题目是多米诺骨牌，前面的长和宽必须都小于后面的长和宽，问最长的多米多骨牌长度为多少。当初被虐，今天一定要学会它。</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>这个题目搞清楚方法之后也非常简单，其实相当于一个二维的最长上升子序列问题，必须满足在两个维度上都上升。其实就是一个排序就可以解决。我们按照第一个维度的升序进行排列，这个小伙伴们都想得到，然后按照第二个维度的降序进行排列，再找第二个维度的最长上升子序列的长度即可。这个如何理解呢？</p>
<p>按照第一个维度升序排列后，后面元素的第一个维度一定大于等于前面的，而且按照第二个维度降序排列后，寻找最长上升子序列时，上升子序列后面的元素值一定大于前面的元素值，因此后面的元素的第一个维度一定大于前面的元素，不会出现等于的情况，如果等于，那么第二个维度降序排列，后面的元素值一定小于等于前面的元素值，上升子序列无法找到。</p>
<p>举一个例子，[3, 5], [5, 8], [5, 6], [5, 4], [6, 8]，按照第二个维度寻找[5, 8, 6, 4, 8]上升子序列的结果是[5, 6, 8]，[3, 5]的两个维度都严格小于[5, 6]，[5, 6]的两个维度都严格小于[6, 8]。也就是说第一个维度为5的元素，在[5, 6]后面时，其第二个维度一定小于6，如[5, 4]，那么寻找上升子序列时，要寻找大于6的元素，找不到4，所以保证上升子序列中的后面元素两个维度都一定大于前面的元素。</p>
<p>为什么给这道题目DP的标签呢，其实是最长上升子序列的DP求法</p>
<p>我们使用动态规划进行求解，<strong>dp[i]表示右端点选择第i个数可得的最长上升子序列</strong>，可以得到状态转移方程</p>
<script type="math/tex; mode=display">dp[i] = \max_{j = 1}^{i - 1} dp[j] + 1 if nums[i] > nums[j]</script><p><strong>当考虑到所有情况后，就可以得到右端点为任何情况下的最大值，然后求dp数组的最大值即可</strong>。DP的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxEnvelopes(self, envelopes):</span><br><span class="line">        def lis(nums):</span><br><span class="line">            lens = len(nums)</span><br><span class="line">            dp = [1] * lens </span><br><span class="line">            for i in range(1, lens):</span><br><span class="line">                for j in range(i):</span><br><span class="line">                    if nums[i] &gt; nums[j]:</span><br><span class="line">                        dp[i] = max(dp[i], dp[j] + 1)</span><br><span class="line">            return max(dp) if lens else 0</span><br><span class="line">        </span><br><span class="line">        if not envelopes:</span><br><span class="line">            return 0</span><br><span class="line">        envelopes.sort(key=lambda x:(x[0], -x[1]))</span><br><span class="line">        nums = [x[1] for x in envelopes]</span><br><span class="line">        return lis(nums)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="二分"><a href="#二分" class="headerlink" title="二分"></a><font size="5" color="red">二分</font></h1><p>和DP中的分析过程相同，只是在求最长上升子序列时采用二分的算法，降低时间复杂度。<br>我们思考一些可能出现的情况，假设前k个元素的最长上升子序列为[1, 3, 5, 7, 9]。</p>
<ol>
<li><strong>如果第k + 1个元素大于9，假设为11，则最长上升子序列变为[1, 3, 5, 7, 9, 11]</strong>。</li>
<li><strong>如果第k + 1个元素小于9，假设为6，最长上升子序列长度不变，但是会将大于6的最小值变为6，则此时最长上升子序列变为[1, 3, 5, 6, 9]，当以后再出现7时，最长上升子序列的长度仍然不变，但是子序列就已经更新为更好的一组值了[1, 3, 5, 6, 7]</strong>。<br>也就是说<strong>当后续出现更小的值时，不会立刻改变最长子序列的长度，而是从中间的某个地方开始逐渐替换，当此时出现更大的数字时，仍然按照替换之前的子序列继续追加。如果此时出现较小的数字时，则继续替换。当替换到最后一个数字时，说明子序列已经出现了更优解，以后按照更优解进行计算</strong>。<br><strong>从上升子序列中寻找大于某个值的最小值时，可以使用二分查找法，这样可以将第二次遍历的时间复杂度大大缩小</strong>。算法的<strong>时间复杂度为O(nlog(n))，空间复杂度为O(n)</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxEnvelopes(self, envelopes):</span><br><span class="line">        def lis(nums):</span><br><span class="line">            res = []</span><br><span class="line">            for x in nums:</span><br><span class="line">                if not res or res[-1] &lt; x:</span><br><span class="line">                    res.append(x)</span><br><span class="line">                else:</span><br><span class="line">                    left, right = 0, len(res) - 1</span><br><span class="line">                    while left &lt; right:</span><br><span class="line">                        mid = (left + right) // 2</span><br><span class="line">                        if res[mid] &lt; x:</span><br><span class="line">                            left = mid + 1</span><br><span class="line">                        else:</span><br><span class="line">                            right = mid</span><br><span class="line">                    res[left] = x</span><br><span class="line">            return len(res)</span><br><span class="line">        </span><br><span class="line">        if not envelopes:</span><br><span class="line">            return 0</span><br><span class="line">        envelopes.sort(key=lambda x:(x[0], -x[1]))</span><br><span class="line">        nums = [x[1] for x in envelopes]</span><br><span class="line">        return lis(nums)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  现在想想其实这个题目并不是非常困难，有时候只是一个排序的问题，就可以将一个中等难度的题目变成困难题目，小伙伴们要多做多练，这样遇到时才能够迅速反应过来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>加油站(Leetcode 134)</title>
    <url>/2020/09/20/program%20Leetcode134/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode134.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  加油站是经典的贪心问题，代码量很少，但是思路非常灵活，小伙伴们先尝试能否求解。</p>
<a id="more"></a>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>贪心算法代码量非常少，但是证明难度非常大，这道题更是不容易理解。小伙伴们要清楚一件事情，如果油的总数大于等于走完所有路径所需要的油量，一定能够找到一个合适的起点。最后走的点一定是花费大于等于提供油量的点，如果提供的油量大于花费量，我们可以将起点提前，这样是一种更好的解法。如gas = [1, 3, 5], cost = [3, 2, 4]。这时如果选择2号为起点，走到0号还剩1升油，不够，而且发现终点1号位置的提供油量大于花费，所以可以将起点从2号提前到1号，从1号加油站出发。</p>
<p>因此<strong>贪心的目的是尽可能在前期多保存油量，操作是要从提供多，消耗少的加油站出发</strong>。可以根据提供和消耗算出累积的油量，也就是说要让累积越多越好。也就是让累积为负的放在最后。所以我们找出累积最小值作为结束的加油站编号。</p>
<p>**不妨设k是累积最小值，则k + 1作为起点编号。</p>
<ul>
<li>k + 1的提供量一定大于等于消耗量，因为k是累积的最小值，如果k + 1的提供小于消耗，则k + 1的净增加是负数，那么累积的最小值是k + 1，与条件矛盾，所以这时将k + 2作为起点不如将k + 1作为起点。</li>
<li>k的提供量一定小于消耗量，因为k是累积的最小值，如果k的提供大于等于消耗，则k的净增加是非数，那么累积的最小值是k - 1，与条件矛盾，所以这时将k作为起点不如将k + 1作为起点**。<br>k + 2作为起点的分析同k + 1，k - 1作为起点的分析同k，这个思路非常难以理解，仔细想想好像有道理，但是又很难证明。</li>
</ul>
<p>因此要找出累积的最小值即可，然后加1可得出发编号。这里直接给出代码，算法的<strong>时间复杂度为$O(n)，空间复杂度为$O(1)$</strong><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def canCompleteCircuit(self, gas, cost):</span><br><span class="line">        current, mini_idx, mini_val = 0, 0, float('inf')</span><br><span class="line">        for i in range(len(gas)):</span><br><span class="line">            current += gas[i] - cost[i]</span><br><span class="line">            if current &lt; mini_val:</span><br><span class="line">                mini_val, mini_idx = current, i</span><br><span class="line">        return -1 if current &lt; 0 else (mini_idx + 1) % len(gas)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a><font size="5" color="red">数学</font></h1><p>数学方法相对容易理解，不理解上面思路的小伙伴们可以掌握这种算法。</p>
<p>这个算法<strong>模拟开车过程，i为出发加油站的编号，i从0开始索引到最后一个站点，j为当前到达的站点，remain为当前油量，当remain &lt; 0时，说明无法到达，此时i = j + 1，这一步是这个算法的精华。如果i += 1则相当于遍历所有的情况，时间复杂度为$O(n^2)$，而i = j + 1大大减少了时间复杂度，相当于i和j共用一层循环</strong>。</p>
<p>这句话如何理解呢？<strong>如果从i出发，最多只能到达j站台，那么中间这些站点都没必要进行尝试，假设中间的站点为k，从i到k是满足条件的，说明在k时，remain大于等于0，但是从k到j无法到达。那么从k出发时，如果remain等于0，那么必定也无法到达j的位置，因此不需要模拟站台k，可以直接从j + 1站台开始继续模拟</strong>。这个算法的<strong>时间复杂度为$O(n)，空间复杂度为$O(1)$</strong><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def canCompleteCircuit(self, gas, cost):</span><br><span class="line">        i, lens = 0, len(gas)</span><br><span class="line">        while i &lt; lens:</span><br><span class="line">            j = i</span><br><span class="line">            remain = gas[i] - cost[i]</span><br><span class="line">            while remain &gt;= 0:</span><br><span class="line">                j += 1</span><br><span class="line">                if j - i == lens:</span><br><span class="line">                   return i</span><br><span class="line">                remain += gas[j % lens] - cost[j % lens]</span><br><span class="line">            i = j + 1</span><br><span class="line">        return -1</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目短小而精悍，看似非常简单，但是做起来却非常困难，小伙伴没有没有感受到这个题目的精妙之处。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>C++常用算法</title>
    <url>/2020/09/18/C++_algorithm/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++88.png" alt="2"></p>
<h1 id="C-常用算法"><a href="#C-常用算法" class="headerlink" title="C++常用算法"></a><font size="5" color="red">C++常用算法</font></h1><p>  常用算法是C++刷题的重要法宝，有时需要查找某个元素的索引，有时需要进行排序，有时需要进行替换等等，虽然这些函数的实现并不困难，但是会降低我们的效率，而且C++给我们提供的算法都是非常高效的，我们要充分利用这一优势进行高效的coding。<br><a id="more"></a></p>
<h1 id="常用算法介绍"><a href="#常用算法介绍" class="headerlink" title="常用算法介绍"></a><font size="5">常用算法介绍</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;set&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;numeric&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">void print(int val) {</span><br><span class="line">	cout &lt;&lt; val &lt;&lt; " ";</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">class Print {</span><br><span class="line">public:</span><br><span class="line">	void operator()(int val) {</span><br><span class="line">		cout &lt;&lt; val &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int square(int val) {</span><br><span class="line">	return val * val;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">class Cubic {</span><br><span class="line">public:</span><br><span class="line">	int operator()(int val) {</span><br><span class="line">		return val * val * val;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">bool greater100(int val) {</span><br><span class="line">	return val &gt; 100;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">class Greater50 {</span><br><span class="line">public:</span><br><span class="line">	bool operator()(int val) {</span><br><span class="line">		return val &gt; 50;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">bool myGreater(int a, int b) {</span><br><span class="line">	return a &gt; b;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	vector&lt;int&gt; v0 = { 1,4,6,2,5,8,7 };</span><br><span class="line">	vector&lt;int&gt; v1(12, 0);</span><br><span class="line">	vector&lt;int&gt; v2(20, -1);</span><br><span class="line"></span><br><span class="line">	// 遍历容器，for_each(_InIt _First, _InIt _Last, _Fn _Func)，从对迭代器中的每一个元素进行处理，其中第三个参数是处理方法，可以是普通函数也可以是仿函数</span><br><span class="line">	// 通过普通函数遍历容器</span><br><span class="line">	cout &lt;&lt; "v0：";</span><br><span class="line">	for_each(v0.begin(), v0.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 通过仿函数遍历容器</span><br><span class="line">	cout &lt;&lt; "v0：";</span><br><span class="line">	for_each(v0.begin(), v0.end(), Print());</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 搬运操作，transform(const _InIt _First, const _InIt _Last, _OutIt _Dest, _Fn _Func)，对迭代器的每一个元素进行处理，然后放入某个迭代器中</span><br><span class="line">	// 其中第三个参数为目标迭代器，第四个参数是处理方法，可以是普通函数也可以是仿函数</span><br><span class="line">	// 通过普通函数搬运操作</span><br><span class="line">	transform(v0.begin(), v0.end(), v1.begin(), square);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 通过仿函数搬运操作</span><br><span class="line">	transform(v0.begin(), v0.end(), v1.begin() + 3, Cubic());</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 查找元素，find(_InIt _First, const _InIt _Last, const _Ty&amp; _Val)，对迭代器中的每一个元素进行查找，如果找到了目标元素则返回迭代器，否则返回终止迭代器，其中第三个参数是目标元素</span><br><span class="line">	vector&lt;int&gt;::iterator it1 = find(v1.begin() + 1, v1.end(), 1);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(it1, v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 按条件查找，find_if(_InIt _First, const _InIt _Last, _Pr _Pred)，对迭代器中的每一个元素进行寻找，如果满足条件则返回迭代器，否则返回终止迭代器</span><br><span class="line">	// 其中第三个参数是查找条件，可以是普通函数也可以是仿函数</span><br><span class="line">	// 通过普通函数查找操作</span><br><span class="line">	vector&lt;int&gt;::iterator it2 = find_if(v1.begin(), v1.end(), greater100);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(it2, v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 通过仿函数查找操作</span><br><span class="line">	vector&lt;int&gt;::iterator it3 = find_if(v1.begin(), v1.end(), Greater50());</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(it3, v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 查找相邻重复元素，adjacent_find(const _FwdIt _First, const _FwdIt _Last)，对迭代器中的每一个元素进行寻找，如果范围内存在相邻重复元素则返回迭代器，否则返回终止迭代器</span><br><span class="line">	vector&lt;int&gt;::iterator it4 = adjacent_find(v1.begin(), v1.end());</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(it4 - 2, v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 统计元素个数，count(const _InIt _First, const _InIt _Last, const _Ty&amp; _Val)，统计迭代器范围内，目标元素的个数，其中第三个参数是目标元素</span><br><span class="line">	cout &lt;&lt; "v1中1出现的个数为：" &lt;&lt; count(v1.begin(), v1.end(), 1) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 按条件统计，count_if(_InIt _First, _InIt _Last, _Pr _Pred)，统计迭代器范围内，满足条件的元素个数，其中第三个参数是条件，可以是普通函数也可以是仿函数</span><br><span class="line">	// 通过普通函数统计操作</span><br><span class="line">	cout &lt;&lt; "v1中大于100的元素个数为" &lt;&lt; count_if(v1.begin(), v1.end(), greater100) &lt;&lt; endl;</span><br><span class="line">	// 通过仿函数统计操作</span><br><span class="line">	cout &lt;&lt; "v1中大于50的元素个数为" &lt;&lt; count_if(v1.begin(), v1.end(), Greater50()) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 排序，sort(const _RanIt _First, const _RanIt _Last, _Pr _Pred)，对迭代器范围内的元素进行排序，其中第三个参数是排序方式，可以是普通函数也可以是仿函数</span><br><span class="line">	// 通过普通函数统计操作</span><br><span class="line">	sort(v1.begin(), v1.end(), myGreater);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 通过仿函数统计操作，因为存在内置关系仿函数，因此直接使用即可</span><br><span class="line">	sort(v1.begin(), v1.end(), less&lt;int&gt;());</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 随机打乱，random_shuffle(_RanIt _First, _RanIt _Last)，对迭代器范围内的元素随机打乱</span><br><span class="line">	random_shuffle(v1.begin(), v1.end());</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 合并两个有序容器，merge(_InIt1 _First1, _InIt1 _Last1, _InIt2 _First2, _InIt2 _Last2, _OutIt _Dest)，前两个参数为第一个容器的范围，中间两个参数为第二个容器的范围，最后一个参数为目标容器的迭代器</span><br><span class="line">	// 要注意两个容器要是有序的，而且目标容器的剩余空间要大于等于两个容器空间之和。</span><br><span class="line">	sort(v0.begin(), v0.end());</span><br><span class="line">	sort(v1.begin(), v1.end());</span><br><span class="line">	merge(v0.begin(), v0.end(), v1.begin(), v1.end(), v2.begin());</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 逆序，reverse(const _BidIt _First, const _BidIt _Last)，对迭代器范围内的元素逆序排列</span><br><span class="line">	reverse(v2.begin(), v2.end());</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 拷贝，copy(_InIt _First, _InIt _Last, _OutIt _Dest)，对迭代器的每一个元素拷贝到另一个迭代器中，其中第三个参数为目标迭代器</span><br><span class="line">	// 要注意目标容器的剩余空间要大于等于原容器。</span><br><span class="line">	copy(v0.begin(), v0.end(), v2.begin());</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 替换，replace(const _FwdIt _First, const _FwdIt _Last, const _Ty&amp; _Oldval, const _Ty&amp; _Newval)，将替换迭代器范围内所有旧元素都替换为新元素，其中第三个参数为旧元素，第四个参数为新元素。</span><br><span class="line">	replace(v2.begin(), v2.end(), 8, -8);</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 按条件替换，replace_if(const _FwdIt _First, const _FwdIt _Last, _Pr _Pred, const _Ty&amp; _Val)，将替换迭代器范围内所有符合条件的元素都替换为新元素</span><br><span class="line">	// 其中第三个参数是条件，可以是普通函数也可以是仿函数，第四个参数为新元素。</span><br><span class="line">	// 通过普通函数替换操作</span><br><span class="line">	replace_if(v1.begin(), v1.end(), greater100, 80);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line"></span><br><span class="line">	// 通过仿函数替换操作</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">	replace_if(v1.begin(), v1.end(), Greater50(), 30);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 交换，swap(vector&lt;_Ty, _Alloc&gt;&amp; _Left, vector&lt;_Ty, _Alloc&gt;&amp; _Right)，交换两个容器</span><br><span class="line">	swap(v1, v2);</span><br><span class="line">	cout &lt;&lt; "v1：";</span><br><span class="line">	for_each(v1.begin(), v1.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 累加求和，accumulate(const _InIt _First, const _InIt _Last, _Ty _Val)，需要导入numeric头文件，计算迭代器范围内所有元素之和，并且加上初始元素，其中第三个元素为初始元素</span><br><span class="line">	// 如果只需要计算迭代器范围内元素之和，则初始元素传入0即可</span><br><span class="line">	cout &lt;&lt; "v2的所有元素之和再加10为：" &lt;&lt; accumulate(v2.begin(), v2.end(), 10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 填充，fill(const _FwdIt _First, const _FwdIt _Last, const _Ty&amp; _Val)，需要导入numeric头文件，将迭代器范围内所有元素都替换为目标元素，其中第三个参数为目标元素</span><br><span class="line">	fill(v2.begin() + 5, v2.end(), 10);</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "v0：";</span><br><span class="line">	for_each(v0.begin(), v0.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 集合交集，set_intersection(_InIt1 _First1, _InIt1 _Last1, _InIt2 _First2, _InIt2 _Last2, _OutIt _Dest)，前两个参数为第一个容器的范围，中间两个参数为第二个容器的范围，最后一个参数为目标容器的迭代器</span><br><span class="line">	// 要注意两个容器要是有序的，而且目标容器的剩余空间要满足条件。</span><br><span class="line">	set_intersection(v0.begin() + 2, v0.end(), v0.begin(), v0.end() - 2, v2.begin());</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 集合并集，set_union(_InIt1 _First1, _InIt1 _Last1, _InIt2 _First2, _InIt2 _Last2, _OutIt _Dest)，前两个参数为第一个容器的范围，中间两个参数为第二个容器的范围，最后一个参数为目标容器的迭代器</span><br><span class="line">	// 要注意两个容器要是有序的，而且目标容器的剩余空间要满足条件。</span><br><span class="line">	set_union(v0.begin() + 5, v0.end(), v0.begin(), v0.end() - 5, v2.begin());</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 集合差集，set_difference(_InIt1 _First1, _InIt1 _Last1, _InIt2 _First2, _InIt2 _Last2, _OutIt _Dest)，前两个参数为第一个容器的范围，中间两个参数为第二个容器的范围，最后一个参数为目标容器的迭代器</span><br><span class="line">	// 要注意两个容器要是有序的，而且目标容器的剩余空间要满足条件。</span><br><span class="line">	set_difference(v0.begin() + 2, v0.end(), v0.begin(), v0.end() - 2, v2.begin());</span><br><span class="line">	cout &lt;&lt; "v2：";</span><br><span class="line">	for_each(v2.begin(), v2.end(), print);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++89.png" alt="4"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  在这篇博客中介绍了很多常用的算法，现在想找一个满意的工作，刷题是非常重要的一个环节，而使用C++语言刷题的小伙伴们一定会使用得到，希望能对你起到一些帮助。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>摆动序列(Leetcode 376)</title>
    <url>/2020/09/16/program%20Leetcode376/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode376.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   摆动序列是一个典型的贪心问题，这个题目也可以使用动态规划进行求解，下面给小伙伴们展示一下两种算法的实现过程。<br><a id="more"></a></p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们使用动态规划进行求解，dp[i]表示选择第i个数可得到的最长摆动序列，遍历从0到i - 1的所有数字k，如果nums[i] &gt; nums[k]，说明选择第i个数，并且最后状态为上升的最长摆动序列为选择第k个数，并且最后状态为下降的最长摆动序列长度 + 1。小伙伴们可以仔细理解一下，因此我们<strong>需要记录两个状态，一个是选择第i个数可得到的最后状态为上升的最长摆动序列长度dp_u，和最后状态为下降的最长摆动序列长度dp_d</strong>。可以得到状态转移方程。</p>
<script type="math/tex; mode=display">dp \_ u[i] = \max_{j = 0}^{i - 1} (dp \_ u[i], dp \_ d[j] + 1) \ \ s.t. nums[i] > nums[j]</script><script type="math/tex; mode=display">dp \_ d[i] = \max_{j = 0}^{i - 1} (dp \_ d[i], dp \_ u[j] + 1) \ \ s.t. nums[i] < nums[j]</script><p>这个方案不难想到，<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wiggleMaxLength(self, nums):</span><br><span class="line">        if not nums:</span><br><span class="line">            return 0</span><br><span class="line">        dp_up = [1] * len(nums)</span><br><span class="line">        dp_down = [1] * len(nums)</span><br><span class="line">        res = 1</span><br><span class="line">        for i in range(1, len(nums)):</span><br><span class="line">            for j in range(i):</span><br><span class="line">                if nums[i] &gt; nums[j]:</span><br><span class="line">                    dp_up[i] = max(dp_up[i], dp_down[j] + 1)</span><br><span class="line">                elif nums[i] &lt; nums[j]:</span><br><span class="line">                    dp_down[i] = max(dp_down[i], dp_up[j] + 1)</span><br><span class="line">            res = max(dp_up[i], dp_down[i])</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="改进DP"><a href="#改进DP" class="headerlink" title="改进DP"></a><font size="5" color="red">改进DP</font></h1><p>当我们换一种思路，<strong>使用dp_u[i]记录前i个元素最后状态为上升可得到的最长摆动序列，使用dp_d[i]记录前i个元素最后状态为下降可得到的最长摆动序列</strong>。发现并不需要第二层循环，因为当nums[i] &gt; nums[i - 1]时，dp_u[i] = dp_d[i - 1] + 1，而dp_d[i] = dp_d[i - 1]。nums[i] &lt; nums[i - 1]时同理，可得状态转移方程。</p>
<script type="math/tex; mode=display">dp\_u[i]， dp\_d[i] = \begin{cases} dp\_d[i - 1] + 1, dp\_d[i - 1] & nums[i] > nums[i - 1] \\ dp\_u[i - 1], dp\_u[i - 1] + 1 & nums[i] < nums[i - 1] \\ dp\_u[i - 1], dp\_d[i - 1] & nums[i] = nums[i - 1] \end{cases}</script><p>而且我们发现每次只利用到上一次的结果，因此可以使用两个变量保存即可，不用使用两个数组。<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wiggleMaxLength(self, nums):</span><br><span class="line">        if not nums:</span><br><span class="line">            return 0</span><br><span class="line">        up, down = 1, 1</span><br><span class="line">        for i in range(1, len(nums)):</span><br><span class="line">            if nums[i] &gt; nums[i - 1]:</span><br><span class="line">                up, down = down + 1, down</span><br><span class="line">            elif nums[i] &lt; nums[i - 1]:</span><br><span class="line">                up, down = up, up + 1</span><br><span class="line">        return max(up, down)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a><font size="5" color="red">贪心</font></h1><p>我们思考一种情况，<strong>如果存在连续多个下降的数字，那么我们只需要记录最后一个下降的数字即可，它一定是最优的</strong>。如1,5 4 3 2 3，在5的时候出现了长度为2的摆动序列，4的时候出现了长度为3的摆动序列，那么后面的3和2都不会影响摆动序列的长度，仅仅当下一次上升时长度才会加1，因此保存最小的数会更容易出现上升。这就是一种贪心思想。<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wiggleMaxLength(self, nums):</span><br><span class="line">        if not nums:</span><br><span class="line">            return 0</span><br><span class="line">        res, i = 1, 1</span><br><span class="line">        while i &lt; len(nums):</span><br><span class="line">            if nums[i] &gt; nums[i - 1]:</span><br><span class="line">                while i &lt; len(nums) and nums[i] &gt;= nums[i - 1]:</span><br><span class="line">                    i += 1</span><br><span class="line">                res += 1</span><br><span class="line">            elif nums[i] &lt; nums[i - 1]:</span><br><span class="line">                while i &lt; len(nums) and nums[i] &lt;= nums[i - 1]:</span><br><span class="line">                    i += 1</span><br><span class="line">                res += 1</span><br><span class="line">            else:</span><br><span class="line">                i += 1</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学解法"><a href="#数学解法" class="headerlink" title="数学解法"></a><font size="5" color="red">数学解法</font></h1><p>数学解法的思维方式也很巧妙，我们要寻找摆动序列的长度，即<strong>寻找拐点的数量+2</strong>即可。因为去除连续相同数字需要额外保存一个数组，<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br><img src="/images/ALGORITHM/leetcode376_solve.png" alt="1"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def wiggleMaxLength(self, nums):</span><br><span class="line">        new_nums = []</span><br><span class="line">        for x in nums:</span><br><span class="line">            if not new_nums or new_nums[-1] != x:</span><br><span class="line">                new_nums.append(x)</span><br><span class="line">        lens = len(new_nums)</span><br><span class="line">        if lens &lt;= 2:</span><br><span class="line">            return lens</span><br><span class="line">        res = 2</span><br><span class="line">        for i in range(1, lens - 1):</span><br><span class="line">            if new_nums[i - 1] &gt; new_nums[i] and new_nums[i + 1] &gt; new_nums[i] or new_nums[i - 1] &lt; new_nums[i] and new_nums[i + 1] &lt; new_nums[i]:</span><br><span class="line">                res += 1</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  是不是非常有趣，一个题目存在这么多的解法，小伙伴们重点掌握贪心算法和动态规划算法。优化的DP和普通的DP小伙伴们都要掌握，虽然普通DP解这道题目并不是最优方案，但是思路也非常值得我们去学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
        <category>贪心</category>
      </categories>
  </entry>
  <entry>
    <title>C++仿函数</title>
    <url>/2020/09/14/C++_functor/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++82.png" alt="2"></p>
<h1 id="C-仿函数"><a href="#C-仿函数" class="headerlink" title="C++仿函数"></a><font size="5" color="red">C++仿函数</font></h1><p>  <strong>重载函数调用操作符的类，其对象称为函数对象，因为使用重载的()时，其行为类似于函数的调用，因此也称之为仿函数。但是仿函数是一个类，并不是一个函数</strong>。<br><a id="more"></a></p>
<h1 id="仿函数"><a href="#仿函数" class="headerlink" title="仿函数"></a><font size="5">仿函数</font></h1><p>仿函数是一个类，其特点是：</p>
<ul>
<li><strong>函数对象在使用时可以像普通函数那样调用，可以有返回值</strong></li>
<li><strong>函数对象超出普通函数的概念，函数对象有自己的状态</strong>，可以设置一个成员属性，记录函数调用的次数，时间等等</li>
<li><strong>函数对象可以作为参数进行传递</strong></li>
</ul>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 这里定义一个仿函数</span><br><span class="line">class KxPlusb {</span><br><span class="line">public:</span><br><span class="line">	int operator()(int k, int x, int b) {</span><br><span class="line">		cout &lt;&lt; "这里调用了KxPlusb这个类的运算符重载函数" &lt;&lt; endl;</span><br><span class="line">		return k * x + b;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">// 这里定义一个普通函数</span><br><span class="line">int kxPlusb(int k, int x, int b) {</span><br><span class="line">	cout &lt;&lt; "这里调用了kxPlusb这个普通函数" &lt;&lt; endl;</span><br><span class="line">	return k * x + b;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建一个仿函数的对象</span><br><span class="line">	KxPlusb line;</span><br><span class="line">	// 调用仿函数</span><br><span class="line">	cout &lt;&lt; "1 * 2 + 3 = " &lt;&lt; line(1, 2, 3) &lt;&lt; endl;</span><br><span class="line">	// 调用普通函数</span><br><span class="line">	cout &lt;&lt; "1 * 2 + 3 = " &lt;&lt; kxPlusb(1, 2, 3) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++81.png" alt="1"></p>
<h1 id="一元谓词"><a href="#一元谓词" class="headerlink" title="一元谓词"></a><font size="5">一元谓词</font></h1><p><strong>谓词是返回值为布尔类型的仿函数，如果operator()只接收一个参数，那么称之为一元谓词</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 定义一个一元谓词，判断参数是否为奇数</span><br><span class="line">class IsOdd {</span><br><span class="line">public:</span><br><span class="line">	bool operator()(int val) {</span><br><span class="line">		return val % 2;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	IsOdd isOdd;</span><br><span class="line">	cout &lt;&lt; "2是否为奇数：" &lt;&lt; isOdd(2) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "3是否为奇数：" &lt;&lt; isOdd(3) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	vector&lt;int&gt; v = { 2,4,5,6,8 };</span><br><span class="line">	// 这里使用了后面将要讲到的algorithm中的一些函数</span><br><span class="line">	// 谓词的使用主要是用在一些函数中，可以简化我们的代码。</span><br><span class="line">	// find_if(_InIt _First, const _InIt _Last, _Pr _Pred)是从迭代器范围中寻找第一个满足条件的数据，并返回迭代器位置。其中第三个参数就是谓词，如果为真则停止，为假则继续寻找。</span><br><span class="line">	vector&lt;int&gt;::iterator it = find_if(v.begin(), v.end(), isOdd);</span><br><span class="line"></span><br><span class="line">	if (it == v.end()) {</span><br><span class="line">		cout &lt;&lt; "从vector中没有找到奇数" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">	else {</span><br><span class="line">		cout &lt;&lt; "从vector中找到了奇数，第一个奇数为：" &lt;&lt; *it &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/C++83.png" alt="1"></p>
<h1 id="二元谓词"><a href="#二元谓词" class="headerlink" title="二元谓词"></a><font size="5">二元谓词</font></h1><p><strong>如果operator()接收两个参数，那么称之为二元谓词</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 定义一个二元谓词，判断a的平方是否小于b的平方</span><br><span class="line">class SquareCmp {</span><br><span class="line">public:</span><br><span class="line">	bool operator()(int a, int b) {</span><br><span class="line">		return a * a &lt; b * b;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">void printVector(vector&lt;int&gt; v) {</span><br><span class="line">	cout &lt;&lt; "v：";</span><br><span class="line">	for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	SquareCmp squareCmp;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "3的平方是否小于4的平方：" &lt;&lt; squareCmp(3, 4) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "-5的平方是否小于4的平方：" &lt;&lt; squareCmp(-5, 4) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	vector&lt;int&gt; v = { -5,4,2,-6,8 };</span><br><span class="line">	// 这里使用了后面将要讲到的algorithm中的一些函数</span><br><span class="line">	// 谓词的使用主要是用在一些函数中，可以简化我们的代码。</span><br><span class="line">	// sort(const _RanIt _First, const _RanIt _Last, _Pr _Pred)是对迭代器范围内的元素进行排序。其中第三个参数就是谓词，指定了排序的规则。</span><br><span class="line">	sort(v.begin(), v.end(), squareCmp);</span><br><span class="line"></span><br><span class="line">	printVector(v);</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/C++84.png" alt="1"></p>
<h1 id="内建算术仿函数"><a href="#内建算术仿函数" class="headerlink" title="内建算术仿函数"></a><font size="5">内建算术仿函数</font></h1><p><strong>C++提供了6个内建算数仿函数，可以导入functional头文件进行使用</strong></p>
<ul>
<li>plus 加法二元仿函数，</li>
<li>minus 减法二元仿函数</li>
<li>multiplies 乘法二元仿函数</li>
<li>divides 除法二元仿函数</li>
<li>modulus 取模二元仿函数</li>
<li>negate 取负一元仿函数<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;functional&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	plus&lt;int&gt; pl;</span><br><span class="line">	cout &lt;&lt; "20 + 10 = " &lt;&lt; pl(20, 10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	minus&lt;int&gt; mi;</span><br><span class="line">	cout &lt;&lt; "20 - 10 = " &lt;&lt; mi(20, 10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	multiplies&lt;int&gt; mu;</span><br><span class="line">	cout &lt;&lt; "20 * 10 = " &lt;&lt; mu(20, 10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	divides&lt;int&gt; di;</span><br><span class="line">	cout &lt;&lt; "20 / 10 = " &lt;&lt; di(20, 10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	modulus&lt;int&gt; mo;</span><br><span class="line">	cout &lt;&lt; "20 % 10 = " &lt;&lt; mo(20, 10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	negate&lt;int&gt; ne;</span><br><span class="line">	cout &lt;&lt; "-10 = " &lt;&lt; ne(10) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
</li>
</ul>
<p><img src="/images/LANGUAGE/C++85.png" alt="1"></p>
<h1 id="内建关系仿函数"><a href="#内建关系仿函数" class="headerlink" title="内建关系仿函数"></a><font size="5">内建关系仿函数</font></h1><p><strong>C++提供了6个内建关系仿函数，可以导入functional头文件进行使用</strong></p>
<ul>
<li>equal_to 等于二元仿函数，</li>
<li>not_equal_to 不等于二元仿函数</li>
<li>greater 大于二元仿函数</li>
<li>greater_equal 大于等于二元仿函数</li>
<li>less 小于二元仿函数</li>
<li>less_equal 小于等于二元仿函数<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;functional&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	equal_to&lt;int&gt; eq;</span><br><span class="line">	cout &lt;&lt; "3是否等于3：" &lt;&lt; eq(3, 3) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "2是否等于3：" &lt;&lt; eq(2, 3) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	not_equal_to&lt;int&gt; ne;</span><br><span class="line">	cout &lt;&lt; "3是否不等于3：" &lt;&lt; ne(3, 3) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "2是否不等于3：" &lt;&lt; ne(2, 3) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	greater&lt;int&gt; gr;</span><br><span class="line">	cout &lt;&lt; "3是否大于3：" &lt;&lt; gr(3, 3) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "3是否大于2：" &lt;&lt; gr(3, 2) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	greater_equal&lt;int&gt; ge;</span><br><span class="line">	cout &lt;&lt; "3是否大于等于3：" &lt;&lt; ge(3, 3) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "3是否大于等于2：" &lt;&lt; ge(3, 2) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	less&lt;int&gt; ls;</span><br><span class="line">	cout &lt;&lt; "2是否小于3：" &lt;&lt; ls(2, 3) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "3是否小于3：" &lt;&lt; ls(3, 3) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	less_equal&lt;int&gt; le;</span><br><span class="line">	cout &lt;&lt; "2是否小于等于3：" &lt;&lt; le(2, 3) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "3是否小于等于3：" &lt;&lt; le(3, 3) &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
</li>
</ul>
<p><img src="/images/LANGUAGE/C++86.png" alt="1"></p>
<h1 id="内建逻辑仿函数"><a href="#内建逻辑仿函数" class="headerlink" title="内建逻辑仿函数"></a><font size="5">内建逻辑仿函数</font></h1><p><strong>C++提供了3个内建逻辑仿函数，可以导入functional头文件进行使用</strong></p>
<ul>
<li>logical_and 与二元仿函数，</li>
<li>logical_or 或二元仿函数</li>
<li>logical_not 非一元仿函数<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;functional&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	logical_and&lt;bool&gt; la;</span><br><span class="line">	cout &lt;&lt; "true &amp;&amp; true = " &lt;&lt; la(true, true) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "false &amp;&amp; true = " &lt;&lt; la(false, true) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "true &amp;&amp; false = " &lt;&lt; la(true, false) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "false &amp;&amp; false = " &lt;&lt; la(false, false) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	logical_or&lt;bool&gt; lo;</span><br><span class="line">	cout &lt;&lt; "true || true = " &lt;&lt; lo(true, true) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "false || true = " &lt;&lt; lo(false, true) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "true || false = " &lt;&lt; lo(true, false) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "false || false = " &lt;&lt; lo(false, false) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	logical_not&lt;bool&gt; ln;</span><br><span class="line">	cout &lt;&lt; "!true = " &lt;&lt; ln(true) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "!false = " &lt;&lt; ln(false) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
</li>
</ul>
<p><img src="/images/LANGUAGE/C++87.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  <strong>仿函数是C++STL算法的基础</strong>，在这里我们先掌握基本的仿函数定义，以及C++的一些内建仿函数。在后面我们将要学习一些常用的算法，其中<strong>如果想按照自己需要的方式改进标准算法，则需要传入一元谓词或者二元谓词</strong>，在这一讲的find_if和sort函数中也有所涉及。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>数组中的逆序对(Leetcode 剑指Offer51)</title>
    <url>/2020/09/10/program%20Leetcode_offer51/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer51.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目还有一种另外的表达方式，交换两个相邻数，使得数组有序的最少交换次数，两个题目的意思是相同的，都是寻找逆序数的对数。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>这个题目最简单的方法是暴力，遍历每一个位置，并且对于每一个位置枚举在它之前的所有元素，记录比它大的元素的个数即可。时间复杂度为$O(n^2)$，空间复杂度为$O(1)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def reversePairs(self, nums):</span><br><span class="line">        res = 0</span><br><span class="line">        for i in range(1, len(nums)):</span><br><span class="line">            for j in range(i):</span><br><span class="line">                if nums[j] &gt; nums[i]:</span><br><span class="line">                    res += 1</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a><font size="5" color="red">分治算法</font></h1><p>暴力法当然可以求解，但是时间复杂度太高。我们考虑一种情况，两个有序数组，进行合并时，是否可以利用一些大小关系缩小时间复杂度。<br>这里使用官方题解中的数据进行演示，小伙伴们也可以去观看官方题解中的视频教程进行学习。<br><img src="/images/ALGORITHM/leetcodeoffer51.png" alt="1"><br>由两个有序数组合并为一个有序数组的过程就是一个归并排序的过程。先将长度为n的数组，逐步分解，直到长度为1，然后进行合并，在合并的过程中求解逆序对的个数。<br>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def reversePairs(self, nums):</span><br><span class="line">        def merge(nums, begin, mid, end):</span><br><span class="line">            if begin == end:</span><br><span class="line">                return 0</span><br><span class="line">            new_nums = []</span><br><span class="line">            res = 0</span><br><span class="line">            left, right = begin, mid + 1</span><br><span class="line">            while left &lt; mid + 1 and right &lt; end + 1:</span><br><span class="line">                if nums[left] &lt;= nums[right]:</span><br><span class="line">                    new_nums.append(nums[left])</span><br><span class="line">                    left += 1</span><br><span class="line">                else:</span><br><span class="line">                    new_nums.append(nums[right])</span><br><span class="line">                    right += 1</span><br><span class="line">                    res += mid - left + 1</span><br><span class="line">            new_nums += nums[left:mid + 1] + nums[right:end + 1]</span><br><span class="line">            nums[begin:end + 1] = new_nums</span><br><span class="line">            return res</span><br><span class="line"></span><br><span class="line">        def partition(nums, begin, end):</span><br><span class="line">            if begin &lt; end:</span><br><span class="line">                return partition(nums, begin, (begin + end) // 2) + partition(nums, (begin + end) // 2 + 1, end) + merge(nums, begin, (begin + end) // 2, end)</span><br><span class="line">            else:</span><br><span class="line">                return 0</span><br><span class="line"></span><br><span class="line">        return partition(nums, 0, len(nums) - 1)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目算一个非常有难度的题目，是笔试面试中的高频考点。归并排序已经不是笔试面试中的考点了，因为比较简单，所以通过考察归并排序的变形题，考察小伙伴们的思维能力和代码能力，这非常重要。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>排序</category>
        <category>分治</category>
      </categories>
  </entry>
  <entry>
    <title>最小的k个数(Leetcode 剑指Offer40)</title>
    <url>/2020/09/08/program%20Leetcode_offer40/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer40.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目太经典了，面试时遇到了两次，刷题时遇到了两次，虽然题目很简单，但是却暗藏杀机。</p>
<a id="more"></a>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a><font size="5" color="red">排序</font></h1><p>当然了这个方法是最简单的，也是最没用的。因为面试官一定不想听到这样的解法，你他喵的在逗我？这种侮辱智商的解法，怎么会出现在这里？不过我在这里还是写一下代码的实现，虽然这种方法时间复杂度最高为$O(nlog(n))$，空间复杂度为$O(1)$，但是速度却很快，因为sorted函数太强大了。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def getLeastNumbers(self, arr, k):</span><br><span class="line">        return sorted(arr)[:k]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="最大堆"><a href="#最大堆" class="headerlink" title="最大堆"></a><font size="5" color="red">最大堆</font></h1><p>k个最小值则需要维护一个大小为k的最大堆，因为堆顶元素为堆中的最大值。当新来的元素小于堆中的最大值时，则将堆顶元素弹出，插入该元素，否则新来的元素一定大于堆中的所有元素，不用操作即可。这种方法的时间复杂度为$O(nlog(k))$，空间复杂度为$O(k)$。当内存较小，数据量较大的时候常常使用，因为无法获取所有数据进行排序。</p>
<p>在Python中heapq库中的堆默认为最小堆，因此可以将数据加负号放入堆中，实现最大堆。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import heapq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def getLeastNumbers(self, arr, k):</span><br><span class="line">        if k == 0:</span><br><span class="line">            return []</span><br><span class="line">        hp = [-x for x in arr[:k]]</span><br><span class="line">        heapq.heapify(hp)</span><br><span class="line">        for i in range(k, len(arr)):</span><br><span class="line">            if -hp[0] &gt; arr[i]:</span><br><span class="line">                heapq.heappushpop(hp, -arr[i])</span><br><span class="line">        ans = [-x for x in hp]</span><br><span class="line">        return ans</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="快速排序思想"><a href="#快速排序思想" class="headerlink" title="快速排序思想"></a><font size="5" color="red">快速排序思想</font></h1><p>在快速排序中，我们选择一个基准值，将小于等于基准值的元素放在基准值的左边，大于基准值的元素放在基准值的右边，因此会出现三种情况。<br>当基准值左边的元素个数等k时，则已经找到k个，不需要进行后面的排序。<br>当基准值左边的元素个数大于k时，右边的元素一定不在top k中，因此右边部分不需要处理，所以只需要递归左边部分即可。<br>当基准值左边的元素个数小于k时，左边的元素一定在top k中，因此左边部分不需要处理，所以只需要递归右边的部分即可，此时从右边部分中寻找k减左边元素个数之后的剩余个数即可。</p>
<p>算法的平均时间复杂度为$O(n)$，空间复杂度为O(1)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def getLeastNumbers(self, arr, k):</span><br><span class="line">        def quick_sort(arr, k, begin, end):</span><br><span class="line">            if k != 0 or begin &lt; end:</span><br><span class="line">                pivot, head, tail = arr[begin], begin, end</span><br><span class="line">                while head &lt; tail:</span><br><span class="line">                    while head &lt; tail and arr[tail] &gt; pivot:</span><br><span class="line">                        tail -= 1</span><br><span class="line">                    while head &lt; tail and arr[head] &lt;= pivot:</span><br><span class="line">                        head += 1</span><br><span class="line">                    arr[head], arr[tail] = arr[tail], arr[head]</span><br><span class="line">                arr[begin], arr[tail] = arr[tail], arr[begin]</span><br><span class="line">                if head - begin + 1 == k:</span><br><span class="line">                    return</span><br><span class="line">                elif head - begin + 1 &gt; k:</span><br><span class="line">                    quick_sort(arr, k, begin, head - 1)</span><br><span class="line">                else:</span><br><span class="line">                    quick_sort(arr, k - (head - begin + 1), head + 1, end)</span><br><span class="line"></span><br><span class="line">        quick_sort(arr, k, 0, len(arr) - 1)</span><br><span class="line">        return arr[:k]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这就是这道题目的三种解法，要面试的小伙伴们一定要记住后两种。快速排序看起来简单，但是一定要多写一写实现一下，千万不要出现差错，尽量一次成功。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>排序</category>
      </categories>
  </entry>
  <entry>
    <title>实现堆的插入和删除(某大厂手撕面试题)</title>
    <url>/2020/09/05/program%20Interview2/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview2.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   堆是一种非常常见的数据结构，使用的频率也非常的高，小伙伴们经常使用堆，但是往往不关注其实现过程，今天给小伙伴们梳理一下堆的实现过程。</p>
<a id="more"></a>
<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a><font size="5" color="red">递归</font></h1><p>堆是一个完全二叉树，可以通过数组进行实现，数组的下标对应节点的编号。设根节点的下标从0开始，那么它的左孩子和右孩子的编号为1和2，我们可以得出一个规律，下标为i的节点，它的左孩子和右孩子的编号为i x 2 + 1和i x 2 + 2。</p>
<p>我们以一个最小堆为例子，插入元素，要想获得最快的时间复杂度，因此我们要从尾部进行插入，让它和它的父节点进行比较，如果插入的元素更小，则需要和父节点进行交换，并且递归寻找它的爷爷节点进行比较。</p>
<p>删除元素时，要想获得最快的时间复杂度，因此我们要从尾部进行删除，因为要删除的元素在0号索引，因此要先交换头部元素和尾部元素的值，然后将尾部元素弹出。这时头部元素可能并不是最小的元素，因此要将它和它的左右孩子进行对比，哪一个小则和哪一个进行交换，并且递归寻找它的孙子节点进行比较。</p>
<p>计算长度和获取堆顶元素就非常简单了，长度就是数组的长度，堆顶元素就是数组的第一个元素。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class heap:</span><br><span class="line">    @staticmethod</span><br><span class="line">    def length(nums):</span><br><span class="line">        return len(nums)</span><br><span class="line">    </span><br><span class="line">    @staticmethod</span><br><span class="line">    def top(nums):</span><br><span class="line">        return nums[0]</span><br><span class="line">    </span><br><span class="line">    @staticmethod</span><br><span class="line">    def push(nums, x):</span><br><span class="line">        nums.append(x)</span><br><span class="line">        idx = len(nums) - 1</span><br><span class="line">        while idx != 0:</span><br><span class="line">            parent_idx = idx // 2</span><br><span class="line">            if nums[idx] &lt; nums[parent_idx]:</span><br><span class="line">                nums[idx], nums[parent_idx] = nums[parent_idx], nums[idx]</span><br><span class="line">                idx = parent_idx</span><br><span class="line">            else:</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    @staticmethod</span><br><span class="line">    def pop(nums):</span><br><span class="line">        nums[0], nums[-1] = nums[-1], nums[0]</span><br><span class="line">        res = nums.pop()</span><br><span class="line">        lens, idx = len(nums), 0</span><br><span class="line">        while True:</span><br><span class="line">            temp = idx</span><br><span class="line">            left = idx * 2 + 1</span><br><span class="line">            right = idx * 2 + 2</span><br><span class="line">            if left &lt; lens and nums[idx] &gt; nums[left]:</span><br><span class="line">                idx = left</span><br><span class="line">            if right &lt; lens and nums[idx] &gt; nums[right]:</span><br><span class="line">                idx = right</span><br><span class="line">            if idx == temp:</span><br><span class="line">                break</span><br><span class="line">            else:</span><br><span class="line">                nums[idx], nums[temp] = nums[temp], nums[idx]</span><br><span class="line">        return res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 下面我使用自己创建的堆进行排序，验证正确性。</span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    a = [-4, 0, 7, 4, 9, -5, 1, 0, -7, -1]</span><br><span class="line">    res = []</span><br><span class="line"></span><br><span class="line">    for x in a:</span><br><span class="line">        heap.push(res, x)</span><br><span class="line"></span><br><span class="line">    a.clear()</span><br><span class="line">    </span><br><span class="line">    while res:</span><br><span class="line">        a.append(heap.pop(res))</span><br><span class="line"></span><br><span class="line">    print(a)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  在数据结构和算法中，往往关注链表，栈，队列，树这些基本的数据结构，对于堆是小伙伴们容易遗忘的，请不要忘记它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>递归</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(Map)</title>
    <url>/2020/09/05/C++_stl_map/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++75.png" alt="2"></p>
<h1 id="C-容器-Map"><a href="#C-容器-Map" class="headerlink" title="C++容器(Map)"></a><font size="5" color="red">C++容器(Map)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍map库，map库是C++中的字典，，其特点是字典中的每一项存储一个键值对，每一个键对应一个确定的值，键不能重复，在统计元素出现个数等题目中有很好的使用场景，也是小伙伴们必须掌握的一种数据结构。<br><a id="more"></a></p>
<h1 id="pair容器"><a href="#pair容器" class="headerlink" title="pair容器"></a><font size="5">pair容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 介绍map之前，首先介绍对组的概念。对组就是将两个元素绑定为一对，通常有三种创建方法。</span><br><span class="line">	// 和之前学的容器都不一样，需要在创建时需要传入两个类型，分别代表对组的第一个元素和第二个元素的类型。</span><br><span class="line">	// 可以通过初始化参数创建对组对象。</span><br><span class="line">	pair&lt;string, int&gt; p1("C++程序员", 30);</span><br><span class="line">	// 可以通过花括号创建对组对象。</span><br><span class="line">	pair&lt;string, int&gt; p2 = { "Java程序员", 27 };</span><br><span class="line">	// 也可以通过make_pair方法创建对组对象。</span><br><span class="line">	pair&lt;string, int&gt; p3 = make_pair("Python程序员", 25);</span><br><span class="line">	</span><br><span class="line">	// 访问对组元素时，可以通过first访问第一个元素，second访问第二个元素，要注意first和second后面没有括号。</span><br><span class="line">	cout &lt;&lt; p1.first &lt;&lt; "的年龄为：" &lt;&lt; p1.second &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; p2.first &lt;&lt; "的年龄为：" &lt;&lt; p2.second &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; p3.first &lt;&lt; "的年龄为：" &lt;&lt; p3.second &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++80.png" alt="1"></p>
<h1 id="map容器"><a href="#map容器" class="headerlink" title="map容器"></a><font size="5">map容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;map&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 为了方便显示，在这里将打印操作定义为一个函数</span><br><span class="line">// 注意，map中的顺序为插入元素的先后顺序，multimap的顺序为key从小到大的顺序，如果key无法比较则需要自定义比较函数，否则报错。</span><br><span class="line">void printMap(map&lt;string, int&gt; m) {</span><br><span class="line">	for (map&lt;string, int&gt;::iterator it = m.begin(); it != m.end(); it++) {</span><br><span class="line">		cout &lt;&lt; it-&gt;first &lt;&lt; "的年龄为：" &lt;&lt; it-&gt;second &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	pair&lt;string, int&gt; p1("C++程序员", 30);</span><br><span class="line">	pair&lt;string, int&gt; p2 = { "Java程序员", 27 };</span><br><span class="line">	pair&lt;string, int&gt; p3 = make_pair("Python程序员", 25);</span><br><span class="line">	pair&lt;string, int&gt; p4 = make_pair("Python程序员", 26);</span><br><span class="line"></span><br><span class="line">	// 创建一个map容器，存放对组，其中对组的第一个元素称为map的key，对组的第二个元素称为map的value，可以它们称为键值对。</span><br><span class="line">	map&lt;string, int&gt; m;</span><br><span class="line">	// insert用于向容器中插入键值对。</span><br><span class="line">	m.insert(p1);</span><br><span class="line">	m.insert(p2);</span><br><span class="line">	m.insert(p3);</span><br><span class="line">	//当map容器中已经存在某个key，则再插入相同的key时则会插入失败，此时不会覆盖原来的value。想要修改可以通过m[key] = value进行修改。</span><br><span class="line">                //map容器有默认元素，即使没有初始化，也可以访问其中的元素，如果value的类型是int，则默认为0</span><br><span class="line">	m.insert(p4);</span><br><span class="line">	printMap(m);</span><br><span class="line">	</span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "m是否为空：" &lt;&lt; m.empty() &lt;&lt; endl;</span><br><span class="line">	// size方法获取容器中的元素个数。</span><br><span class="line">	cout &lt;&lt; "m的尺寸为：" &lt;&lt; m.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// erase方法和insert相反，将map中的元素移除。</span><br><span class="line">	m.erase("Python程序员");</span><br><span class="line">	printMap(m);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "m的尺寸为：" &lt;&lt; m.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//find方法查找map中某个元素所在的位置，并且返回迭代器对象，在这里不进行演示。</span><br><span class="line"></span><br><span class="line">	// count方法判断某个key是否存在于字典之中。</span><br><span class="line">	// count值为0说明元素不在其中，count元素为1说明在字典中。</span><br><span class="line">	cout &lt;&lt; "查找Python程序员：" &lt;&lt; m.count("Python程序员") &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "查找C++程序员：" &lt;&lt; m.count("C++程序员") &lt;&lt; endl;</span><br><span class="line">	// 访问键对应的值时，可以采用类似数组的方式索引key，就可以得到key对应的value，想修改value的方式也是通过索引进行修改。但是multimap无法通过索引进行访问value，因为一个key会对应很多value。</span><br><span class="line">	cout &lt;&lt; "C++程序员" &lt;&lt; "的年龄为：" &lt;&lt; m["C++程序员"] &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// clear清空容器中的所有内容</span><br><span class="line">	m.clear();</span><br><span class="line">	cout &lt;&lt; "m是否为空：" &lt;&lt; m.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "m的尺寸为：" &lt;&lt; m.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++76.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  字典无法通过索引下标进行遍历。使用字典时，只要记住4个重要的函数insert，erase，count，size和一个key索引即可。常常在数组中出现，如统计每一个元素出现的次数，遇到新元素时加入字典中，遇到旧元素，则对应的value加1即可，非常方便。因此小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(Set)</title>
    <url>/2020/09/03/C++_stl_set/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++73.png" alt="2"></p>
<h1 id="C-容器-Set"><a href="#C-容器-Set" class="headerlink" title="C++容器(Set)"></a><font size="5" color="red">C++容器(Set)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍set库，set库是C++中的哈希表，也可以称其为集合，其特点是每个元素只出现一次，可以查找某个元素是否在集合中出现，在判重或者记忆化等题目中有很好的使用场景，是小伙伴们必须掌握的一种数据结构。<br><a id="more"></a></p>
<h1 id="set容器"><a href="#set容器" class="headerlink" title="set容器"></a><font size="5">set容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;set&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 为了方便显示，在这里将打印操作定义为一个函数</span><br><span class="line">// 注意，set集合中插入元素时会自动进行排序，因此传入其他类型时，要加载比较函数。</span><br><span class="line">void printSet(set&lt;int&gt; s) {</span><br><span class="line">	cout &lt;&lt; "s：";</span><br><span class="line">	for (set&lt;int&gt;::iterator it = s.begin(); it != s.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建一个set容器，同vector相同，可以存放任意类型的数据，但是需要指定数据类型。</span><br><span class="line">	// 而且建立以后只能存放该类型的数据。</span><br><span class="line">	set&lt;int&gt; s = { 6, 2, 4 };</span><br><span class="line">	printSet(s);</span><br><span class="line"></span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	// set对象没有capacity方法，只有size方法，和vector相同，可以获取容器中的元素个数。</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// insert是set中最最重要的一个方法，用于向容器中添加元素。</span><br><span class="line">	// 虽然其他容器也有insert方法，但是我并没有介绍，因为要传入一个迭代器对象，而且操作并不是很方便。</span><br><span class="line">	// 但是set集合的insert非常方便，也是唯一一个能够增加元素的方法。</span><br><span class="line">	s.insert(3);</span><br><span class="line">	s.insert(1);</span><br><span class="line">	s.insert(5);</span><br><span class="line">	s.insert(1);</span><br><span class="line">	printSet(s);</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// erase方法和insert相反，将set集合中的元素移除。</span><br><span class="line">	// 在其他容器中也有erase方法，但是也要传入迭代器对象，因此也没有过多介绍。</span><br><span class="line">	s.erase(2);</span><br><span class="line">	printSet(s);</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//find方法查找set集合中某个元素所在的位置，并且返回迭代器对象，在这里不进行演示，对于multiset则是第一次出现该元素所在的位置。</span><br><span class="line"></span><br><span class="line">	// count方法也是set集合非常重要的方法，一般使用set集合，就是为了判断某个元素是否存在于集合之中。</span><br><span class="line">	// count值为0说明元素不在其中，count元素为1说明在集合中。</span><br><span class="line">	// 为什么不返回布尔类型呢，小伙伴们可以参考multiset数据类型，是一种可插入重复元素的集合。</span><br><span class="line">	cout &lt;&lt; "1的个数为：" &lt;&lt; s.count(1) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "2的个数为：" &lt;&lt; s.count(2) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// clear清空容器中的所有内容</span><br><span class="line">	s.clear();</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++74.png" alt="1"></p>
<h1 id="unordered-set容器"><a href="#unordered-set容器" class="headerlink" title="unordered_set容器"></a><font size="5">unordered_set容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;unordered_set&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 为了方便显示，在这里将打印操作定义为一个函数</span><br><span class="line">// 注意，unordered_set集合中插入元素时不会自动进行排序，其顺序为创建时和插入的顺序。因此可以传入任意类型。</span><br><span class="line">void printUnorderedSet(unordered_set&lt;int&gt; s) {</span><br><span class="line">	cout &lt;&lt; "s：";</span><br><span class="line">	for (unordered_set&lt;int&gt;::iterator it = s.begin(); it != s.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建一个unordered_set容器，创建方法与set相同</span><br><span class="line">	// 而且建立以后只能存放该类型的数据。</span><br><span class="line">	unordered_set&lt;int&gt; s = { 6, 2, 4 };</span><br><span class="line">	printUnorderedSet(s);</span><br><span class="line"></span><br><span class="line">	// 其他方法和set容器几乎完全相同，可以参考上面的内容，在这也不做过多赘述。</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	s.insert(3);</span><br><span class="line">	s.insert(1);</span><br><span class="line">	s.insert(5);</span><br><span class="line">	s.insert(1);</span><br><span class="line">	printSet(s);</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	s.erase(2);</span><br><span class="line">	printSet(s);</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "1的个数为：" &lt;&lt; s.count(1) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "2的个数为：" &lt;&lt; s.count(2) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	s.clear();</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的尺寸为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++79.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  哈希表没有front和back方法，也无法通过索引进行遍历。使用哈希表时，只要记住4个重要的函数即可，insert，erase，count，size。常常在BFS或者DFS或者数组中出现，如搜索时，该点已经搜索完成，则可以将其加入哈希表，下次查到该点时则可以不再进行查找，节约大量的时间，因此小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(List)</title>
    <url>/2020/08/31/C++_stl_list/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++77.png" alt="2"></p>
<h1 id="C-容器-List"><a href="#C-容器-List" class="headerlink" title="C++容器(List)"></a><font size="5" color="red">C++容器(List)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍List库，List库是C++中的链表容器，其优点是不会造成内存的浪费和溢出，这和Vector相反，而且插入元素非常方便。但是缺点也很明显，需要一个额外的内存空间存放指针，而且因为其不按照内存进行存放，因此遍历花费时间较长。<br><a id="more"></a></p>
<h1 id="List容器"><a href="#List容器" class="headerlink" title="List容器"></a><font size="5">List容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;list&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 为了方便显示，在这里将打印操作定义为一个函数</span><br><span class="line">void printList(list&lt;int&gt; l) {</span><br><span class="line">	cout &lt;&lt; "l：";</span><br><span class="line">	for (list&lt;int&gt;::iterator it = l.begin(); it != l.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建一个list容器，同vector相同，可以存放任意类型的数据，但是需要指定数据类型。</span><br><span class="line">	// 而且建立以后只能存放该类型的数据。</span><br><span class="line">	list&lt;int&gt; l = { 2, 3, 4 };</span><br><span class="line"></span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "l是否为空：" &lt;&lt; l.empty() &lt;&lt; endl;</span><br><span class="line">	// list对象没有capacity方法，只有size方法，和vector相同，可以获取容器中的元素个数。</span><br><span class="line">	cout &lt;&lt; "l的尺寸为：" &lt;&lt; l.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// resize是将list调整大小，如果大于原始数组，则填充数值，达到resize的大小，否则会删除超出的部分。</span><br><span class="line">	l.resize(10);</span><br><span class="line">	printList(l);</span><br><span class="line">	cout &lt;&lt; "l的尺寸为：" &lt;&lt; l.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// push_front是list最经常用的操作，在头部添加元素。</span><br><span class="line">	// push_back在尾部添加元素。</span><br><span class="line">	l.push_front(1);</span><br><span class="line">	l.push_back(4);</span><br><span class="line">	printList(l);</span><br><span class="line">	cout &lt;&lt; "l的尺寸为：" &lt;&lt; l.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 和push_front相反，pop_front时在头部移除元素。</span><br><span class="line">	//pop_back在尾部移除元素。</span><br><span class="line">	l.pop_front();</span><br><span class="line">	l.pop_back();</span><br><span class="line">	printList(l);</span><br><span class="line">	cout &lt;&lt; "l的尺寸为：" &lt;&lt; l.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// front获取list第一个元素，但是不能使用l[0]，因为list是不连续的内存空间，因此无法通过索引直接访问。</span><br><span class="line">	cout &lt;&lt; "第一个元素为：" &lt;&lt; l.front() &lt;&lt; endl;</span><br><span class="line">	// back获取list最后一个元素。</span><br><span class="line">	cout &lt;&lt; "最后一个元素为：" &lt;&lt; l.back() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// remove移除所有值为目标的节点</span><br><span class="line">	l.remove(0);</span><br><span class="line">	printList(l);</span><br><span class="line">	cout &lt;&lt; "l的尺寸为：" &lt;&lt; l.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// clear清空容器中的所有内容</span><br><span class="line">	l.clear();</span><br><span class="line">	printList(l);</span><br><span class="line">	cout &lt;&lt; "l的尺寸为：" &lt;&lt; l.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++78.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  list容器使用并不是很频繁，一般都是使用vector和deque就可以完成大部分的应用场景，而且list不方便的地方在于无法通过下表对元素进行索引，因此小伙伴们作为了解即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>最长上升子序列(Leetcode 300)</title>
    <url>/2020/08/30/program%20Leetcode300/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode300.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  <strong>最长上升子序列(Longest  Increasing Subsequence, LIS)</strong>:这是非常有趣的一个题目，也是笔试面试常常出现的一道数组题，这道题目小伙伴们必须要掌握动态规划的解法，但是能否想到更加巧妙的方法呢？</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们使用动态规划进行求解，<strong>dp[i]表示右端点选择第i个数可得的最长上升子序列</strong>，可以得到状态转移方程</p>
<script type="math/tex; mode=display">dp[i] = \max_{j = 1}^{i - 1} dp[j] + 1 if nums[i] > nums[j]</script><p><strong>当考虑到所有情况后，就可以得到右端点为任何情况下的最大值，然后求dp数组的最大值即可</strong>。DP的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def lengthOfLIS(self, nums):</span><br><span class="line">        lens = len(nums)</span><br><span class="line">        dp = [1] * lens </span><br><span class="line">        for i in range(1, lens):</span><br><span class="line">            for j in range(i):</span><br><span class="line">                if nums[i] &gt; nums[j]:</span><br><span class="line">                    dp[i] = max(dp[i], dp[j] + 1)</span><br><span class="line">        return max(dp) if lens else 0</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="贪心-二分查找"><a href="#贪心-二分查找" class="headerlink" title="贪心+二分查找"></a><font size="5" color="red">贪心+二分查找</font></h1><p>我们思考一些可能出现的情况，假设前k个元素的最长上升子序列为[1, 3, 5, 7, 9]。</p>
<ol>
<li><strong>如果第k + 1个元素大于9，假设为11，则最长上升子序列变为[1, 3, 5, 7, 9, 11]</strong>。</li>
<li><strong>如果第k + 1个元素小于9，假设为6，最长上升子序列长度不变，但是会将大于6的最小值变为6，则此时最长上升子序列变为[1, 3, 5, 6, 9]，当以后再出现7时，最长上升子序列的长度仍然不变，但是子序列就已经更新为更好的一组值了[1, 3, 5, 6, 7]</strong>。<br>也就是说<strong>当后续出现更小的值时，不会立刻改变最长子序列的长度，而是从中间的某个地方开始逐渐替换，当此时出现更大的数字时，仍然按照替换之前的子序列继续追加。如果此时出现较小的数字时，则继续替换。当替换到最后一个数字时，说明子序列已经出现了更优解，以后按照更优解进行计算</strong>。<br><strong>从上升子序列中寻找大于某个值的最小值时，可以使用二分查找法，这样可以将第二次遍历的时间复杂度大大缩小</strong>。算法的<strong>时间复杂度为O(nlog(n))，空间复杂度为O(n)</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def lengthOfLIS(self, nums):</span><br><span class="line">        res = []</span><br><span class="line">        for x in nums:</span><br><span class="line">            if not res or res[-1] &lt; x:</span><br><span class="line">                res.append(x)</span><br><span class="line">            else:</span><br><span class="line">                left, right = 0, len(res)</span><br><span class="line">                while left &lt; right:</span><br><span class="line">                    mid = (left + right) // 2</span><br><span class="line">                    if res[mid] &gt;= x:</span><br><span class="line">                        right = mid</span><br><span class="line">                    else:</span><br><span class="line">                        left = mid + 1</span><br><span class="line">                res[left] = x</span><br><span class="line">        return len(res)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目虽然动态规划是必须要掌握的，但是贪心+二分的思路也是非常非常重要的，因为一旦笔试面试中出现这个问题，往往不是考察动态规划的知识点。笔试中会给很大的数据量，面试时面试官也会问有没有更好的解法，所以小伙伴们一定要学会它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(Stack &amp; Queue)</title>
    <url>/2020/08/29/C++_stl_stack_queue/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++70.png" alt="2"></p>
<h1 id="C-容器-Stack-amp-Queue"><a href="#C-容器-Stack-amp-Queue" class="headerlink" title="C++容器(Stack &amp; Queue)"></a><font size="5" color="red">C++容器(Stack &amp; Queue)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍stack和queue库，一个是栈，一个是队列，在数据结构中这两个内容也是必须掌握的重点内容，在刷题时也常常使用它们，因此在一篇博客中将它们放在一起介绍。<br><a id="more"></a></p>
<h1 id="stack容器"><a href="#stack容器" class="headerlink" title="stack容器"></a><font size="5">stack容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;stack&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建栈的时候，只有拷贝构造和空构造方法，不能像vector一样传入一个数组。</span><br><span class="line">	stack&lt;int&gt; s;</span><br><span class="line">	</span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	// stack对象没有capacity方法，只有size方法，和vector相同，可以获取容器中的元素个数。</span><br><span class="line">	cout &lt;&lt; "s的大小为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	// 堆栈中最最重要的一个函数，push，这要简单介绍一下堆栈的特点，堆栈是一个先进后出的数据结构。</span><br><span class="line">	// 生活中类似于洗盘子，进电梯，先洗的盘子都是放在最下面，最先进电梯的人是最后出来的。</span><br><span class="line">	// 向堆栈中放入元素的方法之有一个，就是push，向栈顶放入元素，因此非常重要。</span><br><span class="line">	s.push(1);</span><br><span class="line">	s.push(2);</span><br><span class="line">	s.push(3);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的大小为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line">	// top可以查看堆栈顶部的元素，因为堆栈中只能看到顶部元素，因此不可以随机访问，也不能够遍历。</span><br><span class="line">	// 因为3是最后入栈的，因此栈顶元素尾3</span><br><span class="line">	cout &lt;&lt; "栈顶元素为：" &lt;&lt; s.top() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 堆栈中和push相反的操作，和push的地位相同，pop弹出栈顶元素。</span><br><span class="line">	s.pop();</span><br><span class="line">	// 因为栈顶元素3被弹出，因此现在栈顶元素为2</span><br><span class="line">	cout &lt;&lt; "栈顶元素为：" &lt;&lt; s.top() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s是否为空：" &lt;&lt; s.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的大小为：" &lt;&lt; s.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++71.png" alt="1"></p>
<h1 id="queue容器"><a href="#queue容器" class="headerlink" title="queue容器"></a><font size="5">queue容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;queue&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建队列的时候，和栈相同，只有拷贝构造和空构造方法。</span><br><span class="line">	queue&lt;int&gt; q;</span><br><span class="line"></span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "q是否为空：" &lt;&lt; q.empty() &lt;&lt; endl;</span><br><span class="line">	// size方法，获取容器中的元素个数。</span><br><span class="line">	cout &lt;&lt; "q的大小为：" &lt;&lt; q.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 队列中最最重要的一个函数，push，这要简单介绍一下队列的特点，队列是一个先进先出的数据结构。</span><br><span class="line">	// 生活中类似于排队购物，先排的人可以最先获得服务。</span><br><span class="line">	// 向队列中放入元素的方法之有一个，就是push，向队列尾增加元素，因此非常重要。</span><br><span class="line">	q.push(1);</span><br><span class="line">	q.push(2);</span><br><span class="line">	q.push(3);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "q是否为空：" &lt;&lt; q.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "q的大小为：" &lt;&lt; q.size() &lt;&lt; endl;</span><br><span class="line">	// 和栈不同的是，栈只能获取栈顶元素，而队列可以通过front获取队头元素，也可以通过back获取队尾元素。</span><br><span class="line">	// 因为队列中只能看到队头和队尾元素，因此不可以随机访问，也不能够遍历。</span><br><span class="line">	// 因为1先入队，3最后入队，所以队列头元素为1，队列尾元素为3</span><br><span class="line">	cout &lt;&lt; "队列头元素为：" &lt;&lt; q.front() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "队列尾元素为：" &lt;&lt; q.back() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 队列中和push相反的操作，和push的地位相同，pop弹出队列头部元素。</span><br><span class="line">	q.pop();</span><br><span class="line">	// 当弹出队列头元素时，2就变成了新的队列头元素，队列尾元素仍为3。</span><br><span class="line">	cout &lt;&lt; "队列头元素为：" &lt;&lt; q.front() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "队列尾元素为：" &lt;&lt; q.back() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "q是否为空：" &lt;&lt; q.empty() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "q的大小为：" &lt;&lt; q.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++72.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  栈和队列非常重要，相比较而言栈会更加常用一些，有一个经典的括号匹配的问题，其就是利用堆栈的思想，小伙伴可以去尝试一下呦。细心的小伙伴也可以发现vector能够看成一个堆栈，deque能够看成一个队列，而且功能也比stack和queue要强大，所以一般可以使用vector和deque完成相应的操作。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>最长公共子序列(Leetcode 1143)</title>
    <url>/2020/08/28/program%20Leetcode1143/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1143.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最长公共子序列(Longest Common Subsequence, LCS):是一个经典的问题，也是在某厂的笔试中遇到了这个问题，小伙伴们一定要会做呀。</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们使用动态规划进行求解，dp[i][j]表示text1前i个字符和text2前j个字符的最长公共子序列，<strong>因为空序列和任何序列匹配都是0，初始状态i = 0或j = 0时，dp[i][j] = 0</strong>。可以得到状态转移方程。</p>
<script type="math/tex; mode=display">dp[i][j] =  \begin{case} dp[i - 1][j - 1] + 1 & text[i - 1] = text[j - 1] \\ max(dp[i - 1][j], dp[i][j - 1]) & text[i - 1] \ne text[j - 1] \end{cases}</script><p>DP的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n^2)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def longestCommonSubsequence(self, text1, text2):</span><br><span class="line">        len1, len2 = len(text1), len(text2)</span><br><span class="line">        dp = [[0 for _ in range(len2 + 1)] for _ in range(len1 + 1)]</span><br><span class="line">        for i in range(1, len1 + 1):</span><br><span class="line">            for j in range(1, len2 + 1):</span><br><span class="line">                if text1[i - 1] == text2[j - 1]:</span><br><span class="line">                    dp[i][j] = dp[i - 1][j - 1] + 1</span><br><span class="line">                else:</span><br><span class="line">                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])</span><br><span class="line">        return dp[-1][-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DP"><a href="#优化DP" class="headerlink" title="优化DP"></a><font size="5" color="red">优化DP</font></h1><p><strong>动态规划一般都可以进行优化，优化的方法大多是通过空间复杂度进行优化，因为DP中保存着大量的数据，可能这些数据我们在后面的计算中并不会用到</strong>。<br>如此题中第i次循环，只会用到第i次循环和第i - 1次循环中的内容，之前的计算结果并不会用到，因此可以只保留第i次的结果和第i - 1次的结果，这样优化DP的<strong>时间复杂度为$O(n^2)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def longestCommonSubsequence(self, text1, text2):</span><br><span class="line">        if len(text1) &lt; len(text2):</span><br><span class="line">            text1, text2 = text2, text1</span><br><span class="line">        len1, len2 = len(text1), len(text2)</span><br><span class="line">        dp_pre, dp_cur = [0] * (len2 + 1), [0] * (len2 + 1)</span><br><span class="line">        for i in range(1, len1 + 1):</span><br><span class="line">            for j in range(1, len2 + 1):</span><br><span class="line">                if text1[i - 1] == text2[j - 1]:</span><br><span class="line">                    dp_cur[j] = dp_pre[j - 1] + 1</span><br><span class="line">                else:</span><br><span class="line">                    dp_cur[j] = max(dp_pre[j], dp_cur[j - 1])</span><br><span class="line">            dp_cur, dp_pre = [0] * (len2 + 1), dp_cur</span><br><span class="line">        return dp_pre[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  LCS问题太经典了，不需要过多介绍，干就完事了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>字符串</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(Deque)</title>
    <url>/2020/08/27/C++_stl_deque/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++68.png" alt="2"></p>
<h1 id="C-容器-Deque"><a href="#C-容器-Deque" class="headerlink" title="C++容器(Deque)"></a><font size="5" color="red">C++容器(Deque)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍deque库，vector库是C++专门用于处理动态双端数组的库，里面内置了许多增删改查的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="deque容器"><a href="#deque容器" class="headerlink" title="deque容器"></a><font size="5">deque容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;deque&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 为了方便显示，在这里将打印操作定义为一个函数</span><br><span class="line">void printDeque(deque&lt;int&gt; d) {</span><br><span class="line">	cout &lt;&lt; "d：";</span><br><span class="line">	for (deque&lt;int&gt;::iterator it = d.begin(); it &lt; d.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建一个deque容器，同vector相同，可以存放任意类型的数据，但是需要指定数据类型。</span><br><span class="line">	// 而且建立以后只能存放该类型的数据。</span><br><span class="line">	deque&lt;int&gt; d = { 2, 3, 4 };</span><br><span class="line">	printDeque(d);</span><br><span class="line"></span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "d是否为空：" &lt;&lt; d.empty() &lt;&lt; endl;</span><br><span class="line">	// deque对象没有capacity方法，只有size方法，和vector相同，可以获取容器中的元素个数。</span><br><span class="line">	cout &lt;&lt; "d的尺寸为：" &lt;&lt; d.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// resize是将deque调整大小，如果大于原始数组，则填充数值，达到resize的大小，否则会删除超出的部分。</span><br><span class="line">	d.resize(10);</span><br><span class="line">	printDeque(d);</span><br><span class="line">	cout &lt;&lt; "d的尺寸为：" &lt;&lt; d.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// push_front是deque最经常用的操作，在头部添加元素，deque最核心的地方就在于此，头插可以节约大量时间。</span><br><span class="line">	// push_back和vector相同，在尾部添加元素。</span><br><span class="line">	d.push_front(1);</span><br><span class="line">	d.push_back(4);</span><br><span class="line">	printDeque(d);</span><br><span class="line">	cout &lt;&lt; "d的尺寸为：" &lt;&lt; d.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 和push_front相反，pop_front时在头部移除元素，除了push_front和pop_front，deque和vector其他的内容几乎相同。</span><br><span class="line">	//pop_back和vector也相同，在尾部移除元素。</span><br><span class="line">	d.pop_front();</span><br><span class="line">	d.pop_back();</span><br><span class="line">	printDeque(d);</span><br><span class="line">	cout &lt;&lt; "d的尺寸为：" &lt;&lt; d.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 索引元素可以直接类似于数组的写法，也可以使用at进行索引</span><br><span class="line">	cout &lt;&lt; "d[2] = " &lt;&lt; d[2] &lt;&lt; endl;</span><br><span class="line">	// front获取deque第一个元素，等价于d[0]</span><br><span class="line">	cout &lt;&lt; "第一个元素为：" &lt;&lt; d.front() &lt;&lt; endl;</span><br><span class="line">	// back获取deque最后一个元素，等价于d[d.size() - 1]</span><br><span class="line">	cout &lt;&lt; "最后一个元素为：" &lt;&lt; d.back() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// clear清空容器中的所有内容</span><br><span class="line">	d.clear();</span><br><span class="line">	printDeque(d);</span><br><span class="line">	cout &lt;&lt; "d的尺寸为：" &lt;&lt; d.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++69.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  当然了deque的相关操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是empty，size，push_front，push_back，pop_front，pop_back，clear，back，索引和遍历这些操作，是deque最最常用的操作，在BFS有大量的应用，因为BFS需要在尾部插入元素，从头部弹出元素，使用vector不是很方便，因此deque可以大放异彩，有了deque容器，使得我们写代码时更加方便，请小伙伴们务必放在心上。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>乘积最大子数组(Leetcode 152)</title>
    <url>/2020/08/26/program%20Leetcode152/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode152.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和前两天说的一个最大子序和的题目类似，不过这个题目不是求和而是求积。求和和求积有什么区别呢？为啥这个题目的难度就是中等，而上一个题目的难度是简单呢。<strong>求和的题目不会涉及到符号的问题，如果前缀和小于0，则相加时不考虑前缀，这时上一个题目的核心思想。而这个题目的难点在于，可能出现负数乘负数产生正数的情况</strong>。</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们使用动态规划进行求解，这时我们<strong>不但要记录最大值的状态也要记录最小值的状态，对正数和负数进行分别讨论</strong>。dp_max[i]表示右端点选择第i个数可得的最大值，dp_min[i]表示右端点选择第i个数可得的最小值。可以得到状态转移方程</p>
<script type="math/tex; mode=display">dp_max[i] =  \begin{case} max(dp_max[i - 1] * nums[i] , nums[i]) & nums[i] > 0 \\ nums[i] & max(dp_min[i - 1] * nums[i], nums[i]) \le 0 \end{cases}</script><script type="math/tex; mode=display">dp_min[i] =  \begin{case} min(dp_min[i - 1] * nums[i] , nums[i]) & nums[i] > 0 \\ nums[i] & min(dp_max[i - 1] * nums[i], nums[i]) \le 0 \end{cases}</script><p>当考虑到所有情况后，就可以得到右端点为任何情况下的最大值，然后求dp_max数组的最大值即可。DP的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxProduct(self, nums):</span><br><span class="line">        lens = len(nums)</span><br><span class="line">        dp_max = [0] * lens</span><br><span class="line">        dp_min = [0] * lens</span><br><span class="line">        dp_max[0] = dp_min[0] = nums[0]</span><br><span class="line">        for i in range(1, lens):</span><br><span class="line">            if nums[i] &gt; 0:</span><br><span class="line">                dp_max[i] = max(dp_max[i - 1] * nums[i], nums[i])</span><br><span class="line">                dp_min[i] = min(dp_min[i - 1] * nums[i], nums[i])</span><br><span class="line">            else:</span><br><span class="line">                dp_max[i] = max(dp_min[i - 1] * nums[i], nums[i])</span><br><span class="line">                dp_min[i] = min(dp_max[i - 1] * nums[i], nums[i])</span><br><span class="line">        return max(dp_max)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DP"><a href="#优化DP" class="headerlink" title="优化DP"></a><font size="5" color="red">优化DP</font></h1><p>我们发现<strong>每次只需要使用到dp_max[i - 1]和dp_min[i - 1]，因此可以使用一个变量pre_num保存dp[i - 1]，然后实时更新这个变量即可，并且更新同时记录最大值</strong>，这样可以节约空间复杂度。这种算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxProduct(self, nums):</span><br><span class="line">        pre_max = pre_min = res = nums[0]</span><br><span class="line">        for num in nums[1:]:</span><br><span class="line">            if num &gt; 0:</span><br><span class="line">                pre_max, pre_min = max(pre_max * num, num), min(pre_min * num, num)</span><br><span class="line">            else:</span><br><span class="line">                pre_max, pre_min = max(pre_min * num, num), min(pre_max * num, num)</span><br><span class="line">            res = max(pre_max, res)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目需要和leetcode53题一起做，并且仔细比较两个题目之间的差异，观察状态转移方程的写法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(Vector)</title>
    <url>/2020/08/25/C++_stl_vector/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++66.png" alt="2"></p>
<h1 id="C-容器-Vector"><a href="#C-容器-Vector" class="headerlink" title="C++容器(Vector)"></a><font size="5" color="red">C++容器(Vector)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍vector库，vector库是C++专门用于处理动态单端数组的库，里面内置了许多增删改查的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="vector容器"><a href="#vector容器" class="headerlink" title="vector容器"></a><font size="5">vector容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">// 为了方便显示，在这里将打印操作定义为一个函数</span><br><span class="line">void printVector(vector&lt;int&gt; v) {</span><br><span class="line">	cout &lt;&lt; "v：";</span><br><span class="line">	for (vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	// 创建一个vector容器，因为vector是一个模板，可以存放任意类型的数据，但是需要指定数据类型。</span><br><span class="line">	// 而且建立以后只能存放该类型的数据，还可以存放vector类型的数据，类似于二维数组。</span><br><span class="line">	vector&lt;int&gt; v = { 1, 2, 3 };</span><br><span class="line">	printVector(v);</span><br><span class="line"></span><br><span class="line">	// empty判断容器是否为空，为空则返回true，否则返回false</span><br><span class="line">	cout &lt;&lt; "v是否为空：" &lt;&lt; v.empty() &lt;&lt; endl;</span><br><span class="line">	// capacity求容器的容量</span><br><span class="line">	cout &lt;&lt; "v的容量为：" &lt;&lt; v.capacity() &lt;&lt; endl;</span><br><span class="line">	// size求容器的大小，注意大小和容量虽然给人的感觉是一样的，但是它们完全不同</span><br><span class="line">	// 大小是求得容器中元素的个数，而容量相当于目前申请的内存空间。因为vector是动态数组，因此为了扩展方便，一次性会申请很多内存，这样避免每添加一个元素申请一次内存。</span><br><span class="line">	// 所以容量就是目前申请的内存，以但达到vector容量时，会自动再去申请一部分内存。</span><br><span class="line">	cout &lt;&lt; "v的尺寸为：" &lt;&lt; v.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// resize是将vector调整大小，如果大于原始数组，则填充数值，达到resize的大小，否则会删除超出的部分。</span><br><span class="line">	v.resize(10);</span><br><span class="line">	printVector(v);</span><br><span class="line">	cout &lt;&lt; "v的容量为：" &lt;&lt; v.capacity() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "v的尺寸为：" &lt;&lt; v.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// push_back是最经常用的操作，在末尾添加元素。</span><br><span class="line">	v.push_back(4);</span><br><span class="line">	printVector(v);</span><br><span class="line">	cout &lt;&lt; "v的容量为：" &lt;&lt; v.capacity() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "v的尺寸为：" &lt;&lt; v.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// pop_back和push_back相反，将末尾元素移除。</span><br><span class="line">	v.pop_back();</span><br><span class="line">	printVector(v);</span><br><span class="line">	cout &lt;&lt; "v的容量为：" &lt;&lt; v.capacity() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "v的尺寸为：" &lt;&lt; v.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// 索引元素可以直接类似于数组的写法，也可以使用at进行索引</span><br><span class="line">	cout &lt;&lt; "v[2] = " &lt;&lt; v[2] &lt;&lt; endl;</span><br><span class="line">	// front获取vector第一个元素，等价于v[0]</span><br><span class="line">	cout &lt;&lt; "第一个元素为：" &lt;&lt; v.front() &lt;&lt; endl;</span><br><span class="line">	// back()获取vector最后一个元素，等价于v[v.size() - 1]</span><br><span class="line">	cout &lt;&lt; "最后一个元素为：" &lt;&lt; v.back() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	// clear清空容器中的所有内容，注意capacity和size的区别，内存一旦申请，常规的操作就不会释放，但是size不同。</span><br><span class="line">	// size是元素的个数，因此以但清空vector，size就会清0.</span><br><span class="line">	v.clear();</span><br><span class="line">	printVector(v);</span><br><span class="line">	cout &lt;&lt; "v的容量为：" &lt;&lt; v.capacity() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "v的尺寸为：" &lt;&lt; v.size() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++67.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  当然了vector的相关操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是empty，size，push_back，pop_back，clear，back，索引和遍历这些操作，是笔试，面试中的重中之重，有了vector容器，使得我们写代码时更加方便，请小伙伴们务必放在心上。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>最大子序和(Leetcode 53)</title>
    <url>/2020/08/24/program%20Leetcode53/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode53.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   从今天开始进入另一个有趣的部分——<strong>子序列相关题目</strong>，这是笔试面试中最最经典的问题之一，常用的解法是<strong>动态规划</strong>，小伙伴们一定要留心这类题目。虽然看起来难度并不大，但是遇到时可能会出现眼高手低的情况。</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们使用动态规划进行求解，dp[i]表示右端点选择第i个数可得的最大值，可以得到状态转移方程</p>
<script type="math/tex; mode=display">dp[i] =  \begin{case} nums[i] + dp[i - 1] & dp[i - 1] > 0 \\ nums[i] & dp[i - 1] \le 0 \end{cases}</script><p>当考虑到所有情况后，就可以得到右端点为任何情况下的最大值，然后求dp数组的最大值即可。DP的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxSubArray(self, nums):</span><br><span class="line">        lens = len(nums)</span><br><span class="line">        dp = [0] * lens</span><br><span class="line">        dp[0] = nums[0]</span><br><span class="line">        for i in range(1, lens):</span><br><span class="line">            if dp[i - 1] &lt;= 0:</span><br><span class="line">                dp[i] = nums[i]</span><br><span class="line">            else:</span><br><span class="line">                dp[i] = dp[i - 1] + nums[i]</span><br><span class="line">        return max(dp)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DP"><a href="#优化DP" class="headerlink" title="优化DP"></a><font size="5" color="red">优化DP</font></h1><p>我们发现<strong>每次只需要使用到dp[i - 1]，因此可以使用一个变量pre_num保存dp[i - 1]，然后实时更新这个变量即可，并且更新同时记录最大值</strong>，这样可以节约空间复杂度。这种算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxSubArray(self, nums):</span><br><span class="line">        max_sum = pre_num = nums[0]</span><br><span class="line">        for num in nums[1:]:</span><br><span class="line">            if pre_num &lt; 0:</span><br><span class="line">                pre_num = 0</span><br><span class="line">            pre_num += num</span><br><span class="line">            max_sum = max(pre_num, max_sum)</span><br><span class="line">        return max_sum</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目是一个简单的子序列问题，牛刀小试，下面来看一看其他更加精妙的题目吧。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
      </categories>
  </entry>
  <entry>
    <title>C++容器(String)</title>
    <url>/2020/08/23/C++_stl_string/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++63.png" alt="2"></p>
<h1 id="C-容器-String"><a href="#C-容器-String" class="headerlink" title="C++容器(String)"></a><font size="5" color="red">C++容器(String)</font></h1><p>  容器是C++非常方便的功能，今天给小伙伴们介绍string库，string库是C++专门用于处理字符串的库，里面内置了许多字符串的算法，在刷题时常常使用它。<br><a id="more"></a></p>
<h1 id="string容器"><a href="#string容器" class="headerlink" title="string容器"></a><font size="5">string容器</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	//创建时直接当成数据类型使用即可，不需要记构造函数，使用最广泛最方便。</span><br><span class="line">	string a = "hello world!";</span><br><span class="line">	string b = "hello";</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	//length方法，求出字符串的长度。</span><br><span class="line">	int lenA = a.length();</span><br><span class="line">	cout &lt;&lt; "lenA = " &lt;&lt; lenA &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//字符串截取操作，返回一个字符串。如果不指定，默认截取到最后一个字符。</span><br><span class="line">	string c = a.substr(3);</span><br><span class="line">	string d = a.substr(3, 4);</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d = " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//字符串拼接操作，使用加法即可，不需要记append方法。</span><br><span class="line">	string e = a + " hello C++";</span><br><span class="line">	cout &lt;&lt; "e = " &lt;&lt; e &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	//查找操作，find为从左到右查找，rfind为从右到左查找，如果不指定则从头开始查找，如果指定则从指定位置开始。</span><br><span class="line">	int indexL = a.find("l");</span><br><span class="line">	int indexL1 = a.find("l", 3);</span><br><span class="line">	int indexR = a.rfind("l");</span><br><span class="line">	cout &lt;&lt; "indexL = " &lt;&lt; indexL &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "indexL1 = " &lt;&lt; indexL1 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "indexR = " &lt;&lt; indexR &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//字符串替换操作，replace(pos, n, str)用str替换pos后面n个字符，注意这个操作会改变原字符串。</span><br><span class="line">	string f = a.replace(6, 5, "C++");</span><br><span class="line">	cout &lt;&lt; "f = " &lt;&lt; f &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//字符串字典序比较，按照ASCII码进行字符串比较，大于则返回1，小于则返回-1，等于返回0</span><br><span class="line">	int compare = a.compare("Hello world!");</span><br><span class="line">	cout &lt;&lt; "compare = " &lt;&lt; compare &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//索引操作，返回指定位置的字符，也可以使用at方法。</span><br><span class="line">	char at = a[6];</span><br><span class="line">	cout &lt;&lt; "at = " &lt;&lt; at &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//插入操作，insert(pos, str)在pos处插入str字符串，注意这个操作会改变原字符串。</span><br><span class="line">	string g = a.insert(6, "world! hello ");</span><br><span class="line">	cout &lt;&lt; "g = " &lt;&lt; g &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//删除操作，erase(pos, n)删除pos后面的n个字符，注意这个操作会改变原字符串。</span><br><span class="line">	string h = a.erase(6, 7);</span><br><span class="line">	cout &lt;&lt; "h = " &lt;&lt; h &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//字符串打印，有很多种方法，可以使用普通的方法，i从0遍历到length()，对于每一个i，使用索引方法获得。</span><br><span class="line">	//在这里使用一种迭代器方法，begin()返回起始位置的迭代器对象，不可以直接访问，需要用指针才可以访问，end()同理。</span><br><span class="line">	for (string::iterator it = a.begin(); it != a.end(); it++) {</span><br><span class="line">		cout &lt;&lt; *it &lt;&lt; "-";</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++64.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  当然了C++字符串处理操作还有很多很多，在这里也不可能一一讲解，但是常用的一些操作都已经介绍，尤其是截取，增加，查找，比较，插入，删除，替换这些操作，是笔试，面试中一旦考察字符串一定会用到的函数，请小伙伴们务必放在心上。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++类模板</title>
    <url>/2020/08/21/C++_class_template/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++59.png" alt="2"></p>
<h1 id="C-类模板"><a href="#C-类模板" class="headerlink" title="C++类模板"></a><font size="5" color="red">C++类模板</font></h1><p>  前天介绍了C++中函数模板的相关知识，函数模板非常简单，使用也很方便，C++中还给我们提供了类模板的相关知识，但是相比较而言，类模板就非常复杂，知识点很多，也并不经常使用，小伙伴作为了解即可。<br><a id="more"></a></p>
<h1 id="类模板"><a href="#类模板" class="headerlink" title="类模板"></a><font size="5">类模板</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//类模板：建立一个通用类，类的成员数据类型不具体指定，定义方式和函数模板相同。</span><br><span class="line">//区别在于类模板没有自动类型推导，使用时必须指定类型。函数模板中的默认参数没有意义，类模板中默认参数有意义。</span><br><span class="line">//类模板和普通类的区别在于：类模板中的成员函数并不是创建类时创建，而是调用时创建，而普通类中的成员函数是在创建类时创建。</span><br><span class="line">template &lt;class TName, class TAge=int&gt;</span><br><span class="line">class Person</span><br><span class="line">{</span><br><span class="line">public:</span><br><span class="line">	TName tName;</span><br><span class="line">	TAge  tAge;</span><br><span class="line">	Person(TName tName, TAge tAge) {</span><br><span class="line">		this-&gt;tName = tName;</span><br><span class="line">		this-&gt;tAge = tAge;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void print() {</span><br><span class="line">		cout &lt;&lt; "我的名字是：" &lt;&lt; this-&gt;tName &lt;&lt; "，我的年龄是：" &lt;&lt; this-&gt;tAge &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person&lt;string&gt; p1("C++程序员", 30);</span><br><span class="line">	p1.print();</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++60.png" alt="1"></p>
<h1 id="类模板作为函数参数"><a href="#类模板作为函数参数" class="headerlink" title="类模板作为函数参数"></a><font size="5">类模板作为函数参数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">template &lt;class TName, class TAge=int&gt;</span><br><span class="line">class Person</span><br><span class="line">{</span><br><span class="line">public:</span><br><span class="line">	TName tName;</span><br><span class="line">	TAge  tAge;</span><br><span class="line">	Person(TName tName, TAge tAge) {</span><br><span class="line">		this-&gt;tName = tName;</span><br><span class="line">		this-&gt;tAge = tAge;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void print() {</span><br><span class="line">		cout &lt;&lt; "我的名字是：" &lt;&lt; this-&gt;tName &lt;&lt; "，我的年龄是：" &lt;&lt; this-&gt;tAge &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//指定传入类型</span><br><span class="line">void test1(Person&lt;string&gt; &amp;p) {</span><br><span class="line">	p.print();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">//参数模板化</span><br><span class="line">template&lt;class T&gt;</span><br><span class="line">void test2(Person&lt;T&gt; &amp;p) {</span><br><span class="line">	p.print();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">//整体模板化</span><br><span class="line">template&lt;class P&gt;</span><br><span class="line">void test3(P &amp;p) {</span><br><span class="line">	p.print();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	Person&lt;string&gt; p1("C++程序员", 30);</span><br><span class="line">	test1(p1);</span><br><span class="line"></span><br><span class="line">	Person&lt;string&gt; p2("Java程序员", 26);</span><br><span class="line">	test2(p2);</span><br><span class="line"></span><br><span class="line">	Person&lt;string&gt; p3("Python程序员", 22);</span><br><span class="line">	test3(p3);</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++61.png" alt="2"></p>
<h1 id="子类继承类模板"><a href="#子类继承类模板" class="headerlink" title="子类继承类模板"></a><font size="5">子类继承类模板</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">template &lt;class TName, class TAge=int&gt;</span><br><span class="line">class Person</span><br><span class="line">{</span><br><span class="line">public:</span><br><span class="line">	TName tName;</span><br><span class="line">	TAge  tAge;</span><br><span class="line">	Person(TName tName, TAge tAge) {</span><br><span class="line">		this-&gt;tName = tName;</span><br><span class="line">		this-&gt;tAge = tAge;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void print() {</span><br><span class="line">		cout &lt;&lt; "我的名字是：" &lt;&lt; this-&gt;tName &lt;&lt; "，我的年龄是：" &lt;&lt; this-&gt;tAge &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//子类继承类模板有两种方式，第一种是指定父类的类型</span><br><span class="line">class Teacher : public Person&lt;string&gt; {</span><br><span class="line">public:</span><br><span class="line">	Teacher(string s, int age):Person(s, age){}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//第二种是灵活继承，子类也变成类模板。</span><br><span class="line">template &lt;class TName, class TAge=int&gt;</span><br><span class="line">class Student : public Person&lt;TName&gt; {</span><br><span class="line">public:</span><br><span class="line">	Student(TName tName, TAge tAge):Person&lt;TName&gt; (tName, tAge) {}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Teacher t("C++老师", 45);</span><br><span class="line">	t.print();</span><br><span class="line"></span><br><span class="line">	Student&lt;string&gt; s("C++学生", 30);</span><br><span class="line">	s.print();</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++62.png" alt="4"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  类模板相对于函数模板较为复杂，模板元编程不推荐大家使用，对于本来就是菜鸡的小伙伴们，这无疑又强行增加难度，我们学习C++的高级编程主要关注点在于STL库和面向对象与设计模式之间的关系，因此后面介绍的内容，小伙伴们一定要认真学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++函数模板</title>
    <url>/2020/08/19/C++_function_template/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++57.png" alt="2"></p>
<h1 id="C-函数模板"><a href="#C-函数模板" class="headerlink" title="C++函数模板"></a><font size="5" color="red">C++函数模板</font></h1><p>  从今天开始，正式进入C++的高级篇章，之前C++基础介绍的重点内容是函数与指针，C++进阶介绍的重点是引用和面向对象，在高级部分主要介绍模板和STL相关知识，尤其STL是小伙伴们必须要掌握的知识。今天先介绍一下C++的函数模板。<br><a id="more"></a></p>
<h1 id="函数模板"><a href="#函数模板" class="headerlink" title="函数模板"></a><font size="5">函数模板</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//函数模板：建立一个通用函数，其函数返回值类型和形参类型可以不指定，用虚拟类型代表</span><br><span class="line">//定义函数模板时，要在函数声明或者定义的上一行写template关键字，表示下面定义的类型是函数模板。</span><br><span class="line">template &lt;class T&gt;</span><br><span class="line">void myPrint(T t) {</span><br><span class="line">	cout &lt;&lt; t &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "模板函数执行" &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">void myPrint(double a) {</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "普通函数执行" &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 10;</span><br><span class="line">	double b = 10.0;</span><br><span class="line">	string s = "hello world!";</span><br><span class="line"></span><br><span class="line">	//使用函数模板时有两种方法。</span><br><span class="line">	//自动类型推导，将值传入函数中，会根据传入的类型自动确定模板中的类型。</span><br><span class="line">	//显示指定类型，可以用函数名&lt;类型名&gt;(参数)指定传入的类型。myPrint&lt;int&gt;(a);也可以达到相同的效果。</span><br><span class="line">	myPrint(a);</span><br><span class="line">	myPrint(b);</span><br><span class="line">	myPrint(s);</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++58.png" alt="1"></p>
<h1 id="函数模板与普通函数的区别"><a href="#函数模板与普通函数的区别" class="headerlink" title="函数模板与普通函数的区别"></a><font size="5">函数模板与普通函数的区别</font></h1><ol>
<li>普通函数可以发生隐式类型转换，函数模板中自动类型推导不可以，显示指定可以。</li>
<li>如果普通函数和函数模板都可以调用，则优先使用普通函数，可以通过显示指定空模板参数调用函数模板。</li>
<li>如果函数模板可以发生更好的匹配，则优先使用函数模板。</li>
<li>函数模板也可以发生重载。</li>
</ol>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  函数模板是一种高级的技巧，对于多种类似的参数输入，不需要重载大量的函数，减少了代码的冗余度，提高了复用性。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>吃掉 N 个橘子的最少天数(Leetcode 202场单周赛第4题)</title>
    <url>/2020/08/18/program%20Leetcode1553/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1553.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第202周周赛的第四题，题目的意思也很简单，有一堆橘子，每天可以选择吃掉一个，当橘子个数为2的整数倍时，每天还可以选择吃掉一半，当橘子个数为3的整数倍时，每天还可以选择吃掉三分之二，求如何最快吃完这些橘子。</p>
<a id="more"></a>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>这道题目做法有很多，但是测试样例中，橘子的个数可以达到$2 \times 10^9$，这样就不能使用DP来做了。DP的思路非常清晰，dp[i] = min(dp[i - 1], dp[i // 2], dp[i // 3]) + 1，当然i需要是能整除2和3的，否则去掉对应的那一项即可，这里就不再论述。时间复杂度为O(n)。我们思考，因为吃掉一半或者三分之二的概率非常大，所以结果应该不会很大，所以我们可以使用广搜的方法进行求解。为了避免搜到重复的情况，我们建立一个字典保存当前已经搜到的情况。时间复杂度为O(log(n))，空间复杂度为O(log(n))。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def minDays(self, n):</span><br><span class="line">        """</span><br><span class="line">        :type n: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        dic = {n: 0}</span><br><span class="line">        queue = deque([n])</span><br><span class="line">        while 0 not in dic:</span><br><span class="line">            current = queue.popleft()</span><br><span class="line">            if current % 3 == 0 and current // 3 not in dic:</span><br><span class="line">                dic[current // 3] = dic[current] + 1</span><br><span class="line">                queue.append(current // 3)</span><br><span class="line">            if current % 2 == 0 and current // 2 not in dic:</span><br><span class="line">                dic[current // 2] = dic[current] + 1</span><br><span class="line">                queue.append(current // 2)</span><br><span class="line">            if current - 1 not in dic:</span><br><span class="line">                dic[current - 1] = dic[current] + 1</span><br><span class="line">                queue.append(current - 1)</span><br><span class="line">        return dic[0]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="贪心-DFS"><a href="#贪心-DFS" class="headerlink" title="贪心+DFS"></a><font size="5" color="red">贪心+DFS</font></h1><p>DFS速度更快，但是更难以想到， 需要一些数学的思路。<br>能整除，我们就不吃一个，这是DFS的核心。如果n个橘子经过了k次吃一个的操作后，出现了除以3的操作，因此可以说明n - k是3的倍数，那么当k大于3时，这一定不是最优解，因为可以吃k - 3次一个橘子，然后除以3，再吃一个橘子。举个例子，101个橘子，如果每天吃一个橘子，吃了5天，然后剩余96个橘子，然后第六条吃了64个橘子，花费6天，橘子数目变为32。我们可以有一种更快到达32的方法，吃2个橘子，剩余99个橘子，然后第三天吃66个橘子，第四天吃一个橘子，花费4天，橘子数目变为32。</p>
<p>n个橘子经过k次吃一个的操作后，出现了除以2的操作同理。</p>
<p>因此我们采用一种贪心的算法，能整除则整除，不能整除先吃1个或2个然后再整除。使用记忆化的DFS，可以进一步加快搜索。时间复杂度为O(log(n))，空间复杂度为O(log(n))。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def minDays(self, n):</span><br><span class="line">        """</span><br><span class="line">        :type n: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def dfs(n):</span><br><span class="line">            if n &lt; 3:</span><br><span class="line">                return n</span><br><span class="line">            return min(dfs(n // 2) + n % 2, dfs(n // 3) + n % 3) + 1</span><br><span class="line">        return dfs(n)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  非常有趣的题目，我当时想到了使用BFS去求解，但是没有使用字典保存，导致时间复杂度过高。小伙伴们要吸取教训，记忆化是一个非常好的搜索方法，可以从指数级的时间复杂度变成线性复杂度，一定要掌握呀。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>贪心</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>两球之间的磁力(Leetcode 202场单周赛第3题)</title>
    <url>/2020/08/16/program%20Leetcode1552/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1552.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这是第202周周赛的第3题，我觉得非常有价值。题目的意思很简单，通俗的说就是从数组中找m个节点，使得它们的最小距离最大，也就是说让它们两两之间距离最远。小伙伴们先思考应该如何解答。</p>
<a id="more"></a>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>之前应该说过一句话，这里再强调一次，当遇到最小化最大值问题或者最大化最小值问题，首先考虑二分法。最小距离为1，最大距离为max(position)，当然可以优化，不过也没有太大意义，因为二分法以对数的速度收敛，很快就可以达到最优解。<br>我们可以二分查找它们之间的距离，当对于某一个距离使用贪心算法进行判断时，如果能够创建出m个节点，说明该距离是合适的，我们可以令left = mid，否则令right = mid - 1，但是我们要保证数组是有序的。这样做的时间复杂度为$O(n \times log(n))$，空间复杂度为O(1)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxDistance(self, position, m):</span><br><span class="line">        """</span><br><span class="line">        :type position: List[int]</span><br><span class="line">        :type m: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        position.sort()</span><br><span class="line">        left, right = 1, (position[-1] - position[0]) // (m - 1)</span><br><span class="line">        while left &lt; right:</span><br><span class="line">            mid, res, last, flag = (left + right + 1) // 2, 1, position[0], False</span><br><span class="line">            for x in position[1:]:</span><br><span class="line">                if x - last &gt;= mid:</span><br><span class="line">                    res += 1</span><br><span class="line">                    last = x</span><br><span class="line">                    if res &gt;= m:</span><br><span class="line">                        flag = True</span><br><span class="line">                        break</span><br><span class="line">            if flag:</span><br><span class="line">                left = mid</span><br><span class="line">            else:</span><br><span class="line">                right = mid - 1</span><br><span class="line">        return left</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这种题是非常有价值的，因为二分查找是每一个程序员必备的技能，也是面试官常常喜欢考察的内容。而且题目难度适中，所以小伙伴们务必掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>寻找重复数(Leetcode 287)</title>
    <url>/2020/08/15/program%20Leetcode287/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode287.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题也是找数字的题目，但是不同的是，之前讲的都是在重复数字中找单独出现的数字，而这个题目是在单独的数字中，查找重复数字，又该如何去应对呢？</p>
<a id="more"></a>
<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a><font size="5" color="red">二分查找</font></h1><p>因为题目中数字是从1到n，而且存在重复元素，元素的总个数为n+1。我们思考，如果元素总个数为n，并且无重复元素的情况下，那么不就是从1到n的随机排列吗？那么多了一个数，必然存在重复的情况，假设重复的元素为x，当$k \ge x$时，那么小于等于k的元素个数有k + 1个，当$k &lt; x$时，那么小于等于k的元素有k个。我们思考如果不是从1到n全都存在的情况下，即有一个数字重复出现很多次的情况，这种思路还正确吗？当然也是正确的，小伙伴们可以举个例子验证一下，我也只可意会不可言传。因此可以考虑二分法进行求解。<br>令k=mid，当mid代入时，数组中小于mid的元素个数大于mid时，说明$mid \ge x$，则令right = mid。否则令left = mid + 1。时间复杂度为O(nlog(n))，空间复杂度为O(1)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findDuplicate(self, nums):</span><br><span class="line">        n = len(nums)</span><br><span class="line">        left, right = 1, n - 1</span><br><span class="line">        while left &lt; right:</span><br><span class="line">            mid = (left + right) // 2</span><br><span class="line">            cnt = sum([x &lt;= mid for x in nums])</span><br><span class="line">            if cnt &gt; mid:</span><br><span class="line">                right = mid</span><br><span class="line">            else:</span><br><span class="line">                left = mid + 1</span><br><span class="line">        return left</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>这个位运算很简单，从1到n，分别计算每一位上出现的总个数，因为有一个数x重复，假设x的某个二进制位为1，则数组中该位为1的数字个数一定大于从1到n所有数字中该位为1的数字个数，否则一定小于等于。因此我们按位进行比较，最后哪些位为1，就可以得到该数字的二进制表示。时间复杂度为O(nlog(n))，空间复杂度为O(1)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findDuplicate(self, nums):</span><br><span class="line">        n = len(nums)</span><br><span class="line">        k = len(bin(n)) - 2</span><br><span class="line">        res = 0</span><br><span class="line">        for i in range(k):</span><br><span class="line">            bit_nums, bit_origin = 0, 0</span><br><span class="line">            for x in nums:</span><br><span class="line">                if x &amp; (1 &lt;&lt; i):</span><br><span class="line">                    bit_nums += 1</span><br><span class="line">            for x in range(1, n):</span><br><span class="line">                if x &amp; (1 &lt;&lt; i):</span><br><span class="line">                    bit_origin += 1</span><br><span class="line">            if bit_origin &lt; bit_nums:</span><br><span class="line">                res |= 1 &lt;&lt; i</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a><font size="5" color="red">双指针</font></h1><p>这题很难想出和双指针有什么关系，官方和一些民间大神总有一些骚想法，我们来看一看。因为数组的长度为n+1，数组的最大值为n，因此我们可以看成数组中每个元素保存的是下一个元素的索引，这样就相当于一个指针。因此有重复的数字，说明构成了环。我们需要找到环的入口处。<br>这个问题就转化成了一个经典的快慢指针问题。我们以题目中的例子进行讲解。<br><img src="/images/ALGORITHM/leetcode287_solve.png" alt="q"><br>时间复杂度为O(n)，空间复杂度为O(1)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findDuplicate(self, nums):</span><br><span class="line">        slow = 0</span><br><span class="line">        fast = 0</span><br><span class="line">        while True:</span><br><span class="line">            slow = nums[slow]</span><br><span class="line">            fast = nums[nums[fast]]</span><br><span class="line">            if slow == fast:</span><br><span class="line">                break</span><br><span class="line">        find = 0</span><br><span class="line">        while True:</span><br><span class="line">            find = nums[find]</span><br><span class="line">            slow = nums[slow]</span><br><span class="line">            if find == slow:</span><br><span class="line">                return find</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这类题目基本上结束了，无论是从多次出现的数组中寻找单独出现的数字，还是从单独出现的数字中寻找多次出现的数字，都可以使用一些奇技淫巧优化算法。如果面试问到了，掌握最普通的暴力求解法是最最基本的，但是面试官既然出这个题目，一定不是想考察暴力解法，所以小伙伴们一定要掌握呦~</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>二分查找</category>
        <category>位运算</category>
        <category>双指针</category>
      </categories>
  </entry>
  <entry>
    <title>错误的集合(Leetcode 645)</title>
    <url>/2020/08/13/program%20Leetcode645/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode645.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目和昨天讲解的题目非常类似，有的小伙伴就会说骗人，根本不一样，那下面让我们来康一康吧。</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>题目中说集合S中的元素包含从1到n的整数，而且其中的某一个元素替换成了另一个。这其实就是相当于所有数字都出现两次，除了一个出现一次，一个出现三次。因为我们已知数据从1到n，我们可以额外添加一组从1到n的数据，假设x替换成了y，那么新数组为x出现1次，y出现3次，其他的数据都出现2次。是不是和昨天讲解的题目非常相似。只是昨天的数据已经给出了出现两次，今天的数据需要从1到n额外添加一次。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def findErrorNums(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        n = len(nums)</span><br><span class="line">        a = reduce(lambda x, y: x ^ y, nums + list(range(1, n + 1)))</span><br><span class="line">        b = 1</span><br><span class="line">        part1 = 0</span><br><span class="line">        part2 = 0</span><br><span class="line">        while not (a &amp; b):</span><br><span class="line">            b &lt;&lt;= 1</span><br><span class="line">        for x in nums:</span><br><span class="line">            if x &amp; b:</span><br><span class="line">                part1 ^= x</span><br><span class="line">            else:</span><br><span class="line">                part2 ^= x</span><br><span class="line">        for x in range(1, n + 1):</span><br><span class="line">            if x &amp; b:</span><br><span class="line">                part1 ^= x</span><br><span class="line">            else:</span><br><span class="line">                part2 ^= x</span><br><span class="line">        for x in nums:</span><br><span class="line">            if part1 == x:</span><br><span class="line">                return [part1, part2]</span><br><span class="line">        return [part2, part1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这几天的强化位运算找数字问题，让小伙伴们明白，遇到相同数字的问题，首先需要考虑异或的方法，往往可以节省大量的内存空间。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>只出现一次的数字 III(Leetcode 260)</title>
    <url>/2020/08/12/program%20Leetcode260/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode260.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   前面的两道题目都是找出唯一出现的一个数字，如果有两个数字都出现一次，该如何求解呢？</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>对于136题来说，找出唯一出现的一个数字，通过异或可以直接求出。如果有两个数字x和y都出现了一次，那么所有数字异或的结果应该就是x和y的异或结果。因为x和y不相同，所以异或的结果一定不为0，所以一定在某个位上有1出现。我们从低到高找到第一次出现1的位置。于是可以得出一个结论。一定x在该为上位1，y为0或者x为0，y为1。所以就可以将这个数组分成part1和part2，part1中所有的元素在该位上都是1，part2中所有的元素在该位上都是0。因此对于part1能通过异或的方法找出唯一出现的一个数字，part2也能通过异或的方法找出唯一出现的一个数字。<br><img src="/images/ALGORITHM/leetcode260_solve.png" alt="q"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import functools</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def singleNumbers(self, nums):</span><br><span class="line">        """</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        p = functools.reduce(lambda x, y: x ^ y, nums)</span><br><span class="line">        p1 = p2 = 0</span><br><span class="line">        b = 1</span><br><span class="line">        while not (p &amp; b):</span><br><span class="line">            b &lt;&lt;= 1</span><br><span class="line">        for i in nums:</span><br><span class="line">            if i &amp; b:</span><br><span class="line">                p1 ^= i</span><br><span class="line">            else:</span><br><span class="line">                p2 ^= i</span><br><span class="line">        return [p1, p2]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  走过路过不要错过，赶紧尝试尝试，新鲜出炉的位运算，小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>只出现一次的数字 II(Leetcode 137)</title>
    <url>/2020/08/10/program%20Leetcode137/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode137.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  这个题目比昨天的题目难度大很多，是谷歌公司面试的一道题目，拍了拍自己的胸脯，幸好没去谷歌（狗头保命）。</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>想一下每个元素出现两次时是咋做的？是不是记录二进制位中1出现的个数，并对2求余。一个数如果某一位是1，出现2次，就为2，然后对2求余就为0。因此单独的一个数对2求余就为1，所以该数在哪些位置上为1，则最后的结果在哪些位置上也为1。设当前某一位为0，下一个数在该位上为1，那么该位的状态位1，下一个数在该为上位0，那么该位的状态位0。设当前某一位为1，下一个数在该位上为1，那么该位的状态位0，下一个数在该为上位0，那么该位的状态位1。这不正好符合异或的定义吗？</p>
<p>那我们考虑一下每个元素出现三次时的情况，也应该记录二进制位中1出现的个数，并对3求余，一个数如果某一位是1，出现3次，就为3，然后对3求余就为0。因此单独的一个数对3求余就为1，所以该数在哪些位置上为1，则最后的结果在哪些位置上也为1。但是出现了一个问题，出现2次，余数可以用0和1表示，那么出现3次如何表示呢？余数为0，1，2，需要使用3个状态表示，也就是需要两位表示。</p>
<p>下面借用Leetcode Krahets(K神)的图<br><img src="/images/ALGORITHM/leetcode137_solve.png" alt="q"></p>
<p>当two为0时，如果下一个数为0，则one的状态不变，如果下一个数为1，则one的状态反转。<br>当two为1时，无论下一个数时0还是1，one都为0。<br>可以列出下表进行推导one为0或者1时，two的变化，注意one为更新后的值。<br><img src="/images/ALGORITHM/leetcode137_solve1.png" alt="q"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def singleNumber(self, nums):</span><br><span class="line">        ones, twos = 0, 0</span><br><span class="line">        for num in nums:</span><br><span class="line">            ones = ones ^ num &amp; ~twos</span><br><span class="line">            twos = twos ^ num &amp; ~ones</span><br><span class="line">        return ones</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  大佬的思路太漂亮，不禁感叹自己还是太菜啦~，我们不是要记住这一题，而是要记住状态转移的方式，然后列表推导出下一个状态的表达式，这个才是这个问题的核心，以后无论数据重复多少次都有类似的解法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>位运算</category>
        <category>有限状态自动机</category>
      </categories>
  </entry>
  <entry>
    <title>只出现一次的数字(Leetcode 136)</title>
    <url>/2020/08/09/program%20Leetcode136/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode136.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>  接下来的几天给小伙伴介绍一种新题型，当我看到这个题目的时候，我觉得很简单，但是往往面试或者笔试的时候，会对时间复杂度或者空间复杂度进行限制，让我们一起来康一康吧。</p>
<a id="more"></a>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="5" color="red">位运算</font></h1><p>当然暴力求解很容易，用一个字典保存每一个值出现的次数即可。但是空间复杂度为O(n)，可不可以使用一种空间复杂度为O(1)的算法呢？位运算应运而生了，异或的特点是相同为0，那么两个相同的数字异或会得到0，0和x异或为x。如果所有的数都出现两次，那么将所有的数字异或的结果为0，如果只有一个数字出现了一次，那么异或的结果为该数字。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def singleNumber(self, nums):</span><br><span class="line">        return reduce(lambda x, y: x ^ y, nums)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  一个Pythonic的写法，只需要一行代码，非常简洁。妙啊~，位运算往往就是这样，难度可能并不大，但是不容易想到，那接下来让我们看一看难度较大的题目吧。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>位运算</category>
      </categories>
  </entry>
  <entry>
    <title>数字序列中某一位的数字(Leetcode 剑指Offer44)</title>
    <url>/2020/08/07/program%20Leetcode_offer44/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer44.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目应该和43题一起做，都是经典的找规律的题目，这个题目相比上一题简单一些，小伙伴们开动脑筋想一想。</p>
<a id="more"></a>
<h1 id="数学规律"><a href="#数学规律" class="headerlink" title="数学规律"></a><font size="5" color="red">数学规律</font></h1><p>我们一般按照位数进行找规律，0-9一位数中，每个数字只有一个字符，共10个字符。而10-99中，这90个两位数中，每个数字都有2个字符，共180个字符。而100-999中，共有900个数字，每个数字有3个字符，共2700个字符。我们将其累加，就可以得到从0开始到k位数的字符总和。如果n大于该数，说明还需要继续叠加，如果n小于等于该数，说明n在k位数之中。</p>
<p>我以2000这个数字举例，0-99有190个字符，0-999有2890个字符，因此2000在100-999之间，而100-999全都是3位数，因此2000-190=1810说明是从100开始的第1810个字符。1810除以3得到的整数位603，即从100开始的第603个数是602，余数为1，说明是602的第1个字符（索引从0开始计算），因此结果为0。时间复杂度为$O(log(n))$，空间复杂度为$O(log(n))$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findNthDigit(self, n: int) -&gt; int:</span><br><span class="line">        if n &lt; 10:</span><br><span class="line">            return n</span><br><span class="line">        current, next_ = 10, 190</span><br><span class="line">        k = 2</span><br><span class="line">        while next_ &lt; n:</span><br><span class="line">            k += 1</span><br><span class="line">            current = next_</span><br><span class="line">            next_ = next_ + 9 * k * 10 ** (k - 1)</span><br><span class="line">        number = (n - current) // k + 10 ** (k - 1)</span><br><span class="line">        remain = (n - current) % k</span><br><span class="line">        return int(str(number)[remain])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  数学题目的规律往往需要按照数字的位数进行找规律，先找一位数，然后找两位数，然后找三位数，往往就可以发现一些规律。这种题不经常出现，但也是小伙伴们必须要掌握的，否则遇到就两眼一抹黑。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>1～n整数中1出现的次数(Leetcode 剑指Offer43)</title>
    <url>/2020/08/05/program%20Leetcode_offer43/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer43.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题目典型的找规律，为什么这么说呢？从时间复杂度上就可以看出端倪，一般从数据量上就可以看出，这个题目的数据最大为$2^31$，说明用线性复杂度的算法都会超时，那么一定有特殊的方法进行求解。</p>
<a id="more"></a>
<h1 id="数学规律"><a href="#数学规律" class="headerlink" title="数学规律"></a><font size="5" color="red">数学规律</font></h1><p>我们一般按照位数进行找规律，0-9一位数中，只有1个1出现，而00-99中，这100个两位数中，有20个1出现，为什么呢？因为两位数的各位都是0-9，重复了10次，00-09，10-19，20-29，等等，一共10组，每一组的个位都有一个1，因此有10个，但是10-19这十个数中，十位也都是1，那么共有10 + 10 x 1 = 20个1。同理，我们可以得出000-999，这1000个三位数中，000-099，100-199，200-299，等等，一共10组，每一组的后两位都相当于00-99，因此共有10 x 20 = 200个，而且100-199，共有100个1，因此共有100 + 10 x 20 = 300个1。<br>根据这个规律，我们可以使用一种递归的思想，进行求解。<br>我以6666这个数字举例，6666可以分成6000+666因为最高位是6，因此可以看成从0-5999中所有1的个数，加上6000-6666中所有1的个数，0-5999的个数，可以从上面的规律中直接求解，0-999共有300个1，因此0-5999共有1000 + 6 <em> 300 = 2800个1，而6000-6666中，最高位都是6，可以看成0-666中所有的1的个数。就变成求2800 + 0-666中1的个数。再次递归，666可以分成600 + 66，0-599共有 100 + 6 </em> 20 = 220，因此变成求2800 + 220 + 0-66中1的个数。再次递归，66可以分成60 + 6，0-59共有10 + 6 + 1 = 16，因此变为2800 + 220 + 16 + 0-6中1的个数。再次递归，0-6中只有1个，总数为2800 + 220 + 16 + 1 = 3037个。<br>再举一个复杂一点的例子6106，6106可以分成6000 + 106，可以看成0-5999中所有1的个数共有2800个1，加上6000-6106中所有1的个数，因此变成求2800 + 0-106中1的个数。再次递归，106可以分成100 + 6，可以看成0-99中所有1的个数，加上100-106中所有1的个数，0-99中1的个数为20，因为没有超过200，所以不能加100，而且100-106中最高位是1，因此不能看成0-6中1的个数，而是要加上100-106中数字的个数，因为每一个数字的最高位都是1。这样就可以看成0-6中1的个数，因此为2800 + 20 + (106 - 100) + 1 + 0-6中1的个数，等于2828个。<br>因为一位数也满足这个条件，因此可以将一位数也放入该情形，不需要单独进行讨论，所以可以得到下面的代码。时间复杂度为$O(log(n))$，空间复杂度为$O(log(n))$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    res = 0</span><br><span class="line">    def countDigitOne(self, n):</span><br><span class="line">        lens = len(str(n))</span><br><span class="line">        one_num = [0] * lens</span><br><span class="line">        for i in range(1, lens):</span><br><span class="line">            one_num[i] = one_num[i - 1] * 10 + 10 ** (i - 1)</span><br><span class="line">        self.res = 0</span><br><span class="line">        </span><br><span class="line">        def sub_question(n):</span><br><span class="line">            if n == 0:</span><br><span class="line">                return</span><br><span class="line">            array = [int(x) for x in str(n)]</span><br><span class="line">            lens = len(array)</span><br><span class="line">            high = 10 ** (lens - 1)</span><br><span class="line">            if array[0] == 1:</span><br><span class="line">                self.res += n - high + 1 + one_num[lens - 1]</span><br><span class="line">            elif array[0] != 0:</span><br><span class="line">                self.res += high + one_num[lens - 1] * array[0]</span><br><span class="line">            sub_question(n - high * array[0])</span><br><span class="line">        </span><br><span class="line">        sub_question(n)</span><br><span class="line">        return self.res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这个题目还是比较有趣的，难度较大，很多同学采用暴力法进行遍历统计1的个数，那么时间复杂度为$O(n \times log(n))$，在数据量很大的时候，是不合适的。这道题是不是非常有趣呢，小伙伴们务必掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>丑数 II(Leetcode 264)</title>
    <url>/2020/08/04/program%20Leetcode264/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode264.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   非常有趣的一道题，看似简单，其实做起来很不容易想到最优的方法，我第一眼看上去就知道需要使用DP进行求解，然而提交时超出了时间限制，下面带小伙伴们看一看。</p>
<a id="more"></a>
<h1 id="DP-超时"><a href="#DP-超时" class="headerlink" title="DP(超时)"></a><font size="5" color="red">DP(超时)</font></h1><p>第i个数是丑数的前提是，i除以2或i除以3或i除以5是丑数，于是可以从2开始遍历。2除以2等于1，是丑数，因此将2加入哈希表中，3除以3等于1，是丑数，因此将3加入哈希表中，4除以2等于2，是丑数，因此将4加入哈希表中，以此类推。</p>
<p>因为n较大时，这个数非常大，因此会TLE。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def nthUglyNumber(self, n):</span><br><span class="line">        """</span><br><span class="line">        :type n: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        dp = set()</span><br><span class="line">        dp.add(1)</span><br><span class="line">        current = 1</span><br><span class="line">        while len(dp) &lt; n:</span><br><span class="line">            current += 1</span><br><span class="line">            if current / 2 in dp or current / 3 in dp or current / 5 in dp:</span><br><span class="line">                dp.add(current)</span><br><span class="line">        return current</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化DP"><a href="#优化DP" class="headerlink" title="优化DP"></a><font size="5" color="red">优化DP</font></h1><p>上面的方法虽然可行，但是当n=1690时，第n个丑数为2123366400，超过了时间限制。我们需要找一种时间复杂度更小的算法。我们发现丑数除以2，除以3，除以5也都是丑数，因此我们只需要保存丑数序列即可，建立三个指针，都指向1，一个指针每次负责乘2，一个负责乘3，一个负责乘5，因为指针都是指向丑数，因此三个指针乘积结果最小的也就是当前的丑数。再比较这个数是由哪一个指针得到，说明这个指针应该相后移动一个距离，移到下一个可能产生丑数的地方。</p>
<p>算法的<strong>时间复杂度为$O(n)$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def nthUglyNumber(self, n):</span><br><span class="line">        """</span><br><span class="line">        :type n: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        p2, p3, p5 = 0, 0, 0</span><br><span class="line">        dp = [1] * n</span><br><span class="line">        for i in range(1, n):</span><br><span class="line">            mini = min(dp[p2] * 2, dp[p3] * 3, dp[p5] * 5)</span><br><span class="line">            if mini == dp[p2] * 2:</span><br><span class="line">                p2 += 1</span><br><span class="line">            if mini == dp[p3] * 3:</span><br><span class="line">                p3 += 1</span><br><span class="line">            if mini == dp[p5] * 5:</span><br><span class="line">                p5 += 1</span><br><span class="line">            dp[i] = mini</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a><font size="5" color="red">堆</font></h1><p>这个题目也可以使用最小堆来解决，我们每次取一个最小值k，cnt += 1，让k x 2，k x 3，k x 5的值都加入最小堆中，当cnt == k时，返回该值即可。</p>
<p>用哈希表存储最小堆中的值，有重复值时不用重复插入。</p>
<p>因为我们按照位来操作，因此算法的<strong>时间复杂度为$O(nlog(n))$，空间复杂度为$O(n)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import heapq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def nthUglyNumber(self, n):</span><br><span class="line">        """</span><br><span class="line">        :type n: int</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        visited = {1}</span><br><span class="line">        heap = [1]</span><br><span class="line">        cnt = 1</span><br><span class="line">        while cnt != n:</span><br><span class="line">            mini = heapq.heappop(heap)</span><br><span class="line">            mini_2, mini_3, mini_5 = mini * 2, mini * 3, mini * 5</span><br><span class="line">            if mini_2 not in visited:</span><br><span class="line">                visited.add(mini_2)</span><br><span class="line">                heapq.heappush(heap, mini_2)</span><br><span class="line">            if mini_3 not in visited:</span><br><span class="line">                visited.add(mini_3)</span><br><span class="line">                heapq.heappush(heap, mini_3)</span><br><span class="line">            if mini_5 not in visited:</span><br><span class="line">                visited.add(mini_5)</span><br><span class="line">                heapq.heappush(heap, mini_5)</span><br><span class="line">            cnt += 1</span><br><span class="line">        return heap[0]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  丑数是不是非常有趣呢？这个题目的最优解是一个三指针加动态规划的问题，希望小伙伴可以喜欢。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>数学</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>表示数值的字符串(Leetcode 剑指Offer20)</title>
    <url>/2020/08/03/program%20Leetcode_offer20/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcodeoffer20.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   在某大厂的笔试中，我做过这道题目，不过当时的笔试较为简单，没有这个题目来的复杂。我们就来说一说这种判断是否合法的题目。</p>
<a id="more"></a>
<h1 id="有限状态自动机"><a href="#有限状态自动机" class="headerlink" title="有限状态自动机"></a><font size="5" color="red">有限状态自动机</font></h1><p>哇哦，名字就要起成我看不懂的样子，其实认真看下去也并不难，其主要是状态之间的来回转换。我们分析，合法的输入字符有哪些。<br>空格，符号，数字，小数点，e或者E。其他的都是不正确的输入。如果暴力if，当然也可以求解，在这里就不过多赘述，小伙伴们可以自行验证。<br>状态机，顾名思义，就是在状态之间来回转换，看一看能否到达最终的状态，如果可以则为有效输入，否则为无效输入。<br>下面在代码中对重要部分进行解读。<br><img src="/images/ALGORITHM/leetcodeoffer20_solve.png" alt="q"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def isNumber(self, s):</span><br><span class="line">        dic = [</span><br><span class="line">        # 起始状态为0，后面可以为空格" 1"，正负号"-2"，数字"3"或者小数点".4"，其他的都是不合法的。</span><br><span class="line">        # 可以将起始处的空格定义为状态0，符号定义为状态1，数字定义为状态2，小数点定义为状态4。</span><br><span class="line">        {'blank': 0, 'sign': 1, 'digit': 2, 'dot': 4},</span><br><span class="line">        # 如果位于状态1，则为列表dic的索引1，出现了符号，后面可以为数字"-2"，或者小数点"-.4"，其他的都是不合法的。</span><br><span class="line">        # 数字已经定义了为状态2，小数点也定义了为状态4。</span><br><span class="line">        {'digit': 2, 'dot': 4},</span><br><span class="line">        # 如果位于状态2，则出现了数字，后面可以为数字"33"，小数点"3.4"，e"3e5"，空格"3 "，其他的都是不合法的。</span><br><span class="line">        # 数字已经定义了为状态2，小数点定义为状态3，因为状态4为前面无数字的小数点，状态3则为前面有数字的小数点，e定义为状态5，空格定义为状态8</span><br><span class="line">        {'digit': 2, 'dot': 3, 'e': 5, 'blank': 8},</span><br><span class="line">        # 有的小朋友感觉困惑？为什么需要两个状态的小数点，因为前面有数字的小数点，后面还可以跟数字"34"，e"3.e"，或者直接结束"3."</span><br><span class="line">        {'digit': 3, 'e': 5, 'blank': 8},</span><br><span class="line">        # 而前面没有数字的小数点，后面只能够跟数字，因此两个小数点的状态是不同的，所以需要不同的记录方式，符号位，数字位，空格都是相同的道理。</span><br><span class="line">        {'digit': 3},</span><br><span class="line">        # 如果位于状态5，出现了e，那么后面可以跟符号"3e+5"，或者数字"3e5"</span><br><span class="line">        # 符号定义为状态6，数字定义为状态7</span><br><span class="line">        {'sign': 6, 'digit': 7},</span><br><span class="line">        # 如果位于状态6，出现了符号，那么后面只能跟数字"3e+5"</span><br><span class="line">        # 数字定义为状态7</span><br><span class="line">        {'digit': 7},</span><br><span class="line">        # 如果位于状态7，出现了数字，那么后面可以跟数字"3e44"，或者空格"3e4 "</span><br><span class="line">        # 数字定义为状态7，空格定义为状态8</span><br><span class="line">        {'digit': 7, 'blank': 8},</span><br><span class="line">        # 如果位于状态8，出现了空格，那么代表结束，只能跟空格</span><br><span class="line">        {'blank': 8}</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        # 设置初始状态为0</span><br><span class="line">        p = 0</span><br><span class="line">        # 遍历所有的字符，进行状态的转化</span><br><span class="line">        for c in s:</span><br><span class="line">            if c == ' ':</span><br><span class="line">                state = 'blank'</span><br><span class="line">            elif c == '+' or c == '-':</span><br><span class="line">                state = 'sign'</span><br><span class="line">            elif c == '.':</span><br><span class="line">                state = 'dot'</span><br><span class="line">            elif c == 'e' or c == 'E':</span><br><span class="line">                state = 'e'</span><br><span class="line">            elif c.isdigit():</span><br><span class="line">                state = 'digit'</span><br><span class="line">            else:</span><br><span class="line">                state = 'ERROR'</span><br><span class="line">            # 如果下一个状态不在当前状态的表中，说明报错，则不可以表示</span><br><span class="line">            if state not in dic[p]:</span><br><span class="line">                return False</span><br><span class="line">            # 如果在则继续判断是否在下一个状态中。</span><br><span class="line">            p = dic[p][state]</span><br><span class="line">        # 最终的状态是位于2，3，7，8状态中的一个，即必须要以状态2的数字结尾，状态3的小数点结尾，状态7的数字结尾，状态8的空格结尾。</span><br><span class="line">        return p in {2, 3, 7, 8}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  在这个文章里，详细的给小伙伴们捋了一下有限状态自动机的使用情景，小伙伴们需要认真审视自己的状态表，千万不要遗漏情况，要记得考虑一个字符的多种使用情景需要分配多种状态，记得这些事情，小伙伴们再也不用担心使用繁杂的if语句了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>有限状态自动机</category>
      </categories>
  </entry>
  <entry>
    <title>被围绕的区域(Leetcode 130)</title>
    <url>/2020/08/02/program%20Leetcode130/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode130.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题目难度不大，是一个经典的图搜索问题，如何搜索才能达到最高的效率呢？这题有一个巧妙的方法。</p>
<a id="more"></a>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>图的搜索方法，深度优先搜索，但是这道题的技巧在于，从边缘点进行搜索，搜索到的点都是不被围绕的点。为了记录搜索的路径，常用方法是建立一个哈希表，存放已经经过的点，这里为了节省空间，使用了一种技巧，将搜索过的点改为A，那么下次再搜索到时也不会进行重复搜索，非常方便。时间复杂度为$O(m \times n)$，空间复杂度为$O(m \times n)$<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def solve(self, board):</span><br><span class="line">        """</span><br><span class="line">        Do not return anything, modify board in-place instead.</span><br><span class="line">        """</span><br><span class="line">        def dfs(x, y):</span><br><span class="line">            board[x][y] = "A"</span><br><span class="line">            for i, j in direction:</span><br><span class="line">                new_x, new_y = x + i, y + j</span><br><span class="line">                if 0 &lt;= new_x &lt; row and 0 &lt;= new_y &lt; col and board[new_x][new_y] == "O":</span><br><span class="line">                    dfs(new_x, new_y)</span><br><span class="line"></span><br><span class="line">        if not board:</span><br><span class="line">            return board</span><br><span class="line">        direction = [[0, 1], [0, -1], [1, 0], [-1, 0]]</span><br><span class="line">        row, col = len(board), len(board[0])</span><br><span class="line">        for i in range(row):</span><br><span class="line">            if board[i][0] == "O":</span><br><span class="line">                dfs(i, 0)</span><br><span class="line">            if board[i][col - 1] == "O":</span><br><span class="line">                dfs(i, col - 1)</span><br><span class="line">        for j in range(col):</span><br><span class="line">            if board[0][j] == "O":</span><br><span class="line">                dfs(0, j)</span><br><span class="line">            if board[row - 1][j] == "O":</span><br><span class="line">                dfs(row - 1, j)</span><br><span class="line">        for i in range(row):</span><br><span class="line">            for j in range(col):</span><br><span class="line">                if board[i][j] == "A":</span><br><span class="line">                    board[i][j] = "O"</span><br><span class="line">                elif board[i][j] == "O":</span><br><span class="line">                    board[i][j] = "X"</span><br><span class="line"></span><br><span class="line">        return board</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>这道题也可以类似的使用BFS来进行求解，解题思路大致相同。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def solve(self, board):</span><br><span class="line">        """</span><br><span class="line">        Do not return anything, modify board in-place instead.</span><br><span class="line">        """</span><br><span class="line">        if not board:</span><br><span class="line">            return board</span><br><span class="line">        direction = [[0, 1], [0, -1], [1, 0], [-1, 0]]</span><br><span class="line">        row, col = len(board), len(board[0])</span><br><span class="line"></span><br><span class="line">        queue = deque()</span><br><span class="line"></span><br><span class="line">        for i in range(row):</span><br><span class="line">            if board[i][0] == "O":</span><br><span class="line">                queue.append((i, 0))</span><br><span class="line">            if board[i][col - 1] == "O":</span><br><span class="line">                queue.append((i, col - 1))</span><br><span class="line">        for j in range(col):</span><br><span class="line">            if board[0][j] == "O":</span><br><span class="line">                queue.append((0, j))</span><br><span class="line">            if board[row - 1][j] == "O":</span><br><span class="line">                queue.append((row - 1, j))</span><br><span class="line"></span><br><span class="line">        while queue:</span><br><span class="line">            x, y = queue.popleft()</span><br><span class="line">            board[x][y] = "A"</span><br><span class="line">            for i, j in direction:</span><br><span class="line">                new_x, new_y = x + i, y + j</span><br><span class="line">                if 0 &lt;= new_x &lt; row and 0 &lt;= new_y &lt; col and board[new_x][new_y] == "O":</span><br><span class="line">                    queue.append((new_x, new_y))</span><br><span class="line"></span><br><span class="line">        for i in range(row):</span><br><span class="line">            for j in range(col):</span><br><span class="line">                if board[i][j] == "A":</span><br><span class="line">                    board[i][j] = "O"</span><br><span class="line">                elif board[i][j] == "O":</span><br><span class="line">                    board[i][j] = "X"</span><br><span class="line"></span><br><span class="line">        return board</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  路径搜索问题已经不想重复强调了，重要！重要！重要！</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>C++面向对象完结</title>
    <url>/2020/07/31/C++_oop_5/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++52.png" alt="2"></p>
<h1 id="C-面向对象完结"><a href="#C-面向对象完结" class="headerlink" title="C++面向对象完结"></a><font size="5" color="red">C++面向对象完结</font></h1><p>  C++面向对象终于来到了完结篇，最后剩下的内容也是最最重要的内容——多态和虚函数，虽然在自己写代码时很少用到，但是在企业级开发中是必不可少的部分，在最终章会为大家详细介绍。<br><a id="more"></a></p>
<h1 id="函数重写"><a href="#函数重写" class="headerlink" title="函数重写"></a><font size="5">函数重写</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	//父类中存在一个成员方法，名为program</span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是程序员，我会写代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class CppProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line">	//函数重写，发生在继承关系中，子类的方法名和参数列表和父类一样，则会发生函数重写。</span><br><span class="line">	//特点是创建子类对象会优先调用子类方法。</span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Cpp程序员，我会写Cpp代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class JavaProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Java程序员，我会写Java代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class PythonProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Python程序员，我会写Python代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person p;</span><br><span class="line">	CppProgrammer cp;</span><br><span class="line">	JavaProgrammer jp;</span><br><span class="line">	PythonProgrammer pp;</span><br><span class="line"></span><br><span class="line">	//调用父类对象的成员方法时，会使用父类的成员方法。</span><br><span class="line">	p.program();</span><br><span class="line">	//调用子类对象的成员方法时，会使用子类的成员方法。</span><br><span class="line">	cp.program();</span><br><span class="line">	jp.program();</span><br><span class="line">	pp.program();</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++53.png" alt="1"></p>
<h1 id="多态"><a href="#多态" class="headerlink" title="多态"></a><font size="5">多态</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	//虚函数：在成员函数前面加上virtual关键字，称这个函数为虚函数。</span><br><span class="line">	//如果将父类中的函数实现舍去，并且在函数的参数列表后面加上=0;则称为纯虚函数。</span><br><span class="line">	//当有了纯虚函数，这个类就被称为抽象类，抽象类无法实例化对象，而且子类必须重写抽象类中的纯虚函数，否则也是抽象类。</span><br><span class="line">	virtual void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是程序员，我会写代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class CppProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line">	</span><br><span class="line">	//多态的本质：父类指针或者引用指向子类对象，调用时会调用子类的成员方法。</span><br><span class="line">	//多态的两个必要条件：有继承关系，子类要重写父类的虚函数。</span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Cpp程序员，我会写Cpp代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class JavaProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Java程序员，我会写Java代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class PythonProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Python程序员，我会写Python代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void test(Person&amp; p) {</span><br><span class="line">	p.program();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	</span><br><span class="line">	//因为Person类中的program方法有具体的实现，因此不是一个抽象类，可以创建实例对象。</span><br><span class="line">	Person p;</span><br><span class="line">	CppProgrammer cp;</span><br><span class="line">	JavaProgrammer jp;</span><br><span class="line">	PythonProgrammer pp;</span><br><span class="line"></span><br><span class="line">	//将父类的实例对象传给父类的引用，程序正常执行。</span><br><span class="line">	test(p);</span><br><span class="line">	//将子类的实例对象传给父类的引用，将产生多态，会执行子类的成员方法。</span><br><span class="line">	test(cp);</span><br><span class="line">	test(jp);</span><br><span class="line">	test(pp);</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++54.png" alt="1"></p>
<h1 id="虚析构与纯虚析构"><a href="#虚析构与纯虚析构" class="headerlink" title="虚析构与纯虚析构"></a><font size="5">虚析构与纯虚析构</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">	Person() {</span><br><span class="line">		cout &lt;&lt; "父类的构造函数被调用" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	virtual void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是程序员，我会写代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~Person() {</span><br><span class="line">		cout &lt;&lt; "父类的析构函数被调用" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class CppProgrammer :public Person {</span><br><span class="line">public:</span><br><span class="line">	</span><br><span class="line">	CppProgrammer() {</span><br><span class="line">		cout &lt;&lt; "子类的构造函数被调用" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void program() {</span><br><span class="line">		cout &lt;&lt; "我的名字是Cpp程序员，我会写Cpp代码" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~CppProgrammer() {</span><br><span class="line">		cout &lt;&lt; "子类的析构函数被调用" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	{</span><br><span class="line">		//当使用new在堆区中开辟子类对象数据，并返回给父类指针时。</span><br><span class="line">		//delete父类指针，无法看到子类的析构函数，这就不会调用子类的析构函数，因此有内存泄漏的风险。</span><br><span class="line">		//解决办法有两种，一个是在父类的析构函数前加virtual关键字，变成一个虚析构函数。</span><br><span class="line">		//第二种方法是将父类的析构函数变为一个纯虚析构函数，但是此时运行会产生错误，因为父类的一些成员变量可能无法析构，所以还要在类外通过作用域进行实现。</span><br><span class="line">		//此时两者的区别是，虚析构函数的父类不是一个抽象类，而纯虚析构函数的父类是一个抽象类。</span><br><span class="line">		Person* p = new CppProgrammer();</span><br><span class="line">		p-&gt;program();</span><br><span class="line">		delete p;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++55.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  到今天为止，面向对象的所有内容都已经给小伙伴们分享完了，至于其中包含的奇技淫巧，需要小伙伴们慢慢磨砺，多态是设计模式的基础，以后会给小伙伴们详细介绍设计模式，在这里一定要掌握多态的用法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>整数拆分(Leetcode 343)</title>
    <url>/2020/07/30/program%20Leetcode343/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode343.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   整数拆分问题是一个数学问题，如果指定拆分个数是2个的话，那么就是小伙伴们小学都学过的问题，可能小伙伴们会抬杠，小学怎么可能学过求二次函数最大值的问题呢？其实二拆分这个问题有另外一种描述：同样周长的正方形和长方形哪一个面积更大？Leetcode这一题将二拆分进行了推广，不指定拆分个数，这应该怎么做呢？暴力穷举当然是不行的，这是指数级的时间复杂度，应该如何优化呢？</p>
<a id="more"></a>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>我们使用动态规划进行求解，dp[i]表示第i个数分解可得的最大值，可以得到状态转移方程</p>
<script type="math/tex; mode=display">dp[i] = \max_{j = 1}^{i}(dp[i], dp[j] \times (i - j), j \times (i - j))</script><p>这个方案不难想到，小伙伴们千万不要忘记还有$i \times j$，DP的时间复杂度为$O(n^2)$，空间复杂度为$O(n)$，因为数字较小，因此很容易通过。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def integerBreak(self, n):</span><br><span class="line">        dp = [0] * (n + 1)</span><br><span class="line">        for i in range(2, n + 1):</span><br><span class="line">            for j in range(1, i):</span><br><span class="line">                dp[i] = max(dp[j] * (i - j), j * (i - j), dp[i])</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="数学方法"><a href="#数学方法" class="headerlink" title="数学方法"></a><font size="5" color="red">数学方法</font></h1><p>这个方法很巧妙，用一种归纳的方法进行这类问题的求解。有很多算法题，有一些较好的数学解法，这个题目可以给小伙伴们提供一个思路。<br>我们观察，如果一个数大于等于4，它的因子会出现什么情况？</p>
<ol>
<li>可不可能出现大于等于4的因子？答案是不可能的，假设存在这样一个数x，满足$x \ge 4$，那么$2(x - 2) \ge x$在x大于等于4时恒成立，因此可以进行拆分 。</li>
<li>2的个数不会超过3个，因为3个2的乘积为8，小于2个3的乘积9，因此如果可以拆分成3个2，那么不如拆分成2个3.</li>
<li>在大于等于5的情况中，不可能出现1，假设存在这样一个数x，满足$x - 1 \ge 4$，那么x - 1可以拆分成至少2个数，因此在其中一个增加1，乘积都会变大，所以不可能出现1的情况。<br>综上所述，当x大于等于5时，其因数只可能是2和3，且2的个数只能是0个，1个，2个，其余都是3，如果模3等于0，说明全部都是3，如果模3等于1，说明有2个2，如果模3等于2，说明有1个2。这种算法的时间复杂度为$O(1)$，空间复杂度为$O(1)$。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def integerBreak(self, n: int) -&gt; int:</span><br><span class="line">        if n &lt;= 3:</span><br><span class="line">            return n - 1</span><br><span class="line">        k, r = n // 3, n % 3</span><br><span class="line">        if r == 0:</span><br><span class="line">            return 3 ** k</span><br><span class="line">        elif r == 1:</span><br><span class="line">            return 3 ** (k - 1) * 4</span><br><span class="line">        else:</span><br><span class="line">            return 3 ** k * 2</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  数学方法往往很难想到，这道题目数据量较小，因此可以通过DP求解，如果这题的n非常大，那么就需要我们考虑数学方法，现在笔试的数据越来越庞大了，小伙伴们要加油呀。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数学</category>
        <category>动态规划</category>
      </categories>
  </entry>
  <entry>
    <title>C++面向对象拓展</title>
    <url>/2020/07/28/C++_oop_4/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++47.png" alt="2"></p>
<h1 id="C-面向对象拓展"><a href="#C-面向对象拓展" class="headerlink" title="C++面向对象拓展"></a><font size="5" color="red">C++面向对象拓展</font></h1><p>  C++面向对象还有一部分拓展知识，包括运算符重载以及多继承产生的问题，也可以给最终章的虚函数做一个铺垫，在这里给大家做简单的介绍。<br><a id="more"></a></p>
<h1 id="运算符重载"><a href="#运算符重载" class="headerlink" title="运算符重载"></a><font size="5">运算符重载</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line">	int age;</span><br><span class="line">	int money;</span><br><span class="line"></span><br><span class="line">	Person(string name, int age, int money) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;age = age;</span><br><span class="line">		this-&gt;money = money;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//operator加上要重载的运算符，称为运算符重载。</span><br><span class="line">	//在这里重载+运算符，两个对象之间不能进行运算，但是重载了加号运算符之后，可以根据重载的内容实现两个对象的加法运算。</span><br><span class="line">	int operator+(Person&amp; p) {</span><br><span class="line">		return this-&gt;money + p.money;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//在这里重载==运算符，两个对象之间不能进行运算，但是重载了等于号运算符之后，可以根据重载的内容判断两个对象是否相等。</span><br><span class="line">	bool operator==(Person&amp; p) {</span><br><span class="line">		return this-&gt;age == p.age;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person p1("C++程序员", 28, 28000);</span><br><span class="line">	Person p2("Python程序员", 22, 22000);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.name &lt;&lt; " 我的年龄是：" &lt;&lt; p1.age &lt;&lt; " 我的工资是：" &lt;&lt; p1.money &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p2.name &lt;&lt; " 我的年龄是：" &lt;&lt; p2.age &lt;&lt; " 我的工资是：" &lt;&lt; p2.money &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	//重载后加法计算两个对象的money成员变量之和，因此会输出50000</span><br><span class="line">	cout &lt;&lt; "我们的工资总数为：" &lt;&lt; p1 + p2 &lt;&lt; endl;;</span><br><span class="line">	//重载等于号判断两个对象的年龄是否相等，因此会返回0</span><br><span class="line">	cout &lt;&lt; "我们的年龄是否相等：" &lt;&lt; (p1 == p2) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++48.png" alt="1"></p>
<h1 id="C-多继承"><a href="#C-多继承" class="headerlink" title="C++多继承"></a><font size="5">C++多继承</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class A {</span><br><span class="line">public:</span><br><span class="line">	//A类中包括name和a两个成员变量和A的有参构造函数，以及getName成员方法</span><br><span class="line">	string name;</span><br><span class="line">	int a;</span><br><span class="line"></span><br><span class="line">	A(string name, int a) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;a = a;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class B {</span><br><span class="line">public:</span><br><span class="line">	//B类中包括name和b两个成员变量和B的有参构造函数，以及getName成员方法</span><br><span class="line">	string name;</span><br><span class="line">	int b;</span><br><span class="line"></span><br><span class="line">	B(string name, int b) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;b = b;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class C:public A, public B{</span><br><span class="line">public:</span><br><span class="line">	//C类中包括name和c两个成员变量和C的有参构造函数，以及getName成员方法</span><br><span class="line">	//C继承A也继承B，因此同时拥有A和B的成员，但是A和B的同名成员，需要使用作用域进行区分，如果子类也具有同名成员，则会覆盖父类的同名成员。	</span><br><span class="line">	string name;</span><br><span class="line">	int c;</span><br><span class="line"></span><br><span class="line">	//注意子类构造函数的写法，在参数列表后面加冒号，并写调用父类的构造函数，和Java，Python不同。</span><br><span class="line">	C(string name_a, int a, string name_b, int b, string name_c, int c) :A(name_a, a), B(name_b, b) {</span><br><span class="line">		this-&gt;name = name_c;</span><br><span class="line">		this-&gt;c = c;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">};</span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	C c("A", 1, "B", 2, "C", 3);</span><br><span class="line">	//对象c拥有类A的成员变量a</span><br><span class="line">	cout &lt;&lt; "c.a = " &lt;&lt; c.a &lt;&lt; endl;</span><br><span class="line">	//对象c拥有类B的成员变量b</span><br><span class="line">	cout &lt;&lt; "c.b = " &lt;&lt; c.b &lt;&lt; endl;</span><br><span class="line">	//对象c拥有类C的成员变量c</span><br><span class="line">	cout &lt;&lt; "c.c = " &lt;&lt; c.c &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//类C拥有和父类同名的成员变量name，因此子类的成员变量会覆盖父类</span><br><span class="line">	cout &lt;&lt; "c.name = " &lt;&lt; c.name &lt;&lt; endl;</span><br><span class="line">	//类C拥有和父类同名的成员方法getName，因此子类的成员方法会覆盖父类</span><br><span class="line">	cout &lt;&lt; "c.getName() = " &lt;&lt; c.getName() &lt;&lt; endl;</span><br><span class="line">	//类C拥有和类A同名的成员变量name，因此要想访问类A的成员变量，需要加入作用域</span><br><span class="line">	cout &lt;&lt; "c.A::name = " &lt;&lt; c.A::name &lt;&lt; endl;</span><br><span class="line">	//类C拥有和类A同名的成员方法getName，因此要想访问类A的成员方法，需要加入作用域</span><br><span class="line">	cout &lt;&lt; "c.A::getName() = " &lt;&lt; c.A::getName() &lt;&lt; endl;</span><br><span class="line">	//类C拥有和类B同名的成员变量name，因此要想访问类B的成员变量，需要加入作用域</span><br><span class="line">	cout &lt;&lt; "c.B:::name = " &lt;&lt; c.B::name &lt;&lt; endl;</span><br><span class="line">	//类C拥有和类B同名的成员方法getName，因此要想访问类B的成员方法，需要加入作用域</span><br><span class="line">	cout &lt;&lt; "c.B::getName() = " &lt;&lt; c.B::getName() &lt;&lt; endl;</span><br><span class="line">	//类C拥有和父类同名的成员变量name，因此子类默认调用自己的成员变量，c.C::name等价于c.name</span><br><span class="line">	cout &lt;&lt; "c.C::name = " &lt;&lt; c.C::name &lt;&lt; endl;</span><br><span class="line">	//类C拥有和父类同名的成员方法getName，因此子类默认调用自己的成员方法，c.C::getName等价于c.getName</span><br><span class="line">	cout &lt;&lt; "c.C::getName() = " &lt;&lt; c.C::getName() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++49.png" alt="1"></p>
<h1 id="C-菱形继承——解决方案"><a href="#C-菱形继承——解决方案" class="headerlink" title="C++菱形继承——解决方案"></a><font size="5">C++菱形继承——解决方案</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class A {</span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line">	int a;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class B :public A {</span><br><span class="line">public:</span><br><span class="line">	int b;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class C :public A {</span><br><span class="line">public:</span><br><span class="line">	int c;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//D类继承B和C类，然而B和C都继承A类，构成了一种菱形继承关系。</span><br><span class="line">//A类中的name成员变量，在D中的name不知道是从B中继承而来的还是从C中继承而来的</span><br><span class="line">class D :public B, public C {</span><br><span class="line">public:</span><br><span class="line">	int d;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	D d;</span><br><span class="line">	//访问时和之前说过的一样，可以通过指定作用域来实现对哪一个父类的成员变量进行访问。</span><br><span class="line">	//但是不可以直接使用d.name，这就编译器不知道是从哪一个类继承而来的成员变量，会报错。</span><br><span class="line">	d.B::name = "B";</span><br><span class="line">	d.C::name = "C";</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "d.B::name = " &lt;&lt; d.B::name &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d.C::name = " &lt;&lt; d.C::name &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++51.png" alt="1"></p>
<h1 id="C-菱形继承——解决方案-1"><a href="#C-菱形继承——解决方案-1" class="headerlink" title="C++菱形继承——解决方案"></a><font size="5">C++菱形继承——解决方案</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class A {</span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line">	int a;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//对于上面发生的问题，通过在继承前面加上virtual关键字，代表虚继承。</span><br><span class="line">//小伙伴们可以理解为B和C不再保存A中的具体内容，而是保存了一份偏移地址。</span><br><span class="line">//当调用d.B::name时，会指向d.A::name，当调用d.C::name时，也会指向d.A::name，当调用d.name时也会指向d.A::name。</span><br><span class="line">class B :virtual public A {</span><br><span class="line">public:</span><br><span class="line">	int b;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class C :virtual public A {</span><br><span class="line">public:</span><br><span class="line">	int c;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">class D :public B, public C {</span><br><span class="line">public:</span><br><span class="line">	int d;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	D d;</span><br><span class="line">	d.B::name = "B";</span><br><span class="line">	d.C::name = "C";</span><br><span class="line"></span><br><span class="line">	//因此d.B::name和d.C::name和d.name都是相同的结果。</span><br><span class="line">	cout &lt;&lt; "d.B::name = " &lt;&lt; d.B::name &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d.C::name = " &lt;&lt; d.C::name &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d.name = " &lt;&lt; d.name &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	d.name = "D";</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "d.B::name = " &lt;&lt; d.B::name &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d.C::name = " &lt;&lt; d.C::name &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d.name = " &lt;&lt; d.name &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++51.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  今天的内容是C++面向对象的拓展部分，比较重要的部分是运算符的重载，在后面STL中可能会再次见到它，而菱形继承方式，我们在使用面向对象时，要尽量避免碰到它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>矩阵中的最长递增路径(Leetcode 329)</title>
    <url>/2020/07/26/program%20Leetcode329/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode329.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最长递增路径问题，是一个有向图问题，而且要更为复杂一些，不是一个简单的单向图，而是<strong>多向图</strong>。要想找到最长的一条路径，必然要使用两种常见的搜索方法，<strong>DFS和BFS</strong>。但是这两个搜索方法都有一个特点，就是<strong>已知起始点然后进行搜索</strong>，如果不知道起始点，如何搜索得到最长路径呢？一个最暴力的方法是遍历所有起始点，从每一个点开始搜索，并且比较哪一个最长。这样的方法时间复杂度太高，浪费的太多的计算资源，必然无法通过所有的样例，那么如何保存计算过程中的计算结果呢？有一个专业术语称为<strong>记忆化</strong>，下面给小伙伴聊一聊记忆化的DFS。</p>
<a id="more"></a>
<h1 id="记忆化-DFS"><a href="#记忆化-DFS" class="headerlink" title="记忆化+DFS"></a><font size="5" color="red">记忆化+DFS</font></h1><p>Python常用库给我们提供了一种重要的装饰器，<strong>lru_cache，其位于functools包下</strong>。主要是用于<strong>函数的递归调用时，会记录递归调用的结果，这样下次遇到同样的参数时，可以直接调出，不需要再次递归调用。其本质是一个字典，键是参数值，值是递归调用的结果</strong>。例如使用递归求斐波那契数列时，计算f(5)会使用到f(3)+f(4)，如果不使用lru_cache装饰器，已经得到了f(3)时，递归调用f(4)时还会重新调用f(3)的，这样就会出现指数爆炸式的计算量增长。当计算f(100)时，会递归调用f(99)和f(98)，如果有了lru_cache，就可以从字典中直接取出99和98对应的值，此时的时间复杂度为线性的，而递归是指数级的。<br>这道题也类似，<strong>我们遍历所有的点，从第一个点A去寻找最长递增路径的长度，如果寻找到了某一个点B，那么会记录从点B出发的最长递增路径，那么下次当其他点也寻找到了这个点B时，就不用重新遍历点B。时间复杂度为$O(mn)$，空间复杂度为$O(mn)$，m和n为矩阵的行和列</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def longestIncreasingPath(self, matrix):</span><br><span class="line">        """</span><br><span class="line">        :type matrix: List[List[int]]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        if not matrix:</span><br><span class="line">            return 0</span><br><span class="line">        direction = [[1, 0], [-1, 0], [0, 1], [0, -1]]</span><br><span class="line">        m, n = len(matrix), len(matrix[0])</span><br><span class="line"></span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def dfs(i, j):</span><br><span class="line">            res = 1</span><br><span class="line">            for x, y in direction:</span><br><span class="line">                new_x, new_y = i + x, j + y</span><br><span class="line">                if 0 &lt;= new_x &lt; m and 0 &lt;= new_y &lt; n and matrix[i][j] &gt; matrix[new_x][new_y]:</span><br><span class="line">                    res = max(res, dfs(new_x, new_y) + 1)</span><br><span class="line">            return res</span><br><span class="line"></span><br><span class="line">        result = 0</span><br><span class="line">        for i in range(m):</span><br><span class="line">            for j in range(n):</span><br><span class="line">                result = max(result, dfs(i, j))</span><br><span class="line">        return result</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="多源BFS"><a href="#多源BFS" class="headerlink" title="多源BFS"></a><font size="5" color="red">多源BFS</font></h1><p>这道题目也可以使用<strong>多源BFS</strong>来求解，我们理解题意可以发现，<strong>路径的终点一定是无法向四周扩展的点，也就是说终点的值一定大于周围的值</strong>，玩过围棋的小伙伴们更加了解这个说法，可以说是气，说明这个棋子还有几口气，如果周围都是对方的子，说明这个子没有气了，这也是同样道理，因此我们<strong>可以遍历所有的点，对每一个点计算四个方向的值，计算每一个点的气。然后对于每一个气为0的点，作为源，然后进行BFS广度优先搜索，搜索出距离源点为1且满足小于当前值的点，并且更新这些点的气，气的值减1，如果气为0，则加入下一轮的寻找过程中(这一步是关键，为什么气为0则加入下一轮，是因为如果气不为0，说明还有其他点可以到达，说明现在就到达这个点的路径必然不是最长路径)，依次寻找距离为2的点……，直到所有点都寻找完毕，此时的距离就是最长的路径</strong>。<br>这个算法的<strong>时间复杂度为$O(mn)$，空间复杂度也是$O(mn)$</strong>，我就直接将官方的题解借鉴过来，供大家参考。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    DIRS = [(-1, 0), (1, 0), (0, -1), (0, 1)]</span><br><span class="line"></span><br><span class="line">    def longestIncreasingPath(self, matrix):</span><br><span class="line">        if not matrix:</span><br><span class="line">            return 0</span><br><span class="line"></span><br><span class="line">        rows, columns = len(matrix), len(matrix[0])</span><br><span class="line">        outdegrees = [[0] * columns for _ in range(rows)]</span><br><span class="line">        queue = collections.deque()</span><br><span class="line">        for i in range(rows):</span><br><span class="line">            for j in range(columns):</span><br><span class="line">                for dx, dy in Solution.DIRS:</span><br><span class="line">                    newRow, newColumn = i + dx, j + dy</span><br><span class="line">                    if 0 &lt;= newRow &lt; rows and 0 &lt;= newColumn &lt; columns and matrix[newRow][newColumn] &gt; matrix[i][j]:</span><br><span class="line">                        outdegrees[i][j] += 1</span><br><span class="line">                if outdegrees[i][j] == 0:</span><br><span class="line">                    queue.append((i, j))</span><br><span class="line"></span><br><span class="line">        ans = 0</span><br><span class="line">        while queue:</span><br><span class="line">            ans += 1</span><br><span class="line">            size = len(queue)</span><br><span class="line">            for _ in range(size):</span><br><span class="line">                row, column = queue.popleft()</span><br><span class="line">                for dx, dy in Solution.DIRS:</span><br><span class="line">                    newRow, newColumn = row + dx, column + dy</span><br><span class="line">                    if 0 &lt;= newRow &lt; rows and 0 &lt;= newColumn &lt; columns and matrix[newRow][newColumn] &lt; matrix[row][column]:</span><br><span class="line">                        outdegrees[newRow][newColumn] -= 1</span><br><span class="line">                        if outdegrees[newRow][newColumn] == 0:</span><br><span class="line">                            queue.append((newRow, newColumn))</span><br><span class="line"></span><br><span class="line">        return ans</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  多次强调，<strong>DFS和BFS问题是高频考点</strong>，现在的题目难度越来越高，因此在掌握了基本的DFS和BFS之后，还需要多刷题，<strong>掌握一些奇技淫巧</strong>，这样遇到图相关的问题才能从容应对。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>记忆化</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>分割数组的最大值(Leetcode 410)</title>
    <url>/2020/07/25/program%20Leetcode410/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode410.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目非常有难度，<strong>要将一个数组拆分成若干个子数组，并且要求得到的各个子数组之和的最大值最小。也就是说我们要切割的非常巧妙，尽量让每一个子数组之和相同，这样就不会产生有的很大，有的很小的问题</strong>。</p>
<a id="more"></a>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>我们假定f[i][j]代表前i个元素分成j个数组，得到的最优解。而且已知cum_sum为前缀和，前缀和就是前i个数字的总和。如cum_sum[i] = nums[0] + nums[1] + … + nums[i - 1]，当i=0时，cum_sum=0。那么我们可以<strong>得出状态转移方程f[i][j] = min(f[i][j], max(f[k][j-1], cum_sum[i] - cum_sum[k])) for k in range(i - 1)</strong>。具体描述一下，f[k][j-1]说明的是在从前i个数分成j个数组中，已经将前k个数分成了j-1个数组得到的最优解，然后其余的从第k+1个数到第i个数之和为cum_sum[i] - cum_sum[k]，然后求两者的最大值，为这次分割得到的子数组最大值。遍历所有的k，求得使这个最大值最小的值。因为对于每一个数组前缀i和子数组个数j都要遍历i次，求出f[i][j]的最优解。因此<strong>时间复杂度为$O(n^{2}m)$，空间复杂度为$O(nm)$，其中n为数组的长度，m为子数组的个数</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def splitArray(self, nums: List[int], m: int) -&gt; int:</span><br><span class="line">        cum_sum = [0]</span><br><span class="line">        n = len(nums)</span><br><span class="line">        for i in range(n):</span><br><span class="line">            cum_sum.append(cum_sum[-1] + nums[i])</span><br><span class="line">        </span><br><span class="line">        dp = [[float('inf') for _ in range(m + 1)] for _ in range(n + 1)]</span><br><span class="line">        dp[0][0] = 0</span><br><span class="line">        for i in range(1, n + 1):</span><br><span class="line">            for j in range(1, min(i, m) + 1):</span><br><span class="line">                for k in range(i):</span><br><span class="line">                    dp[i][j] = min(dp[i][j], max(dp[k][j - 1], cum_sum[i] - cum_sum[k]))</span><br><span class="line">        return dp[-1][-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="二分查找-贪心"><a href="#二分查找-贪心" class="headerlink" title="二分查找+贪心"></a><font size="5" color="red">二分查找+贪心</font></h1><p>这道题最妙的地方不在于DP，而是<strong>二分查找+贪心</strong>的算法，<strong>官方题解中写道：「使……最大值尽可能小」是二分搜索题目常见的问法</strong>。我们<strong>已知子数组之和的上限和下限，要找到最小的满足条件的子数组之和，就可以采用二分法，让上限和下限逐渐逼近于最终的答案</strong>。因为这是一个连续的子数组之和问题，所以我们只需要<strong>选择一个值，然后让子数组之和尽可能接近这个值，但是不超过这个值，一但超过，说明进入了下一个子数组。如果到最后子数组的个数小于等于给定的子数组个数，则说明这个值是满足条件的，可能需要继续缩小。否则这个值是小的，应该继续增大</strong>。<br><strong>因为子数组的最大值为全部数字之和，记作sum，子数组的最小值为单个数字的最大值，记作max，当然还可以继续优化，可以选择max和sum整除m的较大者。因为sum平分成m份，至少每个数组之和都是sum除以m，因此至少为sum整除m，我们就按照官方题解来叙述。从sum和max之间进行二分查找。因此时间复杂度为$O(nlog(sum-max))$，空间复杂度为$O(1)$</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def splitArray(self, nums: List[int], m: int) -&gt; int:</span><br><span class="line"></span><br><span class="line">        def check(max_val):</span><br><span class="line">            current_sum = 0</span><br><span class="line">            current_group = 1</span><br><span class="line">            for x in nums:</span><br><span class="line">                current_sum += x</span><br><span class="line">                if current_sum &gt; max_val:</span><br><span class="line">                    current_group += 1</span><br><span class="line">                    current_sum = x</span><br><span class="line">                    if current_group &gt; m:</span><br><span class="line">                        return False</span><br><span class="line">            return True</span><br><span class="line"></span><br><span class="line">        left, right = max(nums), sum(nums)</span><br><span class="line">        while left &lt; right:</span><br><span class="line">            mid = (left + right) // 2</span><br><span class="line">            if check(mid):</span><br><span class="line">                right = mid</span><br><span class="line">            else:</span><br><span class="line">                left = mid + 1</span><br><span class="line">        return left</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  这道题目非常有趣，我们<strong>在学习或者使用二分的时候，都觉得没什么难度。但是这个题目，巧妙的利用了二分查找的特点，是二分查找的进阶应用，小伙伴们一定要灵活使用它</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
        <category>二分查找</category>
      </categories>
  </entry>
  <entry>
    <title>除数博弈(Leetcode 1025)</title>
    <url>/2020/07/24/program%20Leetcode1025/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1025.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题目是一个<strong>博弈问题</strong>，因为很难去遍历所有的情况，我们只能通过上一步对手的情况，选择我们相应的行为，因此博弈问题一般可以通过动态规划求解。</p>
<a id="more"></a>
<h1 id="状态转移方程的求解"><a href="#状态转移方程的求解" class="headerlink" title="状态转移方程的求解"></a><font size="5" color="red">状态转移方程的求解</font></h1><p>题目中说每次选取一个满足条件的数，进行减法替换。所以以可以构建一个从0到N的数组，保存到达这N个数字的胜负情况，博弈的题目要求是<strong>两个人都是最优策略</strong>，因此我们可以推断出，<strong>当判断第N个数时，如果从1到N的所有满足条件的数字有一个会导致败局时，那么第N个数就是必胜局，当从1到N的所有满足条件的数字全都是胜局时，那么第N个数就是必败局</strong>。因为爱丽丝先手，0到N中如果有一个数字K会导致必败局，那么爱丽丝就选择K，这样，鲍勃就会走入必败的局面，因此爱丽丝必胜，如果0到N的所有数字都是必胜局，那么爱丽丝无论如何选择，鲍勃都会到达必胜局，因此爱丽丝必败。</p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>根据状态转移方程，我们可以轻易的求得该题，x从2遍历到N，对于每一个数x，计算出所有符合条件的数，因为要满足整除条件，因此符合条件的数从1遍历到x的平方根即可。所以时间复杂度为$O(n\sqrt{n})$，空间复杂度为$O(n)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def divisorGame(self, N: int) -&gt; bool:</span><br><span class="line">        dp = [False] * (N + 1)</span><br><span class="line"></span><br><span class="line">        for i in range(2, N + 1):</span><br><span class="line">            for x in range(1, int(i ** 0.5) + 1):</span><br><span class="line">                if i % x == 0:</span><br><span class="line">                    if not dp[i - x]:</span><br><span class="line">                        dp[i] = True</span><br><span class="line">                        break</span><br><span class="line">        return dp[-1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="归纳法"><a href="#归纳法" class="headerlink" title="归纳法"></a><font size="5" color="red">归纳法</font></h1><p>归纳法是最简单的方法，但不是我首推的方法，因为归纳法不能解决大多数问题，所以说并不是这个问题的通解。<br>我们已知1为必败态，因为找不到满足条件的数。<br>我们已知2为必胜态，因为我们可以找到因数1满足条件，而且1为必败态，因此爱丽丝选择1，就会让鲍勃陷入必败态。<br>我们尝试3，因为1是满足条件的唯一解，而且2为必胜态，所以3为必败态。<br>我们尝试4，因为3是必败态，所以爱丽丝会选择1，让鲍勃陷入必败态，爱丽丝是必胜态。<br>我们尝试5，因为1是满足条件的唯一解，而且4为必胜态，所以5为必败态。<br>……我们会发现，1，3，5，…是必败态，2，4，…是必胜态。所以我们猜测奇数态都是必败态，偶数态都是必胜态。<br>我们假设k为偶数，并且小于等于k的数都满足条件，奇数为必败态，偶数为必胜态。那么当爱丽丝处于k+1奇数时，由于奇数的因子必定为奇数，所以爱丽丝只能选择奇数。这样鲍勃会处于一个小于等于k的偶数，由假定可知偶数是必胜态，那么鲍勃必胜，爱丽丝必败，满足条件。<br>我们假设k为奇数，并且小于等于k的数都满足条件，奇数为必败态，偶数为必胜态。那么当爱丽丝处于k+1偶数时，爱丽丝可以选择1，这样鲍勃会处于等于k的奇数，由假定可知，奇数为必败态，那么鲍勃必败，爱丽丝必胜，也满足条件。<br>综上可知，我们的推论是正确的。因此只需要判断该数的奇偶，就可以直接给出结论，所以时间复杂度为$O(1)$，空间复杂度为$O(1)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def divisorGame(self, N: int) -&gt; bool:</span><br><span class="line">        return N % 2 == 0</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  博弈问题是非常有趣的编程题，其常规解法是使用动态规划，得到状态转移方程，由必胜和必败的相互状态转移，逐步求得最后结果的状态。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>博弈</category>
      </categories>
  </entry>
  <entry>
    <title>C++面向对象进阶</title>
    <url>/2020/07/23/C++_oop_3/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++43.png" alt="2"></p>
<h1 id="C-面向对象进阶"><a href="#C-面向对象进阶" class="headerlink" title="C++面向对象进阶"></a><font size="5" color="red">C++面向对象进阶</font></h1><p>  前面介绍了面向对象的三种访问控制权限。今天带小伙们看一看C++面向对象中的static，const，friend关键字。<br><a id="more"></a></p>
<h1 id="static关键字"><a href="#static关键字" class="headerlink" title="static关键字"></a><font size="5">static关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">public: </span><br><span class="line">	//static修饰的成员变量称为静态成员变量，其特点是所有对象共享一份数据，也可称为类成员变量，说明这个成员变量不属于某一个对象，而是属于这个类。</span><br><span class="line">	//在编译阶段分配内存，并且要在类内声明，在类外定义</span><br><span class="line">	static string name;</span><br><span class="line"></span><br><span class="line">	static int age;</span><br><span class="line"></span><br><span class="line">	int score = 100;</span><br><span class="line"></span><br><span class="line">	//static修饰的成员方法称为静态成员方法，其特点是所有对象共享一个函数，也可称为类成员函数，注意类成员函数只能访问类成员变量，不可以访问普通成员变量。</span><br><span class="line">	static string getName() {</span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	static int getAge() {</span><br><span class="line">		return age;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int getScore() {</span><br><span class="line">		return score;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">string Person::name = "程序员";</span><br><span class="line">int Person::age = 24;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	</span><br><span class="line">	//使用静态成员方法时可以通过对象名.静态成员变量名，也可以通过类名::静态成员变量名，因为所有对象都拥有同一份数据，因此为了区分推荐使用类名::静态成员变量名</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; Person::name &lt;&lt; " 我的年龄是：" &lt;&lt; Person::age &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	Person p1;</span><br><span class="line">	p1.name = "小学生";</span><br><span class="line">	p1.age = 8;</span><br><span class="line">	p1.score = 100;</span><br><span class="line"></span><br><span class="line">	Person p2;</span><br><span class="line">	p2.name = "高中生";</span><br><span class="line">	p2.age = 18;</span><br><span class="line">	p2.score = 150;</span><br><span class="line"></span><br><span class="line">	//因为p1和p2拥有同一个名字和年龄，因此p1的名字和年龄都会变成和p2相同的数据，但是分数不会，因为分数是普通成员变量，每个对象都具有一份独特的数据。</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.name &lt;&lt; " 我的年龄是：" &lt;&lt; p1.age &lt;&lt; " 我的成绩是：" &lt;&lt; p1.score &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p2.name &lt;&lt; " 我的年龄是：" &lt;&lt; p2.age &lt;&lt; " 我的成绩是：" &lt;&lt; p2.score &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; Person::name &lt;&lt; " 我的年龄是：" &lt;&lt; Person::age &lt;&lt; endl;</span><br><span class="line">	//访问成员方法是和成员变量相同，但是要注意静态成员方法不可以访问普通成员变量，在getAge成员方法中，不能够访问score普通成员变量。</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.getName() &lt;&lt; " 我的年龄是：" &lt;&lt; p1.getAge() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; Person::getName() &lt;&lt; " 我的年龄是：" &lt;&lt; Person::getAge() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++44.png" alt="1"></p>
<h1 id="const关键字"><a href="#const关键字" class="headerlink" title="const关键字"></a><font size="5">const关键字</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">	string name = "xxx";</span><br><span class="line">	mutable int arms = 2;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	void setName(string name) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//在成员方法的参数列表后面写上const关键字，称为常函数，此时相当于给this指针前面加入const关键字，因此指针指向的内容也不能发生改变，所以在常函数中不能够修改变量的值。</span><br><span class="line">	//如果想要修改，则需要在对应的成员变量前加入mutable关键字。</span><br><span class="line">	void setArms(int arms) const{</span><br><span class="line">		this-&gt;arms = arms;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int getArms() const{</span><br><span class="line">		return arms;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person p1;</span><br><span class="line">	p1.setName("程序员");</span><br><span class="line">	p1.setArms(2);</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.getName() &lt;&lt; "我的手臂个数为：" &lt;&lt; p1.getArms() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//在声明对象前加const关键字，说明该对象为常对象，常对象只能调用常函数，也只能修改加入mutable修饰的成员变量。</span><br><span class="line">	const Person p2;</span><br><span class="line">	p2.setArms(1);</span><br><span class="line">	cout &lt;&lt; "我的手臂个数为：" &lt;&lt; p2.getArms() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++45.png" alt="1"></p>
<h1 id="friend友元"><a href="#friend友元" class="headerlink" title="friend友元"></a><font size="5">friend友元</font></h1><h1 id="全局函数作为友元"><a href="#全局函数作为友元" class="headerlink" title="全局函数作为友元"></a><font size="4">全局函数作为友元</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">	//通过将全局函数的声明写入类内，并在前面加上friend关键字，说明这个全局函数是这个类的好朋友，称作友元，可以访问其私有成员。</span><br><span class="line">	friend int getAge(Person&amp; p);</span><br><span class="line">	friend void setAge(Person&amp; p, int age);</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">	int age;</span><br><span class="line"></span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//setAge是全局函数，根据访问控制权限，在类外无法访问到类内的私有成员</span><br><span class="line">void setAge(Person&amp; p, int age) {</span><br><span class="line">	p.age = age;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">//getAge是全局函数，根据访问控制权限，在类外无法访问到类内的私有成员</span><br><span class="line">int getAge(Person&amp; p) {</span><br><span class="line">	return p.age;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person p1;</span><br><span class="line">	p1.name = "程序员";</span><br><span class="line">	setAge(p1, 24);</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.name &lt;&lt; " 我的年龄是：" &lt;&lt; getAge(p1) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++46.png" alt="1"></p>
<h1 id="类作为友元"><a href="#类作为友元" class="headerlink" title="类作为友元"></a><font size="4">类作为友元</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">	//将Friend类的声明写入类内，并在前面加上friend关键字，说明Friend是这个类的好朋友，称作友元，可以访问其私有成员。</span><br><span class="line">	friend class Friend;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">	int age;</span><br><span class="line"></span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//根据访问控制权限，Friend类无法访问Person类的私有成员</span><br><span class="line">class Friend {</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	static void setAge(Person&amp; p, int age) {</span><br><span class="line">		p.age = age;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	static int getAge(Person&amp; p) {</span><br><span class="line">		return p.age;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person p1;</span><br><span class="line">	p1.name = "程序员";</span><br><span class="line">	Friend::setAge(p1, 24);</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.name &lt;&lt; " 我的年龄是：" &lt;&lt; Friend::getAge(p1) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++46.png" alt="1"></p>
<h1 id="成员函数作为友元"><a href="#成员函数作为友元" class="headerlink" title="成员函数作为友元"></a><font size="4">成员函数作为友元</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//要将Person的声明写在Friend的定义前面，要告诉编译器后面有Person类的定义，这样参数列表中才可以写入Person，否则编译器也会报错。</span><br><span class="line">class Person;</span><br><span class="line"></span><br><span class="line">//注意写法，要将Friend定义在前面，如果将Person写在前面，则编译器不知道Friend::setAge函数是什么。</span><br><span class="line">class Friend {</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	static void setAge(Person&amp; p, int age);</span><br><span class="line">	static int getAge(Person&amp; p);</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">	//通过将成员函数的声明写入类内，并在前面加上friend关键字，说明这个成员函数是这个类的好朋友，称作友元，可以访问其私有成员。</span><br><span class="line">	//要注意成员函数的前面要写清作用域，否则会当作全局函数作为友元。</span><br><span class="line">	friend void Friend::setAge(Person&amp; p, int age);</span><br><span class="line">	friend int Friend::getAge(Person&amp; p);</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">	int age;</span><br><span class="line"></span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//要注意Friend成员函数要在类外实现，且要放在Person类的定义之后，否则编译器只知道Person类的存在，却不知道Person类中有哪些成员，也会报错。</span><br><span class="line">void Friend::setAge(Person&amp; p, int age) {</span><br><span class="line">	p.age = age;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int Friend::getAge(Person&amp; p) {</span><br><span class="line">	return p.age;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Person p1;</span><br><span class="line">	p1.name = "程序员";</span><br><span class="line">	Friend::setAge(p1, 24);</span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.name &lt;&lt; " 我的年龄是：" &lt;&lt; Friend::getAge(p1) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++46.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  今天的内容也非常重要，static关键字，要记得它不属于某一个对象，而是属于整个类，因此在以后的访问中尽量使用类名的方式进行访问，友元的三种使用方法大家要记得，尤其是第三种非常复杂，牵扯到函数和类的声明等问题，小伙伴们一定要理解它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++面向对象提高</title>
    <url>/2020/07/21/C++_oop_2/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++41.png" alt="2"></p>
<h1 id="C-面向对象提高"><a href="#C-面向对象提高" class="headerlink" title="C++面向对象提高"></a><font size="5" color="red">C++面向对象提高</font></h1><p>  之前介绍了C++面向对象的基础内容，其中引入了public关键字，这时C++面向对象的一种访问控制权限，这非常重要，可以更灵活的使用我们创建的类和对象，保护类中的内容，不被其他人调用。今天带小伙们看一看C++中的三种访问控制权限，与Java稍有不同，Java中包括四类访问控制权限，以后再给小伙伴介绍。<br><a id="more"></a></p>
<h1 id="访问控制权限"><a href="#访问控制权限" class="headerlink" title="访问控制权限"></a><font size="5">访问控制权限</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Father {</span><br><span class="line"></span><br><span class="line">//成员关键字</span><br><span class="line">//public关键字：类内可以访问，子类可以访问，类外可以访问</span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line"></span><br><span class="line">	Father() {</span><br><span class="line">		cout &lt;&lt; "我是父类的构造函数" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~Father() {</span><br><span class="line">		cout &lt;&lt; "我是父类的析构函数" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void setName(string name) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line">		return this-&gt;name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void setAge(int age) {</span><br><span class="line">		this-&gt;age = age;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int getAge() {</span><br><span class="line">		return this-&gt;age;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void setMoney(int money) {</span><br><span class="line">		this-&gt;money = money;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int getMoney() {</span><br><span class="line">		return this-&gt;money;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">//protected关键字：类内可以访问，子类可以访问，类外不可以访问</span><br><span class="line">protected:</span><br><span class="line">	int age;</span><br><span class="line"></span><br><span class="line">//private关键字：类内可以访问，子类不可以访问，类外不可以访问</span><br><span class="line">private:</span><br><span class="line">	int money;</span><br><span class="line"></span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">//继承：面向对象的第二大特点，可以获取父类的部分成员，实现代码的复用。</span><br><span class="line">//语法是class 子类名:继承方式 父类名</span><br><span class="line">//继承关键字</span><br><span class="line">//public关键字：继承父类的public,protected成员变量和成员函数，并且保持不变</span><br><span class="line">//protected关键字：继承父类的public,protected成员变量和成员函数，并且都将变为protected类型</span><br><span class="line">//public关键字：继承父类的public,protected成员变量和成员函数，并且都将变为private类型</span><br><span class="line">class Son :public Father {</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	//在子类中，可以定义父类没有的成员，在父类中无法获取子类成员，但是子类可以获取父类成员。</span><br><span class="line">	int score;</span><br><span class="line"></span><br><span class="line">	Son() {</span><br><span class="line">		cout &lt;&lt; "我是子类的构造函数" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~Son() {</span><br><span class="line">		cout &lt;&lt; "我是子类的析构函数" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//因为name在父类是public的，因此在子类中可以访问</span><br><span class="line">	void printName() {</span><br><span class="line">		cout &lt;&lt; this-&gt;name;</span><br><span class="line">	}</span><br><span class="line">	</span><br><span class="line">	//因为age在父类是protected的，因此在子类中可以访问</span><br><span class="line">	//但是money成员变量，在父类中是private的，在子类中无法访问</span><br><span class="line">	void printAge() {</span><br><span class="line">		cout &lt;&lt; this-&gt;age;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	{</span><br><span class="line">		//创建父类的对象，调用父类的构造函数</span><br><span class="line">		Father f;</span><br><span class="line">		//因为name是public的，所以可以直接进行访问和修改</span><br><span class="line">		f.name = "father";</span><br><span class="line">		cout &lt;&lt; "我的名字是：" &lt;&lt; f.name &lt;&lt; endl;</span><br><span class="line">		//因为age是protected的，所以不可以直接进行访问和修改</span><br><span class="line">		//引入set和get方法，可以实现对protected或这private成员进行类内修改。</span><br><span class="line">		f.setAge(40);</span><br><span class="line">		cout &lt;&lt; "我的年龄是：" &lt;&lt; f.getAge() &lt;&lt; endl;</span><br><span class="line">		//因为age是private的，所以不可以直接进行访问和修改</span><br><span class="line">		f.setMoney(1000000);</span><br><span class="line">		cout &lt;&lt; "我的存款是：" &lt;&lt; f.getMoney() &lt;&lt; endl;</span><br><span class="line">		//当花括号结束时，创建的父类对象会被析构，调用析构方法</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "********************" &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	{	</span><br><span class="line">		//继承的特点：</span><br><span class="line">		//1.父类中的所有非静态成员都会被子类继承，只是私有的会被编译器隐藏，在子类中不可见。</span><br><span class="line">		//2.具有继承关系的构造函数，首先调用父类的构造函数，初始化属性，然后再调用子类的构造函数，析构时顺序相反。</span><br><span class="line">		//3.子类与父类具有相同的成员时，默认访问子类的成员，可以通过作用域访问父类的成员，父类名::父类成员即可。</span><br><span class="line">		//4.如果在子类中访问父类的静态成员，需要通过子类名::父类名::父类静态成员名。</span><br><span class="line">		//创建子类对象，因此即会打印父类的构造函数，也会打印子类的构造函数。</span><br><span class="line">		Son s;</span><br><span class="line">		//name是父类的public属性，而且通过public继承，因此可以访问</span><br><span class="line">		s.name = "son";</span><br><span class="line">		cout &lt;&lt; "我的名字是：" &lt;&lt; s.name &lt;&lt; endl;</span><br><span class="line">		//setAge是父类的public属性，而且通过public继承，因此可以访问</span><br><span class="line">		s.setAge(20);</span><br><span class="line">		cout &lt;&lt; "我的年龄是：" &lt;&lt; s.getAge() &lt;&lt; endl;</span><br><span class="line">		//setMoney是父类的public属性，而且通过public继承，因此可以访问</span><br><span class="line">		s.setMoney(100);</span><br><span class="line">		cout &lt;&lt; "我的存款是：" &lt;&lt; s.getMoney() &lt;&lt; endl;</span><br><span class="line">		s.score = 90;</span><br><span class="line">		cout &lt;&lt; "我的成绩是：" &lt;&lt; s.score &lt;&lt; endl;</span><br><span class="line">		//当花括号结束时，创建的子类对象会被析构，注意子类对象析构时的顺序</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++42.png" alt="1"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  今天给大家介绍三种C++的访问控制权限以及继承的基本概念，这对于C++的学习非常重要，因此小伙伴们务必掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++面向对象基础</title>
    <url>/2020/07/19/C++_oop_1/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++37.png" alt="2"></p>
<h1 id="C-面向对象基础"><a href="#C-面向对象基础" class="headerlink" title="C++面向对象基础"></a><font size="5" color="red">C++面向对象基础</font></h1><p>  面向对象的编程思想(Object Oriented Programming, OOP)是程序设计发展的必然阶段，在70年代初，人们使用面向过程的编程思想解决问题，但是随着时代的进步，人们发现这种编程思想非常繁琐，尤其是定义多个相同或相似的变量，需要进行非常冗余的代码编写。这就引入了OOP的观念，面向对象的思想是C++语言的核心内容，因此我们分成多个篇章进行叙述，今天主要给大家介绍类的创建和使用，以及封装，构造析构函数等内容。<br><a id="more"></a></p>
<h1 id="类的定义及使用"><a href="#类的定义及使用" class="headerlink" title="类的定义及使用"></a><font size="5">类的定义及使用</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//定义类时，需要使用class关键字 + 类名，然后在花括号中定义成员变量和成员方法。</span><br><span class="line">//是不是和结构体非常类似，最简单的类和结构体非常类似，但是类具有结构体所没有的特殊性质，在后面会一一为大家介绍。</span><br><span class="line">//这种将成员变量和成员方法写在一个类中，创建对象时，所有对象都具有这些成员变量，也可以使用成员方法，这种思想称为封装。</span><br><span class="line">class Person {</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	string name;</span><br><span class="line">	int age;</span><br><span class="line"></span><br><span class="line">	void eat() {</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; "I am hungry!" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	void sleep() {</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; "I am sleepy!" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	//对象的创建，可以通过类名 变量名(参数列表)进行创建，但是如果没有参数则不能加括号，否则会和函数的声明发生冲突。</span><br><span class="line">	Person p1;</span><br><span class="line"></span><br><span class="line">	//对象的使用，如果想访问对象的成员变量或者成员方法和结构体相同，使用小数点进行访问。</span><br><span class="line">	p1.name = "睡神";</span><br><span class="line">	p1.age = 24;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "我的名字是：" &lt;&lt; p1.name &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "我的年龄是：" &lt;&lt; p1.age &lt;&lt; endl;</span><br><span class="line">	p1.eat();</span><br><span class="line">	p1.sleep();</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++38.png" alt="1"></p>
<h1 id="构造函数和析构函数"><a href="#构造函数和析构函数" class="headerlink" title="构造函数和析构函数"></a><font size="5">构造函数和析构函数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line">	string name="xxx";</span><br><span class="line">	int age = 0;</span><br><span class="line"></span><br><span class="line">	//构造函数是和类名同名的一种特殊的成员函数，当创建对象时会自动调用类的构造函数。</span><br><span class="line">	//如果没有自定义构造函数，编译器会自动帮你创建一个无参的构造函数，里面是空实现。</span><br><span class="line">	Person(string name, int age) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;age = age;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "我有两个参数的构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//构造函数的出现帮我们省去了每个成员变量重新赋值的操作，而且构造函数可以发生函数重载。</span><br><span class="line">	//注意构造函数的写法，没有返回值。</span><br><span class="line">	Person(string name) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "我有一个参数的构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	Person() {</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "无参的构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//析构函数和构造函数相反，是在类名前加一个波浪号，没有返回值，析构函数是在对象销毁时调用，因此没有参数，也不可以发生重载。</span><br><span class="line">	~Person() {</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt;"的析构函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	//在一个花括号种写代码，则花括号为代码的作用域，当执行结束后，会销毁其中的变量，所以在执行结束后会自动调用对象的析构函数。</span><br><span class="line">	{</span><br><span class="line">		Person p1;</span><br><span class="line">		Person p2("婴儿");</span><br><span class="line">		Person p3("程序员", 24);</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; p1.name &lt;&lt; "的年龄是：" &lt;&lt; p1.age &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; p2.name &lt;&lt; "的年龄是：" &lt;&lt; p2.age &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; p3.name &lt;&lt; "的年龄是：" &lt;&lt; p3.age &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++39.png" alt="2"></p>
<h1 id="拷贝构造函数"><a href="#拷贝构造函数" class="headerlink" title="拷贝构造函数"></a><font size="5">拷贝构造函数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line">	string name="xxx";</span><br><span class="line">	int age = 0;</span><br><span class="line"></span><br><span class="line">	//拷贝构造函数的参数是一个同类型的对象，可以根据传入的对象创建一个相同的对象，为了防止对传入对象的误操作，可以在前面加const关键字修饰。</span><br><span class="line">	//默认情况下编译器会提供一个默认无参构造函数，一个默认拷贝构造函数和一个默认析构函数。</span><br><span class="line">	//如果程序员自定义了一个构造函数，则编译器不会提供默认的无参构造函数，但是会提供拷贝构造函数和析构函数。</span><br><span class="line">	//如果程序员自定义了一个拷贝构造函数，则编译器不会再提供任何构造函数，只会提供析构函数。</span><br><span class="line">	Person(const Person&amp; p) {</span><br><span class="line">		this-&gt;name = p.name;</span><br><span class="line">		this-&gt;age = p.age;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "的拷贝构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	Person(string name, int age) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;age = age;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "我有两个参数的构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~Person() {</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt;"的析构函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	{</span><br><span class="line">		Person p1("程序员", 24);</span><br><span class="line">		//使用p1对象拷贝构造一个p2对象，具有和p1对象相同的成员变量，但是两个对象，具有不同的地址值。</span><br><span class="line">		Person p2(p1);</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; p1.name &lt;&lt; "的年龄是：" &lt;&lt; p1.age &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; p2.name &lt;&lt; "的年龄是：" &lt;&lt; p2.age &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; "p1的地址是：" &lt;&lt; &amp;p1 &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; "p2的地址是：" &lt;&lt; &amp;p2 &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++40.png" alt="2"></p>
<h1 id="深拷贝和浅拷贝"><a href="#深拷贝和浅拷贝" class="headerlink" title="深拷贝和浅拷贝"></a><font size="5">深拷贝和浅拷贝</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line">	string name = "xxx";</span><br><span class="line">	int age = 0;</span><br><span class="line">	int* p = NULL;</span><br><span class="line"></span><br><span class="line">	//在构造函数中申请了一段内存，并且在析构函数中完成释放。</span><br><span class="line">	//此时如果使用默认的拷贝构造函数，则新创建的对象是浅拷贝第一个对象，此时两个对象创建的内存是同一块内存。</span><br><span class="line">	//这时在释放内存时，第一次释放成功，第二次释放就会失败，并且产生异常。</span><br><span class="line">	//解决方法是重写拷贝构造函数，并且在构造函数中重新申请内存。</span><br><span class="line">	Person(const Person&amp; p) {</span><br><span class="line">		this-&gt;name = p.name;</span><br><span class="line">		this-&gt;age = p.age;</span><br><span class="line">		this-&gt;p = new int(10);</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "的拷贝构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//深拷贝：指当对象或者变量复制时，不是简单的赋值操作，而是内存的重新分配，即两个对象或者变量中的地址是不重复的。修改了原对象，拷贝构造对象不会发生改变。</span><br><span class="line">	//浅拷贝：指当对象或者变量复制时，通过简单的赋值号，完成拷贝，两个对象或者变量可能指向同一块内存地址。修改了原对象，拷贝构造对象也会发生改变。</span><br><span class="line">	Person(string name, int age) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;age = age;</span><br><span class="line">		this-&gt;p = new int(10);</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "我有两个参数的构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~Person() {</span><br><span class="line">		delete this-&gt;p;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "的析构函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	{</span><br><span class="line">		Person p1("程序员", 24);</span><br><span class="line">		Person p2(p1);</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; p1.name &lt;&lt; "的年龄是：" &lt;&lt; p1.age &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; p2.name &lt;&lt; "的年龄是：" &lt;&lt; p2.age &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; "p1的地址是：" &lt;&lt; &amp;p1 &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; "p2的地址是：" &lt;&lt; &amp;p2 &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++40.png" alt="2"></p>
<h1 id="this指针"><a href="#this指针" class="headerlink" title="this指针"></a><font size="5">this指针</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">class Person {</span><br><span class="line">public:</span><br><span class="line">	string name = "xxx";</span><br><span class="line">	int age = 0;</span><br><span class="line"></span><br><span class="line">	//this指针是隐含在每一个非静态成员函数中的一个指针，使用时无需定义，指代当前对象，其本质是一个指针常量，指针的指向是该对象，不可以修改，但是指针指向的值可以修改。</span><br><span class="line">	//this指针的作用是指代该对象的成员变量或者成员函数，在构造函数中常有体现，当进行赋值时，由于作用域的原因，参数列表中的参数如果和成员变量同名，则会隐藏成员函数，如果想访问可以通过this指针。</span><br><span class="line">	//当要返回当前对象时，可以使用return *this，返回值仍是一个对象，因此还可以继续调用成员变量或者成员方法，体现出链式编程的思想。</span><br><span class="line">	Person(const Person&amp; p) {</span><br><span class="line">		this-&gt;name = p.name;</span><br><span class="line">		this-&gt;age = p.age;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "的拷贝构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	Person(string name, int age) {</span><br><span class="line">		this-&gt;name = name;</span><br><span class="line">		this-&gt;age = age;</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "我有两个参数的构造函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	~Person() {</span><br><span class="line">		cout &lt;&lt; "我是" &lt;&lt; this-&gt;name &lt;&lt; "的析构函数，我被执行了~" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	{</span><br><span class="line">		Person p1("程序员", 24);</span><br><span class="line">		Person p2(p1);</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; p1.name &lt;&lt; "的年龄是：" &lt;&lt; p1.age &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; p2.name &lt;&lt; "的年龄是：" &lt;&lt; p2.age &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; "p1的地址是：" &lt;&lt; &amp;p1 &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; "p2的地址是：" &lt;&lt; &amp;p2 &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++40.png" alt="2"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  在这里给小伙伴们介绍了C++的基本面向对象的概念，虽然不是很难，但是非常重要，在这里为了方便起见，使用了public关键字，下一节会为大家详细介绍几种访问权限关键字。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++异常</title>
    <url>/2020/07/18/C++_exception/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++90.png" alt="2"></p>
<h1 id="C-异常"><a href="#C-异常" class="headerlink" title="C++异常"></a><font size="5" color="red">C++异常</font></h1><p>  在学习C++时，如果一些操作不当，会导致程序异常终止，没有得到我们想要的输出，这是怎么回事呢？今天我会专门介绍C++中的一些异常，这和Python，Java等绝大部分语言都是类似的。<br><a id="more"></a></p>
<h1 id="抛出和捕获异常"><a href="#抛出和捕获异常" class="headerlink" title="抛出和捕获异常"></a><font size="5">抛出和捕获异常</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">    int a = 10;</span><br><span class="line">    //try...catch用于捕获异常，在try中写可能发生异常的代码，然后在catch中进行捕获处理。</span><br><span class="line">    try {</span><br><span class="line">        //您可以使用 throw 语句在代码块中的任何地方抛出异常。throw 语句的操作数可以是任意的表达式，表达式的结果的类型决定了抛出的异常的类型。</span><br><span class="line">        throw a++;</span><br><span class="line">        cout &lt;&lt; "try" &lt;&lt; endl;</span><br><span class="line">    }</span><br><span class="line">    //catch后面声明异常的类型，如果向捕获任何类型的异常，则用省略号...表示。</span><br><span class="line">    catch (int i) {</span><br><span class="line">        cout &lt;&lt; "i = " &lt;&lt; i &lt;&lt; endl;</span><br><span class="line">        cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">    }</span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++91.png" alt="1"></p>
<h1 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a><font size="5">自定义异常</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//可以通过继承和重载exception类自定义异常</span><br><span class="line">class MyException :public exception {</span><br><span class="line">public:</span><br><span class="line">    char* value;</span><br><span class="line"></span><br><span class="line">    MyException(char* s) {</span><br><span class="line">        value = s;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    const char* what() const throw () {</span><br><span class="line">        return this-&gt;value;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">    char c[] = "月份值不能超过12！";</span><br><span class="line">    char* s = c;</span><br><span class="line">    try {</span><br><span class="line">        throw MyException(s);</span><br><span class="line">        cout &lt;&lt; "try" &lt;&lt; endl;</span><br><span class="line">    }</span><br><span class="line">    catch (MyException e) {</span><br><span class="line">        cout &lt;&lt; "异常信息是：" &lt;&lt; e.what() &lt;&lt; endl;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++92.png" alt="2"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  在这里我们对异常进行了揭秘，可能在平时的做题或者工程中很难用到，我们还是要了解它的机制，当我们需要的时候可以及时回忆起来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++引用</title>
    <url>/2020/07/17/C++_quote/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++33.png" alt="2"></p>
<h1 id="C-引用"><a href="#C-引用" class="headerlink" title="C++引用"></a><font size="5" color="red">C++引用</font></h1><p>  从今天开始，正式进入C++的内容中，引用时C++的代码风格，为了使代码简单清晰，C++引入了引用这个概念。为什么要引入呢？因为人们发现用指针指来指去，非常复杂，而且容易出错，所以提出了一种更加简单的形式。引用可以看成是起别名，就像小名一样，小伙伴们应该都有小名，在家里一般不会直呼其名，常常会给小孩子起一个小名。那么小名就是你，大名也是你，因此对小名进行操作时，相当于对这个变量进行了操作。<br><a id="more"></a></p>
<h1 id="引用的定义"><a href="#引用的定义" class="headerlink" title="引用的定义"></a><font size="5">引用的定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	//引用的定义就是在变量名前加一个取地址符&amp;，并且让其等于另一个变量，相当于给一个变量又起了一个小名</span><br><span class="line">	//注意只能让一个变量名传给引用的数据类型，不可以是常量。而且引用只能在创建时进行赋值，不可以先创建然后再赋值。</span><br><span class="line">	int a = 10;</span><br><span class="line">	int&amp; b = a;</span><br><span class="line">	int&amp; c = b;</span><br><span class="line"></span><br><span class="line">	//我们可以看出，它们a，b，c变量具有相同的地址值，而且数据变化时，它们三个具有相同的变化。</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	b = 20;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	c += 10;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++34.png" alt="1"></p>
<h1 id="引用本质的探寻"><a href="#引用本质的探寻" class="headerlink" title="引用本质的探寻"></a><font size="5">引用本质的探寻</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct Student</span><br><span class="line">{</span><br><span class="line">	int a = 10;</span><br><span class="line">	int&amp; b = a;</span><br><span class="line">	int c = 20;</span><br><span class="line"></span><br><span class="line">	//定义两个变量a和c，定义a的引用b，由先前的知识可以知道a和b具有相同的地址，c的地址和a不同。</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	//让c的值赋值给b会出现什么神奇现象呢？是b和c具有相同的地址？还是a和b具有相同地址？还是a，b，c都具有相同的地址呢？</span><br><span class="line">	b = c;</span><br><span class="line"></span><br><span class="line">	//原来a和b仍然具有相同的地址，a和c的地址不同。这是什么原因呢？</span><br><span class="line">	//我们在指针部分讲解了常量指针和指针常量。这里b的值可以改变，但是b和a绑定了，b只能指向a，不能改变其指向。这种我们称之为指针常量。</span><br><span class="line">	//引用本质就是指针常量，只不过我们隐藏了指针的定义和写法，更加简单。	</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++35.png" alt="2"></p>
<h1 id="引用作为函数参数"><a href="#引用作为函数参数" class="headerlink" title="引用作为函数参数"></a><font size="5">引用作为函数参数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">void swap(int&amp; a, int&amp; b) {</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	int temp = a;</span><br><span class="line">	a = b;</span><br><span class="line">	b = temp;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 10;</span><br><span class="line">	int b = 20;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//既然引用的本质是一个指针，那么必然满足地址传递的性质，所以在函数内部操作会影响到外部变量的值。</span><br><span class="line">	//给小伙伴讲解一下调用函数背后的操作，首先将a和b的值传入函数列表，然后在函数参数中执行int&amp; a = a，int&amp; b = b</span><br><span class="line">	//后面的a和b是实参，前面的a和b是形参，此时形参a就是实参a的小名，那么对小名a操作就等价于对大名a操作，所以外部的值会发生改变。</span><br><span class="line">	swap(a, b);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++36.png" alt="4"></p>
<h1 id="new和delete"><a href="#new和delete" class="headerlink" title="new和delete"></a><font size="5">new和delete</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	</span><br><span class="line">	int a1 = 10;</span><br><span class="line">	int a2 = 20;</span><br><span class="line"></span><br><span class="line">	//栈区：由编译器自动分配释放，存放函数的参数，局部变量等。</span><br><span class="line">	//堆区：由程序员分配和释放，最后由操作系统进行回收。</span><br><span class="line">	//在函数中的局部变量，不要返回其地址，因为函数调用结束后，会由编译器自动释放，会导致异常。</span><br><span class="line">	//在堆区的数据由程序员分配和释放，分配的方式是使用new关键字，并返回开辟的地址，释放的方式是使用delete关键字。</span><br><span class="line">	//如果开辟或释放数组则要使用中括号进行说明，new 数据类型[], delete[]。</span><br><span class="line">	int* b1 = new int(10);</span><br><span class="line">	int* b2 = new int(20);</span><br><span class="line">	int* c1 = &amp;a1;</span><br><span class="line">	int* c2 = &amp;a2;</span><br><span class="line"></span><br><span class="line">	//可以看出b1，b2的地址非常接近，在一个区内，c1和c2的地址也非常接近，也在同一个区内。但是b1和c1的地址却不在同一个区，这就是堆区和栈区的区别。</span><br><span class="line">	cout &lt;&lt; "b1 = " &lt;&lt; b1 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b2 = " &lt;&lt; b2 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c1 = " &lt;&lt; c1 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c2 = " &lt;&lt; c2 &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	delete b1;</span><br><span class="line">	delete b2;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  引用是C++中的重要工具，在C++中推荐使用引用代替指针来传递参数，因为操作简单，使用方便，所以小伙伴们务必记住它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++结构体</title>
    <url>/2020/07/15/C++_struct/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++28.png" alt="2"></p>
<h1 id="C-结构体"><a href="#C-结构体" class="headerlink" title="C++结构体"></a><font size="5" color="red">C++结构体</font></h1><p>  结构体进一步体现了面向对象的思想，但是和真正的面向对象有很大的差别，没有继承和多态的思想，但是已经可以定义成员函数和成员变量了，而且创建结构体变量时，可以实现将成员变量和成员函数封装在一个变量之中，实现多个结构体变量具有相同的结构，这一点类似于面向对象中的类。<br><a id="more"></a></p>
<h1 id="结构体定义"><a href="#结构体定义" class="headerlink" title="结构体定义"></a><font size="5">结构体定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//结构体的定义包括成员变量和成员函数，关键的是成员变量可以是不同的类型，这为我们操作不同类型的数据提供了便利。</span><br><span class="line">//每一个结构体变量都具有相同的结构，但它们之间互不影响。</span><br><span class="line">struct Student</span><br><span class="line">{</span><br><span class="line">	string name = "xxx";</span><br><span class="line">	int age = 0;</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line"></span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int getAge() {</span><br><span class="line"></span><br><span class="line">		return age;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	//结构体变量的创建和基本类型相似，第一种方式是先定义，后初始化。</span><br><span class="line">	//但是和变量不同的是，如果成员变量没有默认值，编译器会自动添加默认值，不会报错，而基本类型没有默认值会报错。</span><br><span class="line">	Student s;</span><br><span class="line">	cout &lt;&lt; "s的姓名是：" &lt;&lt; s.getName() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s的年龄是：" &lt;&lt; s.getAge() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//结构体变量的第二种创建方式，定义的同时进行初始化，还有第三种定义方式，在结构体的花括号后面写上变量名，但是不推荐，因为会让其他人很难发现定义的具体位置，掌握前两种定义方法即可，第三种作为了解。</span><br><span class="line">	Student s1 = { "菜鸟", 24 };</span><br><span class="line">	cout &lt;&lt; "s1的姓名是：" &lt;&lt; s1.getName() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s1的年龄是：" &lt;&lt; s1.getAge() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "···十年之后···" &lt;&lt; endl;</span><br><span class="line">	s1.name = "大神";</span><br><span class="line">	s1.age = 34;</span><br><span class="line">	cout &lt;&lt; "s1的姓名是：" &lt;&lt; s1.getName() &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "s1的年龄是：" &lt;&lt; s1.getAge() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++29.png" alt="1"></p>
<h1 id="结构体数组"><a href="#结构体数组" class="headerlink" title="结构体数组"></a><font size="5">结构体数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">struct Student</span><br><span class="line">{</span><br><span class="line">	string name = "xxx";</span><br><span class="line">	int age = 0;</span><br><span class="line"></span><br><span class="line">	string getName() {</span><br><span class="line"></span><br><span class="line">		return name;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int getAge() {</span><br><span class="line"></span><br><span class="line">		return age;</span><br><span class="line">	}</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	//结构体数组和普通变量的数组有相同的定义方法，访问是也是通过索引进行访问。</span><br><span class="line">	Student s[] = { {"C++程序员", 30}, {"Java程序员", 25}, {"Python程序员", 20} };</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; 3; i++) {</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; "我的名字是：" &lt;&lt; s[i].getName() &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; "我的年龄是：" &lt;&lt; s[i].getAge() &lt;&lt; endl;</span><br><span class="line">		cout &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++30.png" alt="2"></p>
<h1 id="指针作为结构体成员变量"><a href="#指针作为结构体成员变量" class="headerlink" title="指针作为结构体成员变量"></a><font size="5">指针作为结构体成员变量</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//在定义结构体时，将指针作为成员变量，并且指向另一个结构体变量</span><br><span class="line">struct LinkedList</span><br><span class="line">{</span><br><span class="line">	int val;</span><br><span class="line">	LinkedList* next;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	//创建链表数据类型，如果指针作为结构体的成员，那么(*s).xxx可以写为s-&gt;xxx。</span><br><span class="line">	LinkedList l3 = { 3, NULL };</span><br><span class="line">	LinkedList l2 = { 2, &amp;l3 };</span><br><span class="line">	LinkedList l1 = { 1, &amp;l2 };</span><br><span class="line"></span><br><span class="line">	LinkedList* head = &amp;l1;</span><br><span class="line"></span><br><span class="line">	while (head) {</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; head-&gt;val &lt;&lt; " -&gt; ";</span><br><span class="line">		head = head-&gt;next;</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; "NULL" &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++31.png" alt="4"></p>
<h1 id="结构体的嵌套定义"><a href="#结构体的嵌套定义" class="headerlink" title="结构体的嵌套定义"></a><font size="5">结构体的嵌套定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//在一个结构体中定义另一个结构体，可以实现结构体的嵌套定义，又可以保护内部结构体类型在外部不可以访问。</span><br><span class="line">struct Student</span><br><span class="line">{</span><br><span class="line">	struct Score</span><br><span class="line">	{</span><br><span class="line">		int chinese;</span><br><span class="line">		int math;</span><br><span class="line">		int english;</span><br><span class="line">	};</span><br><span class="line"></span><br><span class="line">	string name;</span><br><span class="line">	int age;</span><br><span class="line">	Score score;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	Student s = { "学霸", 24, {95, 100, 95} };</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; s.name &lt;&lt; "的年龄是" &lt;&lt; s.age &lt;&lt; "岁" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "他的语文成绩是：" &lt;&lt; s.score.chinese &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "他的数学成绩是：" &lt;&lt; s.score.math &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "他的英语成绩是：" &lt;&lt; s.score.english &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++32.png" alt="4"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  结构体是C语言中功能强大的工具之一，在没有面向对象的思想中，结构体起到了非常重要的作用，可以实现复杂数据类型的定义，而且可以对多个变量，函数进行封装，也是链表，二叉树等数据结构的重要组成部分，小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++指针</title>
    <url>/2020/07/12/C++_point/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++22.png" alt="2"></p>
<h1 id="C-指针"><a href="#C-指针" class="headerlink" title="C++指针"></a><font size="5" color="red">C++指针</font></h1><p>  指针是C/C++最精髓的内容，也是大多数程序员幼崽的童年阴影，噩梦的开始。当然也包括本菜鸟也深受其害，在这里我们不说的很详尽，因为我也是个freshman，这个博客的内容是普及一下指针的基本用法，至于复杂的情况，可以参考上面的三本宝典，都是C/C++程序员走上不归路的必读书籍。<br><a id="more"></a></p>
<h1 id="指针定义"><a href="#指针定义" class="headerlink" title="指针定义"></a><font size="5">指针定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	</span><br><span class="line">	//指针和普通变量的定义一样，可以定义时初始化，也可以在使用时初始化。指针的意思是指向某一块内存空间，因此其代表的一个地址，前面加上*代表取出地址指向的值。</span><br><span class="line">	int a = 10;</span><br><span class="line">	int* p = &amp;a;</span><br><span class="line">	int* p1;</span><br><span class="line">	p1 = &amp;a;</span><br><span class="line"></span><br><span class="line">	//可以看出p等价于&amp;a，在数组中已经介绍了取地址符&amp;，因此p指代的是a的地址，*p则指代地址中存放的值。</span><br><span class="line">	cout &lt;&lt; "p = " &lt;&lt; p &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*p = " &lt;&lt; *p &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	int b = a;</span><br><span class="line">	b += 2;</span><br><span class="line">	</span><br><span class="line">	//int b = a，说明创建一个变量，让其值等于a，但是b和a是两个不同的变量，因此b的变化和a无关，所以b += 2时，a仍保持不变。</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	*p += 2;</span><br><span class="line"></span><br><span class="line">	//*p += 2，说明让p指向的内存空间中的值加2，但是p指向的内存空间就是a，相当于a的门牌号，因此*p += 2就等价于a += 2，所以a的值发生了变化。</span><br><span class="line">	cout &lt;&lt; "p = " &lt;&lt; p &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*p = " &lt;&lt; *p &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++23.png" alt="1"></p>
<h1 id="const与指针"><a href="#const与指针" class="headerlink" title="const与指针"></a><font size="5">const与指针</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 10;</span><br><span class="line">	int b = 20;</span><br><span class="line"></span><br><span class="line">	//const修饰指针，称为常量指针，const修饰*p，说明指针指向的值是不可以改变的，但是可以改变指针的指向。</span><br><span class="line">	const int* p1 = &amp;a;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "p1 = " &lt;&lt; p1 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*p1 = " &lt;&lt; *p1 &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	p1 = &amp;b;</span><br><span class="line"></span><br><span class="line">	//p1指向了b，因此a的值没有变，p1为b的地址，p1指向的值为b的值</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "p1 = " &lt;&lt; p1 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*p1 = " &lt;&lt; *p1 &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	int c = 30;</span><br><span class="line">	int d = 40;</span><br><span class="line"></span><br><span class="line">	//const修饰常量，称为指针常量，const修饰p，说明指针的指向是不可以改变的，但是可以改变指针指向的值。</span><br><span class="line">	int* const p2 = &amp;c;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d = " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;d = " &lt;&lt; &amp;d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "p2 = " &lt;&lt; p2 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*p2 = " &lt;&lt; *p2 &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	*p2 = d;</span><br><span class="line">	</span><br><span class="line">	//p2为c的地址，现在将地址指向的值改为d，因此c变为d的值，p2的地址没有改变</span><br><span class="line">	cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d = " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;c = " &lt;&lt; &amp;c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;d = " &lt;&lt; &amp;d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "p2 = " &lt;&lt; p2 &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*p2 = " &lt;&lt; *p2 &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++24.png" alt="2"></p>
<h1 id="指针和数组"><a href="#指针和数组" class="headerlink" title="指针和数组"></a><font size="5">指针和数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a[3] = { 1, 2, 3 };</span><br><span class="line"></span><br><span class="line">	//在数组章节中说过，一维数组名就是数组的首地址，因此可以将一位数组名赋值给指针</span><br><span class="line">	int* p = a;</span><br><span class="line"></span><br><span class="line">	//访问元素时，可以通过指针的方式，p++代表指针向后移动一个单位，指针移动的单位根据指针类型确定，指针是什么类型则移动相应的大小。</span><br><span class="line">	//这里指针为int类型，因此p++就相当于指针从数组第一个元素移动到第二个元素，因为数组也是按照内存大小存放的。</span><br><span class="line">	for (int i = 0; i &lt; 3; i++) {</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; *p++ &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	p = a;</span><br><span class="line">	//还可以通过类似数组的方式，通过指针索引访问数组元素。</span><br><span class="line">	for (int i = 0; i &lt; 3; i++) {</span><br><span class="line"></span><br><span class="line">		cout &lt;&lt; p[i] &lt;&lt; " ";</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	int b[3][3] = { 1, 2, 3, 4, 5, 6, 7, 8, 9 };</span><br><span class="line">	</span><br><span class="line">	//指向指针的指针，很好理解，指针p1是二维数组中第一行的首地址，虽然二维数组名也是一个地址，但是不能通过赋值操作直接给指针赋值。</span><br><span class="line">	//指针p2是指针p1的地址，因此p2指向p1，p1指向第一行的首地址，所以*p2就是p1的值，**p2就是b[0][0]的值</span><br><span class="line">	int* p1 = b[0];</span><br><span class="line">	int** p2 = &amp;p1;</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; 3; i++) {</span><br><span class="line">		for (int j = 0; j &lt; 3; j++) {</span><br><span class="line">			//注意这里的写法是有讲究的，p2指向p1，因此在一维数组中p1++就等价于(*p2)++。</span><br><span class="line">			//不能写成*p2++，*p2++指的是p2指针自加1，p2指针自加是没有意义的。</span><br><span class="line">			cout &lt;&lt; *(*p2)++ &lt;&lt; " ";</span><br><span class="line">		}</span><br><span class="line">		cout &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int c[3][3] = { 1, 2, 3, 4, 5, 6, 7, 8, 9 };</span><br><span class="line">	</span><br><span class="line">	//指针数组，p3的每一个元素都是一个指针，分别指向数组c每一行的首地址，指针p4指向指针数组的首地址。</span><br><span class="line">	int* p3[3] = { c[0], c[1], c[2] };</span><br><span class="line">	int** p4 = p3;</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; 3; i++, p4++) {</span><br><span class="line">		for (int j = 0; j &lt; 3; j++) {</span><br><span class="line">			//p4是指针数组的首地址，*p4指的是p3[0]的值，而p3[0]又是数组c[0][0]的地址</span><br><span class="line">			//因此*(*p4)是c[0][0]的值，做完之后(*p4)自增1，等价于p3[0]指向了c[0][1]。</span><br><span class="line">			//注意在第一层循环中包含着p4++这个操作，当p3[0]指向c[0][2]以后，p4指向指针数组的下一个元素p3[1]，然后开始读取c数组第二行的元素。</span><br><span class="line">			//如果将p4++删去，仍可以得到相同的答案，如何理解呢？因为二维数组也是按照顺序存放的，因此指针p3[0]读取到第一行最后一个元素后，自增时也会指向第二行的第一个元素，因此也是正确的。</span><br><span class="line">			cout &lt;&lt; *(*p4)++ &lt;&lt; " ";</span><br><span class="line">		}</span><br><span class="line">		cout &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++25.png" alt="4"></p>
<h1 id="值传递"><a href="#值传递" class="headerlink" title="值传递"></a><font size="5">值传递</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//swap参数列表中的变量为普通变量</span><br><span class="line">void swap(int a, int b) {</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	int temp = a;</span><br><span class="line">	a = b;</span><br><span class="line">	b = temp;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 10;</span><br><span class="line">	int b = 20;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	//当调用函数时，传入变量值，则会将实参值拷贝到形参中去，因此形参会获得实参的值，但是它们的地址是不同的。</span><br><span class="line">	//所以进行交换时，两个形参的值进行了交换，在调用结束后，形参的作用域结束，被销毁，并不会影响到实参的值。</span><br><span class="line">	swap(a, b);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++26.png" alt="4"></p>
<h1 id="址传递"><a href="#址传递" class="headerlink" title="址传递"></a><font size="5">址传递</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//swap参数列表中的变量为指针变量</span><br><span class="line">void swap(int* a, int* b) {</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "*a = " &lt;&lt; *a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*b = " &lt;&lt; *b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	int temp = *a;</span><br><span class="line">	*a = *b;</span><br><span class="line">	*b = temp;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "*a = " &lt;&lt; *a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "*b = " &lt;&lt; *b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 10;</span><br><span class="line">	int b = 20;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	//当调用函数时，传入地址值，则会将实参地址值拷贝到形参中去，因此形参会获得实参的地址值。</span><br><span class="line">	//所以进行交换时，两个地址的指向的内容进行了交换，在调用结束后，形参的作用域结束，被销毁，但是地址指向的内容已经发生了改变，所以实参会发生变化。</span><br><span class="line">	swap(&amp;a, &amp;b);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;a = " &lt;&lt; &amp;a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "&amp;b = " &lt;&lt; &amp;b &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++27.png" alt="4"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  指针是C/C++中最具有魅力的地方，其实所有的高级语言都有指针，只不过将其包装了起来，让使用者感觉不到在操作指针，最简单的例子，Java中的this，和Python中的self，其本质都是一个指针，学好了指针可以让我们更加了解语言背后的动作，因此小伙伴们要克服恐惧，奥里给！</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++函数</title>
    <url>/2020/07/09/C++_function/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++18.png" alt="2"></p>
<h1 id="C-函数"><a href="#C-函数" class="headerlink" title="C++函数"></a><font size="5" color="red">C++函数</font></h1><p>  函数是面向过程的程序设计精髓，也是所有语言中最重要的一个内容，学好函数，可以设计出优雅的程序，下面给小伙伴们介绍C++函数的定义，调用，参数传递，声明，默认参数，占位参数和函数的重载。<br><a id="more"></a></p>
<h1 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a><font size="5">函数定义</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//函数小伙伴们其实并不陌生，在第一行C++代码中就用到了函数的知识，main函数，main函数是程序运行的起始位置，程序必须要有main函数才可以运行</span><br><span class="line">//函数的定义包括返回值类型，函数名，参数列表和函数体。这里单独强调返回值，返回值代表函数运行结束后返回到调用处时产生的数据</span><br><span class="line">//如果没有返回值，类型要写void，可以不写return，如果有返回值，一定要写return</span><br><span class="line">//函数的参数列表要写清楚参数的类型，这和Python有很大的区别</span><br><span class="line">int add(int a, int b) {</span><br><span class="line"></span><br><span class="line">	int c = a + b;</span><br><span class="line">	</span><br><span class="line">	return c;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 5;</span><br><span class="line">	int b = 3;</span><br><span class="line">	</span><br><span class="line">	//函数的调用使用函数名(参数)，如果有返回值可以用变量接收</span><br><span class="line">	int c = add(a, b);</span><br><span class="line">	int d = add(c, b);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "c = a + b = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d = c + b = " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++19.png" alt="1"></p>
<h1 id="函数声明"><a href="#函数声明" class="headerlink" title="函数声明"></a><font size="5">函数声明</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//有时为了更好的看清楚main函数的具体位置，而且让其他人能够能清晰的看出这个文件中的函数具体有哪些，可以在文件开始写清楚函数的声明。</span><br><span class="line">//函数的声明和定义类似，参数列表可以只写参数的类型，并且后面没有花括号，而用分号代替，声明的作用就是告诉编译器，后面有这个函数的具体实现，否则编译器会报错。</span><br><span class="line">int add(int, int);</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 5;</span><br><span class="line">	int b = 3;</span><br><span class="line">	</span><br><span class="line">	//函数的调用使用函数名(参数)，如果有返回值可以用变量接收</span><br><span class="line">	int c = add(a, b);</span><br><span class="line">	int d = add(c, b);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "c = a + b = " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d = c + b = " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int add(int a, int b) {</span><br><span class="line"></span><br><span class="line">	int c = a + b;</span><br><span class="line">	</span><br><span class="line">	return c;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++19.png" alt="2"></p>
<h1 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a><font size="5">默认参数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//默认参数是指在参数列表中，指定了参数的指，这样传递时可以不传递该参数，会使用默认的参数代入函数进行计算。</span><br><span class="line">//注意默认参数只能出现在参数列表的末尾，允许出现多个默认参数。</span><br><span class="line">double calcArea(int r, double pi=3.1415926) {</span><br><span class="line"></span><br><span class="line">	double area = pi * r * r;</span><br><span class="line"></span><br><span class="line">	return area;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	double c = calcArea(3);</span><br><span class="line">	double d = calcArea(3, 3.14);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "圆c的面积为 " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "圆d的面积为 " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++20.png" alt="4"></p>
<h1 id="占位参数"><a href="#占位参数" class="headerlink" title="占位参数"></a><font size="5">占位参数</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//占位参数是指在参数列表中，占了一个位置，传递参数时必须要传入这个参数，否则会报错，但是在函数内无法使用，因为没有变量接收这个参数。</span><br><span class="line">//占位参数使用概率不高，见到时能够认识它即可。</span><br><span class="line">double calcArea(int r, int, double pi=3.1415926) {</span><br><span class="line"></span><br><span class="line">	double area = pi * r * r;</span><br><span class="line"></span><br><span class="line">	return area;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	double c = calcArea(3, 0);</span><br><span class="line">	double d = calcArea(3, 1, 3.14);</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "圆c的面积为 " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "圆d的面积为 " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++20.png" alt="4"></p>
<h1 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a><font size="5">函数重载</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">//函数重载是指，一个函数名有不同的功能实现，当传入的参数个数不同，类型不同或者顺序不同时，函数可以发生重载，调用时，根据和哪一个函数更匹配则调用相应的函数。</span><br><span class="line">//特别注意，参数名和返回值不同不能成为函数重载的发生条件，编译器会报错。</span><br><span class="line">double calcArea(int r, double pi) {</span><br><span class="line"></span><br><span class="line">	double area = pi * r * r;</span><br><span class="line"></span><br><span class="line">	return area;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">double calcArea(int r, double pi, int) {</span><br><span class="line"></span><br><span class="line">	double area = pi * r * r;</span><br><span class="line"></span><br><span class="line">	return area;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">double calcArea(double r, double pi) {</span><br><span class="line"></span><br><span class="line">	double area = pi * r * r;</span><br><span class="line"></span><br><span class="line">	return area;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">double calcArea(double pi, int r) {</span><br><span class="line"></span><br><span class="line">	double area = pi * r * r;</span><br><span class="line"></span><br><span class="line">	return area;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	double c = calcArea(3, 3.14);</span><br><span class="line">	double d = calcArea(3, 3.14, 0);</span><br><span class="line">	double e = calcArea(3.0, 3.14);</span><br><span class="line">	double f = calcArea(3.14, 3);</span><br><span class="line">	</span><br><span class="line">	cout &lt;&lt; "圆c的面积为 " &lt;&lt; c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "圆d的面积为 " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "圆e的面积为 " &lt;&lt; e &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "圆f的面积为 " &lt;&lt; f &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++21.png" alt="4"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  函数是我们面向过程编程的重要思想，同时也是面向对象中封装特性的体现，有了函数我们可以节约大量的时间和空间管理我们的代码，提高了代码的复用率，但是我们要注意编程习惯，尽量一个函数实现一个功能，不要将多个功能写在同一个函数之中。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++数组</title>
    <url>/2020/07/07/C++_array/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++17.png" alt="2"></p>
<h1 id="C-数组"><a href="#C-数组" class="headerlink" title="C++数组"></a><font size="5" color="red">C++数组</font></h1><p>  在前面已经介绍了C++的运算符和流程控制语句，这里主要介绍C++的数组，包括一维数组，二维数组以及数组名和地址之间的关系。<br><a id="more"></a></p>
<h1 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a><font size="5">创建数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	//C++创建数组有三种常见方式，可以先定义然后赋初值，也可以定义的时候赋初值</span><br><span class="line">	//创建时数组的大小必须要固定，而且不能用变量作为数组的长度，int a[b]是错误的语法，虽然第三种方式没有指定数组大小，但是编译器会根据值的个数自动确定</span><br><span class="line">	int a[5];</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; 5; i++) {</span><br><span class="line">		a[i] = i;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int b[5] = { 1, 2, 3, 4, 5 };</span><br><span class="line">	int c[] = { 1, 2, 3, 4, 5 };</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; 5; i++) {</span><br><span class="line">		printf("a[%d] = %d ", i, a[i]);</span><br><span class="line">		printf("b[%d] = %d ", i, b[i]);</span><br><span class="line">		printf("c[%d] = %d\n", i, c[i]);</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++14.png" alt="1"></p>
<h1 id="数组名和数组地址"><a href="#数组名和数组地址" class="headerlink" title="数组名和数组地址"></a><font size="5">数组名和数组地址</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int a[5] = { 1, 2, 3, 4, 5 };</span><br><span class="line">	char c[3] = { 'a', 'b', 'c' };</span><br><span class="line">	</span><br><span class="line">	//数组的特点是每个元素都是相同的数据类型，并且元素存放在连续的内存空间上</span><br><span class="line">	//int的大小为4个字节，a数组有5个元素，因此是20个字节。char的大小为1个字节，c数组有3个元素，因此是3个字节</span><br><span class="line">	cout &lt;&lt; "元素a[0]的大小为" &lt;&lt; sizeof(a[0]) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "数组a的大小为" &lt;&lt; sizeof(a) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "元素c[0]的大小为" &lt;&lt; sizeof(c[0]) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "数组c的大小为" &lt;&lt; sizeof(c) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//元素a[0]和元素a[1]索引相差1，因此大小相差4个字节，数组名代表的是数组首个元素的地址，&amp;符号为取地址符号</span><br><span class="line">	cout &lt;&lt; "元素a[0]的地址为" &lt;&lt; &amp;a[0] &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "元素a[1]的地址为" &lt;&lt; &amp;a[1] &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "数组名的值为" &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++15.png" alt="2"></p>
<h1 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a><font size="5">二维数组</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	//二维数组和一维数组类似，有相似的创建方法</span><br><span class="line">	int a[3][4];</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; 3; i++) {</span><br><span class="line">		for (int j = 0; j &lt; 4; j++) {</span><br><span class="line">			a[i][j] = i * j + 1;</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	int b[3][4] = { {1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12} };</span><br><span class="line">	int c[3][4] = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 };</span><br><span class="line">	int d[][4] = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 };</span><br><span class="line">	</span><br><span class="line">	//二维数组可以看成一位数组中每个元素都是一个一维数组，因此a[3][4]可以看成3个一维数组的组合，每个一维数组有4个元素</span><br><span class="line">	//因此二维数组的大小是一维数组的3倍，一维数组的大小是单个元素的4倍</span><br><span class="line">	cout &lt;&lt; "元素a[0][0]的大小为" &lt;&lt; sizeof(a[0][0]) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "一维数组a[0]的大小为" &lt;&lt; sizeof(a[0]) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "二维数组a的大小为" &lt;&lt; sizeof(a) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	//因为数据是按照内存顺序存放的，所以先存放第一个一维数组，因此a[0][0]和a[1][0]的地址相差4个int大小，是16个字节</span><br><span class="line">	//二维数组名等于一维数组名a[0]等于第一个元素a[0][0]的地址</span><br><span class="line">	cout &lt;&lt; "元素a[0][0]的地址为" &lt;&lt; &amp;a[0][0] &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "元素a[1][0]的地址为" &lt;&lt; &amp;a[1][0] &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "一维数组名a[0]的值为" &lt;&lt; a[0] &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "一维数组名a[1]的值为" &lt;&lt; a[1] &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "二维数组名a的值为" &lt;&lt; a &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++16.png" alt="4"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  数组是我们存放数据的好方法，就如同抽屉一样，每一个抽屉都放置同样的物品，数组的学习非常重要，也是第一次接触到地址的概念，无论以后从事什么样的研究，数组的使用都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++流程控制</title>
    <url>/2020/07/04/C++_control/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python4.jpg" alt="2"></p>
<h1 id="C-流程控制"><a href="#C-流程控制" class="headerlink" title="C++流程控制"></a><font size="5" color="red">C++流程控制</font></h1><p>  在前面已经介绍了C++的运算符，这里主要介绍C++的流程控制，包括if条件语句，switch条件语句，while循环，do…while循环，for循环，goto语句，以及continue和break跳转语句。<br><a id="more"></a></p>
<h1 id="C-条件语句"><a href="#C-条件语句" class="headerlink" title="C++条件语句"></a><font size="5" color="red">C++条件语句</font></h1><h2 id="if条件语句"><a href="#if条件语句" class="headerlink" title="if条件语句"></a><font size="4">if条件语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line"></span><br><span class="line">	int a = 10;</span><br><span class="line"></span><br><span class="line">	//if单分支语句</span><br><span class="line">	if (a &gt; 5) {</span><br><span class="line">		cout &lt;&lt; "a &gt; 5" &lt;&lt; endl;;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//if...else双分支语句</span><br><span class="line">	if (a &gt; 20) {</span><br><span class="line">		cout &lt;&lt; "a &gt; 20" &lt;&lt; endl;</span><br><span class="line">	}else{</span><br><span class="line">		cout &lt;&lt; "a &lt;= 20" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	//if...else if...else多分支语句</span><br><span class="line">	if (a &gt; 20) {</span><br><span class="line">		cout &lt;&lt; "a &gt; 20" &lt;&lt; endl;</span><br><span class="line">	}else if (a &lt; 0) {</span><br><span class="line">		cout &lt;&lt; "a &lt; 0" &lt;&lt; endl;</span><br><span class="line">	}else{</span><br><span class="line">		cout &lt;&lt; "0 &lt;= a &lt;= 20" &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++8.png" alt="1"></p>
<h2 id="switch-case语句"><a href="#switch-case语句" class="headerlink" title="switch case语句"></a><font size="4">switch case语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int a = 6;</span><br><span class="line">	</span><br><span class="line">	//switch中的表达式可以为整型或者字符型，不能为浮点型，字符串型，或者一段区间。而且switch语句具有穿透效果，直至遇到break才会跳出。</span><br><span class="line">	switch (a){</span><br><span class="line"></span><br><span class="line">	case 1:</span><br><span class="line">		cout &lt;&lt; "Monday" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	case 2:</span><br><span class="line">		cout &lt;&lt; "Tuesday" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	case 3:</span><br><span class="line">		cout &lt;&lt; "Wednesday" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	case 4:</span><br><span class="line">		cout &lt;&lt; "Thursday" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	case 5:</span><br><span class="line">		cout &lt;&lt; "Friday" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	case 6:</span><br><span class="line">		cout &lt;&lt; "Saturday is free" &lt;&lt; endl;</span><br><span class="line">	case 7:</span><br><span class="line">		cout &lt;&lt; "Sunday is free" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	default:</span><br><span class="line">		cout &lt;&lt; "Wrong" &lt;&lt; endl;</span><br><span class="line">		break;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++9.png" alt="2"></p>
<h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a><font size="4">while循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int i = 1;</span><br><span class="line">	int sum = 0;</span><br><span class="line"></span><br><span class="line">	//while循环，每次循环开始时，判断表达式的内容，为真时执行循环体，否则跳出循环</span><br><span class="line">	while (i &lt; 10) {</span><br><span class="line">		sum += i++;</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; "1 + 2 + 3 + ... + 9 = " &lt;&lt; sum &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++10.png" alt="4"></p>
<h2 id="do…while循环"><a href="#do…while循环" class="headerlink" title="do…while循环"></a><font size="4">do…while循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int i = 1;</span><br><span class="line">	int sum = 0;</span><br><span class="line"></span><br><span class="line">	//do...while循环，每次循环结束后，判断表达式的内容，为真时执行下一次循环体，否则跳出循环</span><br><span class="line">	//注意do...while语句，一定会执行一次，而且最后有分号。而while语句，可能一次都不会执行。</span><br><span class="line">	do{</span><br><span class="line">		sum += i++;</span><br><span class="line">	} while (i &lt; 10);</span><br><span class="line">	cout &lt;&lt; "1 + 2 + 3 + ... + 9 = " &lt;&lt; sum &lt;&lt; endl;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++10.png" alt="5"></p>
<h2 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a><font size="4">for循环</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int sum = 0;</span><br><span class="line"></span><br><span class="line">	//for循环，括号中有三个表达式，分别为初始化表达式1，布尔表达式2，步进表达式3，循环体内容记为4</span><br><span class="line">	//for循环的执行过程为1-&gt;2-&gt;4-&gt;3-&gt;2-&gt;4-&gt;3-&gt;...-&gt;2，注意表达式1，2，3都可以省略，但是分号不可以省略。</span><br><span class="line">	//三种循环往往可以得到相同的结果，如果确定执行次数一般使用for循环，如果不确定执行次数则可以使用while循环</span><br><span class="line">	for (int i = 1; i &lt; 10; i++) {</span><br><span class="line">		sum += i;</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; "1 + 2 + 3 + ... + 9 = " &lt;&lt; sum &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++10.png" alt="6"></p>
<h2 id="goto语句"><a href="#goto语句" class="headerlink" title="goto语句"></a><font size="4">goto语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int sum = 0;</span><br><span class="line"></span><br><span class="line">	//goto语句，用于强行跳转到指定语句，大多用在多层循环的跳出，其余情况下避免使用goto语句，会导致编码风格混乱</span><br><span class="line">	for (int i = 0; i &lt; 10; i++) {</span><br><span class="line">		for (int j = 0; j &lt; 10; j++) {</span><br><span class="line">			if (i == 6 &amp;&amp; j == 6) {</span><br><span class="line">				goto print;</span><br><span class="line">			}</span><br><span class="line">			cout &lt;&lt; i * 10 + j &lt;&lt; "\t";</span><br><span class="line">		}</span><br><span class="line">		cout &lt;&lt; endl;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">print:</span><br><span class="line">	cout &lt;&lt; "......" &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++11.png" alt="7"></p>
<h2 id="continue关键字"><a href="#continue关键字" class="headerlink" title="continue关键字"></a><font size="4">continue关键字</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int sum = 0;</span><br><span class="line"></span><br><span class="line">	//continue关键字，立即结束本次循环体中的内容，继续进行下一次循环</span><br><span class="line">	for (int i = 0; i &lt; 10; i++) {</span><br><span class="line">		if (i == 5) {</span><br><span class="line">			continue;</span><br><span class="line">		}</span><br><span class="line">		sum += i;</span><br><span class="line">	}</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "1 + 2 + 3 + 4 + 6 + 7 + 8 + 9 = " &lt;&lt; sum &lt;&lt; endl;</span><br><span class="line">	</span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++12.png" alt="4"></p>
<h2 id="break关键字"><a href="#break关键字" class="headerlink" title="break关键字"></a><font size="4">break关键字</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	int sum = 0;</span><br><span class="line"></span><br><span class="line">	//break关键字，立即结束该层循环，如果是多层循环嵌套，则进行上一层循环的下一次循环</span><br><span class="line">	//break语句除了用于循环结构，还可以用于switch语句中，跳出选择结构</span><br><span class="line">	for (int i = 0; i &lt; 10; i++) {</span><br><span class="line">		if (i == 5) {</span><br><span class="line">			break;</span><br><span class="line">		}</span><br><span class="line">		sum += i;</span><br><span class="line">	}</span><br><span class="line">	cout &lt;&lt; "1 + 2 + 3 + 4 = " &lt;&lt; sum &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++13.png" alt="5"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  流程控制每种语言都大同小异，因为流程控制是所有语言的基础，只有掌握不同的流程控制语句，才能达到我们想要的目的，虽然难度较小，但是非常重要，无论以后从事什么样的研究，流程控制都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++运算符</title>
    <url>/2020/07/01/C++_operator/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python3.jpg" alt="2"></p>
<h1 id="C-运算符"><a href="#C-运算符" class="headerlink" title="C++运算符"></a><font size="5" color="red">C++运算符</font></h1><p>  在前面已经介绍了C++的由来，这里主要介绍C++的运算符，包括赋值运算符，算术运算符，关系运算符，逻辑运算符，三目运算符。<br><a id="more"></a></p>
<h1 id="C-创建变量"><a href="#C-创建变量" class="headerlink" title="C++创建变量"></a><font size="4">C++创建变量</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	// C++中的变量创建时必须写清楚数据类型，也可以先定义，然后在其他地方赋初始值</span><br><span class="line">	short s = 1;</span><br><span class="line">	int i = 20;</span><br><span class="line">	long l = 300;</span><br><span class="line">	long long ll = 4000L;</span><br><span class="line">	char c = 'A';</span><br><span class="line">	float f = 3.14f;</span><br><span class="line">	double d = 1.234567;</span><br><span class="line">	bool b;</span><br><span class="line">	b = true</span><br><span class="line"></span><br><span class="line">	// 可以用sizeof(obj) 查看创建的变量大小，typeid(obj).name()可以查看变量的类型</span><br><span class="line">	cout &lt;&lt; "s=" &lt;&lt; s &lt;&lt; "  类型为" &lt;&lt; typeid(s).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(s) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "i=" &lt;&lt; i &lt;&lt; "  类型为" &lt;&lt; typeid(i).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(i) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "l=" &lt;&lt; l &lt;&lt; "  类型为" &lt;&lt; typeid(l).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(l) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "ll=" &lt;&lt; ll &lt;&lt; "  类型为" &lt;&lt; typeid(ll).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(ll) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "c=" &lt;&lt; c &lt;&lt; "  类型为" &lt;&lt; typeid(c).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(c) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "f=" &lt;&lt; f &lt;&lt; "  类型为" &lt;&lt; typeid(f).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(f) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d=" &lt;&lt; d &lt;&lt; "  类型为" &lt;&lt; typeid(d).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(d) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b=" &lt;&lt; b &lt;&lt; "  类型为" &lt;&lt; typeid(b).name() &lt;&lt; "  所占内存大小为" &lt;&lt; sizeof(b) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++2.png" alt="1"></p>
<h1 id="C-算术运算"><a href="#C-算术运算" class="headerlink" title="C++算术运算"></a><font size="4">C++算术运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	// +(加)，-(减)，*(乘)，/(除)，%(求余)，整数除法结果只能得到整数，注意字符型和布尔型也可以参与运算，字符型的值为ASCII码对应的值，布尔型的true代表1，false代表0</span><br><span class="line">	//进行计算时要注意数据的范围，以及低范围和高范围数据类型进行运算时，数据会发生自动类型转换到高范围，高范围数据向低范围数据要强制类型转换</span><br><span class="line">	int a = 2;</span><br><span class="line">	long l = 999;</span><br><span class="line">	char c = 'A';</span><br><span class="line">	bool b = false;</span><br><span class="line">	double d = 3.14159;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "a + c =" &lt;&lt; a + c &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a * b =" &lt;&lt; a * b &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "l / a =" &lt;&lt; l / a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "l % a =" &lt;&lt; l % a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a * a * d =" &lt;&lt; a * a * d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "a * a * d =" &lt;&lt; (int)(a * a * d) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++3.png" alt="2"></p>
<h1 id="C-关系运算"><a href="#C-关系运算" class="headerlink" title="C++关系运算"></a><font size="4">C++关系运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	// &gt;(大于)，&lt;(小于)，&gt;=(大于等于)，&lt;=(小于等于)，==(等于)，!=(不等于)</span><br><span class="line">	int a = 99;</span><br><span class="line">	int b = 'b';</span><br><span class="line">	char c = 'c';</span><br><span class="line">	bool d = a == c;</span><br><span class="line">	bool e = b &gt; c;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; "99是否等于c？ " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "b是否大于c " &lt;&lt; e &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++4.png" alt="4"></p>
<h1 id="C-自增自减运算符"><a href="#C-自增自减运算符" class="headerlink" title="C++自增自减运算符"></a><font size="4">C++自增自减运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	// ++(自增运算符)，--(自减运算符)，++在前代表先进行加1，然后将值代入表达式，++在后代表先将值代入表达式，然后再进行加1，自减操作符同理。</span><br><span class="line">	int a = 1;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; a &lt;&lt; " 此时a=1" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; a++ &lt;&lt; " ++在后，先打印a=1，然后a=a+1" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; " 此时a=2" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; ++a &lt;&lt; " ++在前，先计算a=a+1，然后再打印a=3" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; " 此时a=3" &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	cout &lt;&lt; a-- &lt;&lt; " --在后，先打印a=3，然后a=a-1" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; " 此时a=2" &lt;&lt; endl;;</span><br><span class="line">	cout &lt;&lt; --a &lt;&lt; " --在前，先计算a=a-1，然后再打印a=1" &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; " 此时a=1" &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++5.png" alt="5"></p>
<h1 id="C-逻辑运算"><a href="#C-逻辑运算" class="headerlink" title="C++逻辑运算"></a><font size="4">C++逻辑运算</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	// &amp;&amp;(与)，||(或)，!(非)，注意与或操作只要可以判断出最后结果则停止，具有短路效果。</span><br><span class="line">	//如果与操作的第一个条件为假，则不执行第二个条件，如果或操作的第一个条件为真，则不执行第二个条件。</span><br><span class="line">	int a = 5;</span><br><span class="line">	int b = 6;</span><br><span class="line">	int c = 7;</span><br><span class="line">	int i = 0;</span><br><span class="line">	bool d = a &gt; b || ++i; //此时或操作的第一个表达式为假，需要执行++i，因此i=1</span><br><span class="line">	cout &lt;&lt; "i = " &lt;&lt; i &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "d = " &lt;&lt; d &lt;&lt; endl;</span><br><span class="line">	bool e = a &gt; b &amp;&amp; ++i; //此时与操作的第一个表达式为假，不需要执行++i，因此i=1</span><br><span class="line">	cout &lt;&lt; "i = " &lt;&lt; i &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; "e = " &lt;&lt; e &lt;&lt; endl;</span><br><span class="line">	bool f = !d;</span><br><span class="line">	cout &lt;&lt; "f = " &lt;&lt; f &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++6.png" alt="6"></p>
<h1 id="C-三目运算符"><a href="#C-三目运算符" class="headerlink" title="C++三目运算符"></a><font size="4">C++三目运算符</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main() {</span><br><span class="line">	// 条件?表达式1:表达式2，当条件成立时，执行表达式1的内容，否则执行表达式2的内容。</span><br><span class="line">	int a = 5 &gt; 3 ? 2 : 1; // 5 &gt; 3成立，因此a = 2</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	int b = ++a &gt;= a++ ? ++a : a++; // ++a中a的值先计算为3，再赋值为a，a++中a的值为3，此时++a &gt;= a++等价于3 &gt;= 3成立，当条件判断结束后，a又自增一次，变为4，然后b = ++a，a先自增为5，并且赋值给b</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; b &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">	return 0;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/C++7.png" alt="7"></p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  运算符操作每种语言都大同小异，因为运算符是所有语言的基础，学习每一种语言都离不开运算操作，虽然难度较小，但是非常重要，无论以后从事什么样的研究，都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++介绍</title>
    <url>/2020/06/28/C++_introduction/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/C++1.png" alt="0"></p>
<h1 id="C-介绍"><a href="#C-介绍" class="headerlink" title="C++介绍"></a><font size="5" color="red">C++介绍</font></h1><p>  C++的创始人为美国人本贾尼·斯特劳斯特卢普(Bjarne Stroustrup)，1979年，Bjame Sgoustrup来到了Bell实验室，开始从事将C改良的工作，1983年该语言被正式命名为C++。C++是C语言的继承，既可以面向过程也可以面向对象。可以说是现在高级语言的鼻祖。<br><a id="more"></a></p>
<p><img src="/images/LANGUAGE/C++.png" alt="0"></p>
<h1 id="语言的比较"><a href="#语言的比较" class="headerlink" title="语言的比较"></a><font size="5" color="red">语言的比较</font></h1><p>  <font size="3">将其他语言翻译成机器语言的工具称为编译器，编译的方式有两种，一种是编译，一种是解释</font><br>  <font size="3">编译型语言：C/C++，Pascal等语言都属于编译型语言，先由编译器生成可执行文件，运行时不需要重新编译，直接使用编译的结果即可，因此程序执行效率高，跨平台能力差。</font><br>  <font size="3">解释型语言：Java，C++等语言都属于解释型语言，运行时由解释器逐行解释每一句源代码，每次运行都需要解释一次，因此程序执行效率低，跨平台能力强。</font><br><img src="/images/LANGUAGE/python1.jpg" alt="1"></p>
<h1 id="C-特点"><a href="#C-特点" class="headerlink" title="C++特点"></a><font size="5" color="red">C++特点</font></h1><p>  <font size="3">在C语言的基础上进行扩充和完善，兼容了C的面向过程，也成为了一种面向对象的程序设计语言。</font><br>  <font size="3">功能强大，接近底层，但是也最为复杂，这是C++语言的优点同时也是它的缺点。</font></p>
<h1 id="C-特点-1"><a href="#C-特点-1" class="headerlink" title="C++特点"></a><font size="5" color="red">C++特点</font></h1><p>  <font size="3">在C语言的基础上进行扩充和完善，兼容了C的面向过程，也成为了一种面向对象的程序设计语言。</font><br>  <font size="3">功能强大，接近底层，但是也最为复杂，这是C++语言的优点同时也是它的缺点。</font></p>
<h1 id="C-的开发步骤"><a href="#C-的开发步骤" class="headerlink" title="C++的开发步骤"></a><font size="5" color="red">C++的开发步骤</font></h1><p>首先编写一个.cpp后缀的源程序，接着通过预编译生成.i后缀的预处理文件，然后通过编译获得.s后缀的编译文件，然后通过汇编语言翻译成.o后缀的汇编程序，最后链接过程生成.exe后缀的可执行文件。</p>
<h1 id="C-小结"><a href="#C-小结" class="headerlink" title="C++小结"></a><font size="5" color="red">C++小结</font></h1><p>  C++是大多数高校同学们所接触的第一门语言，因为它经典而且可以学习更多底层的知识体系，所以是我们学习编程的第一个关卡。如果不做C++开发工程师并且具有很长时间的工作经验，很难将这门语言学习透彻，有的小伙伴就会问为什么我们还要学习C++呢？我不做C++开发工程师是不是可以不用学习C++了呢？我认为无论在什么时候，只要是程序员，都需要和C++,Java等语言打交道，因为你的项目总要落地，总要应用在不同的场景之中(服务器开发，游戏开发，图形图像处理，嵌入式等等)，所以了解其他的语言可以更好的和其他部门的同事合作。想要在程序员的道路上越走越远，那么你就需要掌握多种语言，少年，你渴望力量吗<del>~</del>~</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>YOLO-V3</title>
    <url>/2020/06/26/Object%20detection%20YOLO-V3/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">YOLO-V3</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>YOLO-V3(You Only Look Once)</strong>:于<strong>2018年发表</strong>上。You Only Look Once体现了较高的检测速度，是一步法的典型代表，也是YOLO系列的第三个版本。<a id="more"></a></p>
<p><img src="/images/Object_detection/YOLO-V3.png" alt="YOLO-V3"></p>
<h1 id="YOLO-V3和SSD的区别"><a href="#YOLO-V3和SSD的区别" class="headerlink" title="YOLO-V3和SSD的区别"></a><font size="5" color="red">YOLO-V3和SSD的区别</font></h1><p>  <font size="3"><strong>特征提取网络不同</strong>，SSD的特征提取网络为<strong>VGG</strong>，YOLO-V3中的特征提取网络是ResNet的改进版本<strong>Darknet-53</strong>，实现深层次的特征融合。</font><br>  <font size="3"><strong>先验框不同</strong>，SSD是<strong>根据每一层的尺寸和长宽比计算出来</strong>的，YOLO-V3中每一层的先验框是<strong>根据大量数据聚类</strong>而得的。</font><br>  <font size="3"><strong>编解码函数不同</strong>，SSD的预测的是<strong>中心和宽高的相对偏移量</strong>，YOLO-V3预测的是<strong>中心的绝对偏移量，宽高的相对偏移量</strong></font><br>  <font size="3"><strong>损失函数不同</strong>，SSD采用<strong>Smooth-L1-Loss损失函数和多分类交叉熵损失函数</strong>。YOLO-V3采用<strong>MSE和二分类交叉熵损失函数</strong></font><br>  <font size="3"><strong>预测结果不同</strong>，SSD是<strong>在多个类别上求Softmax，选择最高的一个类别作为预测类别</strong>，YOLO-V3是<strong>通过Sigmoid函数，用置信度和预测结果相乘，超过阈值即可认为有目标存在，因此可以预测多个物体存在于一个预测框的情况</strong>。</font><br>  <font size="3"><strong>正负样本数量不同</strong>，SSD<strong>正样本的数量是根据真实框的先验框的IOU确定的，只要大于设定值就视为正样本，然后设置正负样本的比例为1：3确定负样本的个数</strong>，YOLO-V3<strong>选择与真实框最接近的一个先验框作为正样本，然后从剩余样本中选择IOU小于设定值的作为负样本</strong></font></p>
<h1 id="YOLO-V3图像分析"><a href="#YOLO-V3图像分析" class="headerlink" title="YOLO-V3图像分析"></a><font size="5" color="red">YOLO-V3图像分析</font></h1><p><img src="/images/Object_detection/YOLO-V3_A.png" alt="YOLO-V3"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, **kwargs):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__(**kwargs)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_regularizer=keras.regularizers.l2(5e-4)))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.LeakyReLU(0.1))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.blocks(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, filters, times, name):</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((1, 1), name='{}_zeropadding'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (3, 3), (2, 2), 'valid', name='{}_conv_bn_relu'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    for i in range(times):</span><br><span class="line">        shortcut = x</span><br><span class="line">        x = compose(Conv_Bn_Relu(filters // 2, (1, 1), (1, 1), 'same', name='{}_resblock{}_conv1'.format(name, i + 1)),</span><br><span class="line">                    Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_resblock{}_conv2'.format(name, i + 1)))(x)</span><br><span class="line">        x = keras.layers.Add(name='{}_resblock{}_add'.format(name, i + 1))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def five_conv(x, filters, name):</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters * 2, (3, 3), (1, 1), 'same', name='{}_conv_bn_relu2'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu3'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters * 2, (3, 3), (1, 1), 'same', name='{}_conv_bn_relu4'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu5'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def yolo_v3(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = Conv_Bn_Relu(32, (3, 3), (1, 1), 'same', name='conv_bn_relu')(x)</span><br><span class="line">    x1 = block(x1, 64, 1, name='block1')</span><br><span class="line">    x1 = block(x1, 128, 2, name='block2')</span><br><span class="line">    x1 = block(x1, 256, 8, name='block3')</span><br><span class="line"></span><br><span class="line">    x2 = block(x1, 512, 8, name='block4')</span><br><span class="line"></span><br><span class="line">    x3 = block(x2, 1024, 4, name='block5')</span><br><span class="line">    feature3 = five_conv(x3, 512, name='feature3')</span><br><span class="line"></span><br><span class="line">    pred3 = compose(Conv_Bn_Relu(1024, (3, 3), (1, 1), 'same', name='pred3_conv1'),</span><br><span class="line">                    keras.layers.Conv2D(3 * 85, (1, 1), (1, 1), 'same', name='pred3_conv2'),</span><br><span class="line">                    keras.layers.Flatten(name='pred3_flatten'))(feature3)</span><br><span class="line"></span><br><span class="line">    upsampling2 = compose(Conv_Bn_Relu(256, (1, 1), (1, 1), 'same', name='conv_bn_relu2'),</span><br><span class="line">                          keras.layers.UpSampling2D((2, 2), name='upsampling2'))(feature3)</span><br><span class="line">    concatenate2 = keras.layers.Concatenate(name='concatenate2')([upsampling2, x2])</span><br><span class="line">    feature2 = five_conv(concatenate2, 256, name='feature2')</span><br><span class="line">    pred2 = compose(Conv_Bn_Relu(512, (3, 3), (1, 1), 'same', name='pred2_conv1'),</span><br><span class="line">                    keras.layers.Conv2D(3 * 85, (1, 1), (1, 1), 'same', name='pred2_conv2'),</span><br><span class="line">                    keras.layers.Flatten(name='pred2_flatten'))(feature2)</span><br><span class="line"></span><br><span class="line">    upsampling1 = compose(Conv_Bn_Relu(128, (1, 1), (1, 1), 'same', name='conv_bn_relu1'),</span><br><span class="line">                          keras.layers.UpSampling2D((2, 2), name='upsampling1'))(feature2)</span><br><span class="line">    concatenate1 = keras.layers.Concatenate(name='concatenate1')([upsampling1, x1])</span><br><span class="line">    feature1 = five_conv(concatenate1, 128, name='feature1')</span><br><span class="line">    pred1 = compose(Conv_Bn_Relu(256, (3, 3), (1, 1), 'same', name='pred1_conv1'),</span><br><span class="line">                    keras.layers.Conv2D(3 * 85, (1, 1), (1, 1), 'same', name='pred1_conv2'),</span><br><span class="line">                    keras.layers.Flatten(name='pred1_flatten'))(feature1)</span><br><span class="line"></span><br><span class="line">    concatenate = keras.layers.Concatenate(name='concatenate')([pred1, pred2, pred3])</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Reshape((10647, 85), name='reshape')(concatenate)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='YOLO-V3')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = yolo_v3(input_shape=(416, 416, 3))</span><br><span class="line">    model.build(input_shape=(None, 416, 416, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Object_detection/YOLO-V3_R.png" alt="YOLO-V3"></p>
<h1 id="Shape数据集完整实战"><a href="#Shape数据集完整实战" class="headerlink" title="Shape数据集完整实战"></a><font size="5" color="red">Shape数据集完整实战</font></h1><h2 id="文件路径关系说明"><a href="#文件路径关系说明" class="headerlink" title="文件路径关系说明"></a>文件路径关系说明</h2><ul>
<li>project<ul>
<li>shape<ul>
<li>train_imgs(训练集图像文件夹)</li>
<li>annotations(训练集标签文件夹)</li>
<li>test_imgs(测试集图像文件夹)</li>
</ul>
</li>
<li>YOLO-V3_weight(模型权重文件夹)</li>
<li>YOLO-V3_test_result(测试集结果文件夹)</li>
<li>YOLO-V3.py</li>
</ul>
</li>
</ul>
<h2 id="实战步骤说明"><a href="#实战步骤说明" class="headerlink" title="实战步骤说明"></a>实战步骤说明</h2><ol>
<li>目标检测和语义分割是两种不同类型的工程项目，目标检测实战处理比语义分割困难的多，首先要<strong>读取真实框信息</strong>，将其保存下来，为了后面编码使用。</li>
<li><strong>建立先验框</strong>，根据网络结构，在不同特征层上建立不同的先验框，先验框的总个数为每个回归分类特征层的像素点个数x每个像素点上的先验框个数。以论文中的先验框为例，特征层有3个，大小分别为52x52，26x26，13x13，特征层上每个像素点的先验框个数都是3个。<br><img src="/images/Object_detection/YOLO-V3_P.png" alt="anchor"><script type="math/tex; mode=display">52^2 \times 3+26^2 \times 3+13^2 \times 3=10647</script>故先验框总数为10647个。</li>
<li>根据真实框的信息，和所有先验框计算IOU，将IOU最大的先验框作为正样本。然后进行<strong>编码</strong>，在置信度上面置1说明该位置有目标，对应目标类别置信度置1，其他目标类别置信度置0，并计算正样本先验框的中心坐标与宽高和真实框的中心坐标与宽高之间的差异。输出(batch_size, num_prior, 4 + 1 + num_class + 1)，num_prior为先验框的个数，每个先验框有4 + 1 + num_class + 1个值，4代表中心坐标和宽高相对真实框的差异，1代表属于有目标的置信度，num_class代表属于某一个类别的置信度，最后一个1代表真实框与先验框的IOU，方便计算损失时得到负样本。编码的目的是得到真实框对应的神经网络的输出应该是什么样子，然后让两者尽可能的接近。<br><strong>IOU(Intersection Over Union，交并比)</strong>：用于<strong>评估语义分割算法性能的指标是平均IOU</strong>，交并比也非常好理解，算法的结果与真实物体进行<strong>交运算的结果除以进行并运算的结果</strong>。通过下图可以直观的看出IOU的计算方法。<br><img src="/images/Semantic_segmentation/Dataset_I.png" alt="IOU"></li>
<li><strong>设计损失函数</strong>，因为先验框中大部分都是负样本，因此不能直接计算损失函数，<strong>选择与真实框最接近的一个先验框作为正样本，然后从剩余样本中选择IOU小于设定值的作为负样本</strong>。</li>
<li>搭建神经网络，<strong>设置合适参数</strong>，进行训练。</li>
<li>预测时，需要根据神经网络的输出进行<strong>逆向解码(编码的反过程)</strong>，根据置信度，选择<strong>背景置信度乘类别置信度大于设定值的先验框作为候选框</strong>，然后<strong>根据先验框的坐标和4个回归参数确定候选框的左上角和右下角坐标</strong>。对<strong>每一类候选框进行NMS得到预测框</strong>，并且在图像上<strong>画出预测框</strong>，并且<strong>标出置信度</strong>即可完成目标检测任务。<br><strong>NMS(Non-Maximum Suppression，非极大值抑制)</strong>：简单地说，<strong>不是最大的我不要</strong>，在目标检测中，往往图像上存在大量先验框，会导致很多附近的框都会预测出同一个物体，但是我们<strong>只保留最大的一个预测结果</strong>，这就是非极大值抑制。<br>步骤：<br>(1)<strong>从最大概率矩形框F开始</strong>，分别判断A~E与F的IOU是否大于某个设定的阈值，<strong>假设B、D与F的重叠度超过阈值，那么就扔掉B、D</strong>；并<strong>标记第一个矩形框F</strong>，是我们保留下来的。<br>(2)<strong>从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框</strong>。<br>(3)<strong>重复步骤(2)，直到所有的框都被抛弃或者保留</strong>。<br><img src="/images/Object_detection/Dataset_N.png" alt="NMS"></li>
</ol>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>神经网络的输出维度为(batch_size, num_prior, 4 + 1 + num_class)，<strong>此数据集为3类，因此最后一个维度是8</strong>。每个先验框有8个索引，前面4个索引代表先验框的回归参数，用来对先验框进行调整得到预测框，索引为4代表有目标的置信度，索引为5代表圆形，索引为6代表三角形，索引为7代表正方形。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
<li>设置了<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li>使用<strong>yield</strong>关键字，产生可迭代对象，不用将所有的数据都保存下来，大大节约内存。</li>
<li>其中将1000个数据，分成800个训练集，100个验证集和100个测试集，小伙伴们可以自行修改。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>YOLO-V3的<strong>特征提取网络为Darknet-53</strong>，小伙伴们可以参考特征提取网络部分内容，选择其他的网络进行特征提取，比较不同网络参数量，运行速度，最终结果之间的差异。</li>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li><strong>根据实际的图像大小，选择合适的特征层数，先验框的形状，先验框数量，以及各种阈值</strong></li>
<li><strong>anchor尺寸的确定</strong>，anchor通过聚类方法确定，anchor的大小对于检测效果有很大的影响，小伙伴们可以尝试不同的anchor，看一看测试的结果。<br>11.TF2.0是一个不太稳定的版本，在训练时，常常出现卡顿情况，在损失函数中前面加上一句打印损失函数的值，就不会发生卡顿。。。喵喵喵~~~。</li>
<li>因为这个博客是对学习的一些总结和记录，意在和学习者探讨和交流，并且给准备入门的同学一些手把手的教学，因此关于目标检测的算法参数设计，我都是自己尝试的，不是针对于这个数据集最优的参数，大家可以根据自己的实际需要修改网络结构。</li>
</ol>
<h2 id="完整实战代码"><a href="#完整实战代码" class="headerlink" title="完整实战代码"></a>完整实战代码</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import colorsys</span><br><span class="line">import os</span><br><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取先验框函数</span><br><span class="line">def get_prior(layer_id):</span><br><span class="line">    layer_id = layer_id - 1</span><br><span class="line"></span><br><span class="line">    box_widths = [x[1] for x in anchors[layer_id]]</span><br><span class="line">    box_heights = [x[0] for x in anchors[layer_id]]</span><br><span class="line"></span><br><span class="line">    step_x = img_size[1] / feature_map[layer_id]</span><br><span class="line">    step_y = img_size[0] / feature_map[layer_id]</span><br><span class="line">    linx = np.linspace(0.5 * step_x, img_size[1] - 0.5 * step_x, feature_map[layer_id])</span><br><span class="line">    liny = np.linspace(0.5 * step_y, img_size[0] - 0.5 * step_y, feature_map[layer_id])</span><br><span class="line"></span><br><span class="line">    centers_x, centers_y = np.meshgrid(linx, liny)</span><br><span class="line">    centers_x = centers_x.reshape(-1, 1)</span><br><span class="line">    centers_y = centers_y.reshape(-1, 1)</span><br><span class="line"></span><br><span class="line">    # 获得先验框的中心坐标</span><br><span class="line">    prior_center = np.concatenate((centers_x, centers_y), axis=1)</span><br><span class="line">    prior_center = np.tile(prior_center, (1, prior[layer_id] * 2))</span><br><span class="line"></span><br><span class="line">    prior_lt_rb = prior_center.copy()</span><br><span class="line"></span><br><span class="line">    # 获得先验框的左上右下</span><br><span class="line">    prior_lt_rb[:, ::4] -= box_widths</span><br><span class="line">    prior_lt_rb[:, 1::4] -= box_heights</span><br><span class="line">    prior_lt_rb[:, 2::4] += box_widths</span><br><span class="line">    prior_lt_rb[:, 3::4] += box_heights</span><br><span class="line"></span><br><span class="line">    # 归一化到[0, 1]</span><br><span class="line">    prior_lt_rb[:, ::2] /= img_size[1]</span><br><span class="line">    prior_lt_rb[:, 1::2] /= img_size[0]</span><br><span class="line">    prior_lt_rb = prior_lt_rb.reshape(-1, 4)</span><br><span class="line">    prior_lt_rb = np.minimum(np.maximum(prior_lt_rb, 0.0), 1.0)</span><br><span class="line"></span><br><span class="line">    prior_center_wh = np.zeros_like(prior_lt_rb)</span><br><span class="line">    # 获得先验框的宽和高</span><br><span class="line">    prior_center_wh[:, 0] = 0.5 * (prior_lt_rb[:, 2] + prior_lt_rb[:, 0])</span><br><span class="line">    prior_center_wh[:, 1] = 0.5 * (prior_lt_rb[:, 3] + prior_lt_rb[:, 1])</span><br><span class="line">    prior_center_wh[:, 2] = prior_lt_rb[:, 2] - prior_lt_rb[:, 0]</span><br><span class="line">    prior_center_wh[:, 3] = prior_lt_rb[:, 3] - prior_lt_rb[:, 1]</span><br><span class="line"></span><br><span class="line">    return prior_center_wh.astype(np.float32), prior_lt_rb.astype(np.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 从xml文件中获取bounding-box信息</span><br><span class="line">def get_bbox(image_id, bbox_path, annotations_path):</span><br><span class="line">    with open(bbox_path, 'w') as f:</span><br><span class="line">        for id in image_id:</span><br><span class="line">            # 图片路径</span><br><span class="line">            info = os.getcwd() + imgs_path[1:] + '\\' + str(id) + '.jpg'</span><br><span class="line">            in_file = open(annotations_path + '\\' + str(id) + '.xml', encoding='utf-8')</span><br><span class="line">            tree = ET.parse(in_file)</span><br><span class="line">            root = tree.getroot()</span><br><span class="line"></span><br><span class="line">            for obj in root.iter('object'):</span><br><span class="line">                difficult = obj.find('difficult').text</span><br><span class="line">                cls = obj.find('name').text</span><br><span class="line">                if cls not in classes or int(difficult) == 1:</span><br><span class="line">                    continue</span><br><span class="line">                cls_id = classes.index(cls)</span><br><span class="line">                xmlbox = obj.find('bndbox')</span><br><span class="line">                b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))</span><br><span class="line">                info += " " + ",".join([str(x) for x in b]) + ',' + str(cls_id)</span><br><span class="line">            f.writelines(info + '\n')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, **kwargs):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__(**kwargs)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_regularizer=keras.regularizers.l2(5e-4)))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.LeakyReLU(0.1))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.blocks(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, filters, times, name):</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((1, 1), name='{}_zeropadding'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (3, 3), (2, 2), 'valid', name='{}_conv_bn_relu'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    for i in range(times):</span><br><span class="line">        shortcut = x</span><br><span class="line">        x = compose(Conv_Bn_Relu(filters // 2, (1, 1), (1, 1), 'same', name='{}_resblock{}_conv1'.format(name, i + 1)),</span><br><span class="line">                    Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_resblock{}_conv2'.format(name, i + 1)))(x)</span><br><span class="line">        x = keras.layers.Add(name='{}_resblock{}_add'.format(name, i + 1))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def five_conv(x, filters, name):</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters * 2, (3, 3), (1, 1), 'same', name='{}_conv_bn_relu2'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu3'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters * 2, (3, 3), (1, 1), 'same', name='{}_conv_bn_relu4'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu5'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def small_yolo_v3(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = Conv_Bn_Relu(16, (3, 3), (1, 1), 'same', name='conv_bn_relu')(x)</span><br><span class="line">    x1 = block(x1, 32, 2, name='block2')</span><br><span class="line">    x1 = block(x1, 64, 2, name='block3')</span><br><span class="line"></span><br><span class="line">    x2 = block(x1, 128, 2, name='block4')</span><br><span class="line"></span><br><span class="line">    x3 = block(x2, 256, 2, name='block5')</span><br><span class="line">    feature3 = five_conv(x3, 128, name='feature3')</span><br><span class="line">    pred_reg3 = compose(Conv_Bn_Relu(256, (3, 3), (1, 1), 'same', name='pred3_reg_conv1'),</span><br><span class="line">                    keras.layers.Conv2D(2 * 4, (1, 1), (1, 1), 'same', name='pred3_reg_conv2'),</span><br><span class="line">                    keras.layers.Flatten(name='pred3_reg_flatten'))(feature3)</span><br><span class="line"></span><br><span class="line">    pred_conf3 = compose(Conv_Bn_Relu(256, (3, 3), (1, 1), 'same', name='pred3_conf_conv1'),</span><br><span class="line">                    keras.layers.Conv2D(2 * num_class, (1, 1), (1, 1), 'same', name='pred3_conf_conv2'),</span><br><span class="line">                    keras.layers.Flatten(name='pred3_conf_flatten'))(feature3)</span><br><span class="line"></span><br><span class="line">    upsampling2 = compose(Conv_Bn_Relu(64, (1, 1), (1, 1), 'same', name='conv_bn_relu2'),</span><br><span class="line">                          keras.layers.UpSampling2D((2, 2), name='upsampling2'))(feature3)</span><br><span class="line">    concatenate2 = keras.layers.Concatenate(name='concatenate2')([upsampling2, x2])</span><br><span class="line">    feature2 = five_conv(concatenate2, 64, name='feature2')</span><br><span class="line">    pred_reg2 = compose(Conv_Bn_Relu(128, (3, 3), (1, 1), 'same', name='pred2_reg_conv1'),</span><br><span class="line">                        keras.layers.Conv2D(2 * 4, (1, 1), (1, 1), 'same', name='pred2_reg_conv2'),</span><br><span class="line">                        keras.layers.Flatten(name='pred2_reg_flatten'))(feature2)</span><br><span class="line"></span><br><span class="line">    pred_conf2 = compose(Conv_Bn_Relu(128, (3, 3), (1, 1), 'same', name='pred2_conf_conv1'),</span><br><span class="line">                         keras.layers.Conv2D(2 * num_class, (1, 1), (1, 1), 'same', name='pred2_conf_conv2'),</span><br><span class="line">                         keras.layers.Flatten(name='pred2_conf_flatten'))(feature2)</span><br><span class="line"></span><br><span class="line">    upsampling1 = compose(Conv_Bn_Relu(32, (1, 1), (1, 1), 'same', name='conv_bn_relu1'),</span><br><span class="line">                          keras.layers.UpSampling2D((2, 2), name='upsampling1'))(feature2)</span><br><span class="line">    concatenate1 = keras.layers.Concatenate(name='concatenate1')([upsampling1, x1])</span><br><span class="line">    feature1 = five_conv(concatenate1, 32, name='feature1')</span><br><span class="line">    pred_reg1 = compose(Conv_Bn_Relu(64, (3, 3), (1, 1), 'same', name='pred1_reg_conv1'),</span><br><span class="line">                        keras.layers.Conv2D(2 * 4, (1, 1), (1, 1), 'same', name='pred1_reg_conv2'),</span><br><span class="line">                        keras.layers.Flatten(name='pred1_reg_flatten'))(feature1)</span><br><span class="line"></span><br><span class="line">    pred_conf1 = compose(Conv_Bn_Relu(64, (3, 3), (1, 1), 'same', name='pred1_conf_conv1'),</span><br><span class="line">                         keras.layers.Conv2D(2 * num_class, (1, 1), (1, 1), 'same', name='pred1_conf_conv2'),</span><br><span class="line">                         keras.layers.Flatten(name='pred1_conf_flatten'))(feature1)</span><br><span class="line"></span><br><span class="line">    concatenate_reg = keras.layers.Concatenate(name='concatenate_reg')([pred_reg1, pred_reg2, pred_reg3])</span><br><span class="line">    concatenate_cls = keras.layers.Concatenate(name='concatenate_cls')([pred_conf1, pred_conf2, pred_conf3])</span><br><span class="line"></span><br><span class="line">    reshape_reg = keras.layers.Reshape((num_prior, 4), name='reshape_reg')(concatenate_reg)</span><br><span class="line">    reshape_cls = keras.layers.Reshape((num_prior, num_class), name='reshape_cls')(concatenate_cls)</span><br><span class="line"></span><br><span class="line">    softmax_cls = keras.layers.Activation('sigmoid', name='sigmoid_cls')(reshape_cls)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Concatenate(name='concatenate')([reshape_reg, softmax_cls])</span><br><span class="line"></span><br><span class="line">    # 输出维度是[batch_size, 先验框的总数num_prior, 先验框的位置回归 + 物体的置信度 + 先验框的预测类别]，这里是[8, 1008, 8]</span><br><span class="line">    model = keras.Model(input_tensor, output, name='YOLO-V3')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 计算IOU函数</span><br><span class="line">def iou(box):</span><br><span class="line">    inter_upleft = np.maximum(prior_lt_rb[:, :2], box[:2])</span><br><span class="line">    inter_botright = np.minimum(prior_lt_rb[:, 2:4], box[2:])</span><br><span class="line"></span><br><span class="line">    inter_wh = inter_botright - inter_upleft</span><br><span class="line">    inter_wh = np.maximum(inter_wh, 0)</span><br><span class="line">    inter = inter_wh[:, 0] * inter_wh[:, 1]</span><br><span class="line">    # 真实框的面积</span><br><span class="line">    area_true = (box[2] - box[0]) * (box[3] - box[1])</span><br><span class="line">    # 先验框的面积</span><br><span class="line">    area_gt = (prior_lt_rb[:, 2] - prior_lt_rb[:, 0]) * (prior_lt_rb[:, 3] - prior_lt_rb[:, 1])</span><br><span class="line">    # 计算iou</span><br><span class="line">    union = area_true + area_gt - inter</span><br><span class="line"></span><br><span class="line">    iou = inter / union</span><br><span class="line"></span><br><span class="line">    return iou</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 根据真实框bounding-box编码函数</span><br><span class="line">def encoder(box):</span><br><span class="line">    iou_val = iou(box)</span><br><span class="line">    encoded_box = np.zeros((num_prior, 5))</span><br><span class="line"></span><br><span class="line">    # 找到每一个真实框，重合程度较高的先验框</span><br><span class="line">    assign_mask = iou_val &gt; overlap_threshold</span><br><span class="line">    encoded_box[:, -1][assign_mask] = iou_val[assign_mask]</span><br><span class="line"></span><br><span class="line">    # 先计算真实框的中心与长宽</span><br><span class="line">    encoded_box[:, 0:2] = (0.5 * (box[:2] + box[2:]) - prior_center_wh[:, :2]) * feature_shape</span><br><span class="line">    encoded_box[:, 2:4] = tf.math.log((box[2:] - box[:2]) / prior_center_wh[:, 2:])</span><br><span class="line"></span><br><span class="line">    return encoded_box</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取网络输出标签数据，即作为损失函数的真实输入y_true</span><br><span class="line">def assign_boxes(boxes):</span><br><span class="line">    # 大小为num_box * (4 + num_class + 1)，4代表4个位置回归，1代表iou</span><br><span class="line">    assignment = np.zeros((num_prior, 4 + num_class + 1))</span><br><span class="line">    if len(boxes) == 0:</span><br><span class="line">        return assignment</span><br><span class="line">    # 对每一个真实框都进行iou计算</span><br><span class="line">    encoded_boxes = np.apply_along_axis(f_encode, 1, boxes[:, :4])</span><br><span class="line">    # 每一个真实框的编码后的值，和iou</span><br><span class="line">    encoded_boxes = encoded_boxes.reshape(-1, num_prior, 5)</span><br><span class="line">    # 取重合程度最大的先验框，并且获取这个先验框的index</span><br><span class="line">    best_iou_idx = encoded_boxes[:, :, -1].argmax(axis=1)</span><br><span class="line"></span><br><span class="line">    # 前面4列代表中心和宽高</span><br><span class="line">    assignment[:, :4][best_iou_idx] = encoded_boxes[np.arange(len(best_iou_idx)), best_iou_idx, :4]</span><br><span class="line">    # 中间num_class代表标签信息</span><br><span class="line">    assignment[:, 4:-1][best_iou_idx] = boxes[..., 4:]</span><br><span class="line">    # 最后一列代表iou</span><br><span class="line">    assignment[:, -1] = encoded_boxes[:, :, -1].max(axis=0)</span><br><span class="line">    return assignment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 通过yield获取可迭代对象</span><br><span class="line">def generate_arrays_from_file(train_data, batch_size):</span><br><span class="line">    # 获取总长度</span><br><span class="line">    n = len(train_data)</span><br><span class="line">    i = 0</span><br><span class="line">    while True:</span><br><span class="line">        X_train = []</span><br><span class="line">        Y_train = []</span><br><span class="line">        # 获取一个batch_size大小的数据</span><br><span class="line">        while len(X_train) &lt; batch_size:</span><br><span class="line">            if i == 0:</span><br><span class="line">                np.random.shuffle(train_data)</span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(imgs_path + '\\' + str(train_data[i]) + '.jpg')</span><br><span class="line">            img = img / 127.5 - 1</span><br><span class="line">            info = np.array([list(map(int, x.split(','))) for x in bounding_info[train_data[i]].split()[3:]])</span><br><span class="line">            if not len(info):</span><br><span class="line">                i = (i + 1) % n</span><br><span class="line">                continue</span><br><span class="line">            box = (info[:, :4] + 1).astype(np.float32)</span><br><span class="line">            box[:, [0, 2]] = box[:, [0, 2]] / img_size[1]</span><br><span class="line">            box[:, [1, 3]] = box[:, [1, 3]] / img_size[0]</span><br><span class="line">            label = np.eye(num_class)[np.array(info[:, 4] + 1, np.int32)]</span><br><span class="line">            label[:, 0] = 1</span><br><span class="line">            if ((box[:, 0] - box[:, 2]) &gt;= 0).any() or ((box[:, 1] - box[:, 3]) &gt;= 0).any():</span><br><span class="line">                i = (i + 1) % n</span><br><span class="line">                continue</span><br><span class="line">            box = np.concatenate([box, label], axis=-1)</span><br><span class="line">            X_train.append(img)</span><br><span class="line">            y = assign_boxes(box)</span><br><span class="line">            Y_train.append(y)</span><br><span class="line">            i = (i + 1) % n</span><br><span class="line">        yield tf.constant(X_train), tf.constant(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义损失函数</span><br><span class="line">@tf.function</span><br><span class="line">def compute_loss(y_true, y_pred):</span><br><span class="line"></span><br><span class="line">    y_true = tf.reshape(y_true, (-1, 9))</span><br><span class="line">    y_pred = tf.reshape(y_pred, (-1, 8))</span><br><span class="line"></span><br><span class="line">    pos = tf.equal(y_true[:, 4], 1)</span><br><span class="line">    neg = tf.logical_and(tf.equal(y_true[:, 4], 0), tf.less(y_true[:, -1], overlap_threshold))</span><br><span class="line"></span><br><span class="line">    y_true_pos = tf.boolean_mask(y_true[:, :-1], axis=0, mask=pos)</span><br><span class="line">    y_true_neg = tf.boolean_mask(y_true[:, :-1], axis=0, mask=neg)</span><br><span class="line">    y_pred_pos = tf.boolean_mask(y_pred, axis=0, mask=pos)</span><br><span class="line">    y_pred_neg = tf.boolean_mask(y_pred, axis=0, mask=neg)</span><br><span class="line">    y_true_valid = tf.concat([y_true_pos, y_true_neg], axis=0)</span><br><span class="line">    y_pred_valid = tf.concat([y_pred_pos, y_pred_neg], axis=0)</span><br><span class="line">    reg_loss = tf.reduce_mean((y_true_pos[:, :4] - y_pred_pos[:, :4]) ** 2)</span><br><span class="line">    conf_loss = tf.reduce_mean(keras.losses.binary_crossentropy(y_true_valid[:, 4:], y_pred_valid[:, 4:]))</span><br><span class="line">    tf.print(conf_loss)</span><br><span class="line">    return reg_loss + conf_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 根据网络预测解码函数，获得候选框</span><br><span class="line">def decoder(loc):</span><br><span class="line">    # 获得先验框的中心与宽高</span><br><span class="line">    prior_center_x = prior_center_wh[:, 0]</span><br><span class="line">    prior_center_y = prior_center_wh[:, 1]</span><br><span class="line">    prior_width = prior_center_wh[:, 2]</span><br><span class="line">    prior_height = prior_center_wh[:, 3]</span><br><span class="line"></span><br><span class="line">    # 获得真实框的中心与宽高</span><br><span class="line">    decode_bbox_center_x = (loc[:, 0] / feature_shape[:, 0] + prior_center_x)</span><br><span class="line">    decode_bbox_center_y = (loc[:, 1] / feature_shape[:, 1] + prior_center_y)</span><br><span class="line">    decode_bbox_width = np.exp(loc[:, 2]) * prior_width</span><br><span class="line">    decode_bbox_height = np.exp(loc[:, 3]) * prior_height</span><br><span class="line"></span><br><span class="line">    # 获取真实框的左上角与右下角</span><br><span class="line">    decode_bbox_xmin = decode_bbox_center_x - 0.5 * decode_bbox_width</span><br><span class="line">    decode_bbox_ymin = decode_bbox_center_y - 0.5 * decode_bbox_height</span><br><span class="line">    decode_bbox_xmax = decode_bbox_center_x + 0.5 * decode_bbox_width</span><br><span class="line">    decode_bbox_ymax = decode_bbox_center_y + 0.5 * decode_bbox_height</span><br><span class="line"></span><br><span class="line">    # 真实框的左上角与右下角进行堆叠</span><br><span class="line">    decode_bbox = np.concatenate((decode_bbox_xmin[:, np.newaxis], decode_bbox_ymin[:, np.newaxis], decode_bbox_xmax[:, np.newaxis], decode_bbox_ymax[:, np.newaxis]), axis=-1)</span><br><span class="line">    # 防止超出0与1</span><br><span class="line">    decode_bbox = np.minimum(np.maximum(decode_bbox, 0.0), 1.0)</span><br><span class="line">    return decode_bbox</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 将候选框进行非极大值抑制，获得最终的预测框</span><br><span class="line">def detection_out(pred):</span><br><span class="line">    # 回归网络预测结果</span><br><span class="line">    mbox_loc = pred[:, :4]</span><br><span class="line">    # 分类网络预测结果</span><br><span class="line">    mbox_conf = pred[:, 4:]</span><br><span class="line">    results = []</span><br><span class="line">    # 对每一个图像进行处理</span><br><span class="line">    decode_bbox = decoder(mbox_loc)</span><br><span class="line">    for c in range(1, num_class):</span><br><span class="line">        c_confs = mbox_conf[:, c] * mbox_conf[:, 0]</span><br><span class="line">        c_confs_mask = c_confs &gt; confidence_threshold</span><br><span class="line">        if len(c_confs[c_confs_mask]) &gt; 0:</span><br><span class="line">            # 取出得分高于confidence_threshold的框</span><br><span class="line">            boxes_to_process = decode_bbox[c_confs_mask]</span><br><span class="line">            confs_to_process = c_confs[c_confs_mask]</span><br><span class="line">            # 进行iou的非极大抑制</span><br><span class="line">            idx = tf.image.non_max_suppression(boxes_to_process.astype(np.float32), confs_to_process, max_output_size=keep_top_k, iou_threshold=nms_thresh)</span><br><span class="line">            idx = idx.numpy()</span><br><span class="line">            # 取出在非极大抑制中效果较好的内容</span><br><span class="line">            box = boxes_to_process[idx]</span><br><span class="line">            confs = confs_to_process[idx][:, np.newaxis]</span><br><span class="line">            # 将label、置信度、框的位置进行堆叠。</span><br><span class="line">            labels = c * np.ones((len(idx), 1))</span><br><span class="line">            c_pred = np.concatenate((labels, confs, box), axis=1)</span><br><span class="line">            # 添加进result里</span><br><span class="line">            results.extend(c_pred)</span><br><span class="line">    if len(results) &gt; 0:</span><br><span class="line">        # 按照置信度进行排序</span><br><span class="line">        results = np.array(results)</span><br><span class="line">        arg = np.argsort(results[:, 1])[::-1][:keep_top_k]</span><br><span class="line">        results = results[arg]</span><br><span class="line">    return results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 将图像进行预测并画框</span><br><span class="line">def detect_image(filename):</span><br><span class="line"></span><br><span class="line">    test_img = cv.imread(filename)</span><br><span class="line">    preds = tf.squeeze(model.predict(tf.constant([test_img / 127.5 - 1])), axis=0).numpy()</span><br><span class="line"></span><br><span class="line">    # 将预测结果进行解码</span><br><span class="line">    results = detection_out(preds)</span><br><span class="line"></span><br><span class="line">    if len(results) &lt;= 0:</span><br><span class="line">        return test_img</span><br><span class="line">    print(filename)</span><br><span class="line">    # 筛选出其中得分高于confidence的框</span><br><span class="line">    det_label = results[:, 0]</span><br><span class="line">    det_conf = results[:, 1]</span><br><span class="line">    det_xmin, det_ymin, det_xmax, det_ymax = results[:, 2], results[:, 3], results[:, 4], results[:, 5]</span><br><span class="line">    indices = [index for index, conf in enumerate(det_conf) if conf &gt;= confidence_threshold]</span><br><span class="line">    top_conf = det_conf[indices]</span><br><span class="line">    top_label_indices = det_label[indices].tolist()</span><br><span class="line">    top_xmin = np.expand_dims(det_xmin[indices], -1) * img_size[1]</span><br><span class="line">    top_ymin = np.expand_dims(det_ymin[indices], -1) * img_size[0]</span><br><span class="line">    top_xmax = np.expand_dims(det_xmax[indices], -1) * img_size[1]</span><br><span class="line">    top_ymax = np.expand_dims(det_ymax[indices], -1) * img_size[0]</span><br><span class="line">    boxes = np.concatenate([top_xmin, top_ymin, top_xmax, top_ymax], axis=-1)</span><br><span class="line"></span><br><span class="line">    font = cv.FONT_HERSHEY_SIMPLEX</span><br><span class="line"></span><br><span class="line">    for i, c in enumerate(top_label_indices):</span><br><span class="line">        cls = int(c) - 1</span><br><span class="line">        predicted_class = classes[cls]</span><br><span class="line">        score = top_conf[i]</span><br><span class="line"></span><br><span class="line">        left, top, right, bottom = boxes[i]</span><br><span class="line">        left = left - expand</span><br><span class="line">        top = top - expand</span><br><span class="line">        right = right + expand</span><br><span class="line">        bottom = bottom + expand</span><br><span class="line"></span><br><span class="line">        left = max(0, np.floor(left + 0.5).astype('int32'))</span><br><span class="line">        top = max(0, np.floor(top + 0.5).astype('int32'))</span><br><span class="line">        right = min(img_size[1], np.floor(right + 0.5).astype('int32'))</span><br><span class="line">        bottom = min(img_size[0], np.floor(bottom + 0.5).astype('int32'))</span><br><span class="line"></span><br><span class="line">        # 画框</span><br><span class="line">        label = '{} {:.2f}'.format(predicted_class, score)</span><br><span class="line"></span><br><span class="line">        cv.rectangle(test_img, (left, top), (right, bottom), colors[cls], 1)</span><br><span class="line">        cv.putText(test_img, label, (left, top - int(label_size * 10)), font, label_size, colors[cls], 1)</span><br><span class="line">    return test_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    neg_pos_ratio = 3</span><br><span class="line">    # 包括背景的类别数目</span><br><span class="line">    num_class = 4</span><br><span class="line">    train_data = list(range(800))</span><br><span class="line">    validation_data = list(range(800, 900))</span><br><span class="line">    test_data = range(900, 1000)</span><br><span class="line">    epochs = 50</span><br><span class="line">    batch_size = 8</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    classes = ["circle", "triangle", "square"]</span><br><span class="line">    # 每个特征图上每个像素先验框的个数</span><br><span class="line">    prior = [2, 2, 2]</span><br><span class="line">    # 特征图的大小</span><br><span class="line">    feature_map = [32, 16, 8]</span><br><span class="line">    # anchor的长宽</span><br><span class="line">    anchors = [[(4, 4), (8, 8)], [(16, 16), (24, 24)], [(36, 36), (64, 64)]]</span><br><span class="line">    # 先验框的个数</span><br><span class="line">    num_prior = sum([prior[x] * feature_map[x] ** 2 for x in range(len(prior))])</span><br><span class="line">    # 获取所有先验框</span><br><span class="line">    prior_center_wh = []</span><br><span class="line">    prior_lt_rb = []</span><br><span class="line">    feature_shape = []</span><br><span class="line">    for i in range(len(prior)):</span><br><span class="line">        c_wh, tl_br = get_prior(i + 1)</span><br><span class="line">        prior_center_wh.append(c_wh)</span><br><span class="line">        prior_lt_rb.append(tl_br)</span><br><span class="line">        feature_shape.append(np.broadcast_to(feature_map[i], (feature_map[i] ** 2 * prior[i], 2)))</span><br><span class="line">    # 1008 * 4</span><br><span class="line">    prior_center_wh = np.vstack(prior_center_wh)</span><br><span class="line">    # 1008 * 4</span><br><span class="line">    prior_lt_rb = np.vstack(prior_lt_rb)</span><br><span class="line">    # 1008 * 2</span><br><span class="line">    feature_shape = np.vstack(feature_shape)</span><br><span class="line">    # IOU超过0.5的视为正样本</span><br><span class="line">    overlap_threshold = 0.3</span><br><span class="line">    # 编码函数</span><br><span class="line">    f_encode = encoder</span><br><span class="line">    # 画框设置不同的颜色</span><br><span class="line">    hsv_tuples = [(x / (num_class - 1), 1., 1.) for x in range(num_class - 1)]</span><br><span class="line">    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))</span><br><span class="line">    colors = list(map(lambda x: (int(x[1] * 255), int(x[2] * 255), int(x[0] * 255)), colors))</span><br><span class="line">    # 设置图像检测最多的框数目</span><br><span class="line">    keep_top_k = 5</span><br><span class="line">    # 设置检测置信度，大于该值认为有物体</span><br><span class="line">    confidence_threshold = 0.5</span><br><span class="line">    # 非极大值抑制阈值，重叠度不得大于该值</span><br><span class="line">    nms_thresh = 0.5</span><br><span class="line">    # 预测框不要紧贴物体，向外扩展像素大小</span><br><span class="line">    expand = 5</span><br><span class="line">    # 标签大小</span><br><span class="line">    label_size = 0.3</span><br><span class="line"></span><br><span class="line">    imgs_path = r'.\shape\train_imgs'</span><br><span class="line">    annotations_path = r'.\shape\annotations'</span><br><span class="line">    test_path = r'.\shape\test_imgs'</span><br><span class="line">    save_path = r'.\Yolo_V3_test_result'</span><br><span class="line">    weight_path = r'.\Yolo_V3_weight'</span><br><span class="line">    bbox_path = r'.\shape\bbox.txt'</span><br><span class="line"></span><br><span class="line">    # 将xml存储的bbox转换为bbox.txt文件，内容为file_path + bbox + class_id</span><br><span class="line">    if 'bbox.txt' not in os.listdir(r'.\shape'):</span><br><span class="line">        get_bbox(train_data + validation_data, bbox_path, annotations_path)</span><br><span class="line"></span><br><span class="line">    with open(bbox_path, 'r') as f:</span><br><span class="line">        bounding_info = f.readlines()</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(save_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(save_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(weight_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(weight_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    model = small_yolo_v3(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(batch_size, img_size[0], img_size[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizor = keras.optimizers.Adam(lr=1e-4)</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizor, loss=compute_loss)</span><br><span class="line"></span><br><span class="line">    # 保存的方式，3世代保存一次</span><br><span class="line">    checkpoint_period = keras.callbacks.ModelCheckpoint(</span><br><span class="line">        weight_path + '\\' + 'ep{epoch:03d}-loss{loss:.3f}.h5',</span><br><span class="line">        monitor='loss',</span><br><span class="line">        save_weights_only=True,</span><br><span class="line">        save_best_only=True,</span><br><span class="line">        period=3</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 学习率下降的方式，val_loss3次不下降就下降学习率继续训练</span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor='loss',</span><br><span class="line">        factor=0.5,</span><br><span class="line">        patience=3,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor='loss',</span><br><span class="line">        min_delta=0,</span><br><span class="line">        patience=10,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model.fit_generator(generate_arrays_from_file(train_data, batch_size),</span><br><span class="line">                        steps_per_epoch=max(1, len(train_data) // batch_size),</span><br><span class="line">                        validation_data=generate_arrays_from_file(validation_data, batch_size),</span><br><span class="line">                        validation_steps=max(1, len(validation_data) // batch_size),</span><br><span class="line">                        epochs=epochs,</span><br><span class="line">                        callbacks=[checkpoint_period, reduce_lr, early_stopping])</span><br><span class="line"></span><br><span class="line">    for name in test_data:</span><br><span class="line">        test_img_path = test_path + '\\' + str(name) + '.jpg'</span><br><span class="line">        save_img_path = save_path + '\\' + str(name) + '.png'</span><br><span class="line">        test_img = detect_image(test_img_path)</span><br><span class="line">        cv.imwrite(save_img_path, test_img)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Object_detection/YOLO-V3_T.png" alt="YOLO-V3"></p>
<h1 id="YOLO-V3小结"><a href="#YOLO-V3小结" class="headerlink" title="YOLO-V3小结"></a><font size="5" color="red">YOLO-V3小结</font></h1><p>  YOLO-V3是一种简单的目标检测网络，从上图可以看出YOLO-V3模型的参数量有62M，由于其<strong>结构简单，效果稳定</strong>，因此很多场合仍然使用YOLO-V3作为目标检测算法。YOLO-V3作为一步法目标检测的元老级模型，是小伙伴们需要掌握的一个模型。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>目标检测网络</category>
      </categories>
  </entry>
  <entry>
    <title>BigGAN</title>
    <url>/2020/06/20/generative_adversarial%20BigGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">BigGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>BigGAN</strong>:于<strong>2019年</strong>发表于<strong>ICLR</strong>，<strong>被誉为史上最强GAN图像生成器，BigGAN为什么那么强，因为引入了大量的黑科技，目前GitHub上面都是基于Pytorch的实现，而且代码特别繁琐，这里向小伙伴们介绍我的TensorFlow2.0简易版实现</strong>。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/biggan.png" alt="biggan"></p>
<h1 id="BigGAN的特点"><a href="#BigGAN的特点" class="headerlink" title="BigGAN的特点"></a><font size="5" color="red">BigGAN的特点</font></h1><p>  <font size="3"><strong>BigGAN可以认为SNGAN和SAGAN的结合，为了解决WGAN中的1-Lipshcitz问题，BigGAN在生成器和判别器中都借鉴了SNGAN中的Spectral Normalization(频谱归一化)的思想，而且借鉴了SAGAN的Self-Attention(注意力机制)</strong>。</font><br>  <font size="3"><strong>Truncation Trick(截断技巧)，将噪声向量进行截断，可以提高样本的质量，但是降低了样本的多样性</strong>。</font><br>  <font size="3"><strong>Orthogonal Regularization(正交正则化)，可以降低权重系数之间的干扰</strong>。</font><br>  <font size="3"><strong>Class-Conditional-BatchNorm(类条件批归一化)，在归一化时引入分类信息，可以生成指定类型的图像</strong>。</font><br>  <font size="3"><strong>Hierarchical latent spaces(分层潜在空间)，输入噪声分布在网络的各个层，并不只作用于第一层</strong>。</font><br>  <font size="3"><strong>使用了ResNet网络结构，其中有输入和输出尺寸相同的Resblock层，输入尺寸宽高缩小两倍的Resblock_down层和输入尺寸宽高增大两倍的Resblock_up层</strong>。</font><br>  <font size="3"><strong>batch大，参数量大，训练时间长，在这里我只展示网络结构和一些细节，训练过程我就跳过了</strong>。</font></p>
<h1 id="128x128网络结构"><a href="#128x128网络结构" class="headerlink" title="128x128网络结构"></a><font size="5" color="red">128x128网络结构</font></h1><p><img src="/images/Generative_adversarial/biggan_S.png" alt="BigGAN"></p>
<h1 id="BigGAN图像分析"><a href="#BigGAN图像分析" class="headerlink" title="BigGAN图像分析"></a><font size="5" color="red">BigGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/BigGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/BigGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">try:</span><br><span class="line">    import tensorflow.python.keras as keras</span><br><span class="line">except:</span><br><span class="line">    import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def orthogonal_regularizer(scale):</span><br><span class="line"></span><br><span class="line">    def ortho_reg(w):</span><br><span class="line">        shape = w.get_shape().as_list()</span><br><span class="line">        c = shape[-1]</span><br><span class="line"></span><br><span class="line">        w = tf.reshape(w, [-1, c])</span><br><span class="line"></span><br><span class="line">        identity = tf.eye(c)</span><br><span class="line"></span><br><span class="line">        w_transpose = tf.transpose(w)</span><br><span class="line">        w_mul = tf.matmul(w_transpose, w)</span><br><span class="line">        reg = tf.subtract(w_mul, identity)</span><br><span class="line"></span><br><span class="line">        ortho_loss = tf.nn.l2_loss(reg)</span><br><span class="line"></span><br><span class="line">        return scale * ortho_loss</span><br><span class="line"></span><br><span class="line">    return ortho_reg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def orthogonal_regularizer_fully(scale):</span><br><span class="line"></span><br><span class="line">    def ortho_reg_fully(w):</span><br><span class="line">        _, c = w.get_shape().as_list()</span><br><span class="line"></span><br><span class="line">        identity = tf.eye(c)</span><br><span class="line">        w_transpose = tf.transpose(w)</span><br><span class="line">        w_mul = tf.matmul(w_transpose, w)</span><br><span class="line">        reg = tf.subtract(w_mul, identity)</span><br><span class="line"></span><br><span class="line">        ortho_loss = tf.nn.l2_loss(reg)</span><br><span class="line"></span><br><span class="line">        return scale * ortho_loss</span><br><span class="line"></span><br><span class="line">    return ortho_reg_fully</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SpectralNorm(keras.layers.Layer):</span><br><span class="line">    def __init__(self, iteration=1, **kwargs):</span><br><span class="line">        super(SpectralNorm, self).__init__(**kwargs, dynamic=True)</span><br><span class="line">        self.iteration = iteration</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.u = self.add_variable(shape=[1, input_shape[-1]],</span><br><span class="line">                                   initializer=tf.initializers.TruncatedNormal(1.),</span><br><span class="line">                                   trainable=False)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        shape = tf.shape(inputs)</span><br><span class="line">        w = tf.reshape(inputs, shape=[-1, shape[-1]])</span><br><span class="line">        u_hat = self.u</span><br><span class="line">        for i in range(self.iteration):</span><br><span class="line">            v_hat = tf.nn.l2_normalize(tf.matmul(u_hat, tf.transpose(w)))</span><br><span class="line">            u_hat = tf.nn.l2_normalize(tf.matmul(v_hat, w))</span><br><span class="line"></span><br><span class="line">        u_hat = tf.stop_gradient(u_hat)</span><br><span class="line">        v_hat = tf.stop_gradient(v_hat)</span><br><span class="line"></span><br><span class="line">        sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))</span><br><span class="line">        with tf.control_dependencies([self.u.assign(u_hat)]):</span><br><span class="line">            w_norm = w / sigma</span><br><span class="line">            w_norm = tf.reshape(w_norm, inputs.get_shape())</span><br><span class="line">        return w_norm</span><br><span class="line"></span><br><span class="line">    def compute_output_shape(self, input_shape):</span><br><span class="line"></span><br><span class="line">        return input_shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ClassConditionalBatchNorm(keras.layers.Layer):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(ClassConditionalBatchNorm, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.beta_dense = keras.layers.Dense(units=input_shape[0][-1])</span><br><span class="line">        self.gamma_dense = keras.layers.Dense(units=input_shape[0][-1])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, is_training=True):</span><br><span class="line"></span><br><span class="line">        x, condition = inputs</span><br><span class="line">        #</span><br><span class="line">        split = keras.layers.Flatten()(condition)</span><br><span class="line">        beta = self.beta_dense(split)</span><br><span class="line">        gamma = self.gamma_dense(split)</span><br><span class="line"></span><br><span class="line">        beta = tf.reshape(beta, shape=[-1, 1, 1, x.shape[-1]])</span><br><span class="line">        gamma = tf.reshape(gamma, shape=[-1, 1, 1, x.shape[-1]])</span><br><span class="line"></span><br><span class="line">        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], keepdims=True)</span><br><span class="line"></span><br><span class="line">        return (x - batch_mean) / batch_var * gamma + beta</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyConv(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(MyConv, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.filters = filters</span><br><span class="line">        self.kernel_size = kernel_size</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.padding = padding</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.w = self.add_weight(name='kernel',</span><br><span class="line">                                 shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),</span><br><span class="line">                                 initializer=weight_init, regularizer=weight_regularizer)</span><br><span class="line">        self.b = self.add_weight(name='bias', shape=(self.filters,), initializer=keras.initializers.Zeros())</span><br><span class="line"></span><br><span class="line">        if self._name.find('sn') != -1:</span><br><span class="line">            self.u = self.add_weight(shape=[1, self.w.shape[-1]], initializer=tf.initializers.TruncatedNormal(1.))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        if self._name.find('sn') != -1:</span><br><span class="line">            shape = tf.shape(self.w)</span><br><span class="line">            w = tf.reshape(self.w, shape=[-1, shape[-1]])</span><br><span class="line">            u_hat = self.u</span><br><span class="line">            for i in range(1):</span><br><span class="line">                v_hat = tf.nn.l2_normalize(tf.matmul(u_hat, tf.transpose(w)))</span><br><span class="line">                u_hat = tf.nn.l2_normalize(tf.matmul(v_hat, w))</span><br><span class="line"></span><br><span class="line">            sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))</span><br><span class="line"></span><br><span class="line">            with tf.control_dependencies([self.u.assign(u_hat)]):</span><br><span class="line">                w_norm = w / sigma</span><br><span class="line">                w_norm = tf.reshape(w_norm, self.w.get_shape())</span><br><span class="line"></span><br><span class="line">            return tf.nn.bias_add(tf.nn.conv2d(inputs, w_norm, (1, self.strides, self.strides, 1), self.padding), self.b)</span><br><span class="line"></span><br><span class="line">        return tf.nn.bias_add(tf.nn.conv2d(inputs, self.w, (1, self.strides, self.strides, 1), self.padding), self.b)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyDense(keras.layers.Layer):</span><br><span class="line">    def __init__(self, units, name):</span><br><span class="line">        super(MyDense, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.units = units</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.w = self.add_weight(name='kernel', shape=(input_shape[-1], self.units),</span><br><span class="line">                                 initializer=weight_init, regularizer=weight_regularizer_fully)</span><br><span class="line">        self.b = self.add_weight(name='bias', shape=(self.units,), initializer=keras.initializers.Zeros())</span><br><span class="line"></span><br><span class="line">        if self._name.find('sn') != -1:</span><br><span class="line">            self.u = self.add_weight(shape=[1, self.w.shape[-1]], initializer=tf.initializers.TruncatedNormal(1.))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        if self._name.find('sn') != -1:</span><br><span class="line">            shape = tf.shape(self.w)</span><br><span class="line">            w = tf.reshape(self.w, shape=[-1, shape[-1]])</span><br><span class="line">            u_hat = self.u</span><br><span class="line">            for i in range(1):</span><br><span class="line">                v_hat = tf.nn.l2_normalize(tf.matmul(u_hat, tf.transpose(w)))</span><br><span class="line">                u_hat = tf.nn.l2_normalize(tf.matmul(v_hat, w))</span><br><span class="line"></span><br><span class="line">            sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))</span><br><span class="line"></span><br><span class="line">            with tf.control_dependencies([self.u.assign(u_hat)]):</span><br><span class="line">                w_norm = w / sigma</span><br><span class="line">                w_norm = tf.reshape(w_norm, self.w.get_shape())</span><br><span class="line"></span><br><span class="line">            return tf.matmul(inputs, w_norm) + self.b</span><br><span class="line"></span><br><span class="line">        return tf.matmul(inputs, self.w) + self.b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Resblock(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, name):</span><br><span class="line">        super(Resblock, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([MyConv(filters, 3, 1, 'SAME', name='{}_part1_snconv1'.format(name)),</span><br><span class="line">                                       keras.layers.BatchNormalization(momentum=0.8, name='{}_bn1'.format(name)),</span><br><span class="line">                                       keras.layers.ReLU(name='{}_relu'.format(name)),</span><br><span class="line">                                       MyConv(filters, 3, 1, 'SAME', name='{}_part1_snconv2'.format(name)),</span><br><span class="line">                                       keras.layers.BatchNormalization(momentum=0.8, name='{}_bn2'.format(name))])</span><br><span class="line">        self.add = keras.layers.Add(name='{}_add'.format(name))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        x = self.block(inputs)</span><br><span class="line">        output = self.add([x, inputs])</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Resblock_Down(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, name):</span><br><span class="line">        super(Resblock_Down, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block1 = keras.Sequential([keras.layers.ReLU(name='{}_part1_relu1'.format(name)),</span><br><span class="line">                                        MyConv(filters, 3, 1, 'SAME', name='{}_part1_snconv1'.format(name)),</span><br><span class="line">                                        keras.layers.ReLU(name='{}_part1_relu2'.format(name)),</span><br><span class="line">                                        MyConv(filters, 3, 1, 'SAME', name='{}_part1_snconv2'.format(name)),</span><br><span class="line">                                        keras.layers.AveragePooling2D((2, 2), name='{}_part1_averagepool'.format(name))])</span><br><span class="line"></span><br><span class="line">        self.block2 = keras.Sequential([MyConv(filters, 1, 1, 'SAME', name='{}_part2_snconv'.format(name)),</span><br><span class="line">                                        keras.layers.AveragePooling2D((2, 2), name='{}_part2_averagepool'.format(name))])</span><br><span class="line"></span><br><span class="line">        self.add = keras.layers.Add(name='{}_add'.format(name))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        x1 = self.block1(inputs)</span><br><span class="line">        x2 = self.block2(inputs)</span><br><span class="line">        output = self.add([x1, x2])</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Resblock_Up(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, name):</span><br><span class="line">        super(Resblock_Up, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.cbn1 = ClassConditionalBatchNorm(name='{}_part1_cbn1'.format(name))</span><br><span class="line">        self.cbn2 = ClassConditionalBatchNorm(name='{}_part1_cbn2'.format(name))</span><br><span class="line">        self.block1_1 = keras.Sequential([keras.layers.ReLU(name='{}_part1_relu1'.format(name)),</span><br><span class="line">                                          keras.layers.UpSampling2D((2, 2), name='{}_part1_upsampling'.format(name)),</span><br><span class="line">                                          MyConv(filters, 3, 1, 'SAME', name='{}_part1_snconv1'.format(name))])</span><br><span class="line"></span><br><span class="line">        self.block1_2 = keras.Sequential([keras.layers.ReLU(name='{}_part1_relu2'.format(name)),</span><br><span class="line">                                          MyConv(filters, 3, 1, 'SAME', name='{}_part1_snconv2'.format(name))])</span><br><span class="line"></span><br><span class="line">        self.block2 = keras.Sequential([keras.layers.UpSampling2D((2, 2), name='{}_part2_upsampling'.format(name)),</span><br><span class="line">                                        MyConv(filters, 1, 1, 'SAME', name='{}_part2_snconv1'.format(name))])</span><br><span class="line"></span><br><span class="line">        self.add = keras.layers.Add(name='{}_add'.format(name))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        x, z = inputs</span><br><span class="line">        x1 = self.cbn1([x, z])</span><br><span class="line">        x1 = self.block1_1(x1)</span><br><span class="line">        x1 = self.cbn2([x1, z])</span><br><span class="line">        x1 = self.block1_2(x1)</span><br><span class="line">        x2 = self.block2(x)</span><br><span class="line">        output = self.add([x1, x2])</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SAblock(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, name):</span><br><span class="line">        super(SAblock, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.theta = MyConv(filters // 8, 1, 1, 'SAME', name='{}_theta'.format(name))</span><br><span class="line">        self.phi = MyConv(filters // 8, 1, 1, 'SAME', name='{}_phi'.format(name))</span><br><span class="line">        self.g = MyConv(filters, 1, 1, 'SAME', name='{}_g'.format(name))</span><br><span class="line">        self.o = MyConv(filters, 1, 1, 'SAME', name='{}_conv4'.format(name))</span><br><span class="line">        self.gamma = tf.Variable([0.])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        theta = self.theta(inputs)</span><br><span class="line">        theta = tf.reshape(theta, (-1, theta.shape[1] * theta.shape[2], theta.shape[-1]), name='{}_theta_reshape'.format(self._name))</span><br><span class="line">        phi = self.phi(inputs)</span><br><span class="line">        phi = tf.reshape(phi, (-1, phi.shape[1] * phi.shape[2], phi.shape[-1]), name='{}_phi_reshape'.format(self._name))</span><br><span class="line">        g = self.g(inputs)</span><br><span class="line">        g = tf.reshape(g, (-1, g.shape[1] * g.shape[2], g.shape[-1]), name='{}_g_reshape'.format(self._name))</span><br><span class="line">        theta_phi = tf.matmul(theta, phi, transpose_b=True, name='{}_theta_dot_phi'.format(self._name))</span><br><span class="line">        theta_phi = tf.nn.softmax(theta_phi, name='{}_softmax'.format(self.name))</span><br><span class="line">        theta_phi_g = tf.matmul(theta_phi, g, name='{}_theta_phi_dot_g'.format(self._name))</span><br><span class="line">        theta_phi_g = tf.reshape(theta_phi_g, shape=(-1, inputs.shape[1], inputs.shape[2], inputs.shape[3]), name='{}_theta_phi_g_reshape'.format(self._name))</span><br><span class="line">        o = self.o(theta_phi_g)</span><br><span class="line"></span><br><span class="line">        return o * self.gamma + inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape_noise, input_shape_label):</span><br><span class="line">    input_tensor_noise = keras.layers.Input(input_shape_noise, name='input_noise')</span><br><span class="line">    input_tensor_label = keras.layers.Input(input_shape_label, name='input_label')</span><br><span class="line"></span><br><span class="line">    embedding_tensor = compose(keras.layers.Embedding(1000, 120, name='embedding'),</span><br><span class="line">                               keras.layers.Flatten(name='flatten'))(input_tensor_label)</span><br><span class="line"></span><br><span class="line">    noise_split = tf.split(input_tensor_noise, 6, -1, name='split')</span><br><span class="line">    for i in range(1, 6):</span><br><span class="line">        noise_split[i] = keras.layers.Concatenate(name='concatenate{}'.format(i + 1))([noise_split[i], embedding_tensor])</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(1024 * 16, activation='relu', name='dense_relu'),</span><br><span class="line">                keras.layers.Reshape((4, 4, 1024), name='reshape'))(noise_split[0])</span><br><span class="line">    x = Resblock_Up(1024, name='resblockup1')([x, noise_split[1]])</span><br><span class="line">    x = Resblock_Up(512, name='resblockup2')([x, noise_split[2]])</span><br><span class="line">    x = Resblock_Up(256, name='resblockup3')([x, noise_split[3]])</span><br><span class="line">    x = Resblock_Up(128, name='resblockup4')([x, noise_split[4]])</span><br><span class="line">    x = SAblock(128, name='sablock')(x)</span><br><span class="line">    x = Resblock_Up(64, name='resblockup5')([x, noise_split[5]])</span><br><span class="line">    x = compose(keras.layers.BatchNormalization(momentum=0.8, name='bn'),</span><br><span class="line">                keras.layers.ReLU(name='relu'),</span><br><span class="line">                MyConv(3, 3, 1, 'SAME', name='conv'),</span><br><span class="line">                keras.layers.Activation('tanh', name='tanh'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([input_tensor_noise, input_tensor_label], x, name='BigGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape_image, input_shape_label):</span><br><span class="line">    input_tensor_image = keras.layers.Input(input_shape_image, name='input_image')</span><br><span class="line">    input_tensor_label = keras.layers.Input(input_shape_label, name='input_label')</span><br><span class="line"></span><br><span class="line">    x = compose(Resblock_Down(64, name='resblockdown1'),</span><br><span class="line">                SAblock(64, name='sablock'),</span><br><span class="line">                Resblock_Down(128, name='resblockdown2'),</span><br><span class="line">                Resblock_Down(256, name='resblockdown3'),</span><br><span class="line">                Resblock_Down(512, name='resblockdown4'),</span><br><span class="line">                Resblock_Down(1024, name='resblockdown5'),</span><br><span class="line">                Resblock(1024, name='resblock6'))(input_tensor_image)</span><br><span class="line"></span><br><span class="line">    x = tf.reduce_sum(x, axis=[1, 2], name='global_sumpool')</span><br><span class="line">    output_tensor = keras.layers.Dense(1, name='dense')(x)</span><br><span class="line"></span><br><span class="line">    embedding_tensor = compose(keras.layers.Embedding(1000, 1024, name='embedding'),</span><br><span class="line">                               keras.layers.Flatten(name='flatten'))(input_tensor_label)</span><br><span class="line">    output_tensor = output_tensor + tf.reduce_sum(embedding_tensor * x, 1, keepdims=True, name='reduce_sum')</span><br><span class="line"></span><br><span class="line">    model = keras.Model([input_tensor_image, input_tensor_label], output_tensor, name='BigGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def biggan(input_shape_noise, input_shape_image, input_shape_label, model_g, model_d):</span><br><span class="line">    input_noise = keras.layers.Input(input_shape_noise, name='input_noise')</span><br><span class="line">    input_real_image = keras.layers.Input(input_shape_image, name='input_image')</span><br><span class="line">    input_label = keras.layers.Input(input_shape_label, name='input_label')</span><br><span class="line"></span><br><span class="line">    model_g.trainable = False</span><br><span class="line">    fake = model_g([input_noise, input_label])</span><br><span class="line">    real_conf = model_d([input_real_image, input_label])</span><br><span class="line">    fake_conf = model_d([fake, input_label])</span><br><span class="line"></span><br><span class="line">    model_discriminator = keras.Model([input_noise, input_real_image, input_label], [real_conf, fake_conf], name='BigGAN-discriminator')</span><br><span class="line">    model_discriminator.compile(optimizer=optimizer_d, loss=[d_loss, d_loss], loss_weights=[1, 1])</span><br><span class="line"></span><br><span class="line">    model_g.trainable = True</span><br><span class="line">    model_d.trainable = False</span><br><span class="line"></span><br><span class="line">    model_generator = keras.Model([input_noise, input_label], fake_conf, name='BigGAN-generator')</span><br><span class="line">    model_generator.compile(optimizer=optimizer_g, loss=g_loss)</span><br><span class="line"></span><br><span class="line">    return model_generator, model_discriminator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def d_loss(y_true, y_pred):</span><br><span class="line"></span><br><span class="line">    return tf.reduce_mean(tf.nn.relu(1 - y_true * y_pred))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def g_loss(y_true, y_pred):</span><br><span class="line"></span><br><span class="line">    return -tf.reduce_mean(y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    weight_init = tf.initializers.TruncatedNormal(mean=0.0, stddev=0.02)</span><br><span class="line">    weight_regularizer = orthogonal_regularizer(0.0001)</span><br><span class="line">    weight_regularizer_fully = orthogonal_regularizer_fully(0.0001)</span><br><span class="line"></span><br><span class="line">    optimizer_g = keras.optimizers.Adam(0.00005, 0, 0.999, epsilon=1e-5)</span><br><span class="line">    optimizer_d = keras.optimizers.Adam(0.0002, 0, 0.999, epsilon=1e-5)</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape_image=(128, 128, 3), input_shape_label=(1,))</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape_noise=(120,), input_shape_label=(1,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=[(120,), (1,)])</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'BigGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=[(128, 128, 3), (1,)])</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'BigGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_generator, model_discriminator = biggan(input_shape_noise=(120,), input_shape_image=(128, 128, 3), input_shape_label=(1,), model_g=model_g, model_d=model_d)</span><br><span class="line"></span><br><span class="line">    model_generator.build(input_shape=[(120,), (1,)])</span><br><span class="line">    model_generator.summary()</span><br><span class="line">    keras.utils.plot_model(model_generator, 'BigGAN-generate.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_discriminator.build(input_shape=[(120,), (128, 128, 3), (1,)])</span><br><span class="line">    model_discriminator.summary()</span><br><span class="line">    keras.utils.plot_model(model_discriminator, 'BigGAN-discriminate.png', show_shapes=True, show_layer_names=True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/biggan_R.png" alt="biggan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/biggan_T.png" alt="biggan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>BigGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li>代码中正交正则化使用了闭包的概念，有关闭包的使用，可以参考我的另一篇博客，Closure &amp; Decorators(闭包和装饰器)</li>
<li><strong>这个模型效果太好，生成的图片甚至比真实图片还要好，一些纹理，背景细节都可以完美呈现，但是想自己实现训练过程，非常困难，因此建议小伙伴了解就可以，不用亲自实践</strong>。</li>
</ol>
<h1 id="BigGAN小结"><a href="#BigGAN小结" class="headerlink" title="BigGAN小结"></a><font size="5" color="red">BigGAN小结</font></h1><p>  <strong>BigGAN分为很多版本，有128的图像版本，256的图像版本和512的图像版本，具体模型结构都很类似，但是参数量指数级增长</strong>。这是最小的BigGAN版本，<strong>参数量都可以达到80M，虽然VGG16的参数量有一亿多，但是网络结构简单，因此训练反而快，而BigGAN含有很多细节操作，会花费较长的时间，因此训练起来非常慢</strong>，BigGAN不是单打独斗，在特点中已经分析了，可以看成<strong>SNGAN和SAGAN的共同作品</strong>，因此关于其中的数学推导可以参考网络的其他资源，在这里也不过多赘述，作为史上最强的GAN图像生成器，小伙伴们一定要了解它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>最佳观光组合(Leetcode 1014)</title>
    <url>/2020/06/17/program%20Leetcode1014/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1014.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这题思路明显，但是并不简单，暴力法没有难度，但是无法通过所有样例，要寻找一种时间复杂度为O(n)的算法解题。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>暴力法可以根据题目中给出的公式进行直接求解，<strong>遍历所有的景点对，两层循环，时间复杂度为$O(n^2)$，空间复杂度为$O(1)$，在这里给出了一种更加Pythonic的写法，一行代码实现</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxScoreSightseeingPair(self, A):</span><br><span class="line">        """</span><br><span class="line">        :type A: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        return max([A[i] + A[j] + i - j for i in range(len(A)) for j in range(i + 1, len(A))])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a><font size="5" color="red">动态规划</font></h1><p>上面的暴力法虽然简单，容易想到，但是无法通过所有样例，因此我们需要降低时间复杂度，发现在比较中浪费了大量的计算资源，每一个点都需要比较n次，所以时间复杂度为$O(n^2)$，可不可以记录之前的状态，每个点比较一次呢？我们发现<strong>公式可以分为两个部分，一部分是A[i] + i，另一部分是A[j] - j，最终将两部分相加即可。可以推出状态转移方程</strong>。</p>
<script type="math/tex; mode=display">\begin{case} F = max(F, P + A[i] - i) \\ P = max(P, A[i] + i) \end{case}</script><p><strong>F为最佳观光组合，P为选择当前第i个点时，在i之前的所有点的最优选择，即上面的第一部分，记录A[i] + [i]的最大值为P，然后遍历所有点一次即可</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def maxScoreSightseeingPair(self, A):</span><br><span class="line">        """</span><br><span class="line">        :type A: List[int]</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        pre_val = A[0]</span><br><span class="line">        res = 0</span><br><span class="line">        for i in range(1, len(A)):</span><br><span class="line">            res = max(res, pre_val + A[i] - i)</span><br><span class="line">            pre_val = max(pre_val, A[i] + i)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  思路简单的题目一般都会有更巧妙的解法，<strong>对于数学问题，可能利用数学公式推出巧妙解，这个难度太大，或者是利用单调栈进行求解，或者利用动态规划进行求解</strong>。数学问题一般描述简单，难度适中，适合面试考察，因此小伙伴们尤其要注意。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>动态规划</category>
        <category>数组</category>
      </categories>
  </entry>
  <entry>
    <title>每日温度(Leetcode 739)</title>
    <url>/2020/06/15/program%20Leetcode739/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode739.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   题意很简单，找出比当前数字大的下一个数字的距离，是不是可以按照我们的想法来解题呢？遍历每一个元素，找出比它大的下一个元素的位置。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>最直观的想法，从第一个元素开始遍历，对每一个元素遍历它后面的所有元素，如果找到比它大的数字，则索引相减并break，从下一个元素开始寻找，否则置为0。暴力法的时间复杂度为$O(n^2)$，空间复杂度为$O(n)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def dailyTemperatures(self, T):</span><br><span class="line">        """</span><br><span class="line">        :type T: List[int]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        lens = len(T)</span><br><span class="line">        res = [0] * lens</span><br><span class="line">        for i in range(lens):</span><br><span class="line">            for j in range(i + 1, lens):</span><br><span class="line">                if T[j] &gt; T[i]:</span><br><span class="line">                    res[i] = j - i</span><br><span class="line">                    break</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化暴力法"><a href="#优化暴力法" class="headerlink" title="优化暴力法"></a><font size="5" color="red">优化暴力法</font></h1><p>暴力法虽然可以求解，但是无法通过，因为时间复杂度太高，我们观察到题目中的信息，温度的范围在[30, 100]之间，因此我们对于每一个数，找后面比它大的数，哪个出现的最早即可。以题目的示例，第一个数为73，那么只需要寻找74到100，看哪一个数出现的最早即可。从后向前计算，并且用字典记录当前值出现的索引，这样寻找时直接查找是否存在于字典中，不需要遍历，因此可以将暴力法的第二层循环从n次查找变为最多100次的字典查找，时间复杂度为$O(mn)$，其中m最大为100，空间复杂度为$O(n)$，官方题解中有Pythonic的写法，在此我就不献丑了。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def dailyTemperatures(self, T):</span><br><span class="line">        """</span><br><span class="line">        :type T: List[int]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        n = len(T)</span><br><span class="line">        ans, nxt, big = [0] * n, dict(), 10**9</span><br><span class="line">        for i in range(n - 1, -1, -1):</span><br><span class="line">            print(i)</span><br><span class="line">            warmer_index = min(nxt.get(t, big) for t in range(T[i] + 1, 102))</span><br><span class="line">            if warmer_index != big:</span><br><span class="line">                ans[i] = warmer_index - i</span><br><span class="line">            nxt[T[i]] = i</span><br><span class="line">        return ans</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a><font size="5" color="red">单调栈</font></h1><p>这道题遍历法肯定不是最优的解法，单调栈是这类问题的最优解，下面我用图示说明如何使用单调栈求解这个问题。<br><img src="/images/ALGORITHM/leetcode739_stack.png" alt="stack"><br>单调栈的时间复杂度为$O(n)$，空间复杂度为$O(n)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def dailyTemperatures(self, T):</span><br><span class="line">        """</span><br><span class="line">        :type T: List[int]</span><br><span class="line">        :rtype: List[int]</span><br><span class="line">        """</span><br><span class="line">        lens = len(T)</span><br><span class="line">        stack = []</span><br><span class="line">        res = [0] * lens</span><br><span class="line">        for i, v in enumerate(T):</span><br><span class="line">            while stack and T[stack[-1]] &lt; v:</span><br><span class="line">                tmp_i = stack.pop()</span><br><span class="line">                res[tmp_i] = i - tmp_i</span><br><span class="line">            stack.append(i)</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  单调栈算法时解决数字问题的常用算法，因为单调栈只需要遍历一次数组，因此非常高效，所以小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>单调栈/单调队列</category>
      </categories>
  </entry>
  <entry>
    <title>pix2pix</title>
    <url>/2020/06/14/generative_adversarial%20pix2pix/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">pix2pix</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>pix2pix</strong>:于<strong>2017年</strong>发表在<strong>CVPR</strong>上，可以实现图像的风格迁移，风格迁移是GAN网络提出后才出现在人们视野里面的图像处理算法，在生成式对抗网络问世之前，人们很难通过传统的图像处理算法实现风格迁移，今天带小伙伴们看一看瞧一瞧。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/pix2pix.png" alt="pix2pix"></p>
<h1 id="pix2pix的特点"><a href="#pix2pix的特点" class="headerlink" title="pix2pix的特点"></a><font size="5" color="red">pix2pix的特点</font></h1><p>  <font size="3"><strong>类似于半个DiscoGAN，只是从风格A转换到风格B，没有从风格B转换到风格A</strong>。</font><br>  <font size="3"><strong>网络结构也类似于DiscoGAN，使用了UNet结构</strong>。</font><br>  <font size="3"><strong>生成器损失函数采用绝对误差，判别器损失函数采用均方误差</strong>。</font><br>  <font size="3"><strong>对生成器损失函数的权重进行调节，使网络更多关注于生成的图像质量</strong>。</font></p>
<h1 id="pix2pix图像分析"><a href="#pix2pix图像分析" class="headerlink" title="pix2pix图像分析"></a><font size="5" color="red">pix2pix图像分析</font></h1><p><img src="/images/Generative_adversarial/pix2pix-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/pix2pix-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Relu_In(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Relu_In, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([keras.layers.Conv2D(filters, kernel_size, strides, padding),</span><br><span class="line">                                       keras.layers.LeakyReLU(0.2)])</span><br><span class="line">        if name.find('bn') != -1:</span><br><span class="line">            self.block.add(keras.layers.BatchNormalization(momentum=0.8))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Upsampling_Conv_Relu_In_Concatenate(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Upsampling_Conv_Relu_In_Concatenate, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([keras.layers.UpSampling2D((2, 2)),</span><br><span class="line">                                       keras.layers.Conv2D(filters, kernel_size, strides, padding, activation='relu'),</span><br><span class="line">                                       keras.layers.BatchNormalization(momentum=0.8)])</span><br><span class="line">        self.concatenate = keras.layers.Concatenate()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        x, shortcut = inputs</span><br><span class="line">        x = self.block(x)</span><br><span class="line">        output = self.concatenate([x, shortcut])</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape, name):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = Conv_Relu_In(64, (4, 4), (2, 2), 'same', name='conv_leakyrelu1')(x)</span><br><span class="line">    x2 = Conv_Relu_In(128, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn2')(x1)</span><br><span class="line">    x3 = Conv_Relu_In(256, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn3')(x2)</span><br><span class="line">    x4 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn4')(x3)</span><br><span class="line">    x5 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn5')(x4)</span><br><span class="line">    x6 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn6')(x5)</span><br><span class="line">    x7 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn7')(x6)</span><br><span class="line"></span><br><span class="line">    y6 = Upsampling_Conv_Relu_In_Concatenate(512, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_bn_concatenate1')([x7, x6])</span><br><span class="line">    y5 = Upsampling_Conv_Relu_In_Concatenate(512, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_bn_concatenate2')([y6, x5])</span><br><span class="line">    y4 = Upsampling_Conv_Relu_In_Concatenate(512, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_bn_concatenate3')([y5, x4])</span><br><span class="line">    y3 = Upsampling_Conv_Relu_In_Concatenate(256, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_bn_concatenate4')([y4, x3])</span><br><span class="line">    y2 = Upsampling_Conv_Relu_In_Concatenate(128, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_bn_concatenate5')([y3, x2])</span><br><span class="line">    y1 = Upsampling_Conv_Relu_In_Concatenate(64, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_bn_concatenate6')([y2, x1])</span><br><span class="line"></span><br><span class="line">    y = compose(keras.layers.UpSampling2D((2, 2), name='upsampling'),</span><br><span class="line">                keras.layers.Conv2D(3, (4, 4), (1, 1), 'same', activation='tanh', name='conv_tanh'))(y1)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, y, name=name)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape, name):</span><br><span class="line">    input_tensor1 = keras.layers.Input(input_shape, name='input1')</span><br><span class="line">    input_tensor2 = keras.layers.Input(input_shape, name='input2')</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='concatenate')([input_tensor1, input_tensor2])</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Relu_In(64, (4, 4), (2, 2), 'same', name='conv_leakyrelu1'),</span><br><span class="line">                Conv_Relu_In(128, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn2'),</span><br><span class="line">                Conv_Relu_In(256, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn3'),</span><br><span class="line">                Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_bn4'),</span><br><span class="line">                keras.layers.Conv2D(1, (4, 4), (1, 1), 'same', name='conv'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([input_tensor1, input_tensor2], x, name=name)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pix2pix(input_shapeA, input_shapeB, model_g, model_d):</span><br><span class="line">    input_tensorA = keras.layers.Input(input_shapeA, name='input_A')</span><br><span class="line">    input_tensorB = keras.layers.Input(input_shapeB, name='input_B')</span><br><span class="line"></span><br><span class="line">    # 输入风格B生成的风格A类型的图像</span><br><span class="line">    fake_A = model_g(input_tensorB)</span><br><span class="line"></span><br><span class="line">    model_d.trainable = False</span><br><span class="line"></span><br><span class="line">    conf_A = model_d([fake_A, input_tensorB])</span><br><span class="line"></span><br><span class="line">    model = keras.Model([input_tensorA, input_tensorB], [conf_A, fake_A], name='Pix2Pix')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_data(data_path, batch_size):</span><br><span class="line">    filename = glob.glob(data_path + '\\*.jpg')</span><br><span class="line">    choose_name = np.random.choice(filename, batch_size)</span><br><span class="line"></span><br><span class="line">    image_A, image_B = [], []</span><br><span class="line">    for i in range(batch_size):</span><br><span class="line">        image = cv.imread(choose_name[i]).astype(np.float32)</span><br><span class="line">        image_A.append(image[:, 256:, :])</span><br><span class="line">        image_B.append(image[:, :256, :])</span><br><span class="line"></span><br><span class="line">    image_A = np.array(image_A) / 127.5 - 1</span><br><span class="line">    image_B = np.array(image_B) / 127.5 - 1</span><br><span class="line"></span><br><span class="line">    return image_A, image_B</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    batch_size = 2</span><br><span class="line">    epochs = 2000</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (256, 256)</span><br><span class="line">    data_path = r'.\edges2shoes\train'</span><br><span class="line">    save_path = r'.\pix2pix'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    fake_dmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    gmse = keras.metrics.MeanSquaredError()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(img_size[0], img_size[1], 3), name='pix2pix-Discriminator')</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss='mse')</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(img_size[0], img_size[1], 3), name='pix2pix-Generator')</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'pix2pix-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'pix2pix-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = pix2pix(input_shapeA=(img_size[0], img_size[1], 3), input_shapeB=(img_size[0], img_size[1], 3), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['mse', 'mae'], loss_weights=[1, 100])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=[(img_size[0], img_size[1], 3), (img_size[0], img_size[1], 3)])</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'pix2pix.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        image_A, image_B = read_data(data_path, batch_size)</span><br><span class="line"></span><br><span class="line">        fake_A = model_g(image_B)</span><br><span class="line"></span><br><span class="line">        real_dmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_d([image_A, image_B]))</span><br><span class="line">        fake_dmse(np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_d([fake_A, image_B]))</span><br><span class="line">        gmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model([image_A, image_B])[0])</span><br><span class="line"></span><br><span class="line">        real_dloss = model_d.train_on_batch([image_A, image_B], np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        fake_dloss = model_d.train_on_batch([fake_A, image_B], np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line"></span><br><span class="line">        gloss = model.train_on_batch([image_A, image_B], [np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), image_A])</span><br><span class="line"></span><br><span class="line">        if epoch % 20 == 0:</span><br><span class="line">            print('epoch = {}, real_dmse = {}, fake_dmse = {}, gmse = {}'.format(epoch, real_dmse.result(), fake_dmse.result(), gmse.result()))</span><br><span class="line">            real_dmse.reset_states()</span><br><span class="line">            fake_dmse.reset_states()</span><br><span class="line">            gmse.reset_states()</span><br><span class="line">            image_A, image_B = read_data(data_path, batch_size=1)</span><br><span class="line">            fake_A = ((model_g(image_B).numpy().squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            image_A = ((image_A.squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            image_B = ((image_B.squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            cv.imwrite(save_path + '\\epoch{}.jpg'.format(epoch), np.concatenate([image_A, image_B, fake_A], axis=1))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/pix2pix_R.png" alt="pix2pix"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/pix2pix_T.png" alt="pix2pix"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>pix2pix对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li>在pix2pix的测试图像中，为了体现模型的效果，第一个图片为风格A的鞋子，第二个图片为风格B的鞋子，第三个图片为由风格B生成的风格A的鞋子，这里只是训练了2000代，而且每一代只有2个图像就可以看出pix2pix的效果。小伙伴们可以选择更大的数据集，更加快速的GPU，训练更长的时间，这样风格迁移的效果就会更加明显。</li>
</ol>
<h1 id="pix2pix小结"><a href="#pix2pix小结" class="headerlink" title="pix2pix小结"></a><font size="5" color="red">pix2pix小结</font></h1><p>  pix2pix是一种有效的风格迁移生成式对抗网络，网络结构，损失函数都和DiscoGAN几乎相同，但是DiscoGAN的生成器和判别器都是两个，可以实现AB风格的互换，而pix2pix只有一个生成器和判别器，因此只能完成风格的单向转换，因此参数量也是DiscoGAN的一半，从上图可以看出<strong>pix2pix模型的参数量只有43M</strong>，如果数据集足够，还可以生成人物表情包，是不是非常有趣呢？小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>DiscoGAN</title>
    <url>/2020/06/12/generative_adversarial%20DiscoGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">DiscoGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>DiscoGAN(Discover Cross-Domain Relations with Generative Adversarial Networks)</strong>:于<strong>2017年</strong>发表在<strong>ICML</strong>上，可以实现图像的风格迁移，风格迁移是GAN网络提出后才出现在人们视野里面的图像处理算法，在生成式对抗网络问世之前，人们很难通过传统的图像处理算法实现风格迁移，今天带小伙伴们看一看瞧一瞧。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/discogan.png" alt="discogan"></p>
<h1 id="DiscoGAN理论思想"><a href="#DiscoGAN理论思想" class="headerlink" title="DiscoGAN理论思想"></a><font size="5" color="red">DiscoGAN理论思想</font></h1><p>DiscoGAN引入了4个网络结构，分别是生成器GAB，生成器GBA，判别器DA，判别器DB。<br>GAB的输入是风格A的图像，输出是风格B的图像，目的是将风格A的图像转换为风格B的图像。<br>GBA的输入是风格B的图像，输出是风格A的图像，目的是将风格B的图像转换为风格A的图像。<br>DA的输入是风格A的图像，输出是对输入图像的分类，目的是判断输入图像是否为由B转换的风格A的图像<br>DB的输入是风格B的图像，输出是对输入图像的分类，目的是判断输入图像是否为由A转换的风格B的图像</p>
<p>其中的图像名称有很多，在这里进行简单的介绍。<br>image_A, image_B指数据集中读取的真实图像，使用DA和DB进行预测时，结果应该是全1。<br>fake_A指imge_B由GBA生成的风格A类型的图像，使用DA预测时，希望应该是全1，fake_B指imge_A由GAB生成的风格B类型的图像，使用DB预测时，希望应该是全1。<br>recon_A指fake_B由GBA生成风格A类型的图像，也就是原图image_A经过GAB，再经过GBA生成风格A的图像，希望和image_A越接近越好。<br>recon_B指fake_A由GAB生成风格B类型的图像，也就是原图image_B经过GBA，再经过GAB生成风格B的图像，希望和image_B越接近越好。</p>
<h1 id="DiscoGAN的特点"><a href="#DiscoGAN的特点" class="headerlink" title="DiscoGAN的特点"></a><font size="5" color="red">DiscoGAN的特点</font></h1><p>  <font size="3"><strong>使用InstanceNormalization代替BatchNormalization</strong>。</font><br>  <font size="3"><strong>生成器使用UNet网络结构对图像进行深层特征提取</strong>。</font><br>  <font size="3"><strong>生成器损失函数采用绝对误差，判别器损失函数采用均方误差</strong>。</font><br>  <font size="3"><strong>对生成器损失函数的权重进行调节，使网络更多关注于生成的图像质量</strong>。</font></p>
<h1 id="DiscoGAN图像分析"><a href="#DiscoGAN图像分析" class="headerlink" title="DiscoGAN图像分析"></a><font size="5" color="red">DiscoGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/DiscoGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/DiscoGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class InstanceNormalization(keras.layers.Layer):</span><br><span class="line">    def __init__(self, beta_initializer='zeros', gamma_initializer='ones',</span><br><span class="line">                 beta_regularizer=None, gamma_regularizer=None,</span><br><span class="line">                 beta_constraint=None, gamma_constraint=None, epsilon=1e-5,</span><br><span class="line">                 **kwargs):</span><br><span class="line">        super(InstanceNormalization, self).__init__(**kwargs)</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        self.beta_initializer = keras.initializers.get(beta_initializer)</span><br><span class="line">        self.gamma_initializer = keras.initializers.get(gamma_initializer)</span><br><span class="line">        self.beta_regularizer = keras.regularizers.get(beta_regularizer)</span><br><span class="line">        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)</span><br><span class="line">        self.beta_constraint = keras.constraints.get(beta_constraint)</span><br><span class="line">        self.gamma_constraint = keras.constraints.get(gamma_constraint)</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        assert len(input_shape) == 4</span><br><span class="line">        self.gamma = self.add_weight(shape=(input_shape[-1],), name='gamma', initializer=self.gamma_initializer,</span><br><span class="line">                                     regularizer=self.gamma_regularizer, constraint=self.gamma_constraint)</span><br><span class="line">        self.beta = self.add_weight(shape=(input_shape[-1],), name='beta', initializer=self.beta_initializer,</span><br><span class="line">                                    regularizer=self.beta_regularizer, constraint=self.beta_constraint)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, axes=[1, 2])</span><br><span class="line">        mean = tf.reshape(mean, shape=[-1, 1, 1, inputs.shape[-1]])</span><br><span class="line">        variance = tf.reshape(variance, shape=[-1, 1, 1, inputs.shape[-1]])</span><br><span class="line">        outputs = (inputs - mean) / tf.sqrt(variance + self.epsilon)</span><br><span class="line">        return outputs * self.gamma + self.beta</span><br><span class="line"></span><br><span class="line">    def get_config(self):</span><br><span class="line">        config = {</span><br><span class="line">            'epsilon': self.epsilon,</span><br><span class="line">            'beta_initializer': keras.initializers.serialize(self.beta_initializer),</span><br><span class="line">            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),</span><br><span class="line">            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),</span><br><span class="line">            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),</span><br><span class="line">            'beta_constraint': keras.constraints.serialize(self.beta_constraint),</span><br><span class="line">            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint)</span><br><span class="line">        }</span><br><span class="line">        base_config = super(InstanceNormalization, self).get_config()</span><br><span class="line"></span><br><span class="line">        return dict(list(base_config.items()) + list(config.items()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Relu_In(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Relu_In, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([keras.layers.Conv2D(filters, kernel_size, strides, padding),</span><br><span class="line">                                       keras.layers.LeakyReLU(0.2)])</span><br><span class="line">        if name.find('in') != -1:</span><br><span class="line">            self.block.add(InstanceNormalization())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Upsampling_Conv_Relu_In_Concatenate(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Upsampling_Conv_Relu_In_Concatenate, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([keras.layers.UpSampling2D((2, 2)),</span><br><span class="line">                                       keras.layers.Conv2D(filters, kernel_size, strides, padding, activation='relu'),</span><br><span class="line">                                       InstanceNormalization()])</span><br><span class="line">        self.concatenate = keras.layers.Concatenate()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        x, shortcut = inputs</span><br><span class="line">        x = self.block(x)</span><br><span class="line">        output = self.concatenate([x, shortcut])</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape, name):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = Conv_Relu_In(64, (4, 4), (2, 2), 'same', name='conv_leakyrelu1')(x)</span><br><span class="line">    x2 = Conv_Relu_In(128, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in2')(x1)</span><br><span class="line">    x3 = Conv_Relu_In(256, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in3')(x2)</span><br><span class="line">    x4 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in4')(x3)</span><br><span class="line">    x5 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in5')(x4)</span><br><span class="line">    x6 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in6')(x5)</span><br><span class="line">    x7 = Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in7')(x6)</span><br><span class="line"></span><br><span class="line">    y6 = Upsampling_Conv_Relu_In_Concatenate(512, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_in_concatenate1')([x7, x6])</span><br><span class="line">    y5 = Upsampling_Conv_Relu_In_Concatenate(512, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_in_concatenate2')([y6, x5])</span><br><span class="line">    y4 = Upsampling_Conv_Relu_In_Concatenate(512, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_in_concatenate3')([y5, x4])</span><br><span class="line">    y3 = Upsampling_Conv_Relu_In_Concatenate(256, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_in_concatenate4')([y4, x3])</span><br><span class="line">    y2 = Upsampling_Conv_Relu_In_Concatenate(128, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_in_concatenate5')([y3, x2])</span><br><span class="line">    y1 = Upsampling_Conv_Relu_In_Concatenate(64, (4, 4), (1, 1), 'same', name='upsampling_conv_relu_in_concatenate6')([y2, x1])</span><br><span class="line"></span><br><span class="line">    y = compose(keras.layers.UpSampling2D((2, 2), name='upsampling'),</span><br><span class="line">                keras.layers.Conv2D(3, (4, 4), (1, 1), 'same', activation='tanh', name='conv_tanh'))(y1)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, y, name=name)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape, name):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Relu_In(64, (4, 4), (2, 2), 'same', name='conv_leakyrelu1'),</span><br><span class="line">                Conv_Relu_In(128, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in2'),</span><br><span class="line">                Conv_Relu_In(256, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in3'),</span><br><span class="line">                Conv_Relu_In(512, (4, 4), (2, 2), 'same', name='conv_leakyrelu_in4'),</span><br><span class="line">                keras.layers.Conv2D(1, (4, 4), (1, 1), 'same', name='conv'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name=name)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discogan(input_shapeA, input_shapeB, model_gAB, model_gBA, model_dA, model_dB):</span><br><span class="line">    input_tensorA = keras.layers.Input(input_shapeA, name='input_A')</span><br><span class="line">    input_tensorB = keras.layers.Input(input_shapeB, name='input_B')</span><br><span class="line"></span><br><span class="line">    # 输入风格B由BA生成的风格A类型的图像和输入风格A由AB生成的风格B类型的图像，称为假A和假B</span><br><span class="line">    fake_A = model_gBA(input_tensorB)</span><br><span class="line">    fake_B = model_gAB(input_tensorA)</span><br><span class="line"></span><br><span class="line">    # 输入假风格B由BA生成的重建风格A和假风格A由AB生成的重建风格B，称为重建A和重建B</span><br><span class="line">    recon_A = model_gBA(fake_B)</span><br><span class="line">    recon_B = model_gAB(fake_A)</span><br><span class="line"></span><br><span class="line">    model_dA.trainable = False</span><br><span class="line">    model_dB.trainable = False</span><br><span class="line"></span><br><span class="line">    conf_A = model_dA(fake_A)</span><br><span class="line">    conf_B = model_dB(fake_B)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([input_tensorA, input_tensorB], [conf_A, conf_B, fake_A, fake_B, recon_A, recon_B], name='DiscoGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_data(data_path, img_size, batch_size):</span><br><span class="line">    filename = glob.glob(data_path + '\\*.jpg')</span><br><span class="line">    choose_name = np.random.choice(filename, batch_size)</span><br><span class="line"></span><br><span class="line">    image_A, image_B = [], []</span><br><span class="line">    for i in range(batch_size):</span><br><span class="line">        image = cv.imread(choose_name[i]).astype(np.float32)</span><br><span class="line">        image_A.append(cv.resize(image[:, 256:, :], img_size))</span><br><span class="line">        image_B.append(cv.resize(image[:, :256, :], img_size))</span><br><span class="line"></span><br><span class="line">    image_A = np.array(image_A) / 127.5 - 1</span><br><span class="line">    image_B = np.array(image_B) / 127.5 - 1</span><br><span class="line"></span><br><span class="line">    return image_A, image_B</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    batch_size = 2</span><br><span class="line">    epochs = 2000</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    data_path = r'.\edges2shoes\train'</span><br><span class="line">    save_path = r'.\discogan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dAmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    fake_dAmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    real_dBmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    fake_dBmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    gAmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    gBmse = keras.metrics.MeanSquaredError()</span><br><span class="line"></span><br><span class="line">    model_dA = discriminator(input_shape=(img_size[0], img_size[1], 3), name='DiscoGAN-DiscriminatorA')</span><br><span class="line">    model_dA.compile(optimizer=optimizer, loss='mse')</span><br><span class="line">    model_dB = discriminator(input_shape=(img_size[0], img_size[1], 3), name='DiscoGAN-DiscriminatorB')</span><br><span class="line">    model_dB.compile(optimizer=optimizer, loss='mse')</span><br><span class="line"></span><br><span class="line">    model_gAB = generator(input_shape=(img_size[0], img_size[1], 3), name='DiscoGAN-GeneratorAB')</span><br><span class="line">    model_gBA = generator(input_shape=(img_size[0], img_size[1], 3), name='DiscoGAN-GeneratorBA')</span><br><span class="line"></span><br><span class="line">    model_gAB.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_gAB.summary()</span><br><span class="line">    keras.utils.plot_model(model_gAB, 'DiscoGAN-generatorAB.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_gBA.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_gBA.summary()</span><br><span class="line">    keras.utils.plot_model(model_gBA, 'DiscoGAN-generatorBA.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_dA.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_dA.summary()</span><br><span class="line">    keras.utils.plot_model(model_dA, 'DiscoGAN-discriminatorA.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_dB.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_dB.summary()</span><br><span class="line">    keras.utils.plot_model(model_dB, 'DiscoGAN-discriminatorB.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = discogan(input_shapeA=(img_size[0], img_size[1], 3), input_shapeB=(img_size[0], img_size[1], 3), model_gAB=model_gAB, model_gBA=model_gBA, model_dA=model_dA, model_dB=model_dB)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'], loss_weights=[0.5, 0.5, 5, 5, 5, 5])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=[(img_size[0], img_size[1], 3), (img_size[0], img_size[1], 3)])</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'DiscoGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        image_A, image_B = read_data(data_path, img_size, batch_size)</span><br><span class="line"></span><br><span class="line">        fake_A = model_gBA(image_B)</span><br><span class="line">        fake_B = model_gAB(image_A)</span><br><span class="line"></span><br><span class="line">        real_dAmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dA(image_A))</span><br><span class="line">        fake_dAmse(np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dA(fake_A))</span><br><span class="line">        real_dBmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dB(image_B))</span><br><span class="line">        fake_dBmse(np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dB(fake_B))</span><br><span class="line">        gAmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model([image_A, image_B])[0])</span><br><span class="line">        gBmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model([image_A, image_B])[1])</span><br><span class="line"></span><br><span class="line">        real_dAloss = model_dA.train_on_batch(image_A, np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        fake_dAloss = model_dA.train_on_batch(fake_A, np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        real_dBloss = model_dB.train_on_batch(image_B, np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        fake_dBloss = model_dB.train_on_batch(fake_B, np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line"></span><br><span class="line">        gloss = model.train_on_batch([image_A, image_B], [np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), image_A, image_B, image_A, image_B])</span><br><span class="line"></span><br><span class="line">        if epoch % 20 == 0:</span><br><span class="line">            print('epoch = {}, real_dAmse = {}, fake_dAmse = {}, real_dBmse = {}, fake_dBmse = {}, gAmse = {}, gBmse = {}'.format(epoch, real_dAmse.result(), fake_dAmse.result(), real_dBmse.result(), fake_dBmse.result(), gAmse.result(), gBmse.result()))</span><br><span class="line">            real_dAmse.reset_states()</span><br><span class="line">            fake_dAmse.reset_states()</span><br><span class="line">            real_dBmse.reset_states()</span><br><span class="line">            fake_dBmse.reset_states()</span><br><span class="line">            gAmse.reset_states()</span><br><span class="line">            gBmse.reset_states()</span><br><span class="line">            image_A, image_B = read_data(data_path, img_size, batch_size=1)</span><br><span class="line">            fake_A = ((model_gBA(image_B).numpy().squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            fake_B = ((model_gAB(image_A).numpy().squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            image_A = ((image_A.squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            image_B = ((image_B.squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            cv.imwrite(save_path + '\\epoch{}.jpg'.format(epoch), np.concatenate([np.concatenate([image_B, fake_A], axis=1), np.concatenate([image_A, fake_B], axis=1)], axis=0))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/discogan_R.png" alt="discogan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/discogan_T.png" alt="discogan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>DiscoGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li>在DiscoGAN的测试图像中，为了体现模型的效果，第一行的奇数个为鞋子的轮廓，第一行的偶数个为转换风格后的鞋子图像，第二行的奇数个为鞋子图像，第二行的偶数个为转换风格后的鞋子轮廓，这里只是训练了2000代，而且每一代只有2个图像就可以看出DiscoGAN的效果。小伙伴们可以选择更大的数据集，更加快速的GPU，训练更长的时间，这样风格迁移的效果就会更加明显。</li>
</ol>
<h1 id="DiscoGAN小结"><a href="#DiscoGAN小结" class="headerlink" title="DiscoGAN小结"></a><font size="5" color="red">DiscoGAN小结</font></h1><p>  DiscoGAN是一种有效的风格迁移生成式对抗网络，和CycleGAN模型非常相似，只是更换了部分损失函数，网络结构从ResNet更换为UNet，从上图可以看出<strong>DiscoGAN模型的参数量有89M</strong>，可以实现任意风格之间的迁移，如果数据集足够，还可以生成人物表情包，是不是非常有趣呢？小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>CycleGAN</title>
    <url>/2020/06/11/generative_adversarial%20CycleGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">CycleGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>CycleGAN(Cycle Consistent Generative Adversarial Networks, 循环一致生成式对抗网络)</strong>:于<strong>2017年</strong>发表在<strong>ICCV</strong>上，可以实现图像的风格迁移，风格迁移是GAN网络提出后才出现在人们视野里面的图像处理算法，在生成式对抗网络问世之前，人们很难通过传统的图像处理算法实现风格迁移，今天带小伙伴们看一看瞧一瞧。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/cyclegan.png" alt="cyclegan"></p>
<h1 id="CycleGAN理论思想"><a href="#CycleGAN理论思想" class="headerlink" title="CycleGAN理论思想"></a><font size="5" color="red">CycleGAN理论思想</font></h1><p>CycleGAN引入了4个网络结构，分别是生成器GAB，生成器GBA，判别器DA，判别器DB。<br>GAB的输入是风格A的图像，输出是风格B的图像，目的是将风格A的图像转换为风格B的图像。<br>GBA的输入是风格B的图像，输出是风格A的图像，目的是将风格B的图像转换为风格A的图像。<br>DA的输入是风格A的图像，输出是对输入图像的分类，目的是判断输入图像是否为由B转换的风格A的图像<br>DB的输入是风格B的图像，输出是对输入图像的分类，目的是判断输入图像是否为由A转换的风格B的图像</p>
<p>其中的图像名称有很多，在这里进行简单的介绍。<br>image_A, image_B指数据集中读取的真实图像，使用DA和DB进行预测时，结果应该是全1。<br>fake_A指imge_B由GBA生成的风格A类型的图像，使用DA预测时，希望应该是全1，fake_B指imge_A由GAB生成的风格B类型的图像，使用DB预测时，希望应该是全1。<br>recon_A指fake_B由GBA生成风格A类型的图像，也就是原图image_A经过GAB，再经过GBA生成风格A的图像，希望和image_A越接近越好。<br>recon_B指fake_A由GAB生成风格B类型的图像，也就是原图image_B经过GBA，再经过GAB生成风格B的图像，希望和image_B越接近越好。<br>self_A指image_A由GBA生成的风格A类型的图像，因为GBA是将风格B的图像转换为风格A的图像，输入风格A的图像，应该是不会产生变化，希望和image_A越接近越好。<br>self_B指image_B由GAB生成的风格B类型的图像，因为GAB是将风格A的图像转换为风格B的图像，输入风格B的图像，应该是不会产生变化，希望和image_B越接近越好。</p>
<h1 id="CycelGAN的特点"><a href="#CycelGAN的特点" class="headerlink" title="CycelGAN的特点"></a><font size="5" color="red">CycelGAN的特点</font></h1><p>  <font size="3"><strong>使用InstanceNormalization代替BatchNormalization</strong>。</font><br>  <font size="3"><strong>生成器使用下采样+ResNet结构+上采样对图像进行深层特征提取</strong>。</font><br>  <font size="3"><strong>生成器损失函数采用绝对误差，判别器损失函数采用均方误差</strong>。</font><br>  <font size="3"><strong>对生成器损失函数的权重进行调节，使网络更多关注于生成的图像质量</strong>。</font></p>
<h1 id="CycleGAN图像分析"><a href="#CycleGAN图像分析" class="headerlink" title="CycleGAN图像分析"></a><font size="5" color="red">CycleGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/CycleGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/CycleGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class InstanceNormalization(keras.layers.Layer):</span><br><span class="line">    def __init__(self, beta_initializer='zeros', gamma_initializer='ones',</span><br><span class="line">                 beta_regularizer=None, gamma_regularizer=None,</span><br><span class="line">                 beta_constraint=None, gamma_constraint=None, epsilon=1e-5,</span><br><span class="line">                 **kwargs):</span><br><span class="line">        super(InstanceNormalization, self).__init__(**kwargs)</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        self.beta_initializer = keras.initializers.get(beta_initializer)</span><br><span class="line">        self.gamma_initializer = keras.initializers.get(gamma_initializer)</span><br><span class="line">        self.beta_regularizer = keras.regularizers.get(beta_regularizer)</span><br><span class="line">        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)</span><br><span class="line">        self.beta_constraint = keras.constraints.get(beta_constraint)</span><br><span class="line">        self.gamma_constraint = keras.constraints.get(gamma_constraint)</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        assert len(input_shape) == 4</span><br><span class="line">        self.gamma = self.add_weight(shape=(input_shape[-1],), name='gamma', initializer=self.gamma_initializer,</span><br><span class="line">                                     regularizer=self.gamma_regularizer, constraint=self.gamma_constraint)</span><br><span class="line">        self.beta = self.add_weight(shape=(input_shape[-1],), name='beta', initializer=self.beta_initializer,</span><br><span class="line">                                    regularizer=self.beta_regularizer, constraint=self.beta_constraint)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, axes=[1, 2])</span><br><span class="line">        mean = tf.reshape(mean, shape=[-1, 1, 1, inputs.shape[-1]])</span><br><span class="line">        variance = tf.reshape(variance, shape=[-1, 1, 1, inputs.shape[-1]])</span><br><span class="line">        outputs = (inputs - mean) / tf.sqrt(variance + self.epsilon)</span><br><span class="line">        return outputs * self.gamma + self.beta</span><br><span class="line"></span><br><span class="line">    def get_config(self):</span><br><span class="line">        config = {</span><br><span class="line">            'epsilon': self.epsilon,</span><br><span class="line">            'beta_initializer': keras.initializers.serialize(self.beta_initializer),</span><br><span class="line">            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),</span><br><span class="line">            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),</span><br><span class="line">            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),</span><br><span class="line">            'beta_constraint': keras.constraints.serialize(self.beta_constraint),</span><br><span class="line">            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint)</span><br><span class="line">        }</span><br><span class="line">        base_config = super(InstanceNormalization, self).get_config()</span><br><span class="line"></span><br><span class="line">        return dict(list(base_config.items()) + list(config.items()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_In_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_In_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([keras.layers.Conv2D(filters, kernel_size, strides, padding)])</span><br><span class="line">        if name.find('in') != -1:</span><br><span class="line">            self.block.add(InstanceNormalization())</span><br><span class="line">        if name.find('leakyrelu') != -1:</span><br><span class="line">            self.block.add(keras.layers.LeakyReLU(0.2))</span><br><span class="line">        elif name.find('relu') != -1:</span><br><span class="line">            self.block.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def identity_block(x, filters, kernel_size, strides, padding, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_In_Relu(filters, kernel_size, strides, padding, name='{}_conv_in_relu1'.format(name)),</span><br><span class="line">                Conv_In_Relu(filters, kernel_size, strides, padding, name='{}_conv_in2'.format(name)))(x)</span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line">    x = keras.layers.ReLU(name='{}_relu'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape, name):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_In_Relu(64, (7, 7), (1, 1), 'same', name='conv_in_relu1'),</span><br><span class="line">                Conv_In_Relu(128, (3, 3), (2, 2), 'same', name='conv_in_relu2'),</span><br><span class="line">                Conv_In_Relu(256, (3, 3), (2, 2), 'same', name='conv_in_relu3'))(x)</span><br><span class="line"></span><br><span class="line">    for i in range(9):</span><br><span class="line">        x = identity_block(x, 256, (3, 3), (1, 1), 'same', name='identity_block{}'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.UpSampling2D((2, 2), name='upsampling1'),</span><br><span class="line">                Conv_In_Relu(128, (3, 3), (1, 1), 'same', name='conv_in_relu4'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling2'),</span><br><span class="line">                Conv_In_Relu(64, (3, 3), (1, 1), 'same', name='conv_in_relu5'),</span><br><span class="line">                keras.layers.Conv2D(3, (3, 3), (1, 1), 'same', activation='tanh', name='conv_tanh'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name=name)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape, name):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_In_Relu(64, (4, 4), (2, 2), 'same', name='conv_leakyrelu1'),</span><br><span class="line">                Conv_In_Relu(128, (4, 4), (2, 2), 'same', name='conv_in_leakyrelu2'),</span><br><span class="line">                Conv_In_Relu(256, (4, 4), (2, 2), 'same', name='conv_in_leakyrelu3'),</span><br><span class="line">                Conv_In_Relu(512, (4, 4), (2, 2), 'same', name='conv_in_leakyrelu4'),</span><br><span class="line">                keras.layers.Conv2D(1, (3, 3), (1, 1), 'same', name='conv'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name=name)</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cyclegan(input_shapeA, input_shapeB, model_gAB, model_gBA, model_dA, model_dB):</span><br><span class="line">    input_tensorA = keras.layers.Input(input_shapeA, name='input_A')</span><br><span class="line">    input_tensorB = keras.layers.Input(input_shapeB, name='input_B')</span><br><span class="line"></span><br><span class="line">    # 输入风格B由BA生成的风格A类型的图像和输入风格A由AB生成的风格B类型的图像，称为假A和假B</span><br><span class="line">    fake_A = model_gBA(input_tensorB)</span><br><span class="line">    fake_B = model_gAB(input_tensorA)</span><br><span class="line"></span><br><span class="line">    # 输入假风格B由BA生成的重建风格A和假风格A由AB生成的重建风格B，称为重建A和重建B</span><br><span class="line">    recon_A = model_gBA(fake_B)</span><br><span class="line">    recon_B = model_gAB(fake_A)</span><br><span class="line"></span><br><span class="line">    # 输入风格B由AB生成的风格B类型的图像和输入风格A由BA生成的风格A类型的图像，称为自身B和自身A</span><br><span class="line">    self_A = model_gBA(input_tensorA)</span><br><span class="line">    self_B = model_gAB(input_tensorB)</span><br><span class="line"></span><br><span class="line">    model_dA.trainable = False</span><br><span class="line">    model_dB.trainable = False</span><br><span class="line"></span><br><span class="line">    conf_A = model_dA(fake_A)</span><br><span class="line">    conf_B = model_dB(fake_B)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([input_tensorA, input_tensorB], [conf_A, conf_B, recon_A, recon_B, self_A, self_B], name='CycleGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_data(data_path, img_size, batch_size):</span><br><span class="line">    filename_A = glob.glob(data_path + 'A\\*.jpg')</span><br><span class="line">    filename_B = glob.glob(data_path + 'B\\*.jpg')</span><br><span class="line">    choose_name_A = np.random.choice(filename_A, batch_size)</span><br><span class="line">    choose_name_B = np.random.choice(filename_B, batch_size)</span><br><span class="line"></span><br><span class="line">    image_A, image_B = [], []</span><br><span class="line">    for i in range(batch_size):</span><br><span class="line">        A = cv.imread(choose_name_A[i]).astype(np.float32)</span><br><span class="line">        B = cv.imread(choose_name_B[i]).astype(np.float32)</span><br><span class="line">        image_A.append(cv.resize(A, img_size))</span><br><span class="line">        image_B.append(cv.resize(B, img_size))</span><br><span class="line"></span><br><span class="line">    image_A = np.array(image_A) / 127.5 - 1</span><br><span class="line">    image_B = np.array(image_B) / 127.5 - 1</span><br><span class="line"></span><br><span class="line">    return image_A, image_B</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    batch_size = 2</span><br><span class="line">    epochs = 2000</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    data_path = r'.\monet2photo\train'</span><br><span class="line">    save_path = r'.\cyclegan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dAmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    fake_dAmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    real_dBmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    fake_dBmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    gAmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    gBmse = keras.metrics.MeanSquaredError()</span><br><span class="line"></span><br><span class="line">    model_dA = discriminator(input_shape=(img_size[0], img_size[1], 3), name='CycleGAN-DiscriminatorA')</span><br><span class="line">    model_dA.compile(optimizer=optimizer, loss='mse')</span><br><span class="line">    model_dB = discriminator(input_shape=(img_size[0], img_size[1], 3), name='CycleGAN-DiscriminatorB')</span><br><span class="line">    model_dB.compile(optimizer=optimizer, loss='mse')</span><br><span class="line"></span><br><span class="line">    model_gAB = generator(input_shape=(img_size[0], img_size[1], 3), name='CycleGAN-GeneratorAB')</span><br><span class="line">    model_gBA = generator(input_shape=(img_size[0], img_size[1], 3), name='CycleGAN-GeneratorBA')</span><br><span class="line"></span><br><span class="line">    model_gAB.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_gAB.summary()</span><br><span class="line">    keras.utils.plot_model(model_gAB, 'CycleGAN-generatorAB.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_gBA.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_gBA.summary()</span><br><span class="line">    keras.utils.plot_model(model_gBA, 'CycleGAN-generatorBA.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_dA.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_dA.summary()</span><br><span class="line">    keras.utils.plot_model(model_dA, 'CycleGAN-discriminatorA.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_dB.build(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model_dB.summary()</span><br><span class="line">    keras.utils.plot_model(model_dB, 'CycleGAN-discriminatorB.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = cyclegan(input_shapeA=(img_size[0], img_size[1], 3), input_shapeB=(img_size[0], img_size[1], 3), model_gAB=model_gAB, model_gBA=model_gBA, model_dA=model_dA, model_dB=model_dB)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'], loss_weights=[0.5, 0.5, 5, 5, 2.5, 2.5])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=[(img_size[0], img_size[1], 3), (img_size[0], img_size[1], 3)])</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'CycleGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        image_A, image_B = read_data(data_path, img_size, batch_size)</span><br><span class="line"></span><br><span class="line">        fake_A = model_gBA(image_B)</span><br><span class="line">        fake_B = model_gAB(image_A)</span><br><span class="line"></span><br><span class="line">        real_dAmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dA(image_A))</span><br><span class="line">        fake_dAmse(np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dA(fake_A))</span><br><span class="line">        real_dBmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dB(image_B))</span><br><span class="line">        fake_dBmse(np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model_dB(fake_B))</span><br><span class="line">        gAmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model([image_A, image_B])[0])</span><br><span class="line">        gBmse(np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), model([image_A, image_B])[1])</span><br><span class="line"></span><br><span class="line">        real_dAloss = model_dA.train_on_batch(image_A, np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        fake_dAloss = model_dA.train_on_batch(fake_A, np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        real_dBloss = model_dB.train_on_batch(image_B, np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line">        fake_dBloss = model_dB.train_on_batch(fake_B, np.zeros((batch_size, img_size[0] // 16, img_size[1] // 16, 1)))</span><br><span class="line"></span><br><span class="line">        gloss = model.train_on_batch([image_A, image_B], [np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), np.ones((batch_size, img_size[0] // 16, img_size[1] // 16, 1)), image_A, image_B, image_A, image_B])</span><br><span class="line"></span><br><span class="line">        if epoch % 20 == 0:</span><br><span class="line">            print('epoch = {}, real_dAmse = {}, fake_dAmse = {}, real_dBmse = {}, fake_dBmse = {}, gAmse = {}, gBmse = {}'.format(epoch, real_dAmse.result(), fake_dAmse.result(), real_dBmse.result(), fake_dBmse.result(), gAmse.result(), gBmse.result()))</span><br><span class="line">            real_dAmse.reset_states()</span><br><span class="line">            fake_dAmse.reset_states()</span><br><span class="line">            real_dBmse.reset_states()</span><br><span class="line">            fake_dBmse.reset_states()</span><br><span class="line">            gAmse.reset_states()</span><br><span class="line">            gBmse.reset_states()</span><br><span class="line">            image_A, image_B = read_data(data_path, img_size, batch_size=1)</span><br><span class="line">            fake_A = ((model_gBA(image_B).numpy().squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            fake_B = ((model_gAB(image_A).numpy().squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            image_A = ((image_A.squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            image_B = ((image_B.squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            cv.imwrite(save_path + '\\epoch{}.jpg'.format(epoch), np.concatenate([np.concatenate([image_B, fake_A], axis=1), np.concatenate([image_A, fake_B], axis=1)], axis=0))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/cyclegan_R.png" alt="cyclegan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/cyclegan_T.png" alt="cyclegan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>CycleGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li>在CycleGAN的测试图像中，为了体现模型的效果，第一行的奇数个为拍摄的照片，第一行的偶数个为转换风格后的莫奈风格画作，第二行的奇数个为莫奈风格的画作，第二行的偶数个为转换风格后的照片，这里只是训练了2000代，而且每一代只有2个图像就可以看出CycleGAN的效果。小伙伴们可以选择更大的数据集，更加快速的GPU，训练更长的时间，这样风格迁移的效果就会更加明显。</li>
</ol>
<h1 id="CycleGAN小结"><a href="#CycleGAN小结" class="headerlink" title="CycleGAN小结"></a><font size="5" color="red">CycleGAN小结</font></h1><p>  CycleGAN是一种有效的风格迁移生成式对抗网络，从上图可以看出<strong>CycleGAN模型的参数量只有28M</strong>，可以实现任意风格之间的迁移，如果数据集足够，还可以生成人物表情包，是不是非常有趣呢？小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>单词接龙 II(Leetcode 126)</title>
    <url>/2020/06/10/program%20Leetcode126/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode126.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题目是一个<strong>路径搜索问题，每次只能改变一个字母，因此每一个单词都有邻接关系，求出从起始单词到终点单词的路径中最短的所有路径</strong>，这题<strong>难点不在于路径搜索，而是如何最高效的确定路径</strong>，因为要判断两个单词是否有邻接关系，遍历所有字符，而且逐个字符判断，<strong>时间复杂度为$O(c * n^2)$</strong>，有没有更好更快的方法呢？</p>
<a id="more"></a>
<h1 id="邻接关系的确定"><a href="#邻接关系的确定" class="headerlink" title="邻接关系的确定"></a><font size="5" color="red">邻接关系的确定</font></h1><p>如果两两挑选，并且逐个字符判断，则<strong>时间复杂度为$O(c * n^2)$</strong>，如果建立一个哈希表，里面存储缺省一个字符的所有匹配单词，则可以在<strong>时间复杂度为$O(c * n)$</strong>的情况下确定邻接关系。<br><img src="/images/ALGORITHM/leetcode126_route.png" alt="route"></p>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>采用DFS来求解，沿着起始单词进行路径搜索，如果搜索到终点则记录长度，并且将路径保存，如果当前长度大于最优长度或者出现环，则剪枝，不继续搜索。最后从所有符合的路径中挑选出长度为最优长度的即可，因为初始最优长度设为无穷大，如果存在大量的环，DFS会耗费非常多的时间，因此不是最优的解法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import deque, defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def findLadders(self, beginWord, endWord, wordList):</span><br><span class="line">        """</span><br><span class="line">        :type beginWord: str</span><br><span class="line">        :type endWord: str</span><br><span class="line">        :type wordList: List[str]</span><br><span class="line">        :rtype: List[List[str]]</span><br><span class="line">        """</span><br><span class="line">        best_route = []</span><br><span class="line">        best_n = float('inf')</span><br><span class="line">        lens = len(beginWord)</span><br><span class="line">        relation = defaultdict(list)</span><br><span class="line">        list(map(lambda word: [relation[word[:i] + '*' + word[i + 1:]].append(word) for i in range(lens)], wordList))</span><br><span class="line"></span><br><span class="line">        def dfs(current, n):</span><br><span class="line">            nonlocal best_n</span><br><span class="line">            if n &gt; best_n or current[-1] in current[:-1]:</span><br><span class="line">                return</span><br><span class="line">            if current[-1] == endWord:</span><br><span class="line">                best_route.append(current)</span><br><span class="line">                best_n = len(current)</span><br><span class="line">                return</span><br><span class="line">            for i in range(lens):</span><br><span class="line">                for next_word in relation[current[-1][:i] + '*' + current[-1][i + 1:]]:</span><br><span class="line">                    dfs(current + [next_word], n + 1)</span><br><span class="line"></span><br><span class="line">        dfs([beginWord], 1)</span><br><span class="line">        return [x for x in best_route if len(x) == best_n]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>想到最短路径就要想到广度优先搜索，因为广度优先搜索是从起点开始一层一层向外搜索，因此最先搜索到终点的路径一定是最短路径，为什么这道题目BFS比DFS快呢，因为BFS经过的路径不需要再次经过，所以建立一个passed集合，经过的点都记录在里面，下次直接跳过即可，注意这道题目要求所有的最短路径，只能每一层寻找完之后再加入passed集合，如果A-B-C是可以的，这时就将C加入passed集合，那么A-D-C就会被跳过，因此要将当前层都遍历后再修改passed集合。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def findLadders(self, beginWord, endWord, wordList):</span><br><span class="line">        """</span><br><span class="line">        :type beginWord: str</span><br><span class="line">        :type endWord: str</span><br><span class="line">        :type wordList: List[str]</span><br><span class="line">        :rtype: List[List[str]]</span><br><span class="line">        """</span><br><span class="line">        lens = len(beginWord)</span><br><span class="line">        relation = defaultdict(list)</span><br><span class="line">        list(map(lambda word: [relation[word[:i] + '*' + word[i + 1:]].append(word) for i in range(lens)], wordList))</span><br><span class="line">        current_passed = set()</span><br><span class="line">        passed = set().union([beginWord])</span><br><span class="line">        current_queue = deque([[beginWord]])</span><br><span class="line">        next_queue = deque()</span><br><span class="line">        flag = False</span><br><span class="line">        while True:</span><br><span class="line">            while current_queue:</span><br><span class="line">                current = current_queue.popleft()</span><br><span class="line">                for i in range(lens):</span><br><span class="line">                    for word in relation[current[-1][:i] + '*' + current[-1][i + 1:]]:</span><br><span class="line">                        if word not in passed:</span><br><span class="line">                            if word == endWord:</span><br><span class="line">                                flag = True</span><br><span class="line">                            current_passed.add(word)</span><br><span class="line">                            next_queue.append(current + [word])</span><br><span class="line">            if not next_queue:</span><br><span class="line">                return []</span><br><span class="line">            if flag:</span><br><span class="line">                return [x for x in next_queue if x[-1] == endWord]</span><br><span class="line">            else:</span><br><span class="line">                passed.update(current_passed)</span><br><span class="line">                current_queue = next_queue</span><br><span class="line">                next_queue = deque()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  路径搜索问题太经典了，多次强调BFS和DFS一定要牢记，两者绝大部分情况是可以相互转换的，但是可能存在着效率不同的问题，小伙伴们多多刷题，多多总结。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>SRGAN</title>
    <url>/2020/06/09/generative_adversarial%20SRGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">SRGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>SRGAN(Supre Resolution Generative Adversarial Networks, 超分辨率生成式对抗网络)</strong>:于<strong>2016年</strong>发表在<strong>CVPR</strong>上，图像处理的一个重要任务就是超分辨率，图像的大小是由分辨率决定的，常见的分辨率有128x128，256x256，512x512，1024x1024，<strong>像素越大，说明像素点越多，图像的表达能力更强，细节更加明显</strong>，看起来也会更加舒适。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/srgan.png" alt="srgan"></p>
<h1 id="分辨率提升的方法"><a href="#分辨率提升的方法" class="headerlink" title="分辨率提升的方法"></a><font size="5" color="red">分辨率提升的方法</font></h1><p>在GAN问世以前，人们就做了许多关于分辨率提升的方法，其中<strong>最简单的也是最常用的方法就是插值法，在opencv库中有imresize函数</strong>，其中<strong>可以指定目标图像的尺寸，而且可以选择插值方法，一般选择双线性插值</strong>，但是插值方法有一个<strong>最致命的问题—模糊</strong>，插值的原理就是根据周围的点进行估计，因此插值的结果会导致某个区域的值都i非常接近，会导致照片模糊。</p>
<p>随着GAN的发展，人们发现GAN既然能够生成图像，能不能生成更高分辨率的图像，答案是肯定的，今天给小伙伴们介绍SRGAN的原理。<br>SRGAN<strong>引入了三个网络，一个是生成器，一个是判别器，还有一个是特征提取器(VGG19)</strong><br>生成器的<strong>输入是低分辨率图像，输出是高分辨率图像，目的是根据输入的低分辨率图像生成高分辨率图像</strong>。<br>判别器的<strong>输入是高分辨率图像，输出是对输入图像的分类，目的是判断输入的图像是生成的高分辨率图像还是原始的高分辨率图像</strong>。<br>特征提取器的<strong>输入是高分辨率图像，输出是对高分辨率图像的特征提取，目的是使生成的图像和原始的高分辨率图像具有相同的特征</strong>。</p>
<h1 id="SRGAN的特点"><a href="#SRGAN的特点" class="headerlink" title="SRGAN的特点"></a><font size="5" color="red">SRGAN的特点</font></h1><p>  <font size="3"><strong>生成器使用ResNet结构+上采样对图像进行分辨率提升</strong>。</font><br>  <font size="3"><strong>引入特征提取网络VGG19，对高分辨率特征进行提取</strong>。</font><br>  <font size="3"><strong>特征提取损失函数采用均方误差，判别器损失函数采用二分类交叉熵</strong>。</font><br>  <font size="3"><strong>对生成器损失函数的权重进行调节，使网络更多关注于生成的图像质量</strong>。</font></p>
<h1 id="SRGAN图像分析"><a href="#SRGAN图像分析" class="headerlink" title="SRGAN图像分析"></a><font size="5" color="red">SRGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/SRGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/SRGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def resblock(x, filters, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(keras.layers.Conv2D(filters, (3, 3), (1, 1), 'same', name='{}_conv1'.format(name)),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='{}_bn1'.format(name)),</span><br><span class="line">                keras.layers.ReLU(name='{}_relu1'.format(name)),</span><br><span class="line">                keras.layers.Conv2D(filters, (3, 3), (1, 1), 'same', name='{}_conv2'.format(name)),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='{}_bn2'.format(name)))(x)</span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_LeakyRelu_Bn(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_LeakyRelu_Bn, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential([keras.layers.Conv2D(filters, kernel_size, strides, padding),</span><br><span class="line">                                       keras.layers.LeakyReLU(0.2)])</span><br><span class="line">        if name.find('bn') != -1:</span><br><span class="line">            self.block.add(keras.layers.BatchNormalization(momentum=0.8))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def vgg(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    vgg = keras.applications.VGG19()</span><br><span class="line">    vgg.outputs = [vgg.layers[9].output]</span><br><span class="line">    x = vgg(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='VGG19')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Conv2D(64, (9, 9), (1, 1), 'same', name='conv1')(x)</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    for i in range(16):</span><br><span class="line">        x = resblock(x, 64, name='resblock{}'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Add(name='add2')([x, shortcut])</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.UpSampling2D((2, 2), name='upsampling1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='conv3_relu'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling2'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='conv4_relu'),</span><br><span class="line">                keras.layers.Conv2D(3, (9, 9), (1, 1), 'same', activation='tanh', name='conv5_tanh'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='SRGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_LeakyRelu_Bn(64, (3, 3), (1, 1), 'same', name='conv_leakyrelu1'),</span><br><span class="line">                Conv_LeakyRelu_Bn(64, (3, 3), (2, 2), 'same', name='conv_leakyrelu_bn2'),</span><br><span class="line">                Conv_LeakyRelu_Bn(128, (3, 3), (1, 1), 'same', name='conv_leakyrelu_bn3'),</span><br><span class="line">                Conv_LeakyRelu_Bn(128, (3, 3), (2, 2), 'same', name='conv_leakyrelu_bn4'),</span><br><span class="line">                Conv_LeakyRelu_Bn(256, (3, 3), (1, 1), 'same', name='conv_leakyrelu_bn5'),</span><br><span class="line">                Conv_LeakyRelu_Bn(256, (3, 3), (2, 2), 'same', name='conv_leakyrelu_bn6'),</span><br><span class="line">                Conv_LeakyRelu_Bn(512, (3, 3), (1, 1), 'same', name='conv_leakyrelu_bn7'),</span><br><span class="line">                Conv_LeakyRelu_Bn(512, (3, 3), (2, 2), 'same', name='conv_leakyrelu_bn8'),</span><br><span class="line">                Conv_LeakyRelu_Bn(1024, (1, 1), (1, 1), 'same', name='conv_leakyrelu9'),</span><br><span class="line">                keras.layers.Conv2D(1, (1, 1), (1, 1), 'same', activation='sigmoid', name='conv_sigmoid'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='SRGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def srgan(input_shape, model_vgg, model_g, model_d):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    model_vgg.trainable = False</span><br><span class="line">    model_d.trainable = False</span><br><span class="line"></span><br><span class="line">    fake_image = model_g(x)</span><br><span class="line">    fake_feature = model_vgg(fake_image)</span><br><span class="line">    conf = model_d(fake_image)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, [conf, fake_feature], name='SRGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_data(data_path, high_resolution, low_resolution, batch_size):</span><br><span class="line">    filename = glob.glob(data_path)</span><br><span class="line">    choose_name = np.random.choice(filename, batch_size)</span><br><span class="line"></span><br><span class="line">    hr_image, lr_image = [], []</span><br><span class="line">    for name in choose_name:</span><br><span class="line">        image = cv.imread(name).astype(np.float32)</span><br><span class="line">        hr_image.append(cv.resize(image, high_resolution))</span><br><span class="line">        lr_image.append(cv.resize(image, low_resolution))</span><br><span class="line"></span><br><span class="line">    hr_image = np.array(hr_image) / 127.5 - 1</span><br><span class="line">    lr_image = np.array(lr_image) / 127.5 - 1</span><br><span class="line"></span><br><span class="line">    return hr_image, lr_image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    batch_size = 2</span><br><span class="line">    epochs = 2000</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    low_resolution = (56, 56)</span><br><span class="line">    high_resolution = (224, 224)</span><br><span class="line">    data_path = r'.\monet2photo\trainB\*.jpg'</span><br><span class="line">    save_path = r'.\srgan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    gacc = keras.metrics.BinaryAccuracy()</span><br><span class="line"></span><br><span class="line">    model_vgg = vgg(input_shape=(high_resolution[0], high_resolution[1], 3))</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(high_resolution[0], high_resolution[1], 3))</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(low_resolution[0], low_resolution[1], 3))</span><br><span class="line"></span><br><span class="line">    model_vgg.build(input_shape=(high_resolution[0], high_resolution[1], 3))</span><br><span class="line">    model_vgg.summary()</span><br><span class="line">    keras.utils.plot_model(model_vgg, 'SRGAN-vgg19.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(low_resolution[0], low_resolution[1], 3))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'SRGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(high_resolution[0], high_resolution[1], 3))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'SRGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = srgan(input_shape=(low_resolution[0], low_resolution[1], 3), model_vgg=model_vgg, model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['binary_crossentropy', 'mse'], loss_weights=[1, 100])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(low_resolution[0], low_resolution[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'SRGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        real_hr_image, real_lr_image = read_data(data_path, high_resolution, low_resolution, batch_size)</span><br><span class="line"></span><br><span class="line">        real_hr_feature = model_vgg(real_hr_image)</span><br><span class="line">        fake_hr_image = model_g(real_lr_image)</span><br><span class="line"></span><br><span class="line">        real_dacc(np.ones((batch_size, high_resolution[0] // 16, high_resolution[1] // 16, 1)), model_d(real_hr_image))</span><br><span class="line">        fake_dacc(np.zeros((batch_size, high_resolution[0] // 16, high_resolution[1] // 16, 1)), model_d(fake_hr_image))</span><br><span class="line">        gacc(np.ones((batch_size, high_resolution[0] // 16, high_resolution[1] // 16, 1)), model(real_lr_image)[0])</span><br><span class="line"></span><br><span class="line">        real_dloss = model_d.train_on_batch(real_hr_image, np.ones((batch_size, high_resolution[0] // 16, high_resolution[1] // 16, 1)))</span><br><span class="line">        fake_dloss = model_d.train_on_batch(fake_hr_image, np.zeros((batch_size, high_resolution[0] // 16, high_resolution[1] // 16, 1)))</span><br><span class="line">        gloss = model.train_on_batch(real_lr_image, [np.ones((batch_size, high_resolution[0] // 16, high_resolution[1] // 16, 1)), real_hr_feature])</span><br><span class="line"></span><br><span class="line">        if epoch % 20 == 0:</span><br><span class="line">            print('epoch = {}, real_dacc = {}, fake_dacc = {}, gacc = {}'.format(epoch, real_dacc.result(), fake_dacc.result(), gacc.result()))</span><br><span class="line">            real_dacc.reset_states()</span><br><span class="line">            fake_dacc.reset_states()</span><br><span class="line">            gacc.reset_states()</span><br><span class="line">            real_hr_image, real_lr_image = read_data(data_path, high_resolution, low_resolution, batch_size=1)</span><br><span class="line">            fake_hr_image = ((model_g(real_lr_image).numpy().squeeze() + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            scale_hr_image = ((cv.resize(real_lr_image.squeeze(), high_resolution) + 1) * 127.5).astype(np.uint8)</span><br><span class="line">            cv.imwrite(save_path + '\\epoch{}.jpg'.format(epoch), np.concatenate([scale_hr_image, fake_hr_image], axis=1))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/srgan_R.png" alt="srgan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/srgan_T.png" alt="srgan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>SRGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li>要注意<strong>使用VGG19特征提取网络权重时，因为VGG19的输入尺寸是224x224x3的，因此图像的尺寸要匹配，如果想生成更大尺寸的高分辨率图像，需要自己训练一个合适的特征提取网络权重</strong>。</li>
<li>在SRGAN的测试图像中，为了说明模型的优越性，左边为低分辨率图像直接resize到高分辨率图像的结果，右边为SRGAN生成的高分辨率图像的结果。只是训练了2000代，每一代只有2个图像就可以看出SRGAN的效果。小伙伴们可以选择更大的数据集，更加快速的GPU，训练更长的时间，这两种算法之间的差距会更加明显。</li>
</ol>
<h1 id="SRGAN小结"><a href="#SRGAN小结" class="headerlink" title="SRGAN小结"></a><font size="5" color="red">SRGAN小结</font></h1><p>  SRGAN是一种有效的超分辨率生成式对抗网络，从上图可以看出<strong>SRGAN模型的参数量只有7M</strong>，最近AI老图像复原引起了人们的注意，训练好SRGAN模型后可以运用在AI老图像复原，可以将原来拍摄的低分辨率的图像转化为清晰的高分辨率图像，是不是非常有趣呢？</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>等式方程的可满足性(Leetcode 990)</title>
    <url>/2020/06/08/program%20Leetcode990/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode990.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题目是一个集合问题，相等的变量位于同一个集合之中，判断不相等的变量是否存在于同一个集合之中，集合之间的查询要想到并查集。</p>
<a id="more"></a>
<h1 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a><font size="5" color="red">并查集</font></h1><p>先将相等关系进行处理，把所有的变量分成不同的集合，最后再遍历不等关系，判断不相等的两个遍历是否存在于同一个集合之中。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class UnionFind:</span><br><span class="line">    def __init__(self, equations):</span><br><span class="line">        self.parents = {}</span><br><span class="line">        for x, _, _, y in equations:</span><br><span class="line">            self.parents[x] = x</span><br><span class="line">            self.parents[y] = y</span><br><span class="line"></span><br><span class="line">    def find(self, x):</span><br><span class="line">        if self.parents[x] != x:</span><br><span class="line">            self.parents[x] = self.find(self.parents[x])</span><br><span class="line">        return self.parents[x]</span><br><span class="line"></span><br><span class="line">    def union(self, x, y):</span><br><span class="line">        root_x, root_y = self.find(x), self.find(y)</span><br><span class="line">        if root_x != root_y:</span><br><span class="line">            self.parents[root_x] = self.parents[root_y]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def equationsPossible(self, equations):</span><br><span class="line">        uf = UnionFind(equations)</span><br><span class="line">        for x, c, _, y in equations:</span><br><span class="line">            if c == '=':</span><br><span class="line">                uf.union(x, y)</span><br><span class="line">        for x, c, _, y in equations:</span><br><span class="line">            if c == '!' and uf.find(x) == uf.find(y):</span><br><span class="line">                return False</span><br><span class="line">        return True</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  此题还可以使用BFS或者DFS求解，类似于岛屿问题，将这些变量分成不同的集合，但是因为还需要判断变量之间的不等号关系，即判断变量之间是否不在同一个集合，如果使用BFS或者DFS还需要将每一组不等号去搜索两个变量是否为同一个集合，而并查集每个元素都有一个老大，因此比较两个老大是否为同一个就可以比较是否在同一个集合中，思路清晰，代码也很简单。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>并查集</category>
      </categories>
  </entry>
  <entry>
    <title>WGAN-GP</title>
    <url>/2020/06/07/generative_adversarial%20WGAN-GP/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">WGAN-GP</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>WGAN-GP(Wasserstein Generative Adversarial Networks-Gradient Penalty)</strong>:于<strong>2017年</strong>发表于<strong>NIPS</strong>，<strong>是WGAN的升级版本，WGAN理论的前提是1-Liposchitz条件，WGAN中使用的方法是权重裁剪，这不是一个非常好的办法，WGAN-GP使用了一种GP(Gradient Penalty, 梯度惩罚)的方法替代权重裁剪，构建了一个更加稳定，收敛更快，质量更高的生成式对抗网络</strong>。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/wgan-gp.png" alt="wgan-gp"></p>
<h1 id="权重裁剪的缺陷"><a href="#权重裁剪的缺陷" class="headerlink" title="权重裁剪的缺陷"></a><font size="5" color="red">权重裁剪的缺陷</font></h1><p>  <font size="3"><strong>极大的限制了网络的表现能力，因为对权重进行的范围限制，使得网络很难模拟出想要得到的函数</strong>。</font><br>  <font size="3"><strong>容易出现梯度爆炸和梯度消失的现象，而且本来生成式对抗网络的参数设置就很敏感，这样更难收敛</strong>。</font></p>
<h1 id="WGAN-GP的特点"><a href="#WGAN-GP的特点" class="headerlink" title="WGAN-GP的特点"></a><font size="5" color="red">WGAN-GP的特点</font></h1><p>  <font size="3"><strong>保持GAN的网络结构不变，将判别器网络最后的sigmoid删去</strong>。</font><br>  <font size="3"><strong>使用随机采样作为惩罚项，不用WGAN中的权重裁剪</strong>。</font><br>  <font size="3"><strong>重新采用Adam优化器，不存在WGAN种Adam稳定性不高的问题</strong>。</font></p>
<h1 id="WGAN-GP图像分析"><a href="#WGAN-GP图像分析" class="headerlink" title="WGAN-GP图像分析"></a><font size="5" color="red">WGAN-GP图像分析</font></h1><p><img src="/images/Generative_adversarial/WGANGP-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/WGANGP-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce, partial</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(256, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8),</span><br><span class="line">                keras.layers.Dense(1024, activation='relu', name='dense_relu3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8),</span><br><span class="line">                keras.layers.Dense(784, activation='tanh', name='dense_tanh'),</span><br><span class="line">                keras.layers.Reshape((28, 28, 1)))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='WGANGP-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.Dense(256, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.Dense(1, name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='WGANGP-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Weight_Addition(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(Weight_Addition, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        r = np.random.uniform(0, 1, (batch_size, 1, 1, 1))</span><br><span class="line"></span><br><span class="line">        return inputs[0] * r + inputs[1] * (1 - r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def wgan_gp(input_image_shape, input_noise_shape, model_g, model_d):</span><br><span class="line">    input_image = keras.layers.Input(input_image_shape, name='input_image')</span><br><span class="line">    input_noise_d = keras.layers.Input(input_noise_shape, name='input_noise_discriminator')</span><br><span class="line">    input_noise_g = keras.layers.Input(input_noise_shape, name='input_noise_generator')</span><br><span class="line"></span><br><span class="line">    model_g.trainable = False</span><br><span class="line">    fake_image = model_g(input_noise_d)</span><br><span class="line">    real_conf = model_d(input_image)</span><br><span class="line">    fake_conf = model_d(fake_image)</span><br><span class="line">    random_sample = Weight_Addition(name='random_sample')([input_image, fake_image])</span><br><span class="line">    sample_conf = model_d(random_sample)</span><br><span class="line">    partial_gp_loss = partial(gp_loss, random_sample=random_sample)</span><br><span class="line">    partial_gp_loss.__name__ = 'gp_loss'</span><br><span class="line">    model_discriminator = keras.Model([input_image, input_noise_d], [real_conf, fake_conf, sample_conf], name='WGAN-GP-discriminator')</span><br><span class="line">    model_discriminator.compile(optimizer=optimizer_d, loss=[wasserstein_loss, wasserstein_loss, partial_gp_loss], loss_weights=[1, 1, 10])</span><br><span class="line"></span><br><span class="line">    model_g.trainable = True</span><br><span class="line">    model_d.trainable = False</span><br><span class="line"></span><br><span class="line">    image = model_g(input_noise_g)</span><br><span class="line">    conf = model_d(image)</span><br><span class="line"></span><br><span class="line">    model_generator = keras.Model(input_noise_g, conf, name='WGAN-GP-generator')</span><br><span class="line">    model_generator.compile(optimizer=optimizer_g, loss=wasserstein_loss)</span><br><span class="line"></span><br><span class="line">    return model_generator, model_discriminator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gp_loss(y_true, y_pred, random_sample):</span><br><span class="line">    gradients = tf.gradients(y_pred, random_sample)[0]</span><br><span class="line">    return tf.reduce_mean((tf.norm(gradients, 2) - 1.) ** 2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def wasserstein_loss(y_true, y_pred):</span><br><span class="line"></span><br><span class="line">    return -tf.reduce_mean(y_true * y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, _), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 50</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\wgangp'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float32) / 127.5 - 1</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer_g = keras.optimizers.Adam(0.00005, 0.5)</span><br><span class="line">    optimizer_d = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line"></span><br><span class="line">    real_dmean = keras.metrics.Mean()</span><br><span class="line">    fake_dmean = keras.metrics.Mean()</span><br><span class="line">    gmean = keras.metrics.Mean()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(28, 28, 1))</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(100,))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'WGANGP-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'WGANGP-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_generator, model_discriminator = wgan_gp(input_image_shape=(28, 28, 1), input_noise_shape=(100,), model_g=model_g, model_d=model_d)</span><br><span class="line"></span><br><span class="line">    model_generator.build(input_shape=(100,))</span><br><span class="line">    model_generator.summary()</span><br><span class="line">    keras.utils.plot_model(model_generator, 'WGAN-GP-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_discriminator.build(input_shape=[(28, 28, 1), (100,)])</span><br><span class="line">    model_discriminator.summary()</span><br><span class="line">    keras.utils.plot_model(model_discriminator, 'WGAN-GP-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line">    </span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, real_image in enumerate(x_db):</span><br><span class="line">            if real_image.shape[0] != batch_size:</span><br><span class="line">                continue</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100))</span><br><span class="line"></span><br><span class="line">            real_dmean(model_discriminator([real_image, noise])[0])</span><br><span class="line">            fake_dmean(model_discriminator([real_image, noise])[1])</span><br><span class="line">            gmean(model_generator(noise))</span><br><span class="line"></span><br><span class="line">            d_loss = model_discriminator.train_on_batch([real_image, noise], [np.ones((real_image.shape[0], 1)), -np.ones((real_image.shape[0], 1)), np.zeros((real_image.shape[0], 1))])</span><br><span class="line">            g_loss = model_generator.train_on_batch(noise, np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dmean = {}, fake_dmean = {}, gmean = {}'.format(epoch, step, real_dmean.result(), fake_dmean.result(), gmean.result()))</span><br><span class="line">                real_dmean.reset_states()</span><br><span class="line">                fake_dmean.reset_states()</span><br><span class="line">                gmean.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100))</span><br><span class="line">                fake_image = model_g(fake_data)</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/wgan-gp_R.png" alt="wgan-gp"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/wgan-gp_T.png" alt="wgan-gp"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>WGAN-GP对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li>代码中使用了partial偏函数的概念，是functools中的内容，有关偏函数的使用，可以参考我的另一篇博客，Function(函数)</li>
<li><strong>本博客中的WGAN-GP是在GAN的基础上进行修改，当然小伙伴们也可以尝试在DCGAN，CGAN等模型上进行尝试</strong>。</li>
</ol>
<h1 id="WGAN-GP小结"><a href="#WGAN-GP小结" class="headerlink" title="WGAN-GP小结"></a><font size="5" color="red">WGAN-GP小结</font></h1><p>  因为<strong>WGAN-GP基本没有修改网络结构，因此网络参数和GAN完全相同</strong>，WGAN-GP在提出时对网络的损失函数进行了大量的分析，<strong>使用随机采样的思想代替权重裁剪，增加了网络的表现能力和稳定性，这种GP思想对后面生成式对抗网络的发展有着巨大的推动作用</strong>，小伙伴们可以跳过WGAN的学习，但是WGAN-GP是需要我们了解的模型。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>WGAN</title>
    <url>/2020/06/05/generative_adversarial%20WGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">WGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>WGAN(Wasserstein Generative Adversarial Networks)</strong>:于<strong>2017年</strong>提出，<strong>和LSGAN类似，没有对网络结构做太多修改，分析了GAN网络中判别器效果越好，生成器梯度消失越严重的问题，而且提出了一种新的损失函数，构建了一个更加稳定，收敛更快，质量更高的生成式对抗网络</strong>。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/wgan.png" alt="wgan"></p>
<h1 id="WGAN特点"><a href="#WGAN特点" class="headerlink" title="WGAN特点"></a><font size="5" color="red">WGAN特点</font></h1><p>  <font size="3"><strong>保持GAN的网络结构不变，将判别器网络最后的sigmoid删去</strong>。</font><br>  <font size="3"><strong>将损失函数中的log删去</strong>。</font><br>  <font size="3"><strong>每次更新判别器的参数，将参数绝对值截断到一个固定常数c</strong>。</font><br>  <font size="3"><strong>不使用基于动量的优化算法(Adam)，推荐使用RMSProp，SGD等方法</strong>。</font></p>
<h1 id="WGAN图像分析"><a href="#WGAN图像分析" class="headerlink" title="WGAN图像分析"></a><font size="5" color="red">WGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/WGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/WGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(256, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.Dense(1024, activation='relu', name='dense_relu3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.Dense(784, activation='tanh', name='dense_tanh'),</span><br><span class="line">                keras.layers.Reshape((28, 28, 1), name='reshape'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='WGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.Dense(256, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.Dense(1, name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='WGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def wgan(input_shape, model_g, model_d):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = model_g(x)</span><br><span class="line">    model_d.trainable = False</span><br><span class="line">    x = model_d(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='WGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def wasserstein_loss(y_true, y_pred):</span><br><span class="line">    return -tf.reduce_mean(y_true * y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, _), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 50</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    c = 0.01</span><br><span class="line">    save_path = r'.\wgan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float32) / 127.5 - 1</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer_g = keras.optimizers.RMSprop(0.00005)</span><br><span class="line">    optimizer_d = keras.optimizers.RMSprop(0.0002)</span><br><span class="line"></span><br><span class="line">    real_dmean = keras.metrics.Mean()</span><br><span class="line">    fake_dmean = keras.metrics.Mean()</span><br><span class="line">    gmean = keras.metrics.Mean()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.compile(optimizer=optimizer_d, loss=wasserstein_loss)</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(100,))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'WGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'WGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = wgan(input_shape=(100,), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer_g, loss=wasserstein_loss)</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(100,))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'WGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, real_image in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100))</span><br><span class="line">            fake_image = model_g(noise)</span><br><span class="line"></span><br><span class="line">            real_dmean(model_d(real_image))</span><br><span class="line">            fake_dmean(model_d(fake_image))</span><br><span class="line">            gmean(model_d(fake_image))</span><br><span class="line"></span><br><span class="line">            real_dloss = model_d.train_on_batch(real_image, np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_dloss = model_d.train_on_batch(fake_image, -np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            _ = [x.assign(tf.clip_by_value(x, -c, c)) for x in model_d.variables]</span><br><span class="line"></span><br><span class="line">            gloss = model.train_on_batch(noise, np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dmean = {}, fake_dmean = {}, gmean = {}'.format(epoch, step, real_dmean.result(), fake_dmean.result(), gmean.result()))</span><br><span class="line">                real_dmean.reset_states()</span><br><span class="line">                fake_dmean.reset_states()</span><br><span class="line">                gmean.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100))</span><br><span class="line">                fake_image = model_g(fake_data)</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/wgan_R.png" alt="wgan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/wgan_T.png" alt="wgan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>WGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li><strong>本博客中的WGAN是在GAN的基础上进行修改，当然小伙伴们也可以尝试在DCGAN，CGAN等模型上进行尝试，可能一些超参数设置的不是非常合理，所以WGAN的效果不是特别好，小伙伴们在使用时可以自己修改</strong>。</li>
</ol>
<h1 id="WGAN小结"><a href="#WGAN小结" class="headerlink" title="WGAN小结"></a><font size="5" color="red">WGAN小结</font></h1><p>  <strong>WGAN在提出时对网络的损失函数进行了大量的分析</strong>，引入W距离，Lipschitz常数等等，我不是大佬，也不对数学公式进行过多的阐述，可能我说了会让小伙伴们更加迷糊，因此<strong>有需要的小伙伴们可以去网上搜索相关资料</strong>。因为<strong>WGAN基本没有修改网络结构，因此网络参数和GAN完全相同</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>LSGAN</title>
    <url>/2020/06/04/generative_adversarial%20LSGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">LSGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>LSGAN(Least Squares Generative Adversarial Networks, 最小二乘生成式对抗网络)</strong>:于<strong>2016年</strong>提出，<strong>分析了GAN网络中使用的交叉熵损失函数时可能会导致在饱和区收敛速度太慢，而且提出了一种新的最小二乘损失函数代替，构建了一个更加稳定，收敛更快，质量更高的生成式对抗网络</strong>。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/lsgan.png" alt="acgan"></p>
<h1 id="LSGAN特点"><a href="#LSGAN特点" class="headerlink" title="LSGAN特点"></a><font size="5" color="red">LSGAN特点</font></h1><p>  <font size="3"><strong>保持GAN的网络结构不变，仅仅将判别器网络最后的sigmoid删去，并且将损失函数由二分类交叉熵修改为均方差</strong>。</font></p>
<h1 id="LSGAN图像分析"><a href="#LSGAN图像分析" class="headerlink" title="LSGAN图像分析"></a><font size="5" color="red">LSGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/LSGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/LSGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(256, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.Dense(1024, activation='relu', name='dense_relu3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.Dense(784, activation='tanh', name='dense_tanh'),</span><br><span class="line">                keras.layers.Reshape((28, 28, 1), name='reshape'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='LSGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.Dense(256, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.Dense(1, name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='LSGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def lsgan(input_shape, model_g, model_d):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = model_g(x)</span><br><span class="line">    model_d.trainable = False</span><br><span class="line">    x = model_d(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='LSGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, _), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 20</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\lsgan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float) / 127.5 - 1</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    fake_dmse = keras.metrics.MeanSquaredError()</span><br><span class="line">    gmse = keras.metrics.MeanSquaredError()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss='mse')</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(100,))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'LSGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'LSGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = lsgan(input_shape=(100,), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss='mse')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(100,))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'LSGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, real_image in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100))</span><br><span class="line">            fake_image = model_g(noise)</span><br><span class="line"></span><br><span class="line">            real_dmse(np.ones((real_image.shape[0], 1)), model_d(real_image))</span><br><span class="line">            fake_dmse(np.zeros((real_image.shape[0], 1)), model_d(fake_image))</span><br><span class="line">            gmse(np.ones((real_image.shape[0], 1)), model(noise))</span><br><span class="line"></span><br><span class="line">            real_dloss = model_d.train_on_batch(real_image, np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_dloss = model_d.train_on_batch(fake_image, np.zeros((real_image.shape[0], 1)))</span><br><span class="line">            gloss = model.train_on_batch(noise, np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dmse = {}, fake_dmse = {}, gmse = {}'.format(epoch, step, real_dmse.result(), fake_dmse.result(), gmse.result()))</span><br><span class="line">                real_dmse.reset_states()</span><br><span class="line">                fake_dmse.reset_states()</span><br><span class="line">                gmse.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100))</span><br><span class="line">                fake_image = model_g(fake_data)</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/lsgan_R.png" alt="lsgan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/lsgan_T.png" alt="lsgan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>LSGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li><strong>本博客中的LSGAN是在GAN的基础上修改了sigmoid函数和损失函数，当然小伙伴们也可以尝试在DCGAN，CGAN等模型上进行尝试</strong>。</li>
</ol>
<h1 id="LSGAN小结"><a href="#LSGAN小结" class="headerlink" title="LSGAN小结"></a><font size="5" color="red">LSGAN小结</font></h1><p>  <strong>LSGAN在提出时对网络的损失函数进行了大量的分析</strong>，我不是大佬，也不对数学公式进行过多的阐述，可能我说了会让小伙伴们更加迷糊，因此<strong>有需要的小伙伴们可以去网上搜索相关资料</strong>。因为<strong>LSGAN基本没有修改网络结构，只是更换了一个激活函数和损失函数，因此网络参数和GAN完全相同</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>COGAN</title>
    <url>/2020/06/03/generative_adversarial%20COGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">COGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>COGAN(Coupled Generative Adversarial Networks, 耦合生成式对抗网络)</strong>:于<strong>2016年</strong>发表在<strong>NIPS</strong>上，只有两个以上模型才能称之为耦合，因此COGAN中存在两个生成模型和两个判别模型，而且共用某些网络层，实现耦合效果。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/cogan.png" alt="cogan"></p>
<h1 id="COGAN特点"><a href="#COGAN特点" class="headerlink" title="COGAN特点"></a><font size="5" color="red">COGAN特点</font></h1><p>  <font size="3"><strong>引入两个GAN模型，并且共用某些网络层，实现少参数多功能的效果</strong>。</font></p>
<h1 id="COGAN图像分析"><a href="#COGAN图像分析" class="headerlink" title="COGAN图像分析"></a><font size="5" color="red">COGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/COGAN-generator1.png" alt="generator"><br><img src="/images/Generative_adversarial/COGAN-discriminator1.png" alt="discriminator"><br><img src="/images/Generative_adversarial/COGAN-COdiscriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(1568, activation='relu', name='dense_relu'),</span><br><span class="line">                keras.layers.Reshape((7, 7, 32), name='reshape'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.ReLU(name='relu1'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling1'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', name='conv2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.ReLU(name='relu2'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling2'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', name='conv3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.ReLU(name='relu3'))(x)</span><br><span class="line"></span><br><span class="line">    x1 = compose(keras.layers.Conv2D(64, (1, 1), (1, 1), 'same', name='conv_part1_4'),</span><br><span class="line">                 keras.layers.BatchNormalization(momentum=0.8, name='bn_part1_4'),</span><br><span class="line">                 keras.layers.ReLU(name='relu_part1_4'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv_part1_5'),</span><br><span class="line">                 keras.layers.BatchNormalization(momentum=0.8, name='bn_part1_5'),</span><br><span class="line">                 keras.layers.ReLU(name='relu_part1_5'),</span><br><span class="line">                 keras.layers.Conv2D(64, (1, 1), (1, 1), 'same', name='conv_part1_6'),</span><br><span class="line">                 keras.layers.BatchNormalization(momentum=0.8, name='bn_part1_6'),</span><br><span class="line">                 keras.layers.ReLU(name='relu_part1_6'),</span><br><span class="line">                 keras.layers.Conv2D(1, (1, 1), (1, 1), 'same', activation='tanh', name='conv_part1_tanh'))(x)</span><br><span class="line"></span><br><span class="line">    x2 = compose(keras.layers.Conv2D(64, (1, 1), (1, 1), 'same', name='conv_part2_4'),</span><br><span class="line">                 keras.layers.BatchNormalization(momentum=0.8, name='bn_part2_4'),</span><br><span class="line">                 keras.layers.ReLU(name='relu_part2_4'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv_part2_5'),</span><br><span class="line">                 keras.layers.BatchNormalization(momentum=0.8, name='bn_part2_5'),</span><br><span class="line">                 keras.layers.ReLU(name='relu_part2_5'),</span><br><span class="line">                 keras.layers.Conv2D(64, (1, 1), (1, 1), 'same', name='conv_part2_6'),</span><br><span class="line">                 keras.layers.BatchNormalization(momentum=0.8, name='bn_part2_6'),</span><br><span class="line">                 keras.layers.ReLU(name='relu_part2_6'),</span><br><span class="line">                 keras.layers.Conv2D(1, (1, 1), (1, 1), 'same', activation='tanh', name='conv_part2_tanh'))(x)</span><br><span class="line"></span><br><span class="line">    model_part1 = keras.Model(input_tensor, x1, name='COGAN-Generator1')</span><br><span class="line">    model_part2 = keras.Model(input_tensor, x2, name='COGAN-Generator2')</span><br><span class="line"></span><br><span class="line">    return model_part1, model_part2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    input_tensor1 = keras.layers.Input(input_shape, name='input1')</span><br><span class="line">    input_tensor2 = keras.layers.Input(input_shape, name='input2')</span><br><span class="line"></span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(64, (3, 3), (2, 2), 'same', name='conv1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.LeakyReLU(0.2, name='leakyrelu1'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (2, 2), 'same', name='conv2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.LeakyReLU(0.2, name='leakyrelu2'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (2, 2), 'same', name='conv3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.LeakyReLU(0.2, name='leakyrelu3'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='COGAN-CODiscriminator')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'COGAN-COdiscriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    x1 = model(input_tensor1)</span><br><span class="line">    x1 = keras.layers.Dense(1, activation='sigmoid', name='dense_part1_sigmoid')(x1)</span><br><span class="line"></span><br><span class="line">    model_part1 = keras.Model(input_tensor1, x1, name='COGAN-Discriminator1')</span><br><span class="line"></span><br><span class="line">    x2 = model(input_tensor2)</span><br><span class="line">    x2 = keras.layers.Dense(1, activation='sigmoid', name='dense_part2_sigmoid')(x2)</span><br><span class="line"></span><br><span class="line">    model_part2 = keras.Model(input_tensor2, x2, name='COGAN-Discriminator2')</span><br><span class="line"></span><br><span class="line">    return model_part1, model_part2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cogan(input_shape, model_g1, model_g2, model_d1, model_d2):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape)</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = model_g1(x)</span><br><span class="line">    x2 = model_g2(x)</span><br><span class="line"></span><br><span class="line">    model_d1.trainable = False</span><br><span class="line">    model_d2.trainable = False</span><br><span class="line"></span><br><span class="line">    x1 = model_d1(x1)</span><br><span class="line">    x2 = model_d1(x2)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, [x1, x2], name='COGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, _), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 20</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\cogan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float32) / 127.5 - 1</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_d1acc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_d1acc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    real_d2acc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_d2acc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    g1acc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    g2acc = keras.metrics.BinaryAccuracy()</span><br><span class="line"></span><br><span class="line">    model_d1, model_d2 = discriminator(input_shape=(28, 28, 1))</span><br><span class="line">    model_d1.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line">    model_d2.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line"></span><br><span class="line">    model_g1, model_g2 = generator(input_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g1.build(input_shape=(100,))</span><br><span class="line">    model_g1.summary()</span><br><span class="line">    keras.utils.plot_model(model_g1, 'COGAN-generator1.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_g2.build(input_shape=(100,))</span><br><span class="line">    model_g2.summary()</span><br><span class="line">    keras.utils.plot_model(model_g2, 'COGAN-generator2.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d1.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d1.summary()</span><br><span class="line">    keras.utils.plot_model(model_d1, 'COGAN-discriminator1.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d2.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d2.summary()</span><br><span class="line">    keras.utils.plot_model(model_d2, 'COGAN-discriminator2.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = cogan(input_shape=(100,), model_g1=model_g1, model_g2=model_g2, model_d1=model_d1, model_d2=model_d2)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['binary_crossentropy', 'binary_crossentropy'])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(100,))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'COGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, real_image in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100))</span><br><span class="line">            fake_image1 = model_g1(noise)</span><br><span class="line">            fake_image2 = model_g2(noise)</span><br><span class="line"></span><br><span class="line">            real_d1acc(np.ones((real_image.shape[0], 1)), model_d1(real_image))</span><br><span class="line">            fake_d1acc(np.zeros((real_image.shape[0], 1)), model_d1(fake_image1))</span><br><span class="line">            real_d2acc(np.ones((real_image.shape[0], 1)), model_d2(real_image))</span><br><span class="line">            fake_d2acc(np.zeros((real_image.shape[0], 1)), model_d2(fake_image2))</span><br><span class="line">            g1acc(np.ones((real_image.shape[0], 1)), model(noise)[0])</span><br><span class="line">            g2acc(np.ones((real_image.shape[0], 1)), model(noise)[1])</span><br><span class="line"></span><br><span class="line">            real_d1loss = model_d1.train_on_batch(real_image, np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_d1loss = model_d1.train_on_batch(fake_image1, np.zeros((real_image.shape[0], 1)))</span><br><span class="line">            real_d2loss = model_d2.train_on_batch(real_image, np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_d2loss = model_d2.train_on_batch(fake_image2, np.zeros((real_image.shape[0], 1)))</span><br><span class="line">            gloss = model.train_on_batch(noise, [np.ones((real_image.shape[0], 1)), np.ones((real_image.shape[0], 1))])</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_d1acc = {}, fake_d1acc = {}, real_d1acc = {}, fake_d1acc = {}, g1acc = {}, g2acc = {}'.format(epoch, step, real_d1acc.result(), fake_d1acc.result(), real_d2acc.result(), fake_d2acc.result(), g1acc.result(), g2acc.result()))</span><br><span class="line">                real_d1acc.reset_states()</span><br><span class="line">                fake_d1acc.reset_states()</span><br><span class="line">                real_d2acc.reset_states()</span><br><span class="line">                fake_d2acc.reset_states()</span><br><span class="line">                g1acc.reset_states()</span><br><span class="line">                g2acc.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100))</span><br><span class="line">                fake_image = model_g1(fake_data)</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/cogan_R.png" alt="cogan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/cogan_T.png" alt="cogan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>COGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li><strong>COGAN中引入了两个GAN网络，其目的不是实现一种功能，虽然在这里我是实现了一种功能，其实他们共用的目的是节约特征提取网络参数，可以让一个GAN来生成某一种图像，另一个GAN来生成另一种图像，如model_g1生成手写数字，model_g2生成镜像手写数字，如果正常训练两个GAN模型，分别生成手写数字和镜像手写数字，同样的网络结构需要1.2M的参数量，而耦合之后的参数量约为0.6M，而且模型越大效果越明显</strong>。</li>
</ol>
<h1 id="COGAN小结"><a href="#COGAN小结" class="headerlink" title="COGAN小结"></a><font size="5" color="red">COGAN小结</font></h1><p>  COGAN是一种有效的耦合生成式对抗网络，从上图可以看出<strong>COGAN模型的参数量只有0.6M</strong>，是一种可以同时完成多任务的网络模型，小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>ACGAN</title>
    <url>/2020/06/01/generative_adversarial%20ACGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">ACGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>ACGAN(Auxiliary Classifier Generative Adversarial Networks, 辅助分类器生成式对抗网络)</strong>:于<strong>2016年</strong>提出，是CGAN类型网络的升级版本，<strong>引入了Embedding层对类别标签进行处理，而且增加了类别分类网络</strong>，因此称之为辅助分类器生成式对抗网络。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/acgan.png" alt="acgan"></p>
<h1 id="ACGAN特点"><a href="#ACGAN特点" class="headerlink" title="ACGAN特点"></a><font size="5" color="red">ACGAN特点</font></h1><p>  <font size="3"><strong>类似于DCGAN和CGAN的结合，将卷积使用在CGAN网络之中</strong>。</font><br>  <font size="3"><strong>引入了Embedding层对类别标签进行处理，Embedding层可以将输入的数字转化为一维向量</strong>。</font><br>  <font size="3"><strong>判别器中不但对真假置信度进行loss计算，而且使用了辅助类别分类器，对判别出的类别进行loss计算</strong>。</font></p>
<h1 id="ACGAN图像分析"><a href="#ACGAN图像分析" class="headerlink" title="ACGAN图像分析"></a><font size="5" color="red">ACGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/ACGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/ACGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_label_shape, input_noise_shape):</span><br><span class="line">    label = keras.layers.Input(input_label_shape, name='input_label')</span><br><span class="line">    label_tensor = compose(keras.layers.Embedding(10, 100, name='embedding'),</span><br><span class="line">                           keras.layers.Flatten(name='flatten'))(label)</span><br><span class="line">    noise = keras.layers.Input(input_noise_shape, name='input_noise')</span><br><span class="line">    x = keras.layers.Multiply(name='multiply')([label_tensor, noise])</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(1568, activation='relu', name='dense_relu'),</span><br><span class="line">                keras.layers.Reshape((7, 7, 32), name='reshape'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.ReLU(name='relu1'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling1'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', name='conv2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.ReLU(name='relu2'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling2'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.ReLU(name='relu3'),</span><br><span class="line">                keras.layers.Conv2D(1, (3, 3), (1, 1), 'same', activation='tanh', name='conv_tanh'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([noise, label], x, name='ACGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(32, (3, 3), (2, 2), 'same'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8),</span><br><span class="line">                keras.layers.LeakyReLU(0.2),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (2, 2), 'same'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8),</span><br><span class="line">                keras.layers.LeakyReLU(0.2),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (2, 2), 'same'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8),</span><br><span class="line">                keras.layers.LeakyReLU(0.2),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'))(x)</span><br><span class="line"></span><br><span class="line">    conf = keras.layers.Dense(1, activation='sigmoid', name='dense_sigmoid')(x)</span><br><span class="line">    label = keras.layers.Dense(10, activation='softmax', name='dense_softmax')(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, [conf, label], name='ACGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def acgan(input_label_shape, input_noise_shape, model_g, model_d):</span><br><span class="line">    label = keras.layers.Input(input_label_shape, name='input_label')</span><br><span class="line">    noise = keras.layers.Input(input_noise_shape, name='input_noise')</span><br><span class="line"></span><br><span class="line">    x = model_g([noise, label])</span><br><span class="line">    model_d.trainable = False</span><br><span class="line">    conf, pred_label = model_d(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([noise, label], [conf, pred_label], name='ACGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, y), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 20</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\acgan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float32) / 127.5 - 1</span><br><span class="line">    y = y[..., np.newaxis]</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    gacc = keras.metrics.BinaryAccuracy()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss=['binary_crossentropy', 'sparse_categorical_crossentropy'])</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_label_shape=(1,), input_noise_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=[(1,), (100,)])</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'ACGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'ACGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = acgan(input_label_shape=(1,), input_noise_shape=(100,), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['binary_crossentropy', 'sparse_categorical_crossentropy'])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=[(1,), (100,)])</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'ACGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, (real_image, real_label) in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100)).astype(np.float32)</span><br><span class="line">            fake_label = np.random.randint(0, 10, (real_image.shape[0], 1))</span><br><span class="line"></span><br><span class="line">            fake_image = model_g([noise, fake_label])</span><br><span class="line"></span><br><span class="line">            real_dacc(np.ones((real_image.shape[0], 1)), model_d(real_image)[0])</span><br><span class="line">            fake_dacc(np.zeros((real_image.shape[0], 1)), model_d(fake_image)[0])</span><br><span class="line">            gacc(np.ones((real_image.shape[0], 1)), model([noise, fake_label])[0])</span><br><span class="line"></span><br><span class="line">            real_dloss = model_d.train_on_batch(real_image, [np.ones((real_image.shape[0], 1)), real_label])</span><br><span class="line">            fake_dloss = model_d.train_on_batch(fake_image, [np.zeros((real_image.shape[0], 1)), fake_label])</span><br><span class="line">            gloss = model.train_on_batch([noise, fake_label], [np.ones((real_image.shape[0], 1)), fake_label])</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dacc = {}, fake_dacc = {}, gacc = {}'.format(epoch, step, real_dacc.result(), fake_dacc.result(), gacc.result()))</span><br><span class="line">                real_dacc.reset_states()</span><br><span class="line">                fake_dacc.reset_states()</span><br><span class="line">                gacc.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100)).astype(np.float32)</span><br><span class="line">                fake_label = np.array(list(range(10)) * 10).reshape((-1, 1))</span><br><span class="line">                fake_image = model_g([fake_data, fake_label])</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/acgan_R.png" alt="acgan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/acgan_T.png" alt="acgan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>ACGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li><strong>ACGAN中引入了Embedding层，并且使用乘法将标签结合在输入随机数之中，这样可以避免标签数远远小于随机数的维度造成的灾难</strong>，因为CGAN中的生成器是采用Concatenate的方式将其结合，但是如果随机数为100维，而类别只有2类，则类别的影响会非常小。而且<strong>采用了卷积层的方式减少了使用全连接层的参数</strong>，<strong>使用辅助分类器对判别器输出的类别标签进行分类，更有效的完成不同类别图像的生成</strong>。</li>
</ol>
<h1 id="ACGAN小结"><a href="#ACGAN小结" class="headerlink" title="ACGAN小结"></a><font size="5" color="red">ACGAN小结</font></h1><p>  ACGAN是一种有效的生成式对抗网络，从上图可以看出<strong>ACGAN模型的参数量只有0.4M</strong>，和DCGAN参数量几乎相同，相比于CGAN，减少了参数量，而且效果有显著的提升，小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>CGAN</title>
    <url>/2020/05/31/generative_adversarial%20CGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">CGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>CGAN(Conditional Generative Adversarial Networks, 条件生成式对抗网络)</strong>:于<strong>2014年</strong>提出，<strong>引入标签变量，可以通过控制其标签变量的值，产生不同类别的图像</strong>，其网络结构和GAN基本类似，只是多了一些条件变量的处理。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/cgan.png" alt="cgan"></p>
<h1 id="CGAN特点"><a href="#CGAN特点" class="headerlink" title="CGAN特点"></a><font size="5" color="red">CGAN特点</font></h1><p>  <font size="3"><strong>生成器的输入有两个，一个是随机数，一个是标签数据的one-hot编码形式，利用Concatenate层将两个输入融合</strong>。</font><br>  <font size="3"><strong>判别器的输入也有两个，一个是输入图像，一个是标签数据的one-hot编码形式，首先利用Flatten将输入图像转化维一维向量，然后利用Concatenate层将两个输入融合</strong>。</font></p>
<h1 id="CGAN图像分析"><a href="#CGAN图像分析" class="headerlink" title="CGAN图像分析"></a><font size="5" color="red">CGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/CGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/CGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_label_shape, input_noise_shape):</span><br><span class="line">    label = keras.layers.Input(input_label_shape, name='input_label')</span><br><span class="line">    noise = keras.layers.Input(input_noise_shape, name='input_noise')</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='concatenate')([noise, label])</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(256, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.Dense(1024, activation='relu', name='dense_relu3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.Dense(784, activation='tanh', name='dense_tanh'),</span><br><span class="line">                keras.layers.Reshape((28, 28, 1), name='reshape'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([noise, label], x, name='CGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_image_shape, input_label_shape):</span><br><span class="line">    label = keras.layers.Input(input_label_shape, name='input_label')</span><br><span class="line">    image = keras.layers.Input(input_image_shape, name='input_image')</span><br><span class="line"></span><br><span class="line">    image_tensor = keras.layers.Flatten(name='flatten')(image)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='concatenate')([image_tensor, label])</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(512, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.Dense(256, activation='relu', name='dense_relu2'))(x)</span><br><span class="line"></span><br><span class="line">    conf = keras.layers.Dense(1, activation='sigmoid', name='dense_sigmoid')(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model([image, label], conf, name='CGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cgan(input_noise_shape, input_label_shape, model_g, model_d):</span><br><span class="line">    label = keras.layers.Input(input_label_shape, name='input_label')</span><br><span class="line">    noise = keras.layers.Input(input_noise_shape, name='input_noise')</span><br><span class="line"></span><br><span class="line">    x = model_g([noise, label])</span><br><span class="line">    model_d.trainable = False</span><br><span class="line">    conf = model_d([x, label])</span><br><span class="line"></span><br><span class="line">    model = keras.Model([noise, label], conf, name='CGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, y), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 20</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\cgan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float32) / 127.5 - 1</span><br><span class="line">    y = tf.one_hot(y, depth=10)</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    gacc = keras.metrics.BinaryAccuracy()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_image_shape=(28, 28, 1), input_label_shape=(10,))</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss=['binary_crossentropy'])</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_noise_shape=(100,), input_label_shape=(10,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=[(100,), (10,)])</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'CGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=[(28, 28, 1), (10,)])</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'CGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = cgan(input_noise_shape=(100,), input_label_shape=(10,), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss=['binary_crossentropy'])</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=[(100,), (10,)])</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'CGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, (real_image, real_label) in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100)).astype(np.float32)</span><br><span class="line">            fake_label = tf.one_hot(np.random.randint(0, 10, (real_image.shape[0])), depth=10)</span><br><span class="line"></span><br><span class="line">            fake_image = model_g([noise, fake_label])</span><br><span class="line"></span><br><span class="line">            real_dacc(np.ones((real_image.shape[0], 1)), model_d([real_image, real_label]))</span><br><span class="line">            fake_dacc(np.zeros((real_image.shape[0], 1)), model_d([fake_image, fake_label]))</span><br><span class="line">            gacc(np.ones((real_image.shape[0], 1)), model([noise, fake_label]))</span><br><span class="line"></span><br><span class="line">            real_dloss = model_d.train_on_batch([real_image, real_label], np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_dloss = model_d.train_on_batch([fake_image, fake_label], np.zeros((real_image.shape[0], 1)))</span><br><span class="line">            gloss = model.train_on_batch([noise, fake_label], np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dacc = {}, fake_dacc = {}, gacc = {}'.format(epoch, step, real_dacc.result(), fake_dacc.result(), gacc.result()))</span><br><span class="line">                real_dacc.reset_states()</span><br><span class="line">                fake_dacc.reset_states()</span><br><span class="line">                gacc.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100)).astype(np.float32)</span><br><span class="line">                fake_label = tf.one_hot(np.array(list(range(10)) * 10), depth=10)</span><br><span class="line">                fake_image = model_g([fake_data, fake_label])</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/cgan_R.png" alt="cgan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/cgan_T.png" alt="cgan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>CGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li><strong>CGAN的网络结构和GAN基本相同，因此也只适合小图像的生成</strong>，其中<strong>生成器使用Concatenate实现标签数据和输入随机数的结合，判别器使用Concatenate实现标签数据和输入图像的结合，一定要注意首先要对图像进行Flatten处理，否则会出错</strong>。</li>
</ol>
<h1 id="CGAN小结"><a href="#CGAN小结" class="headerlink" title="CGAN小结"></a><font size="5" color="red">CGAN小结</font></h1><p>  CGGAN是一种简单的生成式对抗网络，从上图可以看出<strong>CGAN模型的参数量只有2M</strong>，和普通的GAN网络差不多，<strong>通过CGAN可以实现指定类别的图像生成，不再是完全的随机数产生，因此对于实际的工程应用是有意义的</strong>，值得小伙伴们学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>DCGAN</title>
    <url>/2020/05/29/generative_adversarial%20DCGAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">DCGAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>DCGAN(Deep Convolutional Generative Adversarial Networks, 深度卷积生成式对抗网络):</strong>于<strong>2016年</strong>发表于ICLR，是GAN类型网络的升级版本，其中改变的只是<strong>将GAN中的全连接层变为卷积层和上采样层，这样可以使用更少的参数实现更大像素图像的生成</strong>。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/dcgan.png" alt="Dataset"></p>
<h1 id="DCGAN特点"><a href="#DCGAN特点" class="headerlink" title="DCGAN特点"></a><font size="5" color="red">DCGAN特点</font></h1><p>  <font size="3"><strong>将全连接层换成了卷积层和上采样层，极大缩小参数量，可以实现大尺寸图像的生成</strong>。</font></p>
<h1 id="DCGAN图像分析"><a href="#DCGAN图像分析" class="headerlink" title="DCGAN图像分析"></a><font size="5" color="red">DCGAN图像分析</font></h1><p><img src="/images/Generative_adversarial/DCGAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/DCGAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(1568, activation='relu', name='dense_relu'),</span><br><span class="line">                keras.layers.Reshape((7, 7, 32), name='reshape'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.ReLU(name='relu1'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling1'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', name='conv2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.ReLU(name='relu2'),</span><br><span class="line">                keras.layers.UpSampling2D((2, 2), name='upsampling2'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', name='conv3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.ReLU(name='relu3'),</span><br><span class="line">                keras.layers.Conv2D(1, (3, 3), (1, 1), 'same', activation='tanh', name='conv_tanh'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='DCGAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(32, (3, 3), (2, 2), 'same', name='conv1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.LeakyReLU(0.2, name='leakyrelu1'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (2, 2), 'same', name='conv2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.LeakyReLU(0.2, name='leakyrelu2'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (2, 2), 'same', name='conv3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.LeakyReLU(0.2, name='leakyrelu3'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1, activation='sigmoid', name='dense_sigmoid'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='DCGAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dcgan(input_shape, model_g, model_d):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape)</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = model_g(x)</span><br><span class="line">    model_d.trainable = False</span><br><span class="line">    x = model_d(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='DCGAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, _), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 20</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\dcgan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float32) / 127.5 - 1</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    gacc = keras.metrics.BinaryAccuracy()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(100,))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'DCGAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'DCGAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = dcgan(input_shape=(100,), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(100,))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'DCGAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, real_image in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100))</span><br><span class="line">            fake_image = model_g(noise)</span><br><span class="line"></span><br><span class="line">            real_dacc(np.ones((real_image.shape[0], 1)), model_d(real_image))</span><br><span class="line">            fake_dacc(np.zeros((real_image.shape[0], 1)), model_d(fake_image))</span><br><span class="line">            gacc(np.ones((real_image.shape[0], 1)), model(noise))</span><br><span class="line"></span><br><span class="line">            real_dloss = model_d.train_on_batch(real_image, np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_dloss = model_d.train_on_batch(fake_image, np.zeros((real_image.shape[0], 1)))</span><br><span class="line">            gloss = model.train_on_batch(noise, np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dacc = {}, fake_dacc = {}, gacc = {}'.format(epoch, step, real_dacc.result(), fake_dacc.result(), gacc.result()))</span><br><span class="line">                real_dacc.reset_states()</span><br><span class="line">                fake_dacc.reset_states()</span><br><span class="line">                gacc.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100))</span><br><span class="line">                fake_image = model_g(fake_data)</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/dcgan_R.png" alt="gan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/dcgan_T.png" alt="gan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>DCGAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
</ol>
<h1 id="DCGAN小结"><a href="#DCGAN小结" class="headerlink" title="DCGAN小结"></a><font size="5" color="red">DCGAN小结</font></h1><p>  DCGAN是一种非常简单的生成式对抗网络，从上图可以看出<strong>DCGAN模型的参数量只有0.4M，这样使得大图像的生成变得可能</strong>，DCGAN没有特别的创新点，运用了深度卷积在初代GAN上，为以后GAN的发展提供了思路。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>GAN</title>
    <url>/2020/05/27/generative_adversarial%20GAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">GAN</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>GAN(Generative Adversarial Networks, 生成式对抗网络):</strong>是GAN类型网络的初代版本，<strong>据说是Ian Goodfellow在2014年喝了一杯啤酒之后，在梦中产生的想法</strong>，我不禁感叹，大佬就是大佬啊，虽然现在这是最简单的生成式对抗网络模型，其效果也被很多模型超越，但是它的思想值得我们学习。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/gan.png" alt="gan"></p>
<h1 id="GAN特点"><a href="#GAN特点" class="headerlink" title="GAN特点"></a><font size="5" color="red">GAN特点</font></h1><p>  <font size="3"><strong>只采用了全连接层和ReLU激活函数，没有使用卷积层对图像进行处理</strong>。</font><br>  <font size="3"><strong>生成器的输出使用tanh，产生[-1, 1]的图像，判别器的输出使用sigmoid，产生真或者假的逻辑值</strong>。</font></p>
<h1 id="GAN图像分析"><a href="#GAN图像分析" class="headerlink" title="GAN图像分析"></a><font size="5" color="red">GAN图像分析</font></h1><p><img src="/images/Generative_adversarial/GAN-generator.png" alt="generator"><br><img src="/images/Generative_adversarial/GAN-discriminator.png" alt="discriminator"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dense(256, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn1'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn2'),</span><br><span class="line">                keras.layers.Dense(1024, activation='relu', name='dense_relu3'),</span><br><span class="line">                keras.layers.BatchNormalization(momentum=0.8, name='bn3'),</span><br><span class="line">                keras.layers.Dense(784, activation='tanh', name='dense_tanh'),</span><br><span class="line">                keras.layers.Reshape((28, 28, 1)))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='GAN-Generator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def discriminator(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(512, activation='relu', name='dense_relu1'),</span><br><span class="line">                keras.layers.Dense(256, activation='relu', name='dense_relu2'),</span><br><span class="line">                keras.layers.Dense(1, activation='sigmoid', name='dense_sigmoid'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='GAN-Discriminator')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gan(input_shape, model_g, model_d):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = model_g(x)</span><br><span class="line">    model_d.trainable = False</span><br><span class="line">    x = model_d(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='GAN')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, save_path, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line">    cv.imwrite(save_path, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, _), (_, _) = keras.datasets.mnist.load_data()</span><br><span class="line">    batch_size = 256</span><br><span class="line">    epochs = 20</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    save_path = r'.\gan'</span><br><span class="line">    if not os.path.exists(save_path):</span><br><span class="line">        os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">    x = x[..., np.newaxis].astype(np.float) / 127.5 - 1</span><br><span class="line">    x = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(0.0002, 0.5)</span><br><span class="line">    loss = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    real_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    fake_dacc = keras.metrics.BinaryAccuracy()</span><br><span class="line">    gacc = keras.metrics.BinaryAccuracy()</span><br><span class="line"></span><br><span class="line">    model_d = discriminator(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line"></span><br><span class="line">    model_g = generator(input_shape=(100,))</span><br><span class="line"></span><br><span class="line">    model_g.build(input_shape=(100,))</span><br><span class="line">    model_g.summary()</span><br><span class="line">    keras.utils.plot_model(model_g, 'GAN-generator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model_d.build(input_shape=(28, 28, 1))</span><br><span class="line">    model_d.summary()</span><br><span class="line">    keras.utils.plot_model(model_d, 'GAN-discriminator.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    model = gan(input_shape=(100,), model_g=model_g, model_d=model_d)</span><br><span class="line">    model.compile(optimizer=optimizer, loss='binary_crossentropy')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(100,))</span><br><span class="line">    model.summary()</span><br><span class="line">    keras.utils.plot_model(model, 'GAN.png', show_shapes=True, show_layer_names=True)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        x = x.shuffle(np.random.randint(0, 10000))</span><br><span class="line">        x_db = iter(x)</span><br><span class="line"></span><br><span class="line">        for step, real_image in enumerate(x_db):</span><br><span class="line">            noise = np.random.normal(0, 1, (real_image.shape[0], 100))</span><br><span class="line">            fake_image = model_g(noise)</span><br><span class="line"></span><br><span class="line">            real_dacc(np.ones((real_image.shape[0], 1)), model_d(real_image))</span><br><span class="line">            fake_dacc(np.zeros((real_image.shape[0], 1)), model_d(fake_image))</span><br><span class="line">            gacc(np.ones((real_image.shape[0], 1)), model(noise))</span><br><span class="line"></span><br><span class="line">            real_dloss = model_d.train_on_batch(real_image, np.ones((real_image.shape[0], 1)))</span><br><span class="line">            fake_dloss = model_d.train_on_batch(fake_image, np.zeros((real_image.shape[0], 1)))</span><br><span class="line">            gloss = model.train_on_batch(noise, np.ones((real_image.shape[0], 1)))</span><br><span class="line"></span><br><span class="line">            if step % 20 == 0:</span><br><span class="line">                print('epoch = {}, step = {}, real_dacc = {}, fake_dacc = {}, gacc = {}'.format(epoch, step, real_dacc.result(), fake_dacc.result(), gacc.result()))</span><br><span class="line">                real_dacc.reset_states()</span><br><span class="line">                fake_dacc.reset_states()</span><br><span class="line">                gacc.reset_states()</span><br><span class="line">                fake_data = np.random.normal(0, 1, (100, 100))</span><br><span class="line">                fake_image = model_g(fake_data)</span><br><span class="line">                save_picture(fake_image.numpy(), save_path + '\\epoch{}_step{}.jpg'.format(epoch, step), 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Generative_adversarial/gan_R.png" alt="gan"></p>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Generative_adversarial/gan_T.png" alt="gan"></p>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>可以设置一些<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li><strong>GAN对于网络结构，优化器参数，网络层的一些超参数都是非常敏感的，效果不好不容易发现原因，这可能需要较多的工程实践经验</strong>。</li>
<li><strong>先创建判别器，然后进行compile，这样判别器就固定了，然后创建生成器时，不要训练判别器，需要将判别器的trainable改成False，此时不会影响之前固定的判别器</strong>，这个可以<strong>通过模型的_collection_collected_trainable_weights属性查看</strong>，如果该属性为空，则模型不训练，否则模型可以训练，compile之后，该属性固定，无论后面如何修改trainable，只要不重新compile，都不影响训练。</li>
<li><strong>因为全都是全连接层，GAN适用于小目标的生成</strong>，如果是一个512x512x3的图像的生成，使用全连接层，那么就需要786432个神经元，上一层的神经元数目应该更多，设为1048576个，那么这两层之间全连接的参数量为八千多亿个，这是非常不现实的，而且效果也会特别差。</li>
</ol>
<h1 id="GAN小结"><a href="#GAN小结" class="headerlink" title="GAN小结"></a><font size="5" color="red">GAN小结</font></h1><p>  GAN是一种非常简单的生成式对抗网络，从上图可以看出<strong>GAN模型的参数量只有2M</strong>，虽然现在GAN网络不是最好的生成式对抗网络，但是其网络对抗思想，对后面的深度学习网络的发展有重要的影响。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>生成式对抗网络数据集</title>
    <url>/2020/05/25/generative_adversarial%20Dataset/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Data Set</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Generative Adversarial Networks(GAN, 生成式对抗网络):</strong>是一类深度学习模型，也是计算机视觉的<strong>新晋成员</strong>，由<strong>Ian J. Goodfellow在2014年10月</strong>提出，<strong>短短5年多的时间，已经有成百上千种不同的GAN网络被提出，可以说GAN的提出受到了广泛的关注</strong>。现在的GAN不仅仅只是生成网络，而其应用更是越来越广泛，包括<strong>图像生成</strong>，<strong>超分辨率提升</strong>，<strong>风格迁移</strong>等等。而且GAN的使用非常有趣，可以带领我们目睹从0到1的变化趋势。<br><a id="more"></a></p>
<p><img src="/images/Generative_adversarial/Dataset.png" alt="Dataset"></p>
<h1 id="GAN的理论"><a href="#GAN的理论" class="headerlink" title="GAN的理论"></a><font size="5" color="red">GAN的理论</font></h1><p>生成式对抗网络，顾名思义，在对抗中生成图像，其<strong>灵感来源于博弈论</strong>，这里不做太多的数学公式推导，只是简单描述GAN的工作机理。既然提到对抗，当然GAN网络不是一个模型，而是两个模型，其中一个称之为<strong>Generator(生成器)</strong>，负责生成图像，另一个称之为<strong>Discriminator(判别器)</strong>，负责对生成的图像进行打分，它们两者进行对抗和博弈。</p>
<font color="red">假如你是一个刚学习做饭的新手，我想做出来一道精美的饭菜，这不是天方夜谭吗？但是我有一个不嫌弃我做饭难吃的好朋友小明，他也不是一个专业的评委，他每天中午在五星大酒店吃饭，然后晚上来我家吃我做的饭，是不是一脸黑人问号？不过不用纠结小明和我之间的py交易，但是小明并不会做饭，不能够亲自知道我如何操作，而是告诉我哪里欠缺。于是乎我开始了自己的尝试。第一天小明中午吃大酒店之后，晚上来我家吃饭，他很轻松的分辨出了我做的不如酒店好吃，并且告诉我盐放多了。于是乎我下一次少放点盐。第二天小明中午吃了大酒店之后，晚上来我家，也很轻松的分辨出了我做的不好吃，并且告诉我这次油放少了。于是乎我下一次多放一点油。第三天，第四天。。。一直到一年以后，我做饭的技术越来越好，小明很难从中发现问题，认为我做的和大酒店做的很像，小明越来越认真的区分我做的和酒店之间的差距，他的目标是将酒店做的都全部分成一类，将我做的菜都分成一类，而我越来越认真的对自己的厨艺进行改进，我的目标是让小明将我做的菜分成酒店那一类。就这样我们在相互学习中提升自己，5年以后，我成了一名米其林厨师，而小明成为了一名美食鉴赏专家。好了，故事讲完了，GAN的理论也结束了，我在GAN中就扮演生成器的角色，而小明则是一个判别器的角色。</font>

<h1 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a><font size="5" color="red">数据集介绍</font></h1><p><strong>数据集</strong>：因为GAN的任务很多，包括<strong>图像生成，包括分辨率提升，风格迁移</strong>等等，为了方便模型调试的方便，在我的博客中使用到了三个数据集。</p>
<p>第一个是大家的老朋友，也是入门深度学习一定会接触的mnist手写数字数据集，带我们见证如何从杂乱无章的数据生成手写数字的过程。<br>简单介绍一下mnist数据集，在tensorflow2.0中，<strong>不需要专门下载，已经给我们提供了手写数字的函数，位于tf.keras.datasets.mnist.load_data()，返回值为两个元组，第一个为训练数据和训练标签，第二个为测试数据和测试标签。训练数据大小为60000张图像，每张图像为28x28的大小，标签为[0, 9]的稀疏表示，非one-hot编码形式。测试集大小为10000张图像，大小格式和训练集相同</strong>。<br><img src="/images/Generative_adversarial/mnist.png" alt="mnist"></p>
<p>第二个数据集是monet2photo数据集，<strong>用来测试SRGAN, CycleGAN的算法正确性，SRGAN是一种超分辨率算法，CycleGAN是一种风格迁移算法</strong>。<br>简单介绍一下monet2photo数据集，<strong>monet指莫奈风格的画作，photo指拍摄的图像，用于将两张图片的风格进行迁移</strong>，<strong>SRGAN使用了photo图像进行分辨率的提升</strong>。其中monet训练集包括1072张图像，位于trainA文件夹中，测试集包括121张图像，位于testA文件夹中，photo训练集包括6287张图像，位于trainB文件夹中，测试集包括751张图像，位于testB文件夹中，其中图像都是jpg文件，大小都是256x256的。<br><img src="/images/Generative_adversarial/monet2photo.png" alt="monet2photo"></p>
<p>第三个数据集是edges2shoes数据集，<strong>用来测试DiscoGAN和pix2pix的算法正确性，其中DiscoGAN和pix2pix都是风格迁移算法，由于损失函数的计算和CycleGAN不同，因此需要的数据集也不同</strong>。<br>也简单介绍一下edges2shoes数据集，<strong>edges指鞋子的轮廓，shoes指鞋子的图像，其中用于将两张图片的风格进行迁移，特点是相同的图像，只是风格不同，两张图像存放于一个文件中，左边是风格A，右边是风格B，而monet2photo两张图像不但风格不同，而且图像本身也不同，每个图像文件只保存一张图像</strong>，其中edges2shoes训练集包括49825张图像，位于train文件夹中，测试集包括200张图像，位于val文件夹中，其中图像都是jpg文件，大小都是512x256的。<br><img src="/images/Generative_adversarial/edges.png" alt="edges2shoes"></p>
<h1 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a><font size="5" color="red">一些说明</font></h1><ol>
<li>在学习的时候，小伙伴可能会遇到一些代码上的困难，如<strong>tensorflow</strong>，<strong>numpy</strong>，<strong>opencv</strong>的用法，可以查看我的深度学习框架和Python常用库相关文章，里面会有一些简单的介绍，小伙伴们可以进行学习，最好是手动敲一敲，看一看。</li>
<li>因为这个博客是对学习的一些总结和记录，意在和学习者探讨和交流，并且给准备入门的同学一些手把手的教学，因此关于生成式对抗网络的算法参数设计，我都是自己尝试的，不是针对于这个数据集最优的参数，大家可以<strong>根据自己的实际需要修改网络结构</strong>，但是<strong>生成式对抗网络是非常sensitive的，可能调整了一些参数以后，网络模型不收敛，得到完全超出预料的结果，这都是正常的，因此这也需要小伙伴们具有非常丰富的实战经验</strong>。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
<li>为了让学习者看的方便和清晰，我没有使用多个文件对程序进行封装，因为我在刚开始学习模型的时候，查看GitHub代码，一个模型可能需要好几个文件夹，每个文件夹里面又有很多的代码文件，其中很多文件互相调用。虽然这样的工程项目是非常好管理和运行的，但是给初学者一种丈二和尚摸不着头脑的感觉，对此我深有体会。所以我就使用一个.py文件来封装，因此代码可能会有几百行，但是其中的各个函数和类都有自己的名字，可以保证学习者不会被纸老虎吓住。</li>
<li>在生成式对抗网络学习中，我会列举出一些经典的生成式对抗网络模型，因为模型太多，并且仍在不断的更新进步之中，所以大家可以联系我，和我进行沟通和交流，或者推荐给我一些优秀的模型。</li>
<li>关于问题的交流，图像的数据，需要的同学可以到主页查看我的QQ或者邮箱，我会非常荣幸的提供力所能及的帮助，小伙伴加好友的时候一定要记得备注，不然我可能会忽视一些粗心的小伙伴。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>生成式对抗网络</strong>是计算机视觉的<strong>新晋成员</strong>，也是非常具有前景的任务之一，而且现在的网络模型的功能也越来越多，不仅仅是用于图像生成，而是运用于各种实际工程应用之中。自从深度学习的时代到来，各种神经网络结构百花齐放，很难说出最好的生成式对抗网络模型，可能一个模型适用于很多数据，但也<strong>不能说明某一个算法一定优于另一个算法</strong>，我们要做的就是尽可能多的<strong>学习各种各样的深度学习模型</strong>，然后<strong>吸取这些模型成功的原因</strong>，投入到自己的工程应用之中。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>生成式对抗网络</category>
      </categories>
  </entry>
  <entry>
    <title>熵，交叉熵，相对熵的关系</title>
    <url>/2020/05/24/deep%20learning%20entropy/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Entropy &amp; Cross Entropy &amp; Relative Entropy</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Entropy, Cross Entropy, Relative Entropy(熵，交叉熵，相对熵)</strong>:在机器学习或者深度学习的过程中，避免不了与熵接触，但是熵是什么，小伙伴们是否有很多问号？感觉是那么回事，但是又无法说清楚。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/entropy.png" alt="entropy"></p>
<h1 id="Entropy-熵"><a href="#Entropy-熵" class="headerlink" title="Entropy(熵)"></a><font size="5" color="red">Entropy(熵)</font></h1><p><strong>Entropy(熵)</strong>：在<strong>计算机，通信领域指的是Information Entropy(信息熵)</strong>，信息熵<strong>代表随机变化或者系统的不确定性，熵越大则随机变量或系统的不确定性就越大</strong>，如何理解呢？我们可以<strong>根据分布，找到一个最优策略，信息熵就是使用最优策略衡量这个分布所花费的代价</strong>。用公式表示为</p>
<script type="math/tex; mode=display">H(p) = -\sum_{x}^{\ }{p(x)log_{2}(p(x))}</script><p>其中p为随机变化或者系统的分布函数。<br>举个例子说明，假如一个袋子里面有两个红球，一个白球，一个蓝球，取出一个球是什么颜色，问这个系统的信息熵为多少？计算步骤为</p>
<script type="math/tex; mode=display">H = -\frac{1}{2} \times log_{2}\frac{1}{2} -\frac{1}{4} \times log_{2}\frac{1}{4} -\frac{1}{4} \times log_{2}\frac{1}{4} = 1.5</script><p>如何理解这个结果呢？我们按照最优策略进行代价计算，最优策略是花费一次机会猜红球，猜对了概率为0.5，如果猜错了则还需要花费一次机会猜白球或者蓝球，因此总代价为0.5 x 1 + 0.5 x 2 = 1.5。<br>如果有四个球，一个红球，一个蓝球，一个白球，一个黄球，则系统的信息熵则是</p>
<script type="math/tex; mode=display">H = -\frac{1}{4} \times log_{2}\frac{1}{4} -\frac{1}{4} \times log_{2}\frac{1}{4} -\frac{1}{4} \times log_{2}\frac{1}{4} -\frac{1}{4} \times log_{2}\frac{1}{4} = 2</script><p>也很好理解，首先猜是否为红球或者蓝球，如果是，概率为0.5，再猜是否为红色，概率为0.25，所需要的代价为两次机会，其他的球同理，则总代价为0.25 x 2 x 4 = 2。<br>那么如果有四个球，全为红色，系统的信息熵为多少呢？</p>
<script type="math/tex; mode=display">H = -log_{2}1 = 0</script><p>只有红球，我根本不需要任何代价就可以消除系统的不确定性，因此信息熵为0。<br>我第一次接触信息熵时是有点懵的，如果明天一定下雨，信息量为0，明天有50%的可能下雨，信息熵最大，等于1。是不是有点怪怪的，这不是废话吗？这对我来说有啥价值？其实不是这样，信息熵和我们的直观感觉不同，直观感觉只有确定的事情才有意义，而信息熵衡量的就是系统的不确定性，因此有种反人类的感觉。</p>
<h1 id="Cross-Entropy-交叉熵"><a href="#Cross-Entropy-交叉熵" class="headerlink" title="Cross Entropy(交叉熵)"></a><font size="5" color="red">Cross Entropy(交叉熵)</font></h1><p><strong>Cross Entropy(交叉熵)</strong>：<strong>代表两个概率分布之间的差异性信息</strong>。如何理解呢？<strong>交叉熵就是使用预测分布的最佳策略衡量真实分布所花费的代价，这个值一定是大于等于信息熵的</strong>，用公式表示为</p>
<script type="math/tex; mode=display">H(p, q) = -\sum_{x}^{\ }{p(x)log_{2}(q(x))}</script><p>其中p为真实分布函数，q为预测分布函数。<br>用之前的例子说明，假如一个袋子里面有两个红球，一个白球，一个蓝球，预测结果为一个红球，两个白球，一个蓝球，问交叉熵有多少？计算步骤为</p>
<script type="math/tex; mode=display">H = -\frac{1}{2} \times log_{2}\frac{1}{4} -\frac{1}{4} \times log_{2}\frac{1}{2} -\frac{1}{4} \times log_{2}\frac{1}{4} = 1.75</script><p>如何理解这个结果呢？我们<strong>使用预测分布的最优策略按照真实分布的概率，进行代价计算</strong>，<strong>交叉熵越低，则预测分布越接近真实分布，当两个分布相同时，交叉熵等于信息熵，因此在分类函数常常使用交叉熵作为Loss函数</strong>。</p>
<h1 id="Relative-Entropy-相对熵"><a href="#Relative-Entropy-相对熵" class="headerlink" title="Relative Entropy(相对熵)"></a><font size="5" color="red">Relative Entropy(相对熵)</font></h1><p><strong>Relative Entropy(相对熵)</strong>：又被称为<strong>KL散度(Kullback-Leibler divergence)</strong>，<strong>是两个概率分布间差异的非对称性度量</strong>。如何理解呢？设两个分布分别为p和q，<strong>KL(p||q)就是按照p的最佳策略来计算p的分布所需要的代价(信息熵)与按照q的最佳策略计算p的分布所需要的代价(交叉熵)之间的差异，这个值一定是大于等于0的</strong>，用公式表示为</p>
<script type="math/tex; mode=display">KL(p||q) = \sum_{x}^{\ }{p(x)log_2\frac{p(x)}{q(x)}} = H(p, q) - H(p)</script><p>其中p为真实分布函数，q为预测分布函数。<br>用之前的例子说明，假如一个袋子里面有两个红球，一个白球，一个蓝球，预测结果为一个红球，两个白球，一个蓝球，问相对熵有多少？计算步骤为</p>
<script type="math/tex; mode=display">KL(p||q) = \frac{1}{2} \times log_2\frac{\frac{1}{2}}{\frac{1}{4}} + \frac{1}{4} \times log_2\frac{\frac{1}{4}}{\frac{1}{2}} + \frac{1}{4} \times log_2\frac{\frac{1}{4}}{\frac{1}{4}} = 0.25</script><p>如何理解这个结果呢？我们<strong>使用真实分布的最优策略按照真实分布的概率，进行代价计算，得到信息熵</strong>，上面计算的结果为1.5，我们<strong>使用预测分布的最优策略按照真实分布的概率，进行代价计算，得到交叉熵</strong>，上面计算的结果为1.75，<strong>相对熵就是两者之间的差异</strong>1.75 - 1.5 = 0.25，<strong>相对熵熵越低，则预测分布越接近真实分布，当两个分布相同时，相对熵为0</strong>，在<strong>多分类问题中，信息熵等于0，因此交叉熵等于KL散度</strong>，但是因为KL散度计算较为复杂，因此一般都使用交叉熵作为损失函数，但是<strong>KL散度在某些场景下有着交叉熵无法代替的作用，如VAE(Variational Autoencoder)</strong>。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>熵是我们学习机器学习和深度学习必须要掌握的基本知识，在模型的损失函数和评价指标中经常使用</strong>，小伙伴们一定要掌握它，否则只是听别人说什么交叉熵，KL散度之乎者也的，自己完全插不上话，相信大家看了这个博客后，一定能够对熵这个家族有更深刻的理解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Regularization黑科技</title>
    <url>/2020/05/23/deep%20learning%20regularization/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Regularization</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Regularization(正则化)</strong>:简单的说就是<strong>减小测试误差的行为</strong>，我们在构建深度学习模型时，最终目的是为了让模型更好的面对测试数据，而不是训练数据。但是<strong>网络在学习的过程中很容易就出现了Overfitting(过拟合)</strong>，这就导致<strong>模型的泛化能力下降</strong>，所以需要<strong>引入一些正则化的方法，降低模型的复杂度</strong>。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/regularization.png" alt="regularization"></p>
<h1 id="L1-Regularization-L1正则"><a href="#L1-Regularization-L1正则" class="headerlink" title="L1 Regularization(L1正则)"></a><font size="5" color="red">L1 Regularization(L1正则)</font></h1><script type="math/tex; mode=display">J'(\omega, b) = J(\omega, b) + \frac{\lambda}{2m} \underset{i}{\sum} {|\omega_{i}|}</script><p>其中$m$为样本个数，$\lambda$为超参数，用于控制正则化的程度。<br><strong>L1 Regularization(L1正则)</strong>：是<strong>指在目标函数的后面加上系数惩罚项，L1正则对应的惩罚项为L1范数，通过让原目标函数加上了所有权重绝对值之和</strong>来实现正则化。<br><strong>L1 Regularization的优点</strong>：可以<strong>起到特征选择的作用</strong>，因为<strong>在梯度更新的时候，L1正则的导数为1，每次都会加上或者减去一个常数，所以很容易产生权值为0的情况，会使特征变得稀疏</strong>。<br>在TensorFlow中，keras.regularizers.l1给我们提供了L1正则化的函数，在网络模型中，可以<strong>通过将正则化函数赋值给网络层的kernel_regularizer参数</strong>，达到正则化的作用。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#keras.regularizers.l1(l=0.01)：l为正则化因子，默认为0.01</span><br><span class="line">keras.layers.Dense(units, kernel_regularizer=keras.regularizers.l1(1e-4))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="L2-Regularization-L2正则"><a href="#L2-Regularization-L2正则" class="headerlink" title="L2 Regularization(L2正则)"></a><font size="5" color="red">L2 Regularization(L2正则)</font></h1><script type="math/tex; mode=display">J'(\omega, b) = J(\omega, b) + \frac{\lambda}{2m} \underset{i}{\sum} {\omega_{i}^{2}}</script><p>其中$m$为样本个数，$\lambda$为超参数，用于控制正则化的程度。<br><strong>L2 Regularization(L2正则)</strong>：是<strong>指在目标函数的后面加上系数惩罚项，L2正则对应的惩罚项为L2范数，通过让原目标函数加上了所有权重的平方和</strong>来实现正则化。<br><strong>L2 Regularization的优点</strong>：<strong>更适合防止模型过拟合</strong>。因为<strong>在梯度更新的时候，L2正则的导数与权值成比例，因此当权值缩小后，梯度也会变小，所以使系数趋向于变小但是不为0，所以L2正则会使模型变得简单，防止过拟合</strong>。<br>在TensorFlow中，keras.regularizers.l2给我们提供了L2正则化的函数，在网络模型中，可以<strong>通过将正则化函数赋值给网络层的kernel_regularizer参数</strong>，达到正则化的作用。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#keras.regularizers.l2(l=0.01)：l为正则化因子，默认为0.01</span><br><span class="line">keras.layers.Dense(units, kernel_regularizer=keras.regularizers.l2(1e-4))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="为什么通过L1，L2正则可以防止过拟合"><a href="#为什么通过L1，L2正则可以防止过拟合" class="headerlink" title="为什么通过L1，L2正则可以防止过拟合"></a><font size="5" color="red">为什么通过L1，L2正则可以防止过拟合</font></h1><p>首先我们讨论过拟合产生的原因，过拟合是指拟合函数要考虑到每一个点，<strong>当存在噪声时，函数值不平滑，所以只有网络权值足够大时，才能够保证一些特征的变化导致函数值发生剧烈变化</strong>。也就是说网络的权值较大，<strong>加入正则化后，为了达到较小的目标函数，会降低网络的权值，所以可以防止过拟合</strong>。</p>
<h1 id="Dropout-随机失活"><a href="#Dropout-随机失活" class="headerlink" title="Dropout(随机失活)"></a><font size="5" color="red">Dropout(随机失活)</font></h1><p><strong>Dropout(随机失活)</strong>：也是一种计算方便，功能强大的正则化方法，<strong>其原理是随机将某些神经元失活，只训练剩下的节点，每次失活的神经元都不一样，相当于每次迭代都是在训练不同的网络。其目的是降低节点之间的关联性和模型复杂度，使网络不要总是依赖于某些神经元的权值，从而达到正则化的效果</strong>。<br>在TensorFlow中，已经给我们提供了Dropout网络层，在keras.layers模块中，使用时直接在网络的某些层加上Dropout即可，非常简单。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># rate为随机失活的比例，一般设为0.2较好。</span><br><span class="line">keras.layers.Dropout(rate)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/dropout.png" alt="dropout"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  深度学习中经常会出现过拟合的现象，其<strong>主要原因是深度学习网络参数量大，模型结构复杂，因此很容易就学习到一些数据特有的性质</strong>，因此就会产生过拟合，<strong>解决过拟合的方法不止Regularization和Dropout两种</strong>，还可以进行<strong>数据增强</strong>操作，<strong>使得数据变得多样化，防止模型对特定数据产生依赖</strong>，有关数据增强的内容，可以参考我的另一篇博客Data Augmentation(数据增强)，里面列举了一些数据增强的常用操作。<strong>EarlyStopping(早停)</strong>也可以缓解过拟合的现象，<strong>当模型在验证集上效果出现波动，甚至下降时，我们可以考虑将模型停止学习，称之为早停</strong>，有关EarlyStopping的内容，可以参考我的另一篇博客Callbacks黑科技，在里面介绍了如何在训练中自动的监测模型的指标，并以此作为是否早停的依据。关于过拟合现象，有很多种方法可以缓解，具体如何选择，需要小伙伴们多多尝试，熟能生巧。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>TensorFlow训练，验证，预测的三种方法</title>
    <url>/2020/05/22/deep%20learning%20train_evaluate_predict/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Train &amp; Evaluate &amp; Predict</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Train, Evaluate, Predict(训练，验证，预测)</strong>:<strong>是深度学习中的基础内容，想要完成一个深度学习工程问题，训练，验证，预测是必不可少的环节</strong>，今天以LeNet-5模型为例，给入门的小伙伴们提供TensorFlow中三种常用的训练，验证，预测方法。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/train.png" alt="train"></p>
<h1 id="fit，evaluate，predict-训练，验证，预测"><a href="#fit，evaluate，predict-训练，验证，预测" class="headerlink" title="fit，evaluate，predict(训练，验证，预测)"></a><font size="5" color="red">fit，evaluate，predict(训练，验证，预测)</font></h1><p><strong>通过模型的fit方法实现训练过程，evaluate方法实现验证过程，predict方法实现预测过程</strong>。这三种方法灵活性较差， 但是很方便，而且可以通过回调函数实现复杂的逻辑控制，是工程应用中经常使用的方法**。fit方法用于训练过程，较为复杂，因此需要设置很多参数，evaluate方法，往往一个epoch或者几个epoch进行一次验证，因此参数比较固定，一般来说只需要验证集数据，其余参数选择默认参数即可。predict方法更加简单，参数也比较固定，一般来说只需要测试集数据，其他参数选择默认参数即可。只有fit方法的参数需要仔细设计，其常用的参数如下：</p>
<ol>
<li>x：训练集数据。</li>
<li>y：训练集标签。</li>
<li>epochs：达到训练迭代次数epochs停止训练。</li>
<li>verbose：显示方式，verbose=0，不显示，verbose=1，以进度条显示，verbose=2，每轮迭代显示一次。</li>
<li>callbacks：回调函数，可以参考我的Callbacks黑科技博客，里面有回调函数的详细使用方法。</li>
<li>validation_data：验证数据集。</li>
<li>initial_epoch：开始训练的迭代次数，用于多次阶段性训练中，如迁移学习。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=10)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 5</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = keras.Sequential([keras.layers.Conv2D(6, (3, 3), (1, 1), 'same', name='Conv1'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn1'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu1'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool1'),</span><br><span class="line">                              keras.layers.Conv2D(16, (3, 3), (1, 1), 'same', name='Conv2'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn2'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu2'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool2'),</span><br><span class="line">                              keras.layers.Conv2D(120, (3, 3), (1, 1), 'same', name='Conv3'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn3'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu3'),</span><br><span class="line">                              keras.layers.Flatten(name='Flatten'),</span><br><span class="line">                              keras.layers.Dense(84, activation='relu', name='Dense1_1'),</span><br><span class="line">                              keras.layers.Dropout(0.2, name='Dropout'),</span><br><span class="line">                              keras.layers.Dense(10, activation='softmax', name='Dense2_1')], name='Model')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(1e-3)</span><br><span class="line">    lossor = keras.losses.CategoricalCrossentropy()</span><br><span class="line">    metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizer, loss=lossor, metrics=[metrics])</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    model.fit(db, epochs=max_epoch, validation_data=db_test, verbose=2)</span><br><span class="line"></span><br><span class="line">    print('----------------------Validation----------------------')</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line">    it_test = iter(db_test)</span><br><span class="line">    test_x, test_y = next(it_test)</span><br><span class="line">    print('----------------------Prediction----------------------')</span><br><span class="line">    y_pred = model.predict(test_x)</span><br><span class="line">    print('loss: %.6f, categorical_accuracy: %6f' % (lossor(test_y, y_pred), metrics(test_y, y_pred)))</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<p><img src="/images/deep_learning/train1.png" alt="train1"></p>
<h1 id="train-on-batch，test-on-batch，predict-on-batch训练，验证和预测方法"><a href="#train-on-batch，test-on-batch，predict-on-batch训练，验证和预测方法" class="headerlink" title="train_on_batch，test_on_batch，predict_on_batch训练，验证和预测方法"></a><font size="5" color="red">train_on_batch，test_on_batch，predict_on_batch训练，验证和预测方法</font></h1><p><strong>通过模型的train_on_batch方法实现训练过程，test_on_batch方法实现验证过程，predict_on_batch方法实现预测过程</strong>，相对于fit方法更加灵活， 但是需要手写一些回调方法实现对训练过程的控制，predict_on_batch只有一个参数，只需要输入测试集即可。train_on_batch和test_on_batch常用的参数如下：</p>
<ol>
<li>x：训练集或验证集数据。</li>
<li>y：训练集或验证集标签。</li>
<li>reset_metrics：是否累积，如果为True则仅适用于该批次，为False则会跨批次累积。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=10)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 5</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = keras.Sequential([keras.layers.Conv2D(6, (3, 3), (1, 1), 'same', name='Conv1'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn1'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu1'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool1'),</span><br><span class="line">                              keras.layers.Conv2D(16, (3, 3), (1, 1), 'same', name='Conv2'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn2'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu2'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool2'),</span><br><span class="line">                              keras.layers.Conv2D(120, (3, 3), (1, 1), 'same', name='Conv3'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn3'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu3'),</span><br><span class="line">                              keras.layers.Flatten(name='Flatten'),</span><br><span class="line">                              keras.layers.Dense(84, activation='relu', name='Dense1_1'),</span><br><span class="line">                              keras.layers.Dropout(0.2, name='Dropout'),</span><br><span class="line">                              keras.layers.Dense(10, activation='softmax', name='Dense2_1')], name='Model')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(1e-3)</span><br><span class="line">    lossor = keras.losses.CategoricalCrossentropy()</span><br><span class="line">    metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizer, loss=lossor, metrics=[metrics])</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    for epoch in range(max_epoch):</span><br><span class="line">        it_train = iter(db)</span><br><span class="line">        it_test = iter(db_test)</span><br><span class="line">        model.reset_metrics()</span><br><span class="line"></span><br><span class="line">        for train_x, train_y in it_train:</span><br><span class="line">            train_result = model.train_on_batch(train_x, train_y)</span><br><span class="line"></span><br><span class="line">        for val_x, val_y in it_test:</span><br><span class="line">            val_result = model.test_on_batch(val_x, val_y)</span><br><span class="line"></span><br><span class="line">        print('epoch: %d, Train loss: %.6f, Train categorical_accuracy: %6f' % (epoch, train_result[0], train_result[1]))</span><br><span class="line">        print('epoch: %d, Validation loss: %.6f, Validation categorical_accuracy: %6f' % (epoch, val_result[0], val_result[1]))</span><br><span class="line"></span><br><span class="line">    it_test = iter(db_test)</span><br><span class="line">    test_x, test_y = next(it_test)</span><br><span class="line">    y_pred = model.predict_on_batch(test_x)</span><br><span class="line">    print('----------------------Prediction----------------------')</span><br><span class="line">    print('loss: %.6f, categorical_accuracy: %6f' % (lossor(test_y, y_pred), metrics(test_y, y_pred)))</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<p><img src="/images/deep_learning/train2.png" alt="train2"></p>
<h1 id="自定义训练，验证，预测方法"><a href="#自定义训练，验证，预测方法" class="headerlink" title="自定义训练，验证，预测方法"></a><font size="5" color="red">自定义训练，验证，预测方法</font></h1><p><strong>自定义训练不需要对模型进行编译，直接利用优化器和损失函数，利用梯度下降法反向传播迭代参数，灵活度最高，但是难度也最大</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=10)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 5</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = keras.Sequential([keras.layers.Conv2D(6, (3, 3), (1, 1), 'same', name='Conv1'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn1'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu1'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool1'),</span><br><span class="line">                              keras.layers.Conv2D(16, (3, 3), (1, 1), 'same', name='Conv2'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn2'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu2'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool2'),</span><br><span class="line">                              keras.layers.Conv2D(120, (3, 3), (1, 1), 'same', name='Conv3'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn3'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu3'),</span><br><span class="line">                              keras.layers.Flatten(name='Flatten'),</span><br><span class="line">                              keras.layers.Dense(84, activation='relu', name='Dense1_1'),</span><br><span class="line">                              keras.layers.Dropout(0.2, name='Dropout'),</span><br><span class="line">                              keras.layers.Dense(10, activation='softmax', name='Dense2_1')], name='Model')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(1e-3)</span><br><span class="line">    lossor = keras.losses.CategoricalCrossentropy()</span><br><span class="line">    train_loss = keras.metrics.Mean()</span><br><span class="line">    train_metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line">    val_loss = keras.metrics.Mean()</span><br><span class="line">    val_metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">    for epoch in range(max_epoch):</span><br><span class="line">        it_train = iter(db)</span><br><span class="line">        it_test = iter(db_test)</span><br><span class="line">        for train_x, train_y in db:</span><br><span class="line">            with tf.GradientTape() as tape:</span><br><span class="line">                y_pred = model(train_x, training=True)</span><br><span class="line">                loss = lossor(train_y, y_pred)</span><br><span class="line">            grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">            optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line">            train_loss.update_state(loss)</span><br><span class="line">            train_metrics.update_state(train_y, y_pred)</span><br><span class="line"></span><br><span class="line">        for val_x, val_y in db_test:</span><br><span class="line">            y_pred = model(val_x, training=False)</span><br><span class="line">            loss = lossor(val_y, y_pred)</span><br><span class="line">            val_loss.update_state(loss)</span><br><span class="line">            val_metrics.update_state(val_y, y_pred)</span><br><span class="line"></span><br><span class="line">        print('Epoch: %d, Train loss: %.6f, Train acc: %.6f, Valid loss: %.6f, Valid acc: %.6f' % (epoch, train_loss.result(), train_metrics.result(), val_loss.result(), val_metrics.result()))</span><br><span class="line"></span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_metrics.reset_states()</span><br><span class="line">        val_loss.reset_states()</span><br><span class="line">        val_metrics.reset_states()</span><br><span class="line"></span><br><span class="line">    print('----------------------Prediction----------------------')</span><br><span class="line">    it_test = iter(db_test)</span><br><span class="line">    test_x, test_y = next(db_test)</span><br><span class="line">    y_pred = model(test_x, training=False)</span><br><span class="line">    loss = lossor(test_y, y_pred)</span><br><span class="line">    print('loss: %.6f, categorical_accuracy: %6f' % (loss, val_metrics(test_y, y_pred)))</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/train3.png" alt="train3"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  这篇博客给小伙伴们介绍了三种常用的训练，验证和预测方法，主要学习第一种和第三种方法，如果为了使用方便则考虑第一种，如果为了模型更加灵活则考虑第三种，希望小伙伴们都可以熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>TensorFlow定义网络层</title>
    <url>/2020/05/21/deep%20learning%20create%20layer/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Define Layer</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Define Layer(定义网络层)</strong>:<strong>是深度学习中的基础内容，想使用深度学习方法解决实际问题，首先就需要建立一个网络层</strong>，今天以LeNet-5模型为例，给入门的小伙伴们提供TensorFlow2.0两种定义网络层的方法。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/layer.png" alt="layer"></p>
<h1 id="第一种方法"><a href="#第一种方法" class="headerlink" title="第一种方法"></a><font size="5" color="red">第一种方法</font></h1><p>只用TensorFlow中定义好的网络层，直接使用keras.layer下的网络层类即可，是最简单的网络层创建方法，缺点也很明显，灵活度很低。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = keras.models.Sequential([keras.layers.Input(shape=(28, 28, 1), name='input'),</span><br><span class="line">                                     keras.layers.Conv2D(6, kernel_size=(5, 5), padding='same', activation='relu', name='conv1'),</span><br><span class="line">                                     keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool1'),</span><br><span class="line">                                     keras.layers.Conv2D(16, kernel_size=(5, 5), padding='valid', activation='relu', name='conv2'),</span><br><span class="line">                                     keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool2'),</span><br><span class="line">                                     keras.layers.Flatten(name='flatten'),</span><br><span class="line">                                     keras.layers.Dense(120, activation='relu', name='dense1'),</span><br><span class="line">                                     keras.layers.Dense(84, activation='relu', name='dense2'),</span><br><span class="line">                                     keras.layers.Dense(10, activation='softmax', name='dense3')], name='LeNet-5')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/model1.png" alt="model1"></p>
<h1 id="第二种方法"><a href="#第二种方法" class="headerlink" title="第二种方法"></a><font size="5" color="red">第二种方法</font></h1><p>通过<strong>继承keras.layer.Layer来创建模型，是最灵活的方式，可以满足任何网络层的定义，但是难度也更大，必须通过重载call函数自定义调用方式</strong>。<br><strong>__init__函数，是自定义层的构造函数，可以在这里准备一些和输入尺寸无关的网络层，如定义一些参数，接收构造函数的输入等等</strong>。<br><strong>call函数，inputs是上一层网络的输出，return是自定义网络的输出，在call函数中写入本层要实现的内容</strong>。<br><strong>build函数，上面两个都是必须的函数，而build函数是根据需要来创建的，一些参数可能需要根据上一层的网络的输出来确定的，如reshape，resize等等操作，因此这些参数的定义无法在__init__中完成，所以需要在build中完成参数的定义，input_shape参数是上一层网络的输出维度。在没有定义build函数时，会默认调用一次空的build函数</strong>。<br><strong>dynamic=False参数，在调用父类的构造函数时，可以传入dynamic参数，其中默认为False，搭建静态图，如果需要动态调整参数，则需要写入dynamic=True</strong></p>
<p>因此当我们需要自定义一个网络层时，我们的思路为：</p>
<ol>
<li><p>根据需要<strong>判断自定义层是否可以由keras.layer提供的网络层组合而成</strong>，如CNN中大量存在Convlution+BN+ReLU层，因此我们可以定义一个层一次性完成三个步骤，而且这三个层都存在于keras.layer中，所以使用卷积层时也不必要使用build函数，直接调用keras.layers.Conv2D接口即可。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Conv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>根据需要<strong>判断是否必须通过上一层输出的尺寸进行操作，如果是则需要定义build函数，如果不需要根据上一层尺寸来判断，则可以在__init__中创建</strong>。</p>
</li>
</ol>
<p>定义参数说明：</p>
<ul>
<li>在<strong>__init__中定义参数，可以使用self.add_weight()创建指定形状的参数</strong>，但是无法创建和输入尺寸相关的参数，<strong>也可以使用tf.Variable()创建指定形状的参数，其中括号里可以为numpy数组，也可以为EagerTensor(动态张量)</strong>。</li>
<li>在<strong>build中定义参数，可以使用self.add_weight()创建指定形状的参数</strong>，而且可以创建和输入尺寸相关的参数，<strong>也可以使用tf.Variable()创建指定形状的参数，但是使用Input层，build方法或者使用fit和train_on_batch训练时会传入输入参数尺寸，因为没有具体数值，因此会自动启动静态图，在静态模式下无法产生EagerTensor(动态张量)，所以不能在Variable的参数列表中传入动态张量，但是仍然可以传入numpy格式的参数。</strong>。</li>
<li><strong>因此推荐在<strong>init</strong>中搭建和输入不相关的参数，在build中搭建和输入相关的参数</strong>。</li>
</ul>
<p>下面是完全使用自定义网络层完成的LeNet-5网络模型。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyDense(keras.layers.Layer):</span><br><span class="line">    def __init__(self, units, name):</span><br><span class="line">        super(MyDense, self).__init__(name=name)</span><br><span class="line">        self.units = units</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.w = self.add_weight(name='kernel', shape=(input_shape[-1], self.units), initializer=keras.initializers.GlorotUniform())</span><br><span class="line">        self.b = self.add_weight(name='bias', shape=(self.units,), initializer=keras.initializers.Zeros())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return tf.matmul(inputs, self.w) + self.b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyConv(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(MyConv, self).__init__(name=name)</span><br><span class="line">        self.filters = filters</span><br><span class="line">        self.kernel_size = kernel_size</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.padding = padding</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.w = self.add_weight(name='kernel', shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters), initializer=keras.initializers.GlorotUniform())</span><br><span class="line">        self.b = self.add_weight(name='bias', shape=(self.filters,), initializer=keras.initializers.zeros)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return tf.nn.bias_add(tf.nn.conv2d(inputs, self.w, (1, self.strides, self.strides, 1), self.padding), self.b)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyRelu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(MyRelu, self).__init__(name=name)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return tf.nn.relu(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyFlatten(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(MyFlatten, self).__init__(name=name)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return tf.reshape(inputs, (-1, tf.reduce_prod(inputs.shape[1:])))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MySoftmax(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(MySoftmax, self).__init__(name=name)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return tf.nn.softmax(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyMaxpool(keras.layers.Layer):</span><br><span class="line">    def __init__(self, kernel_size, strides, padding, name):</span><br><span class="line">        super(MyMaxpool, self).__init__(name=name)</span><br><span class="line">        self.kernel_size = kernel_size</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.padding = padding</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return tf.nn.max_pool2d(inputs, (1, self.kernel_size, self.kernel_size, 1), (1, self.strides, self.strides, 1), self.padding)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = keras.models.Sequential([keras.layers.Input(shape=(28, 28, 1), name='input'),</span><br><span class="line">                                     MyConv(filters=6, kernel_size=3, strides=1, padding='SAME', name='conv1'),</span><br><span class="line">                                     MyRelu(name='relu1'),</span><br><span class="line">                                     MyMaxpool(kernel_size=2, strides=2, padding='SAME', name='maxpool1'),</span><br><span class="line">                                     MyConv(filters=16, kernel_size=3, strides=1, padding='SAME', name='conv2'),</span><br><span class="line">                                     MyRelu(name='relu2'),</span><br><span class="line">                                     MyMaxpool(kernel_size=2, strides=2, padding='SAME', name='maxpool2'),</span><br><span class="line">                                     MyConv(filters=120, kernel_size=3, strides=1, padding='SAME', name='conv3'),</span><br><span class="line">                                     MyRelu(name='relu3'),</span><br><span class="line">                                     MyFlatten(name='flatten'),</span><br><span class="line">                                     MyDense(units=84, name='dense1'),</span><br><span class="line">                                     MyRelu(name='relu4'),</span><br><span class="line">                                     MyDense(units=10, name='dense2'),</span><br><span class="line">                                     MySoftmax(name='softmax')], name='LeNet-5')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/layer2.png" alt="layer2"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>网络层的第二种定义方式和模型定义的第三种定义方式非常类似</strong>，在call函数中定义符合自己需要的网络层，一般的顺序是<strong>先从keras.layer中寻找自己需要的层是否已经提供，如卷积层，池化层，全连接层等等，这时不需要我们手动定义，但是如果某些层非常复杂，如SE注意力层，需要我们手动定义</strong>，希望小伙伴们可以多多练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>TensorFlow定义模型的三种方法</title>
    <url>/2020/05/20/deep%20learning%20create%20model/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Define Model</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Define Model(定义模型)</strong>:<strong>是深度学习中的基础内容，想使用深度学习方法解决实际问题，首先就需要建立一个模型</strong>，今天以LeNet-5模型为例，给入门的小伙伴们提供TensorFlow2.0三种自定义模型的方法。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/model.png" alt="model"></p>
<h1 id="第一种方法"><a href="#第一种方法" class="headerlink" title="第一种方法"></a><font size="5" color="red">第一种方法</font></h1><p>通过<strong>keras.Sequential来创建一个序列模型，也是最简单的一种模型创建方法，缺点也很明显，灵活度很低，不能共享某一层，不能有分支，不能有多个输入输出。只适合于串联模型的创建(如VGG16)，不适合并联模型的创建(如Inception-V3，ResNet50)</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = keras.models.Sequential([keras.layers.Input(shape=(28, 28, 1), name='input'),</span><br><span class="line">                                     keras.layers.Conv2D(6, kernel_size=(5, 5), padding='same', activation='relu', name='conv1'),</span><br><span class="line">                                     keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool1'),</span><br><span class="line">                                     keras.layers.Conv2D(16, kernel_size=(5, 5), padding='valid', activation='relu', name='conv2'),</span><br><span class="line">                                     keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool2'),</span><br><span class="line">                                     keras.layers.Flatten(name='flatten'),</span><br><span class="line">                                     keras.layers.Dense(120, activation='relu', name='dense1'),</span><br><span class="line">                                     keras.layers.Dense(84, activation='relu', name='dense2'),</span><br><span class="line">                                     keras.layers.Dense(10, activation='softmax', name='dense3')], name='LeNet-5')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/model1.png" alt="model1"></p>
<h1 id="第二种方法"><a href="#第二种方法" class="headerlink" title="第二种方法"></a><font size="5" color="red">第二种方法</font></h1><p><strong>通过函数API来创建一个模型，是一种灵活的方式，可以定义更加复杂的模型，灵活度很高，可以共享层，可以分支，且可以满足多个输入输出</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def lenet(input_shape):</span><br><span class="line"></span><br><span class="line">    net = dict()</span><br><span class="line"></span><br><span class="line">    net['input'] = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    net['conv1'] = keras.layers.Conv2D(6, kernel_size=(5, 5), activation='relu', padding='same', name='conv1')(net['input'])</span><br><span class="line">    net['maxpool1'] = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool1')(net['conv1'])</span><br><span class="line">    net['conv2'] = keras.layers.Conv2D(16, kernel_size=(5, 5), activation='relu', padding='valid', name='conv2')(net['maxpool1'])</span><br><span class="line">    net['maxpool2'] = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool2')(net['conv2'])</span><br><span class="line">    net['flatten'] = keras.layers.Flatten(name='flatten')(net['maxpool2'])</span><br><span class="line">    net['dense1'] = keras.layers.Dense(120, activation='relu', name='dense1')(net['flatten'])</span><br><span class="line">    net['dense2'] = keras.layers.Dense(84, activation='relu', name='dense2')(net['dense1'])</span><br><span class="line">    net['dense3'] = keras.layers.Dense(10, activation='softmax', name='dense3')(net['dense2'])</span><br><span class="line"></span><br><span class="line">    model = keras.Model(net['input'], net['dense3'], name='LeNet-5')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = lenet((28, 28, 1))</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/model2.png" alt="model2"></p>
<h1 id="第三种方法"><a href="#第三种方法" class="headerlink" title="第三种方法"></a><font size="5" color="red">第三种方法</font></h1><p>通过<strong>继承keras.Model来创建模型，是一种最灵活的方式，可以满足任何模型的定义，但是难度也更大，必须通过重载call函数自定义调用方式</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LeNet_5(keras.Model):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(LeNet_5, self).__init__(name='LeNet-5')</span><br><span class="line"></span><br><span class="line">        self.conv1 = keras.layers.Conv2D(6, kernel_size=(5, 5), padding='same', activation='relu', name='conv1')</span><br><span class="line">        self.maxpool1 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool1')</span><br><span class="line">        self.conv2 = keras.layers.Conv2D(16, kernel_size=(5, 5), padding='valid', activation='relu', name='conv2')</span><br><span class="line">        self.maxpool2 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool2')</span><br><span class="line">        self.flatten = keras.layers.Flatten(name='flatten')</span><br><span class="line">        self.dense1 = keras.layers.Dense(120, activation='relu', name='dense1')</span><br><span class="line">        self.dense2 = keras.layers.Dense(84, activation='relu', name='dense2')</span><br><span class="line">        self.dense3 = keras.layers.Dense(10, activation='softmax', name='dense3')</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line"></span><br><span class="line">        conv1 = self.conv1(inputs)</span><br><span class="line">        maxpool1 = self.maxpool1(conv1)</span><br><span class="line">        conv2 = self.conv2(maxpool1)</span><br><span class="line">        maxpool2 = self.maxpool2(conv2)</span><br><span class="line">        flatten = self.flatten(maxpool2)</span><br><span class="line">        dense1 = self.dense1(flatten)</span><br><span class="line">        dense2 = self.dense2(dense1)</span><br><span class="line">        output = self.dense3(dense2)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = LeNet_5()</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/model3.png" alt="model3"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>模型的定义没有固定的方式</strong>，小伙伴们可以<strong>根据平时的代码习惯进行选择</strong>，但是<strong>第二种方法和第三种方法必须要掌握一种</strong>，否则很难定义复杂的网络模型，希望小伙伴们可以多多练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>误差，偏差，方差，噪声的关系</title>
    <url>/2020/05/19/deep%20learning%20variance%20bias/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Error &amp; Bias &amp; Variance &amp; Noise</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Error,Bias,Variance,Noise(误差，偏差，方差，噪声)</strong>:是机器学习中的一组重要概念，小伙伴们可能也听说过这些，但是可能不清楚它们之间到底有什么练习，今天给大家捋一捋。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/error.png" alt="error"></p>
<h1 id="误差，偏差，方差，噪声的定义"><a href="#误差，偏差，方差，噪声的定义" class="headerlink" title="误差，偏差，方差，噪声的定义"></a><font size="5" color="red">误差，偏差，方差，噪声的定义</font></h1><p>Error(误差)：把<strong>学习器的实际预测输出与样本的真是输出之间的差异称为误差</strong>，一般<strong>定义为损失函数Loss</strong>，学习的<strong>主要目的就是最小化Loss</strong>。在<strong>训练数据上得到的Loss称之为training erroe(训练误差)</strong>，在<strong>新样本数据得到的Loss称之为(generalization erroe)泛化误差</strong>。显然，<strong>我们希望得到泛化误差小</strong>的学习器。<br>Bias(偏差)：<strong>度量算法的期望预测与真实结果的偏离程度</strong>，刻画了<strong>学习算法本身的拟合能力</strong>。<br>Variance(方差)：<strong>度量同样大小的不同训练集所导致学习性能的变化</strong>，刻画了<strong>数据扰动的影响</strong>。<br>Noise(噪声)：<strong>表达了当前任务上，学习器所能到达的泛化误差的下界</strong>，刻画了<strong>学习本身的难度</strong>，可以理解为数据的label本身就是不准确的，因此<strong>模型无论如何学习都不可能消除</strong>。</p>
<h1 id="误差，偏差，方差，噪声的关系"><a href="#误差，偏差，方差，噪声的关系" class="headerlink" title="误差，偏差，方差，噪声的关系"></a><font size="5" color="red">误差，偏差，方差，噪声的关系</font></h1><p>下面用公式具体说明它们四者之间的关系，首先定义一些符号，这里参考了周志华老师的《机器学习》，也许叫它西瓜书可能更知名一些，一个一边吃西瓜一边给你侃机器学习的大牛。令测试样本为$x$，令$y_D$为$x$的标签，$y$为$x$的真实标签，$f(x;D)$为训练集$D$上学得得模型$f$对$x$得预测输出。<br>模型得期望预测结果为，各训练集预测结果的均值，用公式表达如下式</p>
<script type="math/tex; mode=display">\overline{f}(x) = E[f(x;D)]</script><p>不同训练集上产生得训练方差为，各训练集预测结果减模型的期望预测结果的均值，用公式表达如下式</p>
<script type="math/tex; mode=display">var(x) = E[(f(x;D) - \overline{f}(x))^2]</script><p>样本中存在的噪声为，数据集中的标签$y_D$与数据$x$的真实标签$y$之间的差异，用公式表达如下式</p>
<script type="math/tex; mode=display">\epsilon^2 = E[(y_D - y)^2]</script><p>该系统的偏差为，期望输出与真实标记之间的差异，用公式表达如下式</p>
<script type="math/tex; mode=display">bias^2(x) = (\overline{f}(x) - y)^2</script><p>假设噪声的期望为0，$E[y_D - y] = 0$<br>下面对期望泛化误差进行分解</p>
<script type="math/tex; mode=display">\\begin{align} E[f;D] & = E[(f(x;D) - y_D)^2] \\\\ & = E[(f(x;D) - \overline{f}(x) + \overline{f}(x) - y_D)^2] \\\\ & = E[(f(x;D - \overline{f}(x))^2] + E[(\overline{f}(x) - y_D)^2] + 2E[(f(x;D) - \overline{f}(x))(\overline{f}(x) - y_D)] \\\\ & = E[(f(x;D) - \overline{f}(x))^2] + E[(\overline{f}(x) - y_D)^2] \\\\ & = E[(f(x;D) - \overline{f}(x))^2] + E[(\overline{f}(x) - y + y - y_D)^2] \\\\ & = E[(f(x;D) - \overline{f}(x))^2] + E[(\overline{f}(x) - y)^2] + E[(y - y_D)^2] + 2E[(\overline{f}(x) - y)(y - y_D)] \\\\ & = E[(f(x;D) - \overline{f}(x))^2] + (\overline{f}(x) - y)^2 + E[(y_D - y)^2] \\\\ & = var(x) + bias^2(x) + \epsilon^2 \\\\ \\end{align}</script><p>因为$ \overline{f}(x) = E[f(x;D)] \Rightarrow E[(f(x;D) - \overline{f}(x))] = 0$，因此第三行的最后一项为0<br>因为$E[y_D - y] = 0 \Rightarrow E[(\overline{f}(x) - y)(y - y_D)] = 0 $，因此第六行的最后一项为0<br>所以得到了一个结论，<strong>泛化误差可以分解为方差，偏差和噪声之和</strong>。<br><img src="/images/deep_learning/error1.png" alt="error1"></p>
<h1 id="偏差和方差的相互制约"><a href="#偏差和方差的相互制约" class="headerlink" title="偏差和方差的相互制约"></a><font size="5" color="red">偏差和方差的相互制约</font></h1><p><strong>随着模型复杂度，模型迭代次数的增加，方差和偏差可能会出现此消彼长的现象</strong>，训练不足，或者模型过于简单时会出现<strong>Under-fitting(欠拟合)</strong>，此时的模型<strong>误差主要来自于偏差</strong>，在训练时的<strong>表现为训练集和验证集上面的准确率都不高</strong>，说明出现了欠拟合。而训练太多，或者模型过于复杂时会出现<strong>Over-fitting(过拟合)</strong>，此时的模型<strong>误差主要来自于方差</strong>，在训练时的<strong>表现为训练集上的准确率非常高，验证集上面的准确率不高</strong>，说明出现了过拟合。<br><img src="/images/deep_learning/regularization.png" alt="underfitting_overfitting"></p>
<h1 id="如何降低泛化误差"><a href="#如何降低泛化误差" class="headerlink" title="如何降低泛化误差"></a><font size="5" color="red">如何降低泛化误差</font></h1><p>在这里我们<strong>不讨论如何降低噪声，在我们获得数据集时，数据集本身可能就会存在噪声，因此很难进行降低</strong>。我们<strong>主要讨论如何通过降低偏差和方差来降低泛化误差</strong>。</p>
<p><strong>如何降低偏差</strong>：</p>
<ol>
<li><strong>增加算法复杂度，但是要注意单纯的增加算法复杂度可能会导致方差的增加，可以结合正则项进行惩罚</strong>。</li>
<li><strong>进行合理的特征工程，检查是否遗漏重要特征</strong>。</li>
<li><strong>优化网络结构，因为偏差大意味着网络的拟合效果不好，因此可以更换网络层</strong>。</li>
</ol>
<p><strong>如何降低方差</strong>：</p>
<ol>
<li><strong>增加训练样本，样本代表性不足时方差大的首要原因，增加样本也是降低方差最简单的方法</strong>。</li>
<li><strong>引入正则项(L1正则，L2正则，Dropout等)</strong>。</li>
<li><strong>特征提取，对输入的特征进行提取，特征变少方差也会减小</strong>。</li>
<li><strong>降低模型复杂度，或者采用早停，减少迭代周期</strong>。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  虽然我们在使用机器学习时，很难直观的看出偏差和方差之间的关系，但是我们可能会对某些情况深有体会，如训练集的准确率达到95%，而验证集只有80%，这个情况小伙伴们都会一眼看出，过拟合了，但是过拟合背后的原因可能就不回去探究，其实<strong>过拟合就是一种方差过大的体现，这时我们就应该考虑增加训练样本，引入正则，降低模型复杂度或者采用早停等策略进行优化</strong>。还可能训练集和验证集的准确率都只达到50%，这个情况小伙伴们也应该很熟悉，欠拟合了，其实<strong>欠拟合就是一种偏差过大的体现，这时我们就应该考虑增加模型参数，优化网络结构</strong>。偏差和方差很多时候都是在理论分析时需要的，实际的工程问题，小伙伴们也可以不用去过多分析，只需要知道过拟合欠拟合该采取什么样的方法解决它，如果能够达到这样的水平，我觉得已经具备解决实际问题的能力了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Callbacks黑科技</title>
    <url>/2020/05/18/deep%20learning%20callbacks/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Callbacks</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Callbacks(回调函数)</strong>:指<strong>在网络学习期间，对网络的性能，参数等进行修改，保存，显示，早停等一系列操作</strong>。不是深度学习必须使用的，但是掌握回调函数可以更好的让网络为我们服务，下面来具体了解一下有哪些常用的回调函数。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/callbacks.png" alt="callbacks"></p>
<h1 id="Early-Stopping-早停"><a href="#Early-Stopping-早停" class="headerlink" title="Early Stopping(早停)"></a><font size="5" color="red">Early Stopping(早停)</font></h1><p>在深度学习任务中，<strong>早停是提升模型性能的一个有效方法</strong>，随着训练的进行，模型在训练集和测试集上的性能会逐渐提高，但是在训练一定的周期后，我们常常会发现<strong>训练集上的准确率仍在增加，而且损失函数在减小，但是测试集上的准确率和损失函数却在某个值附近发生波动，甚至会降低准确率</strong>。这种情况我们会认为发生了<strong>Overfitting(过拟合)</strong>，即模型学的太像了，把训练集中的一些特殊情况也学习进去了。举个简单的例子，我们学习认识一只老虎时，如果这只老虎是一只幼崽，我们学习的太像了，就会认为老虎就应该是那么大，当测试时，来了一只猫，我们就会当成是老虎，这就是Overfitting的简单理解。<br>想解决Overfitting，有很多种方法，最暴力的方法是<strong>增加数据集</strong>，还可以<strong>引入正则项</strong>，<strong>减小模型的参数</strong>，以及<strong>早停</strong>。早停是一种简单的解决Overfitting的方法，当模型的验证集已经发生波动时，我们就认为发生了过拟合，因此停止网络的学习，防止其学到过多训练集的特性。<br>在TensorFlow中在keras.callbacks中已经给我们提供了EarlyStopping的类，其常用参数主要有：</p>
<ol>
<li><strong>monitor：监视的值，默认为val_loss，当验证集的损失函数不下降时停止学习</strong>。</li>
<li><strong>min_delta: 监视值的最小变化，默认为0，即只要损失函数降低则视为有改进</strong>。</li>
<li><strong>patience: 没有改进的周期数，如果连续patience个周期都没有改进，则停止学习</strong>。</li>
<li><strong>verbose：是否在训练过程中详细显示</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<h1 id="Check-Point-检查点"><a href="#Check-Point-检查点" class="headerlink" title="Check Point(检查点)"></a><font size="5" color="red">Check Point(检查点)</font></h1><p>为了<strong>对比各个训练周期的效果，我们可以将模型按照训练迭代周期进行保存</strong>。在TensorFlow中在keras.callbacks中已经给我们提供了ModelCheckpoint的类，其常用参数主要有：</p>
<ol>
<li><strong>filepath：保存模型文件的路径</strong>。</li>
<li><strong>monitor: 监视的值，默认为val_loss</strong>。</li>
<li><strong>verbose：是否在训练过程中详细显示</strong>。</li>
<li><strong>save_best_only: 是否只保存最佳模型</strong>。</li>
<li><strong>period：每个period个周期检查一次是否需要保存</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">check_point = keras.callbacks.ModelCheckpoint(weight_path + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', monitor='val_loss', verbose=1, save_best_only=True, period=3)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<h1 id="CSV-Logger-CSV记录器"><a href="#CSV-Logger-CSV记录器" class="headerlink" title="CSV Logger(CSV记录器)"></a><font size="5" color="red">CSV Logger(CSV记录器)</font></h1><p>为了使我们能够<strong>直观方便的看到各个训练周期下模型的评价指标和损失函数</strong>，在TensorFlow中在keras.callbacks中已经给我们提供了CSVLogger的类，<strong>能够将各个训练周期的模型指标保存在csv文件中</strong>，其常用参数主要有：</p>
<ol>
<li><strong>filepath：保存csv文件的文件名</strong>。</li>
<li><strong>separator: 用于分隔csv文件中元素的分隔符，默认为’,’，一般不要修改</strong>。</li>
<li><strong>append：是否在文件后面追加，如果为True则追加，如果为False则覆盖，默认为False</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">log_csv = keras.callbacks.CSVLogger(filename=csv_path)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a><font size="5" color="red">Tensorboard</font></h1><p>为了能够<strong>可视化我们的模型，以及了解数据流图的结构</strong>，在TensorFlow中在keras.callbacks中已经给我们提供了TensorBoard的类，能够在<strong>本地Web浏览器对网络参数，数据流图进行可视化</strong>，其常用参数主要有：</p>
<ol>
<li><strong>log_dir: 用来保存Tensorboard的日志文件等内容的位置</strong>。</li>
<li><strong>histogram_freq: 用来计算各个层的激活值和模型权重直方图</strong>。</li>
<li><strong>write_graph: 是否在TensorBoard中可视化图形(数据流图)</strong>。</li>
<li><strong>pdate_freq：batch或epoch或整数，默认为epoch。使用batch，每批之后将损失和指标写入TensorBoard。epoch同理。如果使用整数，假设1000，回调将每1000个样本将指标和损失写入TensorBoard，但是向TensorBoard写入太频繁会减慢训练速度</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">log_board = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_grads=True)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<p>运行后<strong>日志文件会保存在log_dir中</strong>，然后<strong>在cmd命令行中运行tensorboard —logdir=path(log_dir的绝对路径即可，也可以使用相对路径)</strong>，然后会<strong>出现一个本地的Web网址，复制并在浏览器中打开</strong>即可完成可视化工作。<br><strong>想了解更多关于Tensorboard的使用方法，可以参考我的另一篇博客TensorBoard黑科技，专门对TensorBoard的使用进行讲解，除了使用keras.callbacks模块下的类，还有一些其他的方法写入TensorBoard</strong>。</p>
<h1 id="Reduce-LR-学习率下降"><a href="#Reduce-LR-学习率下降" class="headerlink" title="Reduce LR(学习率下降)"></a><font size="5" color="red">Reduce LR(学习率下降)</font></h1><p>在训练过程中，往往在<strong>初始阶段使用较大的学习率，方便模型的收敛和跳出局部极小值点，而在训练后期学习率需要降低来细化我们的模型，降低损失函数，提高模型评价指标</strong>。在TensorFlow中在keras.callbacks中已经给我们提供了ReduceLROnPlateau的类，能够<strong>在训练过程中，自适应地调整学习率</strong>，其常用参数主要有：</p>
<ol>
<li><strong>monitor：监视的值，默认为val_loss</strong>。</li>
<li><strong>factor：学习率下降因子，new_lr = lr x factor</strong>。</li>
<li><strong>patience：没有改进的周期数，如果连续patience个周期都没有改进，则下降学习率</strong>。</li>
<li><strong>min_lr：设置最低学习率，防止学习率过低</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3, verbose=1)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<p><strong>想了解更多关于学习率下降的使用方法，可以参考我的另一篇博客Learning Rate黑科技，专门对学习率下降的使用进行讲解，除了使用ReduceLROnPlateau，还有一些其他的方法可以自定义学习率下降的方式</strong>。</p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p>使用mnist手写数字分类作为实战，给小伙伴们演示如何使用回调函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=num_class)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    num_class = 10</span><br><span class="line">    # 分离数据</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line">    time_stamp = datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S")</span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 10</span><br><span class="line">    weight_path = '.\\weights\\'</span><br><span class="line">    log_dir = '.\\logs\\' + time_stamp</span><br><span class="line">    csv_path = '.\\csv\\' + time_stamp + '.csv'</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = keras.Sequential([keras.layers.Conv2D(6, (3, 3), (1, 1), 'same', name='Conv1'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn1'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu1'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool1'),</span><br><span class="line">                              keras.layers.Conv2D(16, (3, 3), (1, 1), 'same', name='Conv2'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn2'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu2'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool2'),</span><br><span class="line">                              keras.layers.Conv2D(120, (3, 3), (1, 1), 'same', name='Conv3'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn3'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu3'),</span><br><span class="line">                              keras.layers.Flatten(name='Flatten'),</span><br><span class="line">                              keras.layers.Dense(84, activation='relu', name='Dense1_1'),</span><br><span class="line">                              keras.layers.Dropout(0.2, name='Dropout'),</span><br><span class="line">                              keras.layers.Dense(10, activation='softmax', name='Dense2_1')], name='Model')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    # 模型参数设置</span><br><span class="line">    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=keras.losses.CategoricalCrossentropy(), metrics=['acc'])</span><br><span class="line"></span><br><span class="line">    log_board = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_grads=True)</span><br><span class="line"></span><br><span class="line">    log_csv = keras.callbacks.CSVLogger(filename=csv_path)</span><br><span class="line"></span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3, verbose=1)</span><br><span class="line"></span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)</span><br><span class="line"></span><br><span class="line">    check_point = keras.callbacks.ModelCheckpoint(weight_path + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', monitor='val_loss', verbose=1, save_best_only=True, period=3)</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    model.fit(db, epochs=max_epoch, callbacks=[log_board, log_csv, reduce_lr, early_stopping, check_point], validation_data=db_test, initial_epoch=0)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/callbacks1.png" alt="callbacks1"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>回调函数是我们优化模型的重要工具，能够帮助我们更好的了解设计的模型，可以直观的看出模型需要如何改进，应该增加迭代周期还是应该早停，增加模型参数还是降低模型参数等等</strong>，要注意<strong>保存模型参数或者记录模型结果的时候，可以加入时间戳作为文件名，这样防止多次训练时产生太多文件导致分不清是哪一次训练的数据</strong>，所以小伙伴们一定要小心。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Transfer learning(迁移学习)</title>
    <url>/2020/05/17/deep%20learning%20transfer%20learning/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Transfer learning</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Transfer learning(迁移学习)</strong>:<strong>是一种常见的机器学习方法</strong>，概括的说就是<strong>将一个预训练的模型重新用在另一个任务上</strong>。其在深度学习问题上是非常受欢迎的，因为<strong>深度学习很大的一个问题就是数据集不够</strong>，神经网络的参数量少说几百万，多则上亿，因此对于数据量的要求也是十分巨大的，但是实际的问题往往很难找到足够数量的数据集，<strong>除了数据增强方法外，还可以利用迁移学习的思想</strong>。以分类问题为例，前面的卷积层和池化层的目的是特征提取，后面全连接层的目的是进行分类。因此<strong>如果我们有很好的特征提取参数，那么我们就不需要浪费太多数据集在特征提取部分，我们重点训练网络的后半部分即可</strong>。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/transfer.png" alt="transfer"></p>
<h1 id="迁移学习实现"><a href="#迁移学习实现" class="headerlink" title="迁移学习实现"></a><font size="5" color="red">迁移学习实现</font></h1><p>要完成迁移学习，首先<strong>两个任务要有一部分相同的网络结构，通常是前半部分的特征提取网络结构</strong>。在这里中使用TensorFlow中自带手写数字数据集mnist和时装数据集fashion_mnist为例，说明迁移学习的实现过程。<br>迁移学习步骤如下：</p>
<ol>
<li>设要解决的问题为Q1，找到与要解决的问题类似并且有较多的数据集的问题为Q2，首先设计一个解决问题Q2的网络结构，<strong>使用Q2的数据集，训练好后将模型的权重保存</strong>。</li>
<li>设计一个解决问题Q1的网络结构，<strong>将相同的层给予相同的名称，加载权重时，调用load_weights()函数，其中参数by_name赋值为True，即根据名称加载对应的权重，名称不相同的层则不加载权重</strong>。</li>
<li><strong>训练时可以使用较大的学习率，而且让model.layers[i].trainable = False，冻结前面的特征提取网络</strong>，因为相似的问题具有相似的特征提取权重，不会偏差太大，<strong>如果一开始就一起训练，则可能会使特征提取网络的权值产生较大的变化，浪费训练周期和数据集</strong>。</li>
<li><strong>训练一段时间后，使用较小的学习率，并将前面的特征提取网络解冻model.layers[i].trainable = True</strong>，<strong>为了更好的提取出适合于本问题的特征</strong>，再训练一定的时间，即可完成整个迁移学习过程。</li>
</ol>
<h1 id="第一部分，获取相似问题的权重"><a href="#第一部分，获取相似问题的权重" class="headerlink" title="第一部分，获取相似问题的权重"></a><font size="5" color="red">第一部分，获取相似问题的权重</font></h1><p>设计一个解决时装分类问题的网络模型，因为类别较少，因此网络模型较小，主要是为了说明迁移学习的过程。模型的参数保存在fashion_mnist.h5文件中，实际的代码如下。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">try:</span><br><span class="line">    import tensorflow.python.keras as keras</span><br><span class="line">except:</span><br><span class="line">    import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=num_class)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    num_class = 10</span><br><span class="line">    # 分离数据</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 10</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = keras.Sequential([keras.layers.Conv2D(16, (3, 3), (1, 1), 'same', name='Conv1'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn1'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu1'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool1'),</span><br><span class="line">                              keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', name='Conv2'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn2'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu2'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool2'),</span><br><span class="line">                              keras.layers.Conv2D(120, (3, 3), (1, 1), 'same', name='Conv3'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn3'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu3'),</span><br><span class="line">                              keras.layers.Flatten(name='Flatten'),</span><br><span class="line">                              keras.layers.Dense(256, activation='relu', name='Dense1'),</span><br><span class="line">                              keras.layers.Dropout(0.2, name='Dropout'),</span><br><span class="line">                              keras.layers.Dense(10, activation='softmax', name='Dense2')], name='Model')</span><br><span class="line"></span><br><span class="line">    # 模型参数设置</span><br><span class="line">    model.compile(</span><br><span class="line">        optimizer=keras.optimizers.Adam(),</span><br><span class="line">        loss=keras.losses.CategoricalCrossentropy(),</span><br><span class="line">        metrics=['acc']</span><br><span class="line">                  )</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    model.fit(db, epochs=max_epoch, validation_data=db_test)</span><br><span class="line"></span><br><span class="line">    model.save_weights('fashion_mnist.h5')</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/transfer1.png" alt="transfer1"></p>
<h1 id="第二部分，加载第一部分的权重，并且训练本问题"><a href="#第二部分，加载第一部分的权重，并且训练本问题" class="headerlink" title="第二部分，加载第一部分的权重，并且训练本问题"></a><font size="5" color="red">第二部分，加载第一部分的权重，并且训练本问题</font></h1><p>设计一个解决手写数字分类问题的网络模型，手写数字比时装分类问题简单一些，因此特征提取网络不变，<strong>只改变最后两层全连接层的参数</strong>，实际的代码如下。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=num_class)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    num_class = 10</span><br><span class="line">    # 分离数据</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 10</span><br><span class="line">    weight_path = '.\\weights'</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = keras.Sequential([keras.layers.Conv2D(16, (3, 3), (1, 1), 'same', name='Conv1'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn1'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu1'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool1'),</span><br><span class="line">                              keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', name='Conv2'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn2'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu2'),</span><br><span class="line">                              keras.layers.MaxPool2D((2, 2), (2, 2), name='Maxpool2'),</span><br><span class="line">                              keras.layers.Conv2D(120, (3, 3), (1, 1), 'same', name='Conv3'),</span><br><span class="line">                              keras.layers.BatchNormalization(name='Bn3'),</span><br><span class="line">                              keras.layers.ReLU(name='Relu3'),</span><br><span class="line">                              keras.layers.Flatten(name='Flatten'),</span><br><span class="line">                              keras.layers.Dense(128, activation='relu', name='Dense1_1'),</span><br><span class="line">                              keras.layers.Dropout(0.2, name='Dropout'),</span><br><span class="line">                              keras.layers.Dense(10, activation='softmax', name='Dense2_2')], name='Model')</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    model.load_weights('.\\fashion_mnist.h5', by_name=True)</span><br><span class="line"></span><br><span class="line">    for i in range(12):</span><br><span class="line">        model.layers[i].trainable = False</span><br><span class="line"></span><br><span class="line">    # 模型参数设置</span><br><span class="line">    model.compile(</span><br><span class="line">        optimizer=keras.optimizers.Adam(1e-3),</span><br><span class="line">        loss=keras.losses.CategoricalCrossentropy(),</span><br><span class="line">        metrics=['acc']</span><br><span class="line">                  )</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    model.fit(db, epochs=5, validation_data=db_test, initial_epoch=0)</span><br><span class="line"></span><br><span class="line">    for i in range(15):</span><br><span class="line">        model.layers[i].trainable = True</span><br><span class="line"></span><br><span class="line">    # 模型参数设置</span><br><span class="line">    model.compile(</span><br><span class="line">        optimizer=keras.optimizers.Adam(1e-4),</span><br><span class="line">        loss=keras.losses.CategoricalCrossentropy(),</span><br><span class="line">        metrics=['acc']</span><br><span class="line">                  )</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    model.fit(db, epochs=max_epoch, validation_data=db_test, initial_epoch=5)</span><br><span class="line"></span><br><span class="line">    model.save_weights('mnist.h5')</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/transfer2.png" alt="transfer2"></p>
<h1 id="使用迁移学习与不使用迁移学习的对比"><a href="#使用迁移学习与不使用迁移学习的对比" class="headerlink" title="使用迁移学习与不使用迁移学习的对比"></a><font size="5" color="red">使用迁移学习与不使用迁移学习的对比</font></h1><p><img src="/images/deep_learning/transfer3.png" alt="transfer3"></p>
<ol>
<li>从上图可以明显的看出，使用了迁移学习之后，<strong>模型训练的速度大大加快了</strong>，因为利用相似问题的特征提取网络权值，只训练最后的分类网络，因此模型的收敛更加迅速。</li>
<li>因为mnist数据量并不是很少，而且分类任务比较简单，因此在很长时代的训练下，迁移学习的优势并不是很明显，在<strong>其他的复杂问题上，尤其是数据量较少的情况，效果非常明显</strong>。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  迁移学习<strong>不是一种算法，更多的是一种思想</strong>，一种将现有的信息借鉴过来的迁移思想，使得我们的<strong>少量数据集可以发挥更大的效果</strong>。因此在工程实际问题中常常使用，小伙伴们必须要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>每个元音包含偶数次的最长子字符串(Leetcode 1371)</title>
    <url>/2020/05/16/program%20Leetcode1371/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode1371.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目第一眼想到的方法是暴力求解，从第i个字符开始到第j个字符，使用两层循环，依次遍历，计算是否满足偶数个元音字母，算法复杂度也很好分析$O(n^2)$，但是求解的过程中浪费了大量的运算资源，如从第一个字符到最后一个字符，对每一个字符都判断了是否为元音字符，从第二个字符到最后一个字符，对每一个字符又判断了依次，因此大大增加了时间复杂度，如果直接使用暴力法，题目是很难通过的。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>暴力法想通过这道题目也是有办法的，我们有一个先验知识，要求最长的字符串，那为何不能<strong>按照字符串长度来遍历</strong>呢？假如字符串长度为10，那么第一次遍历所有长度为10的字符串，第二次遍历所有长度为9的字符串，如果有满足条件的那一定是最优解，这样可以大大节约计算量，图解图下。<br><img src="/images/ALGORITHM/leetcode1371_brute.png" alt="brute"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findTheLongestSubstring(self, s):</span><br><span class="line">        lens = len(s)</span><br><span class="line">        # i 代表迭代字符串长度为i的子串</span><br><span class="line">        for i in range(lens, -1, -1):</span><br><span class="line">            if i == 0:</span><br><span class="line">                return 0</span><br><span class="line">            # j 代表从第j个位置开始</span><br><span class="line">            for j in range(lens - i + 1):</span><br><span class="line">                tmp_s = s[j:j + i]</span><br><span class="line">                for k in ['a', 'e', 'i', 'o', 'u']:</span><br><span class="line">                    # 如果某个元音字符不是偶数个，则搜索下一个字符串</span><br><span class="line">                    if tmp_s.count(k) % 2 != 0:</span><br><span class="line">                        break</span><br><span class="line">                    # 如果u是偶数个，说明所有元音字符串都已经满足偶数，则i一定是最长的长度</span><br><span class="line">                    if k == 'u':</span><br><span class="line">                        return i</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="前缀和-状态压缩"><a href="#前缀和-状态压缩" class="headerlink" title="前缀和+状态压缩"></a><font size="5" color="red">前缀和+状态压缩</font></h1><p>这个思路参考官方题解，我们思考一个问题，<strong>如果中间某个字串满足条件，那么从第一个字符到该字串的前一个字符与从第一个字符到该字串的最后一个字符的状态是相同的</strong>，因此我们只需要维护一个前缀和，即可解决此问题，如下图所示。<br><img src="/images/ALGORITHM/leetcode1371_solve1.png" alt="solve"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findTheLongestSubstring(self, s):</span><br><span class="line">        ans, status, n = 0, 0, len(s)</span><br><span class="line">        chars = ['a', 'e', 'i', 'o', 'u']</span><br><span class="line">        pos = [-1] * (1 &lt;&lt; 5)</span><br><span class="line">        pos[0] = 0</span><br><span class="line">        for i in range(n):</span><br><span class="line">            if s[i] in chars:</span><br><span class="line">                status ^= 1 &lt;&lt; chars.index(s[i])</span><br><span class="line">            if pos[status] != -1:</span><br><span class="line">                ans = max(ans, i + 1 - pos[status])</span><br><span class="line">            else:</span><br><span class="line">                pos[status] = i + 1</span><br><span class="line">        return ans</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="题目延申"><a href="#题目延申" class="headerlink" title="题目延申"></a><font size="5" color="red">题目延申</font></h1><p>思考：如果本题改为<strong>奇数次最长的子串</strong>该如何去解？<br><strong>思路还是相同的，只不过在寻找状态时要寻找完全相反的状态，如果从初始位置到某个位置的状态为(10101)，那么就去寻找(01010)这个状态最早出现的位置即可</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findTheLongestSubstring(self, s):</span><br><span class="line">        ans, status, n = 0, 0, len(s)</span><br><span class="line">        chars = ['a', 'e', 'i', 'o', 'u']</span><br><span class="line">        pos = [-1] * (1 &lt;&lt; 5)</span><br><span class="line">        pos[0] = 0</span><br><span class="line">        for i in range(n):</span><br><span class="line">            if s[i] in chars:</span><br><span class="line">                status ^= 1 &lt;&lt; chars.index(s[i])</span><br><span class="line">            if pos[31 ^ status] != -1:</span><br><span class="line">                ans = max(ans, i + 1 - pos[31 ^ status])</span><br><span class="line">            else:</span><br><span class="line">                pos[status] = i + 1</span><br><span class="line">        return ans</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  状态压缩是一种常用的技巧，尤其在状态较多的时候，如果使用字典存储状态，则需要较大的内存，如果使用二进制位的0和1来保存状态，则只需要bit量级的内存，但是前提是每个状态的定义只有两种，比如此题的奇数和偶数，如果状态数较多，一般不使用这种方法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>字符串</category>
        <category>状态压缩</category>
      </categories>
  </entry>
  <entry>
    <title>新21点(Leetcode 837)</title>
    <url>/2020/05/15/program%20Leetcode837/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode837.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目看上去非常复杂，题目意思是每次获得牌的点数为1-W之间，大于等于K则不再要牌，否则继续要牌，如果手中牌的点数之和小于等于N则赢，求赢的概率。</p>
<a id="more"></a>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>最直观的想法，深度搜索，第一张牌有w种抽法，第二张牌有w种抽法，如果最后值大于N，则不加入获胜总概率，如果最后值大于等于K小于N则加入获胜总概率。时间复杂度较高。但是利用python常用库functools中的lru_cache，可以大大节约计算量，会保存计算过的值，如dfs(20, 0.001)已经计算过了，则会建立一个字典，保存这个值，再次调用时会直接获取字典中的值，避免了重复计算。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def new21Game(self, N, K, W):</span><br><span class="line">        """</span><br><span class="line">        :type N: int</span><br><span class="line">        :type K: int</span><br><span class="line">        :type W: int</span><br><span class="line">        :rtype: float</span><br><span class="line">        """</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        def dfs(current_val, current_pro):</span><br><span class="line">            if current_val &gt;= K:</span><br><span class="line">                return 0 if current_val &gt; N else current_pro</span><br><span class="line">            return sum(map(lambda v: dfs(current_val + v, current_pro / W), range(1, W + 1)))</span><br><span class="line"></span><br><span class="line">        return dfs(0, 1)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>可以使用DFS的题目一般都可以使用BFS来求解，思路也比较清晰，抽取第一张牌有W中可能，将这些可能的结果都保存在双端队列中，然后抽取第二张牌，将第二张牌所有可能的结果都保存到双端队列中，如果最后值大于N，则不加入获胜总概率，如果最后值大于等于K小于N则加入获胜总概率。时间复杂度较高。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution(object):</span><br><span class="line">    def new21Game(self, N, K, W):</span><br><span class="line">        """</span><br><span class="line">        :type N: int</span><br><span class="line">        :type K: int</span><br><span class="line">        :type W: int</span><br><span class="line">        :rtype: float</span><br><span class="line">        """</span><br><span class="line">        queue = deque([[0, 1]])</span><br><span class="line">        res = 0</span><br><span class="line">        while queue:</span><br><span class="line">            current_val, current_pro = queue.popleft()</span><br><span class="line">            for i in range(1, W + 1):</span><br><span class="line">                if current_val &gt; N:</span><br><span class="line">                    break</span><br><span class="line">                elif current_val &gt;= K:</span><br><span class="line">                    res += current_pro</span><br><span class="line">                    break</span><br><span class="line">                else:</span><br><span class="line">                    queue.append([current_val + i, current_pro / W])</span><br><span class="line">        return res</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>使用上面两者暴力搜索方法当然不是最优的解法，因为其中包含了大量的重复计算，如果我们能够保存当前计算的状态，则可以大大降低时间复杂度。因此想到了DP动态规划。在这里我直接使用官方题解中的图片来阐述。<br><img src="/images/ALGORITHM/leetcode837_dp.png" alt="dp"><br>使用动态规划算法的时间复杂度为$O(min(N,K+W))$，空间复杂度为$O(K+W)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def new21Game(self, N, K, W):</span><br><span class="line">        """</span><br><span class="line">        :type N: int</span><br><span class="line">        :type K: int</span><br><span class="line">        :type W: int</span><br><span class="line">        :rtype: float</span><br><span class="line">        """</span><br><span class="line">        if K == 0:</span><br><span class="line">            return 1.0</span><br><span class="line">        dp = [0.0] * (K + W + 1)</span><br><span class="line">        for i in range(K, min(N, K + W - 1) + 1):</span><br><span class="line">            dp[i] = 1.0</span><br><span class="line">        dp[K - 1] = min(N - K + 1, W) / W</span><br><span class="line">        for i in range(K - 2, -1, -1):</span><br><span class="line">            dp[i] = dp[i + 1] - (dp[i + W + 1] - dp[i + 1]) / W</span><br><span class="line">        return dp[0]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  动态规划问题是面试时最常问的算法之一，因此这道题目的关键是掌握DP算法，并且学习反向DP的思考过程。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>动态规划</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>TensorBoard黑科技</title>
    <url>/2020/05/14/deep%20learning%20tensorboard/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">TensorBoard</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>TensorBoard</strong>:是一个<strong>可视化工具</strong>，它可以用来<strong>展示网络流图，损失函数，评价函数等等随epoch的变化过程</strong>，其工作原理是，<strong>程序给磁盘的某个目录写数据，然后监听器就可以监听到这个目录的变化，打开Web浏览器就可以从监听器中获得数据，完成实时的数据更新</strong>。今天给小伙伴们介绍TensorBoard的两种使用方法，希望小伙伴们可以认真学习，动手尝试。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/tensorboard.png" alt="tensorboard"></p>
<h1 id="第一种使用方法"><a href="#第一种使用方法" class="headerlink" title="第一种使用方法"></a><font size="5" color="red">第一种使用方法</font></h1><p>以mnist数据集为例，向小伙伴们介绍TensorBoard的第一种使用方法，<strong>使用tensorflow种keras.callbacks模块下的TensorBoard类</strong>，其常用参数列举如下。</p>
<ol>
<li><strong>log_dir: 用来保存Tensorboard的日志文件等内容的位置</strong>。</li>
<li><strong>histogram_freq: 用来计算各个层的激活值和模型权重直方图</strong>。</li>
<li><strong>write_graph: 是否在TensorBoard中可视化图形(数据流图)</strong>。</li>
<li><strong>pdate_freq：’batch’或’epoch’或整数。使用’batch’，每批之后将损失和指标写入TensorBoard。’epoch’同理。如果使用整数，假设1000，回调将每1000个样本将指标和损失写入TensorBoard，但是向TensorBoard写入太频繁会减慢训练速度</strong>。<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def lenet(input_shape):</span><br><span class="line">    input_tensor = keras.Input(shape=input_shape)</span><br><span class="line">    </span><br><span class="line">    net = dict()</span><br><span class="line">    </span><br><span class="line">    net['input'] = input_tensor</span><br><span class="line">    net['conv1_1'] = keras.layers.Conv2D(6, kernel_size=(3, 3), activation='relu', padding='same', name='conv1_1')(net['input'])</span><br><span class="line">    net['pool1'] = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool1')(net['conv1_1'])</span><br><span class="line">    net['conv2_1'] = keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='conv2_1')(net['pool1'])</span><br><span class="line">    net['pool2'] = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool2')(net['conv2_1'])</span><br><span class="line">    net['conv3_1'] = keras.layers.Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same', name='conv3_1')(net['pool2'])</span><br><span class="line">    net['Flatten'] = keras.layers.Flatten()(net['conv3_1'])</span><br><span class="line">    net['dense1'] = keras.layers.Dense(84, activation='relu')(net['Flatten'])</span><br><span class="line">    net['dense2'] = keras.layers.Dense(num_class, activation='softmax')(net['dense1'])</span><br><span class="line">    </span><br><span class="line">    model = keras.Model(net['input'], net['dense2'])</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=num_class)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    num_class = 10</span><br><span class="line">    # 分离数据</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 20</span><br><span class="line">    log_dir = '.\\logs'</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = lenet((28, 28, 1))</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    # 模型参数设置</span><br><span class="line">    model.compile(</span><br><span class="line">        optimizer=keras.optimizers.Adam(lr=1e-3),</span><br><span class="line">        loss=keras.losses.CategoricalCrossentropy(),</span><br><span class="line">        metrics=['acc']</span><br><span class="line">                  )</span><br><span class="line"></span><br><span class="line">    logging = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_grads=True)</span><br><span class="line"></span><br><span class="line">    # 模型训练</span><br><span class="line">    model.fit(db, epochs=max_epoch, callbacks=[logging], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure>
</li>
</ol>
<p>运行后<strong>日志文件会保存在py文件同级目录logs下</strong>，然后<strong>在cmd命令行中运行tensorboard --logdir=path(logs的绝对路径即可，也可以进入py文件的同级目录中，直接写tensorboard --logdir=logs)</strong>，然后会<strong>出现一个本地的Web网址，复制并在浏览器中打开</strong>即可完成可视化工作。<br><img src="/images/deep_learning/tensorboard1.png" alt="tensorboard1"></p>
<h1 id="第二种使用方法"><a href="#第二种使用方法" class="headerlink" title="第二种使用方法"></a><font size="5" color="red">第二种使用方法</font></h1><p>上面的方法是<strong>通过keras的高层API接口实现TensorBoard的使用</strong>，下面的方法在任何情况下均可以使用，包括在pytorch中也可以使用。其<strong>使用tf.summary.create_file_writer(log_dir)创建一个写入日志文件的对象，log_dir为要写入日志的目录。然后可以像写入文件一样使用with语句进行TensorBoard的写入</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">log_dir = '.\\logs\\mnist'</span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir) </span><br><span class="line"></span><br><span class="line">with summary_writer.as_default():</span><br><span class="line">    # 添加文本模块</span><br><span class="line">    tf.summary.text(name, data, step=None, description=None)</span><br><span class="line">    # 添加图像模块</span><br><span class="line">    tf.summary.image(name, data, step=None, max_outputs=3, description=None)</span><br><span class="line">    # 添加标量模块</span><br><span class="line">    tf.summary.scalar(name, data, step=None, description=None)</span><br><span class="line">    # 添加直方图模块</span><br><span class="line">    tf.summary.histogram(name, data, step=None, buckets=None, description=None)</span><br><span class="line">    # 追踪计算路径，和trace_export配合使用</span><br><span class="line">    tf.summary.trace_on(graph=True, profiler=False)</span><br><span class="line">    # 路径输出，当使用自定义训练方式时，可以查看计算图，前提是要保证函数在静态图中运行，即有@tf.function修饰</span><br><span class="line">    tf.summary.trace_export(name="autograph", step=0, profiler_outdir=log_dir)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>运行后<strong>日志文件会保存在py文件同级目录logs下</strong>，然后<strong>在cmd命令行中运行tensorboard --logdir=path(logs的绝对路径即可，也可以进入py文件的同级目录中，直接写tensorboard --logdir=logs)</strong>，然后会<strong>出现一个本地的Web网址，复制并在浏览器中打开</strong>即可完成可视化工作。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=num_class)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def lenet(input_shape):</span><br><span class="line">    input_tensor = keras.Input(shape=input_shape)</span><br><span class="line"></span><br><span class="line">    net = dict()</span><br><span class="line"></span><br><span class="line">    net['input'] = input_tensor</span><br><span class="line">    net['conv1_1'] = keras.layers.Conv2D(6, kernel_size=(3, 3), activation='relu', padding='same', name='conv1_1')(</span><br><span class="line">        net['input'])</span><br><span class="line">    net['pool1'] = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool1')(net['conv1_1'])</span><br><span class="line">    net['conv2_1'] = keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='conv2_1')(</span><br><span class="line">        net['pool1'])</span><br><span class="line">    net['pool2'] = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool2')(net['conv2_1'])</span><br><span class="line">    net['conv3_1'] = keras.layers.Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same', name='conv3_1')(</span><br><span class="line">        net['pool2'])</span><br><span class="line">    net['Flatten'] = keras.layers.Flatten()(net['conv3_1'])</span><br><span class="line">    net['dense1'] = keras.layers.Dense(84, activation='relu')(net['Flatten'])</span><br><span class="line">    net['dense2'] = keras.layers.Dense(num_class, activation='softmax')(net['dense1'])</span><br><span class="line"></span><br><span class="line">    model = keras.Model(net['input'], net['dense2'])</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@tf.function</span><br><span class="line">def dynamic_gradient_descent(train_x, train_y):</span><br><span class="line">    y_pred = model(train_x, training=True)</span><br><span class="line">    loss = lossor(train_y, y_pred)</span><br><span class="line">    grads = tf.gradients(loss, model.trainable_variables)</span><br><span class="line"></span><br><span class="line">    return grads</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_picture(image, picture_num):</span><br><span class="line">    image = ((image + 1) * 127.5).astype(np.uint8)</span><br><span class="line">    image = np.concatenate([image[i * picture_num:(i + 1) * picture_num] for i in range(picture_num)], axis=2)</span><br><span class="line">    image = np.concatenate([image[i] for i in range(picture_num)], axis=0)</span><br><span class="line"></span><br><span class="line">    return image[np.newaxis, ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    num_class = 10</span><br><span class="line"></span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 250</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 10</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    # 创建模型</span><br><span class="line">    model = lenet((28, 28, 1))</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, 28, 28, 1))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    # 模型参数设置</span><br><span class="line">    model.compile(</span><br><span class="line">        optimizer=keras.optimizers.Adam(lr=1e-3),</span><br><span class="line">        loss=keras.losses.CategoricalCrossentropy(),</span><br><span class="line">        metrics=['acc']</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(1e-3)</span><br><span class="line">    lossor = keras.losses.CategoricalCrossentropy()</span><br><span class="line">    val_metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">    stamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")</span><br><span class="line">    log_dir = '.\\%s' % stamp</span><br><span class="line">    summary_writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line"></span><br><span class="line">    tf.summary.trace_on()</span><br><span class="line"></span><br><span class="line">    for epoch in range(max_epoch):</span><br><span class="line">        it_train = iter(db)</span><br><span class="line">        for train_x, train_y in db:</span><br><span class="line">            grads = dynamic_gradient_descent(train_x, train_y)</span><br><span class="line">            optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">        it_test = iter(db_test.shuffle(10000))</span><br><span class="line">        test_x, test_y = next(it_test)</span><br><span class="line">        y_pred = model(test_x)</span><br><span class="line">        loss = lossor(test_y, y_pred)</span><br><span class="line">        val_metrics(test_y, y_pred)</span><br><span class="line">        acc = val_metrics.result()</span><br><span class="line"></span><br><span class="line">        with summary_writer.as_default():</span><br><span class="line">            tf.summary.scalar('loss', loss, step=epoch)</span><br><span class="line">            tf.summary.scalar('acc', acc, step=epoch)</span><br><span class="line">            tf.summary.image('train_image', save_picture(test_x[:100].numpy(), 10), step=epoch)</span><br><span class="line"></span><br><span class="line">    with summary_writer.as_default():</span><br><span class="line">        tf.summary.trace_export(name="autograph", step=0)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/deep_learning/tensorboard2.png" alt="tensorboard2"><br>此时要注意，<strong>手动追踪计算图时，如果创建了多个计算图则会出错，计算图不显示。如果传入数据的类型或者维度发生了改变，则会创建新的计算图，因此会有多个计算图存在，所以显示会报错，这时可以修改类型或者维度，使其不创建新的计算图，或者给新的计算图赋予其他的step，防止同时存在于一张图上</strong>。上例中，训练集的大小为60000，如果batch设置为256，则60000/256无法整除，所以最后一个batch会额外创建计算图，在这里我将batch修改为250，这时60000/250可以整除，这样就可以成功显示计算图了。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  TensorBoard是我们使用TensorFlow的好帮手，有了可视化工具，我们可以<strong>方便的查看模型在何时出现了过拟合，可以直观的查看模型在合适已经不再有效训练，可以帮助我们更加清晰的了解自己设计的模型</strong>，因此我们需要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Data Augmentation(数据增强)</title>
    <url>/2020/05/13/deep%20learning%20data_augmentation/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Data Augmentation</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Data Augmentation(数据增强)</strong>:在深度学习工程实践中，必不可少的是数据集，但是如果<strong>自己采集数据集，非常的耗时，而且数量往往不够</strong>。这时需要一定的<strong>数据增强</strong>操作，来扩充自己的数据集<strong>使网络更加鲁棒</strong>。今天给小伙伴们盘点常用的数据增强操作。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/data.png" alt="data"></p>
<h1 id="OpenCV和Numpy存储数据差异"><a href="#OpenCV和Numpy存储数据差异" class="headerlink" title="OpenCV和Numpy存储数据差异"></a><font size="5" color="red">OpenCV和Numpy存储数据差异</font></h1><p><strong>OpenCV</strong>：在OpenCV中，图像的存储是<strong>列在前，行在后</strong>，和我们的直观理解不同，因此使用起来，尤其在图像坐标索引时，需要特别注意，有关OpenCV常用操作，可以参考我的另一篇博客OpenCV常用库。<br><strong>Numpy</strong>：在Numpy中，图像的存储是<strong>行在前，列在后</strong>，这符合我们的理解，因为在学习二维数组时，就是按照行在前，列在后的思想，有关Numpy常用操作，可以参考我的另一篇博客Numpy常用库。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">img1 = cv.resize(img, (300, 400))</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>img1的图像Numpy数组的shape为(400, 300, 3)，第一次使用时，奇怪的知识又增加了，一定要记得数据的转换。而且<strong>OpenCV读取和显示的图像默认是BGR类型</strong>的，这也容易产生错误。<br><img src="/images/deep_learning/compare.png" alt="compare"></p>
<h1 id="Flip-翻转"><a href="#Flip-翻转" class="headerlink" title="Flip(翻转)"></a><font size="5" color="red">Flip(翻转)</font></h1><p><strong>Flip(翻转)</strong>：对图像进行<strong>水平翻转，垂直翻转或者水平垂直同时翻转</strong>。翻转时图像的<strong>高宽不会发生变化</strong>，但是图像的<strong>坐标会发生变化</strong>。因此在目标检测等问题上，<strong>bounding-box需要调整相应的坐标</strong>。<br><img src="/images/deep_learning/flip0.png" alt="flip"><br><img src="/images/deep_learning/flip1.png" alt="flip"><br><img src="/images/deep_learning/flip-1.png" alt="flip"><br>在cv2中已经给我们提供了图像翻转的函数flip。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img, boxes):</span><br><span class="line">    cv.namedWindow('result')</span><br><span class="line">    nums = len(img)</span><br><span class="line">    for i in range(nums):</span><br><span class="line">        for box in boxes[i]:</span><br><span class="line">            cv.rectangle(img[i], tuple(box[:2]), tuple(box[2:4]), color[box[-1] - 1], 2)</span><br><span class="line">    if nums == 4:</span><br><span class="line">        result = cv.vconcat([cv.hconcat(img[:2]), cv.hconcat(img[2:])])</span><br><span class="line">    else:</span><br><span class="line">        result = cv.hconcat(img)</span><br><span class="line">    cv.imshow('result', result)</span><br><span class="line">    cv.waitKey(0)</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">boxes = [[24, 18, 220, 260, 1], [196, 16, 330, 244, 2]]</span><br><span class="line">color = [[0, 255, 0], [0, 0, 255]]</span><br><span class="line">output_size = (260, 360)</span><br><span class="line">input_size = tuple(img.shape[:2])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 垂直翻转</span><br><span class="line">flip0 = cv.flip(img, 0)</span><br><span class="line"># 水平翻转</span><br><span class="line">flip1 = cv.flip(img, 1)</span><br><span class="line"># 垂直水平同时翻转</span><br><span class="line">flip2 = cv.flip(img, -1)</span><br><span class="line">boxes0 = [[img.shape[0] - box[4 - i] if i % 2 else box[i] for i in range(4)] + [box[-1]] for box in boxes]</span><br><span class="line">boxes1 = [[box[i] if i % 2 else img.shape[1] - box[2 - i] for i in range(4)] + [box[-1]] for box in boxes]</span><br><span class="line">boxes2 = [[img.shape[0] - box[4 - i] if i % 2 else img.shape[1] - box[2 - i] for i in range(4)] + [box[-1]] for box in boxes]</span><br><span class="line">imshow([img, flip0, flip1, flip2], [boxes, boxes0, boxes1, boxes2])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/flip.png" alt="flip"></p>
<h1 id="Rotate-旋转"><a href="#Rotate-旋转" class="headerlink" title="Rotate(旋转)"></a><font size="5" color="red">Rotate(旋转)</font></h1><p><strong>Rotate(旋转)</strong>：对图像进行旋转，和翻转不同，<strong>不但图像的坐标会发生变化，而且图像的高宽可能会发生变化</strong>。因此在目标检测等问题上，<strong>bounding-box需要调整相应的坐标</strong>。<br><img src="/images/deep_learning/rotate0.png" alt="rotate"><br><img src="/images/deep_learning/rotate1.png" alt="rotate"><br><img src="/images/deep_learning/rotate2.png" alt="rotate"><br>在cv2中已经给我们提供了图像旋转的函数rotate，因为旋转可能会改变图像的高宽，为了展示方便，我先将它们的高宽调成相等。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img, boxes):</span><br><span class="line">    cv.namedWindow('result')</span><br><span class="line">    nums = len(img)</span><br><span class="line">    for i in range(nums):</span><br><span class="line">        for box in boxes[i]:</span><br><span class="line">            cv.rectangle(img[i], tuple(box[:2]), tuple(box[2:4]), color[box[-1] - 1], 2)</span><br><span class="line">    if nums == 4:</span><br><span class="line">        result = cv.vconcat([cv.hconcat(img[:2]), cv.hconcat(img[2:])])</span><br><span class="line">    else:</span><br><span class="line">        result = cv.hconcat(img)</span><br><span class="line">    cv.imshow('result', result)</span><br><span class="line">    cv.waitKey(0)</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">boxes = [[24, 18, 220, 260, 1], [196, 16, 330, 244, 2]]</span><br><span class="line">color = [[0, 255, 0], [0, 0, 255]]</span><br><span class="line">output_size = (260, 360)</span><br><span class="line">input_size = tuple(img.shape[:2])</span><br><span class="line"></span><br><span class="line">new_size = (300, 300)</span><br><span class="line">resize_img = cv.resize(img, new_size)</span><br><span class="line">boxes = [[int(box[i] * resize_img.shape[0] / img.shape[0]) if i % 2 else int(box[i] * resize_img.shape[1] / img.shape[1]) for i in range(4)] + [box[-1]] for box in boxes]</span><br><span class="line"></span><br><span class="line">rotate0 = cv.rotate(resize_img, 0)</span><br><span class="line">boxes0 = [[resize_img.shape[0] - box[3], box[0], resize_img.shape[0] - box[1], box[2]] + [box[-1]] for box in boxes]</span><br><span class="line"></span><br><span class="line">rotate1 = cv.rotate(resize_img, 1)</span><br><span class="line">boxes1 = [[resize_img.shape[1] - box[2], resize_img.shape[0] - box[3], resize_img.shape[1] - box[0], resize_img.shape[0] - box[1]] + [box[-1]] for box in boxes]</span><br><span class="line"></span><br><span class="line">rotate2 = cv.rotate(resize_img, 2)</span><br><span class="line">boxes2 = [[box[1], resize_img.shape[1] - box[2], box[3], resize_img.shape[1] - box[0]] + [box[-1]] for box in boxes]</span><br><span class="line">imshow([resize_img, rotate0, rotate1, rotate2], [boxes, boxes0, boxes1, boxes2])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/rotate.png" alt="rotate"></p>
<h1 id="Resize-调整大小"><a href="#Resize-调整大小" class="headerlink" title="Resize(调整大小)"></a><font size="5" color="red">Resize(调整大小)</font></h1><p><strong>Resize(调整大小)</strong>：对图像进行<strong>大小调整</strong>，这个操作是最复杂的，因为<strong>神经网络的输入是固定尺寸的图像</strong>，所以在<strong>大小调整后还要以相同尺寸输出</strong>，所以还需要加上<strong>灰框</strong>或者<strong>裁剪</strong>，而且<strong>还要考虑目标是否会被裁剪</strong>，因此在目标检测等问题上，<strong>bounding-box需要调整相应的坐标，而且需要判断bounding-box是否有效存在</strong>，在这里我设置了一个阈值，如果没有被裁剪掉的面积占总面积的0.25倍以上，则认为bounding-box是有效的，否则删除这个bounding-box。<br><img src="/images/deep_learning/resize0.png" alt="resize"><br>在cv2中已经给我们提供了图像调整大小的函数resize，为了展示方便，我将输出尺寸设置和输入相同。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img, boxes):</span><br><span class="line">    cv.namedWindow('result')</span><br><span class="line">    nums = len(img)</span><br><span class="line">    for i in range(nums):</span><br><span class="line">        for box in boxes[i]:</span><br><span class="line">            cv.rectangle(img[i], tuple(box[:2]), tuple(box[2:4]), color[box[-1] - 1], 2)</span><br><span class="line">    if nums == 4:</span><br><span class="line">        result = cv.vconcat([cv.hconcat(img[:2]), cv.hconcat(img[2:])])</span><br><span class="line">    else:</span><br><span class="line">        result = cv.hconcat(img)</span><br><span class="line">    cv.imshow('result', result)</span><br><span class="line">    cv.waitKey(0)</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">boxes = [[24, 18, 220, 260, 1], [196, 16, 330, 244, 2]]</span><br><span class="line">color = [[0, 255, 0], [0, 0, 255]]</span><br><span class="line">output_size = (260, 360)</span><br><span class="line">input_size = tuple(img.shape[:2])</span><br><span class="line"></span><br><span class="line">ratio_h, ratio_w = np.where(np.random.rand(2) &lt; 0.5,  np.random.uniform(0.5, 1, 2), np.random.uniform(1, 2, 2))</span><br><span class="line">new_h, new_w = int(input_size[0] * ratio_h), int(input_size[1] * ratio_w)</span><br><span class="line">scale_img = cv.resize(img, (new_w, new_h))</span><br><span class="line">valid_h = 0 if new_h &lt;= output_size[0] else np.random.randint(0, new_h - output_size[0])</span><br><span class="line">valid_w = 0 if new_w &lt;= output_size[1] else np.random.randint(0, new_w - output_size[1])</span><br><span class="line">crop_img = scale_img[valid_h:min(valid_h + output_size[0], new_h), valid_w:min(valid_w + output_size[1], new_w)]</span><br><span class="line">resize_img0 = np.ones((output_size[0], output_size[1], 3), np.uint8) * 127</span><br><span class="line">dy, dx = int(np.random.rand() * (output_size[0] - crop_img.shape[0])), int(np.random.rand() * (output_size[1] - crop_img.shape[1]))</span><br><span class="line">resize_img0[dy:dy + crop_img.shape[0], dx:dx + crop_img.shape[1]] = crop_img</span><br><span class="line">boxes0 = [[int(box[i] * ratio_h) + dy - valid_h if i % 2 else int(box[i] * ratio_w) + dx - valid_w for i in range(4)] + [box[-1]] for box in boxes]</span><br><span class="line">boxes1 = []</span><br><span class="line">for box in boxes0:</span><br><span class="line">    new_box = [min(output_size[3 - i], box[i]) if i &gt;= 2 else max(0, box[i]) for i in range(4)] + [box[-1]]</span><br><span class="line">    area = (box[2] - box[0]) * (box[3] - box[1])</span><br><span class="line">    new_area = (new_box[2] - new_box[0]) * (new_box[3] - new_box[1])</span><br><span class="line">    if new_area &gt; 0.25 * area:</span><br><span class="line">        boxes1.append(new_box)</span><br><span class="line">imshow([img, resize_img0], [boxes, boxes1])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/resize.png" alt="resize"></p>
<h1 id="Noise-噪声"><a href="#Noise-噪声" class="headerlink" title="Noise(噪声)"></a><font size="5" color="red">Noise(噪声)</font></h1><p><strong>Noise(噪声)</strong>：对图像添加噪声，这个操作是最简单的，因为<strong>添加噪声，尺寸不会改变，因此bounding-box不需要修改</strong>，但是要注意，如果加入噪声，<strong>数据变为负数后，直接转化为uint8类型的数据会出错</strong>，所以<strong>需要先clip，将数据限制在[0, 255]之间</strong>。<br>在numpy中直接使用random模块，可以产生随机数，根据需要设置相应的噪声类型即可，一般高斯噪声较为常用。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img, boxes):</span><br><span class="line">    cv.namedWindow('result')</span><br><span class="line">    nums = len(img)</span><br><span class="line">    for i in range(nums):</span><br><span class="line">        for box in boxes[i]:</span><br><span class="line">            cv.rectangle(img[i], tuple(box[:2]), tuple(box[2:4]), color[box[-1] - 1], 2)</span><br><span class="line">    if nums == 4:</span><br><span class="line">        result = cv.vconcat([cv.hconcat(img[:2]), cv.hconcat(img[2:])])</span><br><span class="line">    else:</span><br><span class="line">        result = cv.hconcat(img)</span><br><span class="line">    cv.imshow('result', result)</span><br><span class="line">    cv.waitKey(0)</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">boxes = [[24, 18, 220, 260, 1], [196, 16, 330, 244, 2]]</span><br><span class="line">color = [[0, 255, 0], [0, 0, 255]]</span><br><span class="line">output_size = (260, 360)</span><br><span class="line">input_size = tuple(img.shape[:2])</span><br><span class="line"></span><br><span class="line">noise_img = np.clip(img + np.random.normal(0, 30, (img.shape[0], img.shape[1], 3)), 0, 255).astype(np.uint8)</span><br><span class="line">imshow([img, noise_img], [boxes, boxes])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/noise.png" alt="noise"></p>
<h1 id="HSV-色调，饱和度，明度"><a href="#HSV-色调，饱和度，明度" class="headerlink" title="HSV(色调，饱和度，明度)"></a><font size="5" color="red">HSV(色调，饱和度，明度)</font></h1><p><strong>HSV(色调，饱和度，明度)</strong>：HSV彩色空间不同于我们熟知的RGB彩色空间，其使用<strong>色调，饱和度和明度代替红绿蓝三个通道</strong>。在OpenCV中，<strong>色调的范围是[0, 179]，饱和度和明度的范围都是[0, 255]</strong>，因为<strong>改变HSV的数值，尺寸不会改变，因此bounding-box不需要修改</strong><br>在cv2中直接使用cvtColor进行色彩空间转化，然后给HSV通道引入随机数即可达到改变色调，饱和度和明度的效果。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img, boxes):</span><br><span class="line">    cv.namedWindow('result')</span><br><span class="line">    nums = len(img)</span><br><span class="line">    for i in range(nums):</span><br><span class="line">        for box in boxes[i]:</span><br><span class="line">            cv.rectangle(img[i], tuple(box[:2]), tuple(box[2:4]), color[box[-1] - 1], 2)</span><br><span class="line">    if nums == 4:</span><br><span class="line">        result = cv.vconcat([cv.hconcat(img[:2]), cv.hconcat(img[2:])])</span><br><span class="line">    else:</span><br><span class="line">        result = cv.hconcat(img)</span><br><span class="line">    cv.imshow('result', result)</span><br><span class="line">    cv.waitKey(0)</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">boxes = [[24, 18, 220, 260, 1], [196, 16, 330, 244, 2]]</span><br><span class="line">color = [[0, 255, 0], [0, 0, 255]]</span><br><span class="line">output_size = (260, 360)</span><br><span class="line">input_size = tuple(img.shape[:2])</span><br><span class="line"></span><br><span class="line">hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)</span><br><span class="line">hsv_img = hsv_img * np.random.uniform(0.5, 2, 3)</span><br><span class="line">hsv_img[:, :, 0] = np.clip(hsv_img[:, :, 0], 0, 179)</span><br><span class="line">hsv_img[:, :, 1] = np.clip(hsv_img[:, :, 1], 0, 255)</span><br><span class="line">hsv_img[:, :, 2] = np.clip(hsv_img[:, :, 2], 0, 255)</span><br><span class="line">hsv_img = hsv_img.astype(np.uint8)</span><br><span class="line">bgr_img = cv.cvtColor(hsv_img, cv.COLOR_HSV2BGR)</span><br><span class="line">imshow([img, bgr_img], [boxes, boxes])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/hsv.png" alt="hsv"></p>
<h1 id="整体代码"><a href="#整体代码" class="headerlink" title="整体代码"></a><font size="5" color="red">整体代码</font></h1><p>将上面五种操作结合起来，写在一个函数中，可以实现图像和bounding-box输入，增强后的图像和bounding-box输出。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def imshow(img, boxes):</span><br><span class="line">    cv.namedWindow('result')</span><br><span class="line">    nums = len(img)</span><br><span class="line">    for i in range(nums):</span><br><span class="line">        for box in boxes[i]:</span><br><span class="line">            cv.rectangle(img[i], tuple(box[:2]), tuple(box[2:4]), color[box[-1] - 1], 2)</span><br><span class="line">    if nums == 4:</span><br><span class="line">        result = cv.vconcat([cv.hconcat(img[:2]), cv.hconcat(img[2:])])</span><br><span class="line">    else:</span><br><span class="line">        result = cv.hconcat(img)</span><br><span class="line">    cv.imshow('result', result)</span><br><span class="line">    cv.waitKey(0)</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def data_augmentation(image, bbox, output_shape, resize_scale=2, threshold=0.25, noise_scale=10, h_scale=2, s_scale=2, v_scale=2):</span><br><span class="line"></span><br><span class="line">    # 增加噪声</span><br><span class="line">    noise_img = np.clip(image + (np.random.normal(0, noise_scale, img.shape)), 0, 255).astype(np.uint8)</span><br><span class="line"></span><br><span class="line">    # 改变色调，饱和度，明度</span><br><span class="line">    hsv_img = cv.cvtColor(noise_img, cv.COLOR_BGR2HSV)</span><br><span class="line"></span><br><span class="line">    h_ratio = np.random.uniform(1 / h_scale, 1, 1) if np.random.rand() &lt; 0.5 else np.random.uniform(1, h_scale, 1)</span><br><span class="line">    s_ratio = np.random.uniform(1 / s_scale, 1, 1) if np.random.rand() &lt; 0.5 else np.random.uniform(1, s_scale, 1)</span><br><span class="line">    v_ratio = np.random.uniform(1 / v_scale, 1, 1) if np.random.rand() &lt; 0.5 else np.random.uniform(1, v_scale, 1)</span><br><span class="line"></span><br><span class="line">    hsv_img[:, :, 0] = np.clip(hsv_img[:, :, 0] * h_ratio, 0, 179)</span><br><span class="line">    hsv_img[:, :, 1] = np.clip(hsv_img[:, :, 1] * s_ratio, 0, 255)</span><br><span class="line">    hsv_img[:, :, 2] = np.clip(hsv_img[:, :, 2] * v_ratio, 0, 255)</span><br><span class="line"></span><br><span class="line">    hsv_img = hsv_img.astype(np.uint8)</span><br><span class="line"></span><br><span class="line">    bgr_img = cv.cvtColor(hsv_img, cv.COLOR_HSV2BGR)</span><br><span class="line"></span><br><span class="line">    # 旋转</span><br><span class="line">    rotate_flag = np.random.rand()</span><br><span class="line">    if rotate_flag &lt; 1 / 4:</span><br><span class="line">        rotate_img = cv.rotate(bgr_img, 0)</span><br><span class="line">        rotate_boxes = [[bgr_img.shape[0] - box[3], box[0], bgr_img.shape[0] - box[1], box[2]] + [box[-1]] for box in bbox]</span><br><span class="line">    elif rotate_flag &lt; 2 / 4:</span><br><span class="line">        rotate_img = cv.rotate(bgr_img, 1)</span><br><span class="line">        rotate_boxes = [[bgr_img.shape[1] - box[2], bgr_img.shape[0] - box[3], bgr_img.shape[1] - box[0], bgr_img.shape[0] - box[1]] + [box[-1]] for box in bbox]</span><br><span class="line">    elif rotate_flag &lt; 3 / 4:</span><br><span class="line">        rotate_img = cv.rotate(bgr_img, 2)</span><br><span class="line">        rotate_boxes = [[box[1], bgr_img.shape[1] - box[2], box[3], bgr_img.shape[1] - box[0]] + [box[-1]] for box in bbox]</span><br><span class="line">    else:</span><br><span class="line">        rotate_img = bgr_img</span><br><span class="line">        rotate_boxes = bbox</span><br><span class="line"></span><br><span class="line">    # 翻转操作</span><br><span class="line">    flip_flag = np.random.rand()</span><br><span class="line">    if flip_flag &lt; 1 / 4:</span><br><span class="line">        flip_img = cv.flip(rotate_img, 0)</span><br><span class="line">        flip_boxes = [[rotate_img.shape[0] - box[4 - i] if i % 2 else box[i] for i in range(4)] + [box[-1]] for box in rotate_boxes]</span><br><span class="line">    elif flip_flag &lt; 2 / 4:</span><br><span class="line">        flip_img = cv.flip(rotate_img, 1)</span><br><span class="line">        flip_boxes = [[box[i] if i % 2 else rotate_img.shape[1] - box[2 - i] for i in range(4)] + [box[-1]] for box in rotate_boxes]</span><br><span class="line">    elif flip_flag &lt; 3 / 4:</span><br><span class="line">        flip_img = cv.flip(rotate_img, -1)</span><br><span class="line">        flip_boxes = [[rotate_img.shape[0] - box[4 - i] if i % 2 else rotate_img.shape[1] - box[2 - i] for i in range(4)] + [box[-1]] for box in rotate_boxes]</span><br><span class="line">    else:</span><br><span class="line">        flip_img = rotate_img</span><br><span class="line">        flip_boxes = rotate_boxes</span><br><span class="line"></span><br><span class="line">    # 调整大小，并加灰框</span><br><span class="line">    ratio_h, ratio_w = np.where(np.random.rand(2) &lt; 0.5,  np.random.uniform(1 / resize_scale, 1, 2), np.random.uniform(1, resize_scale, 2))</span><br><span class="line">    new_h, new_w = int(flip_img.shape[0] * ratio_h), int(flip_img.shape[1] * ratio_w)</span><br><span class="line">    scale_img = cv.resize(flip_img, (new_w, new_h))</span><br><span class="line">    valid_h = 0 if new_h &lt;= output_shape[0] else np.random.randint(0, new_h - output_shape[0])</span><br><span class="line">    valid_w = 0 if new_w &lt;= output_shape[1] else np.random.randint(0, new_w - output_shape[1])</span><br><span class="line">    crop_img = scale_img[valid_h:min(valid_h + output_shape[0], new_h), valid_w:min(valid_w + output_shape[1], new_w)]</span><br><span class="line">    resize_img = np.ones((output_shape[0], output_shape[1], 3), np.uint8) * 127</span><br><span class="line">    dy, dx = int(np.random.rand() * (output_shape[0] - crop_img.shape[0])), int(np.random.rand() * (output_shape[1] - crop_img.shape[1]))</span><br><span class="line">    resize_img[dy:dy + crop_img.shape[0], dx:dx + crop_img.shape[1]] = crop_img</span><br><span class="line">    boxes = [[int(box[i] * ratio_h) + dy - valid_h if i % 2 else int(box[i] * ratio_w) + dx - valid_w for i in range(4)] + [box[-1]] for box in flip_boxes]</span><br><span class="line">    resize_boxes = []</span><br><span class="line">    for box in boxes:</span><br><span class="line">        new_box = [min(output_shape[3 - i], box[i]) if i &gt;= 2 else max(0, box[i]) for i in range(4)] + [box[-1]]</span><br><span class="line">        area = (box[2] - box[0]) * (box[3] - box[1])</span><br><span class="line">        new_area = (new_box[2] - new_box[0]) * (new_box[3] - new_box[1])</span><br><span class="line">        if new_area &gt; threshold * area:</span><br><span class="line">            resize_boxes.append(new_box)</span><br><span class="line"></span><br><span class="line">    return resize_img, resize_boxes</span><br><span class="line"></span><br><span class="line">img = cv.imread('origin.png')</span><br><span class="line">boxes = [[24, 18, 220, 260, 1], [196, 16, 330, 244, 2]]</span><br><span class="line">color = [[0, 255, 0], [0, 0, 255]]</span><br><span class="line">output_size = (300, 300)</span><br><span class="line">input_size = tuple(img.shape[:2])</span><br><span class="line"></span><br><span class="line">img1, bbox1 = data_augmentation(img, boxes, output_size)</span><br><span class="line">img2, bbox2 = data_augmentation(img, boxes, output_size)</span><br><span class="line">img3, bbox3 = data_augmentation(img, boxes, output_size)</span><br><span class="line">img4, bbox4 = data_augmentation(img, boxes, output_size)</span><br><span class="line">imshow([img1, img2, img3, img4], [bbox1, bbox2, bbox3, bbox4])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/result.png" alt="result"></p>
<h1 id="其他数据增强操作"><a href="#其他数据增强操作" class="headerlink" title="其他数据增强操作"></a><font size="5" color="red">其他数据增强操作</font></h1><p>上面说的数据增强操作，主要是<strong>针对于有bounding-box的目标检测任务，所以数据增强会受到一定的限制</strong>。如果我们<strong>面对的问题仅仅是一个图像分类问题，那么我们就会有更多的图像增强操作</strong>，如<strong>设置图像的旋转角度，或者进行仿射操作</strong>，但是因为bounding-box的存在，<strong>如果进行任意角度的旋转或者仿射操作，bounding-box就不再是一个与坐标轴平行的矩形框，而且图像的尺寸变化也会变得非常复杂</strong>，因此通过上面5中数据增强操作已经可以满足绝大部分的需要，所以不探讨如何使用其他方法，有感兴趣的小伙伴们可以去寻找一些自己喜欢的数据增强方式。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>数据量是深度学习模型性能的重要决定因素</strong>，数据量很少，可能很好的算法也很难达到较好的效果。因此数据增强操作就变得异常重要，如何进行数据增强是小伙伴们必须要掌握的技术。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Metrics黑科技</title>
    <url>/2020/05/12/deep%20learning%20metrics/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Metrics</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Metrics(评价指标)</strong>:评价指标是<strong>检验神经网络模型好坏的评定依据</strong>，也是<strong>我们要达到的最终目标</strong>，指标越好则我们的任务完成的越好。有时我们需要<strong>根据评价指标修改我们的网络模型，参数</strong>等等，就类似于考试成绩一样，我们根据成绩检验自己薄弱的地方，然后去调整和修改，神经网络也是一样，只有建立好合适的评价指标，才能真正区分网络的优劣。今天给小伙伴们介绍深度学习中常用的评价指标。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/confuse.png" alt="confuse"></p>
<h1 id="Confusion-matrix-混淆矩阵"><a href="#Confusion-matrix-混淆矩阵" class="headerlink" title="Confusion matrix(混淆矩阵)"></a><font size="5" color="red">Confusion matrix(混淆矩阵)</font></h1><p>在介绍评价指标之前，首先要介绍混淆矩阵，以一个二分类问题来说，行标签代表预测值为正还是为负，列标签代表真实值为正还是为负，因此产生4中状态。</p>
<ol>
<li><strong>TP(True Positive，真正率)</strong>：真代表预测正确，正代表预测为正样本，因此含义为<strong>将正样本预测为正样本的个数</strong>。</li>
<li><strong>TN(True Negative，真负率)</strong>：真代表预测正确，负代表预测为负样本，因此含义为<strong>将负样本预测为负样本的个数</strong>。</li>
<li><strong>FP(False Positive，假正率)</strong>：假代表预测错误，正代表预测为正样本，因此含义为<strong>将负样本预测为正样本的个数</strong>。</li>
<li><strong>FN(False Negative，假负率)</strong>：假代表预测错误，负代表预测为负样本，因此含义为<strong>将正样本预测为负样本的个数</strong>。</li>
</ol>
<p>混淆矩阵是将所有可能的状态列举出来，然后通过表格可以计算出相应的评价指标，<strong>对于样本不平衡问题非常有效</strong>。</p>
<h1 id="Accuracy-准确率"><a href="#Accuracy-准确率" class="headerlink" title="Accuracy(准确率)"></a><font size="5" color="red">Accuracy(准确率)</font></h1><script type="math/tex; mode=display">acc = \frac{TP + TN}{TP + TN + FP + FN}</script><p><strong>Accuracy(准确率)</strong>：指<strong>正确预测的数量与总数的比值，准确率越高则代表预测的越准确</strong>。在TensorFlow2.0中已经给我们提供了计算Accuracy的评价函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 计算准确率，必须完全相等才算准确</span><br><span class="line">metrics = keras.metrics.Accuracy()</span><br><span class="line"></span><br><span class="line"># 计算二分类准确率，大于threshold即算为准确</span><br><span class="line">metrics = keras.metrics.BinaryAccuracy(threshold=0.5)</span><br><span class="line"></span><br><span class="line"># 计算多分类准确率</span><br><span class="line">metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line"></span><br><span class="line"># 计算TopK多分类准确率，k默认为5</span><br><span class="line">metrics = keras.metrics.TopKCategoricalAccuracy(k=5)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Precision-精确度"><a href="#Precision-精确度" class="headerlink" title="Precision(精确度)"></a><font size="5" color="red">Precision(精确度)</font></h1><script type="math/tex; mode=display">precision = \frac{TP}{TP + FP}</script><p><strong>Precision(精确度)</strong>：又称为查准率，指<strong>正样本预测为正的数量与所有样本预测为正的数量的比值，精确度越高，代表对预测为正的样本中，正样本的比例越高</strong>。当<strong>负样本判断错误的成本非常高，正样本判断错误的成本非常低的时候，我们选择较高的精确度</strong>，保证预测为正的样本中，负样本尽可能少，减少负样本判断错误的成本。在TensorFlow2.0中已经给我们提供了计算Precision的评价函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 默认选择阈值为0.5</span><br><span class="line">metrics = keras.metrics.Precision(thresholds=None)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Recall-召回率"><a href="#Recall-召回率" class="headerlink" title="Recall(召回率)"></a><font size="5" color="red">Recall(召回率)</font></h1><script type="math/tex; mode=display">recall = \frac{TP}{TP + FN}</script><p><strong>Recall(召回率)</strong>：又称为敏感度(Sensitivity)，查全率，指<strong>正样本预测为正的数量与所有正样本的数量的比值，召回率越高，代表所有正样本中，预测为正的样本的比例越高</strong>。当<strong>正样本判断错误的成本非常高，负样本判断错误的成本非常低的时候，我们选择较高的召回率</strong>，保证正样本尽可能被判断正确，减少正样本判断错误的成本。在TensorFlow2.0中已经给我们提供了计算Recall的评价函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 默认选择阈值为0.5</span><br><span class="line">metrics = keras.metrics.Recall(thresholds=None)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="F1-score"><a href="#F1-score" class="headerlink" title="F1-score"></a><font size="5" color="red">F1-score</font></h1><script type="math/tex; mode=display">F1-score = \frac{2}{\frac{1}{precision} + \frac{1}{recall}} = \frac{2 \times precision \times recall}{precision + recall}</script><p><strong>F1-score</strong>：<strong>精确度和召回率的分子是相同的，分母有差异，两者是此消彼长的</strong>，究竟如何选择两者之间的权重，需要结合具体问题具体分析，判断是正样本判断错误的成本高还是负样本判断错误的成本高。<strong>为了兼顾精确度和召回率，引入了两者的调和平均数F1-score作为指标</strong>。在TensorFlow2.0中没有计算F1-score的评价函数，<strong>需要自己定义计算方法</strong>。</p>
<ol>
<li><strong>继承keras.metrics.Metric类</strong></li>
<li><strong>在<strong>init</strong>(): 中变量要通过下面这种方式创建self.var = self.add_weight(name=name, initializer=’zeros’)</strong></li>
<li><strong>在update_state():中变量要通过下面这种方式更新self.var.assign_add()</strong></li>
<li><strong>在result()中: 返回变量</strong></li>
</ol>
<h1 id="Specificity-特异度"><a href="#Specificity-特异度" class="headerlink" title="Specificity(特异度)"></a><font size="5" color="red">Specificity(特异度)</font></h1><script type="math/tex; mode=display">specificity = \frac{TN}{FP + TN}</script><p><strong>Specificity(特异度)</strong>：指<strong>负样本预测为负的数量与所有负样本的数量的比值，特异度越高，代表所有负样本中，预测为负的样本的比例越高</strong>。在TensorFlow2.0中没有计算Specificity的评价函数，<strong>需要自己定义计算方法</strong>，步骤如下。</p>
<ol>
<li><strong>继承keras.metrics.Metric类</strong></li>
<li><strong>在<strong>init</strong>(): 中变量要通过下面这种方式创建self.var = self.add_weight(name=name, initializer=’zeros’)</strong></li>
<li><strong>在update_state():中变量要通过下面这种方式更新self.var.assign_add()</strong></li>
<li><strong>在result()中: 返回变量</strong></li>
</ol>
<h1 id="FPR-假正率"><a href="#FPR-假正率" class="headerlink" title="FPR(假正率)"></a><font size="5" color="red">FPR(假正率)</font></h1><script type="math/tex; mode=display">FPR = 1 - specificity = \frac{FP}{FP + TN}</script><p><strong>FPR(假正率)</strong>：指<strong>负样本预测为正的数量与所有负样本的数量的比值，假正率越低，代表所有负样本中，预测为正样本的比例越低</strong>。在TensorFlow2.0中已经给我们提供了计算假正个数的评价函数，是<strong>将数据最后一个维度计算之后，对所有结果求和</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 默认选择阈值为0.5，注意计算的是个数，而不是比例</span><br><span class="line">metrics = keras.metrics.FalsePositives(thresholds=None)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="ROC-Curve-Receiver-Operating-Characteristic，受试者操作特性曲线"><a href="#ROC-Curve-Receiver-Operating-Characteristic，受试者操作特性曲线" class="headerlink" title="ROC Curve(Receiver Operating Characteristic，受试者操作特性曲线)"></a><font size="5" color="red">ROC Curve(Receiver Operating Characteristic，受试者操作特性曲线)</font></h1><p><strong>ROC Curve</strong>：是一条<strong>以不同阈值下的FPR(假正率)为横坐标，不同阈值下的Recall(召回率)为纵坐标的曲线</strong>。<br><strong>ROC曲线绘制步骤</strong>：</p>
<ol>
<li><strong>从高到低，依次将每个测试样本属于正样本的概率值从大到小排序</strong>。</li>
<li>根据排序，<strong>从高到低依次将概率值作为阈值，当概率大于等于这个阈值时，预测为正样本，否则预测为负样本</strong>。</li>
<li>根据步骤2得到的结果计算FPR和Recall，<strong>遍历所有样本，得到一组(FPR, Recall)，并和阈值取值为0和1下的(FPR, Recall)结合在图像上绘制出来</strong>，就可以得到ROC曲线。</li>
</ol>
<p>ROC曲线特性：</p>
<ol>
<li>当测试集中的<strong>正负样本的分布变化的时候，ROC曲线能够保持不变</strong>，这是ROC曲线的最大优点，但是<strong>如果正负样本的成本差距较大，则很难从ROC曲线中看出结论</strong>。</li>
<li>ROC曲线<strong>越接近左上角代表模型的效果越好</strong>。<br><img src="/images/deep_learning/roc.png" alt="roc"></li>
</ol>
<h1 id="AUC-Area-Under-Curve，ROC曲线下的面积"><a href="#AUC-Area-Under-Curve，ROC曲线下的面积" class="headerlink" title="AUC(Area Under Curve，ROC曲线下的面积)"></a><font size="5" color="red">AUC(Area Under Curve，ROC曲线下的面积)</font></h1><p><strong>AUC</strong>：<strong>定义为ROC曲线下的面积，值域为[0, 1]</strong>，<strong>该值越大，代表ROC曲线越接近左上角，说明模型效果越好</strong>。在TensorFlow2.0中已经给我们提供了计算AUC的评价函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 默认选择计算阈值的个数为200个</span><br><span class="line">metrics = keras.metrics.AUC(num_thresholds=200)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="PR-Curve-Precision-Recall-Curve，查准率查全率曲线"><a href="#PR-Curve-Precision-Recall-Curve，查准率查全率曲线" class="headerlink" title="PR Curve(Precision Recall Curve，查准率查全率曲线)"></a><font size="5" color="red">PR Curve(Precision Recall Curve，查准率查全率曲线)</font></h1><p><strong>PR Curve</strong>：是一条<strong>以不同阈值下的Recall(查全率)为横坐标，不同阈值下的Precision(查准率)为纵坐标的曲线</strong>。<br><strong>PR曲线绘制步骤</strong>：</p>
<ol>
<li><strong>从高到低，依次将每个测试样本属于正样本的概率值从大到小排序</strong>。</li>
<li>根据排序，<strong>从高到低依次将概率值作为阈值，当概率大于等于这个阈值时，预测为正样本，否则预测为负样本</strong>。</li>
<li>根据步骤2得到的结果计算Recall和Precision，<strong>遍历所有样本，得到一组(Recall, Precision)，并和阈值取值为0和1下的(Recall, Precision)结合在图像上绘制出来</strong>，就可以得到PR曲线。</li>
</ol>
<p>PR曲线特性：</p>
<ol>
<li>PR曲线的两个指标都聚焦于正样本，因此在类别不平衡问题中主要关心正样本，在正负样本的成本差距较大情况下，PR曲线优于ROC曲线。</li>
<li>PR曲线<strong>越接近右上角代表模型的效果越好</strong>。<br><img src="/images/deep_learning/pr.png" alt="pr"></li>
</ol>
<h1 id="AP-Average-Precision，平均精度-和mAP-mean-Average-Precision"><a href="#AP-Average-Precision，平均精度-和mAP-mean-Average-Precision" class="headerlink" title="AP(Average Precision，平均精度)和mAP(mean Average Precision)"></a><font size="5" color="red">AP(Average Precision，平均精度)和mAP(mean Average Precision)</font></h1><p><strong>AP(平均精度)</strong>：<strong>定义为PR曲线下的面积，值域为[0, 1]</strong>，<strong>该值越大，代表PR曲线越接近右上角，说明模型效果越好</strong>。<br><strong>mAP</strong>：<strong>对每个类的AP求平均，值域为[0, 1]</strong>，<strong>该值越大，说明模型效果越好，因为目标检测算法中存在正负样本不平衡的问题，因此mAP是目标检测算法中最重要的指标之一</strong>。在TensorFlow2.0中没有计算AP的评价函数，<strong>需要自己定义计算方法</strong>，步骤如下。</p>
<ol>
<li><strong>继承keras.metrics.Metric类</strong></li>
<li><strong>在<strong>init</strong>(): 中变量要通过下面这种方式创建self.var = self.add_weight(name=name, initializer=’zeros’)</strong></li>
<li><strong>在update_state():中变量要通过下面这种方式更新self.var.assign_add()</strong></li>
<li><strong>在result()中: 返回变量</strong></li>
</ol>
<h1 id="IOU-Intersection-Over-Union，交并比"><a href="#IOU-Intersection-Over-Union，交并比" class="headerlink" title="IOU(Intersection Over Union，交并比)"></a><font size="5" color="red">IOU(Intersection Over Union，交并比)</font></h1><p><strong>IOU(交并比)</strong>：可以理解为算法的结果与标记结果的重合程度，算法的结果与真实物体进行<strong>交运算的结果除以进行并运算的结果</strong>。用于<strong>评估语义分割算法性能的指标是平均IOU</strong>，通过下图可以直观的看出IOU的计算方法，IOU的值越大，算法的效果越好。在TensorFlow2.0中没有计算IOU的评价函数，<strong>需要自己定义计算方法</strong>，步骤如下。</p>
<ol>
<li><strong>继承keras.metrics.Metric类</strong></li>
<li><strong>在<strong>init</strong>(): 中变量要通过下面这种方式创建self.var = self.add_weight(name=name, initializer=’zeros’)</strong></li>
<li><strong>在update_state():中变量要通过下面这种方式更新self.var.assign_add()</strong></li>
<li><strong>在result()中: 返回变量</strong><br><img src="/images/Semantic_segmentation/Dataset_I.png" alt="IOU"></li>
</ol>
<h1 id="MSE-Mean-Squared-Error，均方误差"><a href="#MSE-Mean-Squared-Error，均方误差" class="headerlink" title="MSE(Mean Squared Error，均方误差)"></a><font size="5" color="red">MSE(Mean Squared Error，均方误差)</font></h1><script type="math/tex; mode=display">MSE = \frac{1}{N} \sum_{i=1}^{N}{(y^{(i)} - f(x^{(i)}))^2}</script><p><strong>MSE(均方误差)</strong>：指<strong>预测结果与真实值之差平方的期望值</strong>，其中<strong>平方误差是估计值和实际值之差的平方，也称为(L2 Loss)</strong>，MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。在TensorFlow2.0中已经给我们提供了计算MSE的评价函数，是<strong>将数据最后一个维度计算之后，对所有结果求平均值</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line">metrics = keras.metrics.MeanSquaredError()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="MAE-Mean-Absolute-Error，平均绝对误差"><a href="#MAE-Mean-Absolute-Error，平均绝对误差" class="headerlink" title="MAE(Mean Absolute Error，平均绝对误差)"></a><font size="5" color="red">MAE(Mean Absolute Error，平均绝对误差)</font></h1><script type="math/tex; mode=display">MAE = \frac{1}{N} \sum_{i=1}^{N}{|y^{(i)} - f(x^{(i)})|}</script><p><strong>MAE(平均绝对误差)</strong>：指<strong>预测结果与真实值绝对误差的平均值</strong>，其中<strong>绝对误差是估计值和实际值之间的距离，也称为(L1 Loss)</strong>，MAE能更好地反映预测值误差的实际情况。在TensorFlow2.0中已经给我们提供了计算MAE的评价函数，是<strong>将数据最后一个维度计算之后，对所有结果求平均值</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line">metrics = keras.metrics.MeanAbsoluteError()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Binary-Cross-Entropy-二分类交叉熵"><a href="#Binary-Cross-Entropy-二分类交叉熵" class="headerlink" title="Binary Cross Entropy(二分类交叉熵)"></a><font size="5" color="red">Binary Cross Entropy(二分类交叉熵)</font></h1><script type="math/tex; mode=display">Binary \ Cross \ Entropy =  -\frac{1}{N} \sum_{i=1}^{N}{(y^{(i)} \cdot \ln{(f(x^{(i)})}) + (1 - y^{(i)}) \cdot (1 - \ln{(f(x^{(i)})}))}</script><p><strong>Binary Cross Entropy</strong>：用来<strong>评估当前训练得到的概率分布与真实分布的差异情况</strong>，它刻画的是实际概率与期望概率的距离，也就是交叉熵的值越小，两个概率分布就越接近。在<strong>二分类中，每个数据独立计算交叉熵，和同一维度其他数据无关，允许多个1同时出现，经常配合sigmoid激活函数使用</strong>。在TensorFlow2.0中已经给我们提供了计算Binary Cross Entropy的评价函数，是<strong>将每一个数据单独计算之后，对所有数据求平均值</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line">metrics = keras.metrics.BinaryCrossentropy()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Categorical-Cross-Entropy-多分类交叉熵"><a href="#Categorical-Cross-Entropy-多分类交叉熵" class="headerlink" title="Categorical Cross Entropy(多分类交叉熵)"></a><font size="5" color="red">Categorical Cross Entropy(多分类交叉熵)</font></h1><script type="math/tex; mode=display">Categorical \ Cross \ Entropy =  -\frac{1}{N} \sum_{i=1}^{N}{(y^{(i)} \cdot \ln{(f(x^{(i)})))}}</script><p><strong>Categorical Cross Entropy</strong>：用来<strong>评估当前训练得到的概率分布与真实分布的差异情况</strong>，它刻画的是实际概率与期望概率的距离，也就是交叉熵的值越小，两个概率分布就越接近。在<strong>多分类中，在某个维度上计算交叉熵，在该维度上其他数据一般只有一个1出现，其他全为0，经常配合Softmax激活函数使用</strong>。在TensorFlow2.0中已经给我们提供了计算Categorical Cross Entropy的评价函数，是<strong>将数据最后一个维度计算之后，对所有结果求平均值</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line">metrics = keras.metrics.BinaryCrossentropy()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  评价函数和损失函数类似，<strong>评价函数在一定程度上可以和损失函数相互转化</strong>，如<strong>MSE，MAE，交叉熵既可以作为评价函数，又可以作为损失函数</strong>。在选择评价函数时，我们首先要<strong>判断任务类型</strong>，是分类任务还是回归任务。<strong>分类任务可以考虑Accuracy评价函数，回归任务可以考虑MSE或者MAE评价函数</strong>。也可以<strong>根据正负样本的损失比例，来给予Precision和Recall一定的权重</strong>。在实际的工程应用之中，往往需要自己设计一个合适的评价函数，如<strong>目标检测问题，就需要设计一个mAP评价函数</strong>，<strong>目标分割问题，就需要设计一个IOU评价函数</strong>。因此小伙伴们需要<strong>多实践，多尝试</strong>，实践出真知。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Learning Rate黑科技</title>
    <url>/2020/05/11/deep%20learning%20learning_rate/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Learning Rate</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Learning Rate(学习率)</strong>:深度学习中有一个重要的参数为学习率，小伙伴们应该都知道，这是<strong>设置优化器时的一个必要参数</strong>，学习率<strong>指导我们在梯度下降的过程中，如何去使用损失函数的梯度调整网络的权重</strong>。因此对网络的影响是非常重要的。今天给小伙伴们盘点一下常用的学习率黑科技。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/learning_rate.png" alt="learning_rate"></p>
<h1 id="学习率特点"><a href="#学习率特点" class="headerlink" title="学习率特点"></a><font size="5" color="red">学习率特点</font></h1><p><strong>大学习率优点</strong>：</p>
<ul>
<li>能够<strong>加速学习速率</strong>，更快的使Loss变小， 且<strong>容易跳出局部最优值</strong>。<br>大学习率缺点：</li>
<li>可能导致模型<strong>在极小值震动，使模型不精确</strong>。</li>
</ul>
<p><strong>小学习率优点：</strong></p>
<ul>
<li><strong>帮助模型收敛，有助于模型细化，提高模型精度</strong>。<br>小学习率缺点：</li>
<li><strong>收敛缓慢，可能被困在某个局部最小值附近</strong>。</li>
</ul>
<p>因此在深度学习工程中，<strong>既要使用大学习率加速收敛，跳出局部最优，也要使用小学习率，提高模型精度</strong>。所以我们需要在训练过程中修改学习率的大小。</p>
<h1 id="fixed-固定值"><a href="#fixed-固定值" class="headerlink" title="fixed(固定值)"></a><font size="5" color="red">fixed(固定值)</font></h1><script type="math/tex; mode=display">lr = \eta</script><p>其中$ \eta $为初始学习率<br>在TensorFlow2.0中已经给我们提供了自定义学习率的类LearningRateScheduler。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def scheduler(epoch):</span><br><span class="line">    lr = base_lr </span><br><span class="line">    print('\nBatch %d: setting learning rate to %s.' % (epoch + 1, lr))</span><br><span class="line">    return lr</span><br><span class="line"></span><br><span class="line">base_lr = 0.01</span><br><span class="line">max_epoch = 100</span><br><span class="line">reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)</span><br><span class="line">model.fit(db, epochs=max_epoch, callbacks=[reduce_lr], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/fixed.png" alt="fixed"></p>
<h1 id="step-阶梯下降"><a href="#step-阶梯下降" class="headerlink" title="step(阶梯下降)"></a><font size="5" color="red">step(阶梯下降)</font></h1><script type="math/tex; mode=display">lr = \eta * \gamma^{\left\lfloor {\frac{epoch}{step}} \right\rfloor}</script><p>其中$ \eta $为初始学习率，$ epoch $为当前迭代次数，$ \gamma $为下降比例，$ step $为下降周期<br>在TensorFlow2.0中已经给我们提供了自定义学习率的类LearningRateScheduler。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line">def scheduler(epoch):</span><br><span class="line">    lr = base_lr * gamma ** (epoch // step_size)</span><br><span class="line">    print('\nBatch %d: setting learning rate to %s.' % (epoch + 1, lr))</span><br><span class="line">    return lr</span><br><span class="line"></span><br><span class="line">base_lr = 0.01</span><br><span class="line">step_size = 10</span><br><span class="line">gamma = 0.1</span><br><span class="line">max_epoch = 100</span><br><span class="line">reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)</span><br><span class="line">model.fit(db, epochs=max_epoch, callbacks=[reduce_lr], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/step.png" alt="step"></p>
<h1 id="exp-指数下降"><a href="#exp-指数下降" class="headerlink" title="exp(指数下降)"></a><font size="5" color="red">exp(指数下降)</font></h1><script type="math/tex; mode=display">lr = \eta * (\gamma^{epoch})</script><p>其中$ \eta $为初始学习率，$ epoch $为当前迭代次数，$ \gamma $为指数下降底数<br>在TensorFlow2.0中已经给我们提供了自定义学习率的类LearningRateScheduler。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def scheduler(epoch):</span><br><span class="line">    lr = base_lr * gamma ** epoch</span><br><span class="line">    print('\nBatch %d: setting learning rate to %s.' % (epoch + 1, lr))</span><br><span class="line">    return lr</span><br><span class="line"></span><br><span class="line">base_lr = 0.01</span><br><span class="line">gamma = 0.9</span><br><span class="line">max_epoch = 100</span><br><span class="line">reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)</span><br><span class="line">model.fit(db, epochs=max_epoch, callbacks=[reduce_lr], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/exp.png" alt="exp"></p>
<h1 id="poly-多项式下降"><a href="#poly-多项式下降" class="headerlink" title="poly(多项式下降)"></a><font size="5" color="red">poly(多项式下降)</font></h1><script type="math/tex; mode=display">lr = \eta * (1 - \frac{epoch}{max\_epoch})^\gamma</script><p>其中$ \eta $为初始学习率，$ epoch $为当前迭代次数，$ max_epoch $为最大迭代次数，$ \gamma $为多项式的幂<br>在TensorFlow2.0中已经给我们提供了自定义学习率的类LearningRateScheduler。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def scheduler(epoch):</span><br><span class="line">    lr = base_lr * (1 - epoch / max_epoch) ** gamma</span><br><span class="line">    print('\nBatch %d: setting learning rate to %s.' % (epoch + 1, lr))</span><br><span class="line">    return lr</span><br><span class="line"></span><br><span class="line">base_lr = 0.01</span><br><span class="line">gamma = 2</span><br><span class="line">max_epoch = 100</span><br><span class="line">reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)</span><br><span class="line">model.fit(db, epochs=max_epoch, callbacks=[reduce_lr], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/poly.png" alt="poly"></p>
<h1 id="Cosine-Annealing-余弦退火"><a href="#Cosine-Annealing-余弦退火" class="headerlink" title="Cosine Annealing(余弦退火)"></a><font size="5" color="red">Cosine Annealing(余弦退火)</font></h1><script type="math/tex; mode=display">lr = \begin{cases} epoch \times \frac{ \eta - \alpha }{ warm\_epoch } + \alpha & epoch \le warm\_epoch \\ 0.5 \times \eta \times (1 + \cos{(\pi * \frac{epoch - warm\_epoch}{max\_epoch - warm\_epoch})})& epoch > warm\_epoch \end{cases}</script><p>其中$ \alpha $为初始学习率，$ \eta $为最高学习率，$ epoch $为当前迭代次数，$ max\_epoch $为最大迭代次数，$ warm\_epoch $为开始退火的迭代次数<br>在TensorFlow2.0中已经给我们提供了自定义学习率的类LearningRateScheduler。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def scheduler(epoch):</span><br><span class="line">    lr = (base_lr - begin_lr) / warm_epoch * epoch + begin_lr if epoch &lt;= warm_epoch else 0.5 * base_lr * (1 + np.cos(np.pi * (epoch - warm_epoch) / (max_epoch - warm_epoch)))</span><br><span class="line">    print('\nBatch %d: setting learning rate to %s.' % (epoch + 1, lr))</span><br><span class="line">    return lr</span><br><span class="line"></span><br><span class="line">base_lr = 0.01</span><br><span class="line">begin_lr = 0.001</span><br><span class="line">max_epoch = 100</span><br><span class="line">warm_epoch = 10</span><br><span class="line">reduce_lr = keras.callbacks.LearningRateScheduler(scheduler)</span><br><span class="line">model.fit(db, epochs=max_epoch, callbacks=[reduce_lr], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/cosine.png" alt="cosine"></p>
<h1 id="ReduceLROnPlateau"><a href="#ReduceLROnPlateau" class="headerlink" title="ReduceLROnPlateau"></a><font size="5" color="red">ReduceLROnPlateau</font></h1><p>Plateau意思为高原，从其英文表达中可以清晰的看出，当要<strong>监视的值出现平坦时，学习率会下降</strong>。<br>在TensorFlow2.0中已经给我们提供了ReduceLROnPlateau类，其常用参数有</p>
<ol>
<li><strong>monitor：要监视的值，默认为val_loss</strong>。</li>
<li><strong>factor：学习率下降因子，new_lr = lr x factor</strong>。</li>
<li><strong>patience：耐心周期，如果在patience周期内没有改善，则降低学习率</strong>。</li>
<li><strong>min_lr：设置最低学习率，防止学习率过低</strong>。</li>
</ol>
<p>因为ReduceLROnPlateau<strong>可以实现自适应的学习率变化</strong>，而且<strong>不需要去自定义学习率下降方法</strong>，所以<strong>大部分情况下使用ReduceLROnPlateau即可完成训练任务</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">base_lr = 0.01</span><br><span class="line">begin_lr = 0.001</span><br><span class="line">max_epoch = 100</span><br><span class="line">warm_epoch = 10</span><br><span class="line">reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0)</span><br><span class="line">model.fit(db, epochs=max_epoch, callbacks=[reduce_lr], validation_data=db_test)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="model-optimizer-lr-assign"><a href="#model-optimizer-lr-assign" class="headerlink" title="model.optimizer.lr.assign"></a><font size="5" color="red">model.optimizer.lr.assign</font></h1><p>在<strong>Model类对象中，有optimizer.lr属性，其保存着学习率的值，使用assign方法可以设置学习率</strong>。在<strong>自定义训练过程中，常常使用这种方法进行学习率动态修改</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">model.optimizer.lr.assign(model.optimizer.lr / 2)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  小伙伴们观察几个常见学习率函数后发现，都是<strong>呈现一个递减的函数</strong>，递减是因为<strong>模型刚开始训练，需要加速收敛，而且容易落入局部最小值，因此需要较大的学习率，随着学习的推进，我们需要对模型进行细化，使其精度提高，因此需要较小的学习率</strong>。在这个博客里列举的是一些常用的学习率下降函数，大家可以<strong>根据自己的实际问题进行调整，只要是满足递减条件，都可以用来尝试</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Optimizer黑科技</title>
    <url>/2020/05/10/deep%20learning%20optimizer/</url>
    <content><![CDATA[<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Optimizer(优化器)</strong>:在深度神经网络中，<strong>如果说到达Loss最小是我们的终点站，那么出行方式就是优化器，它给我们提供一种方法接近Loss最小的地方</strong>。打一个简单的比方，如果我要从安徽前往北京，北京就是我们的目标，相当于神经网络中的Loss函数，而我们选择的交通方式则是优化器，我可以选择长途汽车出行，也可以选择火车出行，也可以选择飞机出行。选择哪一种交通方式最为合适呢？这也需要根据实际问题确定，优化器也是这样，<strong>没有最好的优化器，只有最适合的优化器</strong>，这里我不写太多的公式，主要是聊一聊各个优化器的用法，特点和参数表达的意义。</p>
<a id="more"></a>
<h1 id="SGD-Stochastic-Gradient-Descent，随机梯度下降"><a href="#SGD-Stochastic-Gradient-Descent，随机梯度下降" class="headerlink" title="SGD(Stochastic Gradient Descent，随机梯度下降)"></a><font size="5" color="red">SGD(Stochastic Gradient Descent，随机梯度下降)</font></h1><script type="math/tex; mode=display">\begin{cases} W_{t+1}=W_{t}-\eta_{t} g_{t} \\\\ g_{t} = \Delta J_{i_{s}}(W_{t}) \end{cases}</script><p>其中$W_t$表示t时刻模型参数，$g_t$表示第t次迭代的梯度，$\eta_t$表示学习率，一般取值0.001。<br><strong>SGD(随机梯度下降)</strong>：对于每一个样本引入一些随机性和噪声，然后利用梯度下降法进行训练。<br><strong>SGD优点</strong>：</p>
<ol>
<li>梯度计算快，<strong>引入噪声增加鲁棒性</strong>，并且便于逃离鞍点，实验证明只要噪声不是特别大，SGD都能很好地收敛。</li>
<li>应用大型数据集，<strong>比标准的梯度下降算法快速很多</strong>。</li>
</ol>
<p><strong>SGD缺点</strong>：</p>
<ol>
<li><strong>SGD引入噪声，可能使得权值更新的方向不一定正确</strong>。</li>
<li><strong>SGD难以逃离局部最优解</strong>。</li>
</ol>
<p>在TensorFlow2.0中给我们提供了SGD的类。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.0, nesterov=False, name='SGD')</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Momentum-使用动量的随机梯度下降"><a href="#Momentum-使用动量的随机梯度下降" class="headerlink" title="Momentum(使用动量的随机梯度下降)"></a><font size="5" color="red">Momentum(使用动量的随机梯度下降)</font></h1><script type="math/tex; mode=display">\begin{cases} W_{t+1}=W_{t} - v_{t} \\\\ v_{t} = \alpha v_{t-1} + \eta \Delta J(W_{t}) \end{cases}</script><p>其中$W_t$表示t时刻模型参数，$v_t$表示当前积攒的速度，$\alpha$表示动力大小，一般取值0.9，$\Delta J(W_t)$表示第t次迭代的梯度，$\eta_t$表示学习率，一般取值0.001。<br><strong>Momentum(使用动量的随机梯度下降)</strong>：引入一个积攒的梯度信息动量进行加速随机梯度下降法的训练过程。<br><strong>Momentum优点</strong>：</p>
<ol>
<li><strong>加速SGD的收敛</strong>。</li>
<li><strong>引入动量的思想，可能会冲破局部最小值的影响</strong>。</li>
</ol>
<p><strong>Momentum缺点</strong>：</p>
<ul>
<li><strong>依赖动量可能会使下降速度越来越大，使得冲上另一个山坡</strong>。</li>
</ul>
<p>在TensorFlow2.0中SGD类属性引入了动量因子，因此调用SGD即可。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=False, name='Momentum')</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="NAG-Nesterov-accelerated-gradient，牛顿加速梯度"><a href="#NAG-Nesterov-accelerated-gradient，牛顿加速梯度" class="headerlink" title="NAG(Nesterov accelerated gradient，牛顿加速梯度)"></a><font size="5" color="red">NAG(Nesterov accelerated gradient，牛顿加速梯度)</font></h1><script type="math/tex; mode=display">\begin{cases} W_{t+1}=W_{t} - v_{t} \\\\ v_{t} = \alpha v_{t-1} + \eta \Delta J(W_{t} - \alpha v_{t - 1}) \end{cases}</script><p>其中$W_t$表示t时刻模型参数，$v_t$表示当前积攒的速度，$\alpha$表示动力大小，一般取值0.9，$\Delta J(W_t)$表示第t次迭代的梯度，$\eta_t$表示学习率，一般取值0.001。<br><strong>NAG(牛顿加速梯度)</strong>：是Momentum的变种，引入了一个校正因子，使得Momentum不会盲目听从动量指示，能提前知道自己下一步去哪里，并且预防下坡过头而冲上另一个山坡。<br><strong>NAG优点</strong>：</p>
<ul>
<li><strong>较好的解决了Momentum中存在的速度过快的情况</strong>。</li>
</ul>
<p><strong>NAG缺点</strong>：</p>
<ul>
<li>引入了修正因子，根据本次的权重和上次的速度，得到可能的下一次权重，然后计算该权重的梯度，因此<strong>需要再进行一次前向传播和后向传播，速度大大降低</strong>。</li>
</ul>
<p>在TensorFlow2.0中SGD类属性引入了nesterov动量，因此调用SGD即可。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True, name='NAG')</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a><font size="5" color="red">AdaGrad</font></h1><script type="math/tex; mode=display">W_{t+1}=W_t - \frac{\eta_0}{\sqrt{\sum_{t'=1}^t g_{t',i}^2} + \epsilon} \cdot g_{t, i}</script><p>其中$W_t$表示t时刻模型参数，$g_{t, i}$表示第t次迭代的梯度，$\epsilon$避免分母为0，一般取值1e-7，$\eta_t$表示初始学习率，一般取值0.001。<br><strong>AdaGrad</strong>：独立适应所有参数的学习率，缩放每个参数反比于其梯度历史总和的平方根，具有大梯度的参数有较大的学习率，小梯度的参数有较小的学习率<br><strong>AdaGrad优点</strong>：</p>
<ol>
<li>对于<strong>出现较多的特征或类别，给予较小的学习率，对于出现较少的特征或类别，给予较大的学习率，适合于稀疏数据或者分布不平衡的数据集</strong>。</li>
<li><strong>不需要人为调节学习率</strong>，它可以完成自动调节。</li>
</ol>
<p><strong>AdaGrad缺点</strong>：</p>
<ul>
<li><strong>随着迭代次数的增加，学习率会越来越小，最终趋近于0</strong>。</li>
</ul>
<p>在TensorFlow2.0中给我们提供了AdaGrad的类<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = keras.optimizers.Adagrad(learning_rate=0.001, epsilon=1e-7)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a><font size="5" color="red">RMSProp</font></h1><script type="math/tex; mode=display">\begin{cases} W_{t+1}=W_{t} - \frac{\eta_0}{\sqrt{E[g^2]_t} + \epsilon} \cdot g_t \\ E[g^2]_t = \alpha E[g^2]_{t - 1} + (1 - \alpha)g_t^2  \end{cases}</script><p>其中$W_t$表示t时刻模型参数，$g_t$表示第t次迭代的梯度，$\epsilon$避免分母为0，一般取值1e-7，$\eta_t$表示全局学习率，一般取值0.001，$\alpha$表示动力大小，一般取值0.9，$E[g^2]_t$表示前t次的梯度平方的均值。<br><strong>RMSProp</strong>：是对AdaGrad的改进，<strong>修改了AdaGrad的梯度累加变为加权平均</strong>。<br><strong>RMSProp优点</strong>：</p>
<ul>
<li>由于使用加权平均，可以<strong>避免AdaGrad中学习率越来越低的问题</strong>。</li>
</ul>
<p>在TensorFlow2.0中给我们提供了RMSProp的类<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = keras.optimizers.RMSProp(learning_rate=0.001, rho=0.9, epsilon=1e-7)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="AdaDelta"><a href="#AdaDelta" class="headerlink" title="AdaDelta"></a><font size="5" color="red">AdaDelta</font></h1><script type="math/tex; mode=display">\begin{cases} W_{t+1}=W_t + \Delta W_t \\ \Delta W_t = -\frac{\sqrt{\sum_{i=1}^{t-1}{\Delta W_i}}}{\sqrt{E[g^2]_t} + \epsilon} \cdot g_t \\ E[g^2]_t = \alpha E[g^2]_{t - 1} + (1 - \alpha)g_t^2  \end{cases}</script><p>其中$W_t$表示t时刻模型参数，$g_t$表示第t次迭代的梯度，$\epsilon$避免分母为0，一般取值1e-7，$\alpha$表示动力大小，一般取值0.95，$E[g^2]_t$表示前t次的梯度平方的均值。<br><strong>AdaDelta</strong>：和RMSProp公式基本相同，在相同的时间被独立的提出。<br><strong>AdaDelta优点</strong>：</p>
<ul>
<li><strong>不需要设置全局学习率</strong>。</li>
</ul>
<p><strong>AdaDelta缺点</strong>：</p>
<ul>
<li><strong>在模型训练的后期，模型会反复地在局部最小值附近抖动</strong>。</li>
</ul>
<p>在TensorFlow2.0中给我们提供了AdaDelta的类<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 其中的learning_rate匹配论文中的精确形式，使用1.0，等效为实现与学习率无关</span><br><span class="line">optimizer = tf.keras.optimizers.AdaDelta(learning_rate=1.0, rho=0.95, epsilon=1e-7)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a><font size="5" color="red">Adam</font></h1><script type="math/tex; mode=display">\begin{cases} W_{t+1}=W_t - \frac{\eta}{\sqrt{\hat{v_t}} + \epsilon} \hat{m_t} \\ \hat{m_t} = \frac{m_t}{1-\beta_1^t}，\hat{v_t} = \frac{v_t}{1-\beta_2^t} \\ v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2 \\ m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t   \end{cases}</script><p>其中$m_t，v_t$分别表示一阶动量和二阶动量，$\beta_1，\beta_2$分别表示动力大小，一般取值0.9和0.999，$\hat{m_t}，\hat{v_t}$分别为各自的修正值，$W_t$表示第t次迭代模型参数，$g_t$表示第t次迭代的梯度，$\epsilon$避免分母为0，一般取值1e-7，$\eta_t$表示全局学习率，一般取值0.001。<br><strong>Adam</strong>：通过<strong>计算梯度的一阶矩估计和二阶矩估计而为不同的参数设计独立的自适应学习率，同时获得AdaGrad和RMSProp的优点</strong>，在很多情况是算<strong>默认工作性能比较优秀的优化器</strong>。<br><strong>Adam优点</strong>：</p>
<ol>
<li><strong>充分利用了梯度的二阶矩</strong>。</li>
<li><strong>适用于不稳定的目标函数，鲁棒性强</strong>。</li>
<li><strong>适用于大规模的数据和参数的场景</strong>。</li>
</ol>
<p>在TensorFlow2.0中给我们提供了Adam的类<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta1=0.9, beta_2=0.999, epsilon=1e-7)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="优化器的比较"><a href="#优化器的比较" class="headerlink" title="优化器的比较"></a><font size="5" color="red">优化器的比较</font></h1><ol>
<li>在<strong>下降速度</strong>上：<strong>自适应学习优化器(AdaGrad，RMSProp，AdaDelta，Adam)和动量优化器(Momentum，NAG)明显快于SGD</strong>。</li>
</ol>
<p><img src="/images/deep_learning/opt3.webp" alt="optimizer"></p>
<ol>
<li>在<strong>下降轨迹</strong>上：<strong>SGD和自适应学习优化器大致相同，动量优化器因为动量原因，可能会越过最低点，导致多走一段距离</strong>。</li>
</ol>
<p><img src="/images/deep_learning/opt1.webp" alt="optimizer"></p>
<ol>
<li>在<strong>运行效果</strong>上：<strong>自适应学习优化器和动量优化器基本不会停留在鞍点，而SGD可能会停留在鞍点</strong>。</li>
</ol>
<p><img src="/images/deep_learning/opt2.webp" alt="optimizer"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  在选择优化器的时候，往往<strong>首先考虑Adam优化器</strong>，如果Adam优化器的效果不好，可以<strong>尝试RMSProp</strong>，然后再考虑其他的优化器。但是在实际的工程应用中，<strong>不同的优化器适合不同的场景，不能说明在任何情况下Adam都比其他的优化器更加优秀，选择哪种优化器应该结合具体的问题进行分析</strong>，而且要小伙伴们要记住<strong>模型效果不好可能是多方面原因造成的</strong>，可能是<strong>模型结构太小</strong>，或者<strong>参数设置不合理</strong>，或者<strong>损失函数设计偏差</strong>等等，<strong>不能盲目地更换优化器</strong>来提升性能。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Loss黑科技</title>
    <url>/2020/05/09/deep%20learning%20loss/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Loss</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Loss(损失函数)</strong>:在深度学习任务中，一个最重要的概念就是损失函数，这里不区分损失函数，代价函数和目标函数，这里指的就是神经网络中最终需要优化的函数。<strong>损失函数决定者参数更新的方向</strong>，神经网络的<strong>输出y_pred要和真实值y_true进行比较，使两者的距离越小越好，这个距离的度量就是损失函数</strong>。打一个简单的比方，损失函数对于神经网络来说就有如灯塔之于船只，可以指明前进的方向。<strong>神经网络的参数更新是根据损失函数来确定的</strong>，如果损失函数设置错误，则会产生巨大偏差，甚至南辕北辙的效果，在这篇博客中，我向大家介绍一些常用的损失函数。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/loss.png" alt="loss"></p>
<h1 id="MSE-Mean-Squared-Error，均方误差"><a href="#MSE-Mean-Squared-Error，均方误差" class="headerlink" title="MSE(Mean Squared Error，均方误差)"></a><font size="5" color="red">MSE(Mean Squared Error，均方误差)</font></h1><script type="math/tex; mode=display">MSE = \frac{1}{N} \sum_{i=1}^{N}{(y^{(i)} - f(x^{(i)}))^2}</script><p><strong>MSE</strong>：指<strong>参数估计值与参数真值之差平方的期望值</strong>，其中<strong>平方误差是估计值和实际值之差的平方，也称为(L2 Loss)</strong>，MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。在TensorFlow2.0中已经给我们提供了计算MSE的损失函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 使用函数，在最后一个维度上对数据求MSE，输出维度等于输入删去最后一个维度。</span><br><span class="line">keras.losses.mean_squared_error(y_true, y_pred)</span><br><span class="line"></span><br><span class="line"># 使用类对象，在最后一个维度上对数据求MSE，然后对结果求全局平均值，输出结果只有一个数。</span><br><span class="line">loss = keras.losses.MeanSquaredError()</span><br><span class="line">loss(y_true, y_pred)</span><br><span class="line"># 等价于keras.losses.MeanSquaredError()(y_true, y_pred)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="MAE-Mean-Absolute-Error，平均绝对误差"><a href="#MAE-Mean-Absolute-Error，平均绝对误差" class="headerlink" title="MAE(Mean Absolute Error，平均绝对误差)"></a><font size="5" color="red">MAE(Mean Absolute Error，平均绝对误差)</font></h1><script type="math/tex; mode=display">MAE = \frac{1}{N} \sum_{i=1}^{N}{|y^{(i)} - f(x^{(i)})|}</script><p><strong>MAE</strong>：指<strong>参数估计值与参数真值绝对误差的平均值</strong>，其中<strong>绝对误差是估计值和实际值之间的距离，也称为(L1 Loss)</strong>，MAE能更好地反映预测值误差的实际情况。在TensorFlow2.0中已经给我们提供了计算MAE的损失函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 使用函数，在最后一个维度上对数据求MAE，输出维度等于输入删去最后一个维度。</span><br><span class="line">keras.losses.mean_absolute_error(y_true, y_pred)</span><br><span class="line"></span><br><span class="line"># 使用类对象，在最后一个维度上对数据求MAE，然后对结果求全局平均值，输出结果只有一个数。</span><br><span class="line">loss = keras.losses.MeanAbsoluteError()</span><br><span class="line">loss(y_true, y_pred)</span><br><span class="line"># 等价于tf.reduce_mean(keras.losses.mean_absolute_error(y_true, y_pred))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Smooth-L1-Loss-平滑L1损失"><a href="#Smooth-L1-Loss-平滑L1损失" class="headerlink" title="Smooth L1 Loss(平滑L1损失)"></a><font size="5" color="red">Smooth L1 Loss(平滑L1损失)</font></h1><script type="math/tex; mode=display">smooth_{L_1} =  \begin{cases} 0.5x^2 & |x| < 1 \\ |x| - 0.5 & |x| \ge 1 \end{cases}</script><p><strong>MAE的优点</strong>：<strong>鲁棒性更好</strong>，如果<strong>误差大于1，MSE会将误差放大，因此对异常数据更加敏感</strong>，为了调整异常值会牺牲很多样本。<br><strong>MSE的优点</strong>：<strong>稳定性更好</strong>，如果<strong>误差小于1，MSE会将误差缩小，产生一个较小的波动，可以更加细化模型</strong>，MAE可能会跳过这个微小区域，到达另一个误差更大的地方。<br><strong>Smooth L1 Loss</strong>可以<strong>完美的结合MAE和MSE的优点，在误差大于1的情况下，不会放大误差牺牲样本，在误差小于1的情况下，还能够细化模型</strong>，因此是一种较好的损失函数，在<strong>目标检测</strong>算法中常常使用。<br><img src="/images/deep_learning/smoothl1.png" alt="smoothl1"></p>
<h1 id="Binary-Cross-Entropy-二分类交叉熵损失函数"><a href="#Binary-Cross-Entropy-二分类交叉熵损失函数" class="headerlink" title="Binary Cross Entropy(二分类交叉熵损失函数)"></a><font size="5" color="red">Binary Cross Entropy(二分类交叉熵损失函数)</font></h1><script type="math/tex; mode=display">Binary \ Cross \ Entropy =  -\frac{1}{N} \sum_{i=1}^{N}{(y^{(i)} \cdot \ln{(f(x^{(i)})}) + (1 - y^{(i)}) \cdot \ln{(1 - f(x^{(i)})})}</script><p><strong>Binary Cross Entropy</strong>：用来<strong>评估当前训练得到的概率分布与真实分布的差异情况</strong>，它刻画的是实际概率与期望概率的距离，也就是交叉熵的值越小，两个概率分布就越接近，减少交叉熵损失就是在提高模型的预测准确率。在<strong>二分类中，每个数据独立计算交叉熵，和同一维度其他数据无关，允许多个1同时出现，经常配合sigmoid激活函数使用</strong>。在TensorFlow2.0中已经给我们提供了计算Binary Cross Entropy的损失函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 使用函数，对每一个数据做二分类交叉熵，输入维度和输出维度相同，对预测值y_pred先计算sigmoid值，然后计算交叉熵。</span><br><span class="line">tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)</span><br><span class="line"></span><br><span class="line"># 使用函数，对每一个数据做二分类交叉熵，并在最后一个维度上计算平均值，输出维度等于输入删去最后一个维度，from_logits=False(默认)则不计算Sigmoid的值，from_logits=True则先计算Sigmoid的值，然后计算交叉熵。</span><br><span class="line">keras.losses.binary_crossentropy(y_true, y_pred, from_logits=True)</span><br><span class="line"># 等价于keras.losses.binary_crossentropy(y_true, keras.activations.sigmoid(y_pred), from_logits=False)</span><br><span class="line"># 等价于tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred), axis=-1)</span><br><span class="line"></span><br><span class="line"># 使用类对象，对每一个数据做二分类交叉熵，然后对结果求全局平均值，输出结果只有一个数。from_logits=False(默认)则不计算Sigmoid的值，from_logits=True则先计算Sigmoid的值，然后计算交叉熵。</span><br><span class="line">loss = keras.losses.BinaryCrossentropy(from_logits=True)</span><br><span class="line">loss(y_true, y_pred)</span><br><span class="line"># 等价于tf.reduce_mean(keras.losses.binary_crossentropy(y_true, y_pred, from_logits=True))</span><br><span class="line"># 等价于tf.reduce_mean(keras.losses.binary_crossentropy(y_true, keras.activations.sigmoid(y_pred), from_logits=False))</span><br><span class="line"># 等价于tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Categorical-Cross-Entropy-多分类交叉熵损失函数"><a href="#Categorical-Cross-Entropy-多分类交叉熵损失函数" class="headerlink" title="Categorical Cross Entropy(多分类交叉熵损失函数)"></a><font size="5" color="red">Categorical Cross Entropy(多分类交叉熵损失函数)</font></h1><script type="math/tex; mode=display">Categorical \ Cross \ Entropy =  -\frac{1}{N} \sum_{i=1}^{N}{(y^{(i)} \cdot \ln{(f(x^{(i)})))}}</script><p><strong>Categorical Cross Entropy</strong>：用来<strong>评估当前训练得到的概率分布与真实分布的差异情况</strong>，它刻画的是实际概率与期望概率的距离，也就是交叉熵的值越小，两个概率分布就越接近，减少交叉熵损失就是在提高模型的预测准确率。在<strong>多分类中，在某个维度上计算交叉熵，在该维度上其他数据一般只有一个1出现，其他全为0，经常配合Softmax激活函数使用</strong>。在TensorFlow2.0中已经给我们提供了计算Categorical Cross Entropy的损失函数。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"># 使用函数，对最后一个维度做多分类交叉熵，输出维度等于输入删去最后一个维度，对预测值先求Softmax值，然后计算交叉熵。</span><br><span class="line">tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)</span><br><span class="line"></span><br><span class="line"># 使用函数，对最后一个维度做多分类交叉熵，输出维度等于输入删去最后一个维度，from_logits=False(默认)则不计算Softmax的值，from_logits=True则先计算Softmax的值，然后计算交叉熵。</span><br><span class="line">keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)</span><br><span class="line"># 等价于keras.losses.categorical_crossentropy(y_true, keras.activations.softmax(y_pred), from_logits=False)</span><br><span class="line"># 等价于tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)</span><br><span class="line"></span><br><span class="line"># 使用类对象，对最后一个维度做多分类交叉熵，然后对结果求全局平均值，输出结果只有一个数。from_logits=False(默认)则不计算Softmax的值，from_logits=True则先计算Softmax的值，然后计算交叉熵。</span><br><span class="line">loss = keras.losses.CategoricalCrossentropy(from_logits=True)</span><br><span class="line">loss(y_true, y_pred)</span><br><span class="line"># 等价于tf.reduce_mean(keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True))</span><br><span class="line"># 等价于tf.reduce_mean(keras.losses.categorical_crossentropy(y_true, keras.activations.softmax(y_pred), from_logits=False))</span><br><span class="line"># 等价于tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="Focal-Loss-聚焦损失"><a href="#Focal-Loss-聚焦损失" class="headerlink" title="Focal Loss(聚焦损失)"></a><font size="5" color="red">Focal Loss(聚焦损失)</font></h1><script type="math/tex; mode=display">Focal \ Loss =  \begin{cases} - \alpha \cdot (1 - f(x^{(i)}))^{\gamma} \cdot \ln{(f(x^{(i)}))} & y^{(i)} = 1 \\ - (1 - \alpha) \cdot (f(x^{(i)}))^{\gamma} \cdot \ln{(1 - f(x^{(i)}))} & y^{(i)} = 0 \end{cases}</script><p><strong>Focal Loss(聚焦损失)</strong>：是<strong>何凯明于2017年提出的一种解决目标检测算法中，一步法正负样本比例严重失衡的问题</strong>。他认为一步法和两步法的表现差异<strong>主要原因是大量背景类别导致</strong>的，因此设计了一个<strong>简单密集型网络RetinaNet来训练，保证速度的同时达到了精度最优</strong>。Focal Loss中有两个重要特点，<strong>引入$ \alpha $控制正负样本的权重，引入$ \gamma $控制容易分类和难分类样本的权重</strong>。</p>
<p><strong>$ \alpha $</strong>：在这里称之为<strong>平衡因子</strong>，它的作用是<strong>平衡正负样本的占比</strong>，在<strong>论文中取0.25</strong>。为什么负样本多，反而占比还大呢？因为正样本比负样本更难区分，负样本为背景区域，较易区分，损失函数较小，因此占比较大。正样本难以区分，损失函数较大，因此占比较小。</p>
<p><strong>$ \gamma $</strong>：在这里称之为<strong>调制权重</strong>，他的作用是<strong>关注分类的难易程度</strong>，在<strong>论文中取2</strong>。一个正样本，如果预测概率越大，则$1-f(x^{(i)})$越小，那么$(1-f(x^{(i)}))^{\gamma}$就更小，说明让网络不要过多关心容易区分的问题，反之，如果预测概率较小，则$1-f(x^{(i)})$较大，那么$(1-f(x^{(i)}))^{\gamma}$就相对较大，说明让网络多关心难区分的问题。</p>
<p><strong>Focal Loss和Binary Cross Entropy</strong>：当参数<strong>满足$ \alpha=0.5，\gamma=0 $时Focal Loss就变成了Binary Cross Entropy</strong>，Binary Cross Entropy中一个正样本，预测结果为0.8时的损失为$- \ln{0.8}=0.223$，预测结果为0.2时的损失为$- \ln{0.2}=1.609$，两者相差8倍，而在Focal Loss中一个正样本，预测结果为0.8时的损失为$- 0.25 \times (1-0.8)^2 \times \ln{0.8}=0.00223$，预测结果为0.2时的损失为$- 0.25 \times (1-0.2)^2 \times \ln{0.2}=0.2575$，两者相差115倍，此时可以说网络更加关心预测为0.2时产生的损失，这就是Focal Loss受到广泛关注的特点。但是Tensorflow2.0没有给我们提供Focal Loss损失函数，需要我们自己设计。大家可以参考目标检测文章中RetinaNet中的相关内容，里面有Focal Loss的具体实现代码。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  在选择损失函数时，我们首先要<strong>判断任务类型</strong>，是分类任务还是回归任务。<strong>分类任务可以考虑交叉熵损失函数，回归任务可以考虑MSE或者MAE损失函数</strong>。但是在实际工程应用之中，往往不是一个简单的损失函数就能解决的，有时<strong>既用到分类损失函数，又用到回归损失函数</strong>，而且还要为两者之间设置权重系数。有时需要根据需要自己设计一些属于特殊数据集或者特殊模型的损失函数。因此需要小伙伴们多多尝试，总结经验，最终会成为一代大牛，</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Addition VS Concatenate</title>
    <url>/2020/05/08/deep%20learning%20addition_vs_concatenate/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Addition VS Concatenate</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>(Feature fusion)特征融合</strong>:VGG网络提出以后，给人们一种印象，深度学习越复杂，参数越多，会有越强的表达能力。但是在深度神经网络的研究过程中，发现<strong>到达一定深度后，一味地增加网络的深度并不能带来效果的提升，反而会导致网络收敛变慢</strong>。这时需要引入一些其他的方法既能提高网络的表达能力，也不会使网络收敛速度大大降低。两种特征融合方法<strong>(Addition和Concatenate)</strong>随着时代的发展产生了。相信小伙伴们也已经有所了解，在这里我系统的整理一下它们之间的区别。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/addition.png" alt="addition"></p>
<h1 id="Addition"><a href="#Addition" class="headerlink" title="Addition"></a><font size="5" color="red">Addition</font></h1><p>  <strong>Addition</strong>，即<strong>残差相加</strong>，最经典的模型就是<strong>ResNet</strong>。关于ResNet的有关代码解析可以参考特征提取网络中的一篇博客<font size="4"><a href="https://ustccoder.github.io/2020/03/09/feature_extraction ResNet/">ResNet</a></font><br><img src="/images/Feature_extraction/ResNet.png" alt="ResNet"><br>优点：</p>
<ol>
<li>使用残差结构，使得深层网络包含浅层网络的信息，因此<strong>反向传播时可以通过不同的分支到达浅层网络</strong>。并且<strong>梯度中包含常数项</strong>，增加了梯度值，<strong>解决了梯度消失的问题</strong>。</li>
<li><strong>增加了网络的泛化能力</strong>，和VGG这种串行的网络相比，删除一层可能严重破坏网络结构，而ResNet删除一层，性能不会产生很大的退化。</li>
<li>浅层网络代表浅层特征，深层网络代表深层特征，浅层特征可能指代一些纹理信息，深层特征可能指代一些轮廓信息。<strong>残差结构将浅层特征与深层特征进行相加，实现特征互补，因此网络的表达能力更强</strong>。</li>
</ol>
<h1 id="Concatenate"><a href="#Concatenate" class="headerlink" title="Concatenate"></a><font size="5" color="red">Concatenate</font></h1><p>  <strong>Concatenate</strong>，即<strong>通道合并</strong>，最经典的模型就是<strong>DenseNet</strong>。关于DenseNet的有关代码解析可以参考特征提取网络中的一篇博客<font size="4"><a href="https://ustccoder.github.io/2020/03/16/feature_extraction DenseNet/">DenseNet</a></font><br><img src="/images/Feature_extraction/DenseNet.png" alt="DenseNet"><br>优点：</p>
<ol>
<li>使用通道合并，使得深层网络包含浅层网络的信息，因此<strong>反向传播时可以通过不同的分支到达浅层网络</strong>，<strong>解决了梯度消失的问题</strong>。</li>
<li><strong>增加了网络的泛化能力</strong>，和VGG这种串行的网络相比，删除一层可能严重破坏网络结构，而DenseNet删除一层，性能不会产生很大的退化。</li>
<li>浅层网络代表浅层特征，深层网络代表深层特征，浅层特征可能指代一些纹理信息，深层特征可能指代一些轮廓信息。<strong>通道合并可以理解为从不同的角度观察特征图，使重要的细节信息从多方位角度保存下来，然后与深层特征结合互补，因此网络的表达能力更强</strong>。</li>
</ol>
<h1 id="Addition与Concatenate的区别"><a href="#Addition与Concatenate的区别" class="headerlink" title="Addition与Concatenate的区别"></a><font size="5" color="red">Addition与Concatenate的区别</font></h1><ol>
<li>最明显的区别是<strong>数据维度的变化</strong>，<strong>Addition操作要求数据维度完全相同</strong>，并且<em>相加后的维度和之前相同<strong>，</strong>Concatenate操作要求数据可以有一个维度不相同<strong>，一般是通道数维度，即batch_size，图像的高和宽都是相同的，并且</strong>合并后的通道数是参与合并的数据通道数之和*</em>。</li>
<li>Addtion是在<strong>保持特征维度的情况下，增加了特征的信息量</strong>，而Concatenate是通过<strong>增加特征维度的情况下，增加了特征的信息量，但是每一维特征的信息量没有变化</strong>。</li>
<li>因为Addition和Concatenate在数据维度上的差异，当后面加入卷积层时，导致<strong>Addition的计算量比Concatenate小得多，更加节省参数和计算量</strong>。</li>
<li><strong>Concatenate将原始特征直接拼接，让网络自己学习如何融合特征，信息不会丢失，而且更加体现出多角度融合的概念</strong>，而<strong>Addition则将特征进行相加，相当于指定了一种特征融合的方式</strong>，因此可以认为<strong>Addition是Concatenate的一种特殊形式</strong>。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  在这个博客中简单直白的讲述了两种特征融合方法的区别，在使用中根据小伙伴们的需要，如果<strong>参数量较小，则可以使用多角度Concatenate来增加信息量，并让网络自我学习更新参数</strong>。<strong>如果参数量较大，则可以使用Addition来增加信息量，给网络指定一个方向，让网络学习更新参数</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Normalization黑科技</title>
    <url>/2020/05/07/deep%20learning%20BN_VS_LN_VS_IN_VS_GN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Normalization</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Normalization(标准化)</strong>:深度神经网络模型训练困难，其中一个重要的现象就是<strong>ICS(Internal Covariate Shift，内部协变量偏移)</strong>，其中<strong>解决的方法就是Normalization</strong>，现在标准化成为深度学习<strong>必备神器</strong>，今天带小伙伴们看一看，瞧一瞧。<br><a id="more"></a></p>
<h1 id="ICS的解释"><a href="#ICS的解释" class="headerlink" title="ICS的解释"></a><font size="5" color="red">ICS的解释</font></h1><p><strong>ICS(Internal Covariate Shift，内部协变量偏移)</strong>：将神经网络的每一层的输入作为一个分布来看代，由于神经网络的参数是随机的，因此可能会<strong>导致相同的输入分布却得到了不同的输出分布</strong>。随着网络层数的加深，<strong>输入分布再经过多次非线性变换后，已经被改变</strong>，但是其<strong>标签还是一致的</strong>，这就有一种不协调的感觉，这可能会带来下面几种问题。</p>
<ol>
<li>在训练的过程中，<strong>网络需要不断适应新的输入数据分布，所以会大大降低学习速度</strong>。</li>
<li>由于<strong>参数的分布不同，所以可能导致很多数据落入饱和区，使得学习过早停止</strong>。</li>
<li>某些<strong>参数分布偏离太大，对其他层或者输出产生了巨大影响</strong>。</li>
</ol>
<h1 id="Normalization原理分析"><a href="#Normalization原理分析" class="headerlink" title="Normalization原理分析"></a><font size="5" color="red">Normalization原理分析</font></h1><p>  为了解决上述ICS问题，我们需要将变量分布变成相同分布的，这使我们想到了<strong>标准化操作</strong>。<br><img src="/images/deep_learning/normal.png" alt="normal"></p>
<ol>
<li>我们可以通过$ \hat{x} = \frac{x - \mu}{\sigma} $，$ \mu $是平移参数，$ \sigma $是缩放参数<strong>将数据变成符合均值为0，方差为1的标准分布</strong>。</li>
<li>我们再通过$ y = \gamma \cdot \hat{x} + \beta $, $ \beta $是再平移参数，$ \gamma $是再缩放参数<strong>将数据变成符合均值为$ \beta $，方差为$ {\gamma}^2 $的标准分布</strong>。</li>
</ol>
<p><font size="3" color="red">  奇怪的知识增加了？？？为什么第一步得到标准分布之后，第二步又给变走了？</font><br>  是这样的，首先为了<strong>保证模型的表达能力不因为规范化而下降</strong>，如果没有再平移和缩放，会导致输入的参数分布可能发生较大的变化，这样可能会对模型的表达能力产生影响。其次这两组参数是意义上完全不同的概念，<strong>$ \mu $和$ \sigma $受到上一层输入的影响，$ \beta $和$ \gamma $是独立的，与输入无关</strong>，是网络后来加入的，<strong>会在接下来训练过程中不断学习的，也是为了尊重神经网络的学习结果</strong>。因此这两步是有必要的。</p>
<h1 id="Normalization优点"><a href="#Normalization优点" class="headerlink" title="Normalization优点"></a><font size="5" color="red">Normalization优点</font></h1><ol>
<li><strong>解决了ICS(Internal Covariate Shift，内部协变量偏移)问题</strong>。</li>
<li><strong>加快学习速度，防止梯度消失现象</strong>，因为标准化后，会将数据拉回到0附近，对于Sigmoid，tanh激活函数来说，可能就会<strong>从饱和区拉回到线性区</strong>，因此可以防止梯度消失现象。</li>
<li><strong>减弱对初始化的依赖性</strong>，因为参数需要进行标准化，所以初始化参数时，不用限制较大。</li>
<li><strong>可以对抗over fitting</strong>，因为会将输入进行变化，当输入导致均值产生偏移，没关系，后面还有Normalization，会<strong>对偏移进行修正</strong>，所以会起到一些防止过拟合的作用。</li>
</ol>
<h1 id="常见的Normalization"><a href="#常见的Normalization" class="headerlink" title="常见的Normalization"></a><font size="5" color="red">常见的Normalization</font></h1><p><img src="/images/deep_learning/normalization.png" alt="normalization"><br>为了说明的清晰，我们<strong>将输入的feature map shape记为[N, H, W, C]</strong>，其中<strong>N代表batch_size，H，W代表特征图的高和宽，C代表特征图的通道数</strong>。<br>并且为了直观说明，将feature map看作一个学校，N代表年级数量，规定值为3，C代表每个年级的班级数量，规定值为6，H和W代表班级的每一排和每一列，规定值都为10。</p>
<h2 id="BN-Batch-Normalization，2015"><a href="#BN-Batch-Normalization，2015" class="headerlink" title="BN(Batch Normalization，2015)"></a><font color="red">BN(Batch Normalization，2015)</font></h2><p><strong>BN(Batch Normalization)</strong>：<strong>保留通道的维度C，对N，H，W做C次标准化</strong>，相当于分别按照班级将所有年级所有同学的成绩进行标准化(如一年级一班，二年级一班，三年级一班的所有同学进行标准化，然后再将一年级二班，二年级二班，三年级二班的所有同学进行标准化，直到将一年级六班，二年级六班，三年级六班的所有同学进行标准化，一共做了6次标准化)。<strong>batch_size越大，效果越好，适合固定深度的前向神经网络，如CNN，不适用于RNN</strong>。</p>
<h2 id="自定义BN层"><a href="#自定义BN层" class="headerlink" title="自定义BN层"></a><font color="red">自定义BN层</font></h2><p>在TensorFlow2.0中已经给我们提供了BN层的类keras.layers.BatchNormalization，使用时直接调用即可，这里也给出了自定义BN层的方法。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BatchNormalization(keras.layers.Layer):</span><br><span class="line">    def __init__(self, beta_initializer='zeros', gamma_initializer='ones',</span><br><span class="line">                 beta_regularizer=None, gamma_regularizer=None,</span><br><span class="line">                 beta_constraint=None, gamma_constraint=None, epsilon=1e-5,</span><br><span class="line">                 **kwargs):</span><br><span class="line">        super(BatchNormalization, self).__init__(**kwargs)</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        self.beta_initializer = keras.initializers.get(beta_initializer)</span><br><span class="line">        self.gamma_initializer = keras.initializers.get(gamma_initializer)</span><br><span class="line">        self.beta_regularizer = keras.regularizers.get(beta_regularizer)</span><br><span class="line">        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)</span><br><span class="line">        self.beta_constraint = keras.constraints.get(beta_constraint)</span><br><span class="line">        self.gamma_constraint = keras.constraints.get(gamma_constraint)</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        assert len(input_shape) == 4</span><br><span class="line">        self.gamma = self.add_weight(shape=(input_shape[-1],), name='gamma', initializer=self.gamma_initializer,</span><br><span class="line">                                     regularizer=self.gamma_regularizer, constraint=self.gamma_constraint)</span><br><span class="line">        self.beta = self.add_weight(shape=(input_shape[-1],), name='beta', initializer=self.beta_initializer,</span><br><span class="line">                                    regularizer=self.beta_regularizer, constraint=self.beta_constraint)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, axes=[0, 1, 2], keepdims=True)</span><br><span class="line">        outputs = (inputs - mean) / tf.sqrt(variance + self.epsilon)</span><br><span class="line">        return outputs * self.gamma + self.beta</span><br><span class="line"></span><br><span class="line">    def get_config(self):</span><br><span class="line">        config = {</span><br><span class="line">            'epsilon': self.epsilon,</span><br><span class="line">            'beta_initializer': keras.initializers.serialize(self.beta_initializer),</span><br><span class="line">            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),</span><br><span class="line">            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),</span><br><span class="line">            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),</span><br><span class="line">            'beta_constraint': keras.constraints.serialize(self.beta_constraint),</span><br><span class="line">            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint)</span><br><span class="line">        }</span><br><span class="line">        base_config = super(BatchNormalization, self).get_config()</span><br><span class="line"></span><br><span class="line">        return dict(list(base_config.items()) + list(config.items()))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="LN-Layer-Normalization，2016"><a href="#LN-Layer-Normalization，2016" class="headerlink" title="LN(Layer Normalization，2016)"></a><font color="red">LN(Layer Normalization，2016)</font></h2><p><strong>LN(Layer Normalization)</strong>：<strong>保留batch_size的维度N，对H，W，C做N次标准化</strong>，相当于分别按照年级将所有班级所有同学的成绩进行标准化(如一年级一班，一年级二班直到一年级六班的所有同学进行标准化，然后再将二年级一班，二年级二班直到二年级六班的所有同学进行标准化，最后将三年级一班，三年级二班直到三年级六班的所有同学进行标准化，一共做了3次标准化)。<strong>通道数越大，效果越好，不依赖batch_size的大小，适合深度不固定的网络，如RNN，不适用于CNN</strong>。</p>
<h2 id="自定义LN层"><a href="#自定义LN层" class="headerlink" title="自定义LN层"></a><font color="red">自定义LN层</font></h2><p>在TensorFlow2.0中已经给我们提供了LN层的类keras.layers.LayerNormalization，使用时直接调用即可，这里也给出了自定义LN层的方法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LayerNormalization(keras.layers.Layer):</span><br><span class="line">    def __init__(self, beta_initializer='zeros', gamma_initializer='ones',</span><br><span class="line">                 beta_regularizer=None, gamma_regularizer=None,</span><br><span class="line">                 beta_constraint=None, gamma_constraint=None, epsilon=1e-5,</span><br><span class="line">                 **kwargs):</span><br><span class="line">        super(LayerNormalization, self).__init__(**kwargs)</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        self.beta_initializer = keras.initializers.get(beta_initializer)</span><br><span class="line">        self.gamma_initializer = keras.initializers.get(gamma_initializer)</span><br><span class="line">        self.beta_regularizer = keras.regularizers.get(beta_regularizer)</span><br><span class="line">        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)</span><br><span class="line">        self.beta_constraint = keras.constraints.get(beta_constraint)</span><br><span class="line">        self.gamma_constraint = keras.constraints.get(gamma_constraint)</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        assert len(input_shape) == 4</span><br><span class="line">        self.gamma = self.add_weight(shape=(input_shape[-1],), name='gamma', initializer=self.gamma_initializer,</span><br><span class="line">                                     regularizer=self.gamma_regularizer, constraint=self.gamma_constraint)</span><br><span class="line">        self.beta = self.add_weight(shape=(input_shape[-1],), name='beta', initializer=self.beta_initializer,</span><br><span class="line">                                    regularizer=self.beta_regularizer, constraint=self.beta_constraint)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, axes=[1, 2, 3], keepdims=True)</span><br><span class="line">        outputs = (inputs - mean) / tf.sqrt(variance + self.epsilon)</span><br><span class="line">        return outputs * self.gamma + self.beta</span><br><span class="line"></span><br><span class="line">    def get_config(self):</span><br><span class="line">        config = {</span><br><span class="line">            'epsilon': self.epsilon,</span><br><span class="line">            'beta_initializer': keras.initializers.serialize(self.beta_initializer),</span><br><span class="line">            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),</span><br><span class="line">            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),</span><br><span class="line">            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),</span><br><span class="line">            'beta_constraint': keras.constraints.serialize(self.beta_constraint),</span><br><span class="line">            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint)</span><br><span class="line">        }</span><br><span class="line">        base_config = super(LayerNormalization, self).get_config()</span><br><span class="line"></span><br><span class="line">        return dict(list(base_config.items()) + list(config.items()))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="IN-Instance-Normalization，2017"><a href="#IN-Instance-Normalization，2017" class="headerlink" title="IN(Instance Normalization，2017)"></a><font color="red">IN(Instance Normalization，2017)</font></h2><p><strong>IN(Instance Normalization)</strong>：<strong>保留batch_size的维度N和通道的维度C，对H，W做NxC次标准化</strong>，相当于分别按照年级和班级将所有同学的成绩进行标准化(如一年级一班的所有同学进行标准化，一年级二班的所有同学进行标准化，直到一年级六班的所有同学进行标准化，然后再将二年级一班的所有同学进行标准化，二年级二班的所有同学进行标准化，直到二年级六班的所有同学进行标准化，最后将三年级一班的所有同学进行标准化，三年级二班的所有同学进行标准化，直到三年级六班的所有同学进行标准化，一共做了18次标准化)。最初<strong>用于生成式对抗网络中的风格迁移，生成结果依赖于某个图像实例，只对特征图的高和宽进行标准化，保持图像实例之间的独立</strong>。</p>
<h2 id="自定义IN层"><a href="#自定义IN层" class="headerlink" title="自定义IN层"></a><font color="red">自定义IN层</font></h2><p>在TensorFlow2.0中没有提供IN层的类，需要自己定义，这里也给出了自定义IN层的方法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class InstanceNormalization(keras.layers.Layer):</span><br><span class="line">    def __init__(self, beta_initializer='zeros', gamma_initializer='ones',</span><br><span class="line">                 beta_regularizer=None, gamma_regularizer=None,</span><br><span class="line">                 beta_constraint=None, gamma_constraint=None, epsilon=1e-5,</span><br><span class="line">                 **kwargs):</span><br><span class="line">        super(InstanceNormalization, self).__init__(**kwargs)</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        self.beta_initializer = keras.initializers.get(beta_initializer)</span><br><span class="line">        self.gamma_initializer = keras.initializers.get(gamma_initializer)</span><br><span class="line">        self.beta_regularizer = keras.regularizers.get(beta_regularizer)</span><br><span class="line">        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)</span><br><span class="line">        self.beta_constraint = keras.constraints.get(beta_constraint)</span><br><span class="line">        self.gamma_constraint = keras.constraints.get(gamma_constraint)</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        assert len(input_shape) == 4</span><br><span class="line">        self.gamma = self.add_weight(shape=(input_shape[-1],), name='gamma', initializer=self.gamma_initializer,</span><br><span class="line">                                     regularizer=self.gamma_regularizer, constraint=self.gamma_constraint)</span><br><span class="line">        self.beta = self.add_weight(shape=(input_shape[-1],), name='beta', initializer=self.beta_initializer,</span><br><span class="line">                                    regularizer=self.beta_regularizer, constraint=self.beta_constraint)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, axes=[1, 2], keepdims=True)</span><br><span class="line">        outputs = (inputs - mean) / tf.sqrt(variance + self.epsilon)</span><br><span class="line">        return outputs * self.gamma + self.beta</span><br><span class="line"></span><br><span class="line">    def get_config(self):</span><br><span class="line">        config = {</span><br><span class="line">            'epsilon': self.epsilon,</span><br><span class="line">            'beta_initializer': keras.initializers.serialize(self.beta_initializer),</span><br><span class="line">            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),</span><br><span class="line">            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),</span><br><span class="line">            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),</span><br><span class="line">            'beta_constraint': keras.constraints.serialize(self.beta_constraint),</span><br><span class="line">            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint)</span><br><span class="line">        }</span><br><span class="line">        base_config = super(InstanceNormalization, self).get_config()</span><br><span class="line"></span><br><span class="line">        return dict(list(base_config.items()) + list(config.items()))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="GN-Group-Normalization，2018"><a href="#GN-Group-Normalization，2018" class="headerlink" title="GN(Group Normalization，2018)"></a><font color="red">GN(Group Normalization，2018)</font></h2><p><strong>GN(Group Normalization)</strong>：为了解决BN中对较小batch_size效果较差的问题，将通道数C分为G组，每组有C/G个通道数，然后将这些通道数中的元素标准化，<strong>做NxC/G次标准化</strong>，如果将班级数量分为2组，相当于分别按照年级先将班级分为2组，一共分成6组，然后对所有组所有同学的成绩进行标准化(如一年级一班，一年级二班，一年级三班的所有同学进行标准化，一年级四班，一年级五班，一年级六班的所有同学进行标准化，然后再将二年级一班，二年级二班，二年级三班的所有同学进行标准化，二年级四班，二年级五班，二年级六班的所有同学进行标准化，最后将三年级一班，三年级二班，三年级三班的所有同学进行标准化，三年级四班，三年级五班，三年级六班的所有同学进行标准化，一共做了6次标准化)。分组之后，<strong>不依赖batch_size的大小，因此不会被batch_size约束</strong>。</p>
<h2 id="自定义GN层"><a href="#自定义GN层" class="headerlink" title="自定义GN层"></a><font color="red">自定义GN层</font></h2><p>在TensorFlow2.0中没有提供GN层的类，需要自己定义，这里也给出了自定义GN层的方法。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GroupNormalization(keras.layers.Layer):</span><br><span class="line">    def __init__(self, group=32, beta_initializer='zeros', gamma_initializer='ones',</span><br><span class="line">                 beta_regularizer=None, gamma_regularizer=None,</span><br><span class="line">                 beta_constraint=None, gamma_constraint=None, epsilon=1e-5,</span><br><span class="line">                 **kwargs):</span><br><span class="line">        super(GroupNormalization, self).__init__(**kwargs)</span><br><span class="line">        self.group = group</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        self.beta_initializer = keras.initializers.get(beta_initializer)</span><br><span class="line">        self.gamma_initializer = keras.initializers.get(gamma_initializer)</span><br><span class="line">        self.beta_regularizer = keras.regularizers.get(beta_regularizer)</span><br><span class="line">        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)</span><br><span class="line">        self.beta_constraint = keras.constraints.get(beta_constraint)</span><br><span class="line">        self.gamma_constraint = keras.constraints.get(gamma_constraint)</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        assert len(input_shape) == 4</span><br><span class="line">        assert input_shape[-1] &gt;= self.group</span><br><span class="line">        assert input_shape[-1] % self.group == 0</span><br><span class="line"></span><br><span class="line">        self.gamma = self.add_weight(shape=(input_shape[-1],), name='gamma', initializer=self.gamma_initializer,</span><br><span class="line">                                     regularizer=self.gamma_regularizer, constraint=self.gamma_constraint)</span><br><span class="line">        self.beta = self.add_weight(shape=(input_shape[-1],), name='beta', initializer=self.beta_initializer,</span><br><span class="line">                                    regularizer=self.beta_regularizer, constraint=self.beta_constraint)</span><br><span class="line">        self.built = True</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        inputs = tf.reshape(inputs, shape=[-1, inputs.shape[1], inputs.shape[2], self.group, inputs.shape[-1] // self.group])</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, axes=[1, 2, 3], keepdims=True)</span><br><span class="line">        outputs = (inputs - mean) / tf.sqrt(variance + self.epsilon)</span><br><span class="line">        outputs = tf.reshape(outputs, shape=[-1, inputs.shape[1], inputs.shape[2], inputs.shape[3] * inputs.shape[4]])</span><br><span class="line">        return outputs * self.gamma + self.beta</span><br><span class="line"></span><br><span class="line">    def get_config(self):</span><br><span class="line">        config = {</span><br><span class="line">            'epsilon': self.epsilon,</span><br><span class="line">            'beta_initializer': keras.initializers.serialize(self.beta_initializer),</span><br><span class="line">            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),</span><br><span class="line">            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),</span><br><span class="line">            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),</span><br><span class="line">            'beta_constraint': keras.constraints.serialize(self.beta_constraint),</span><br><span class="line">            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint)</span><br><span class="line">        }</span><br><span class="line">        base_config = super(GroupNormalization, self).get_config()</span><br><span class="line">        return dict(list(base_config.items()) + list(config.items()))</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  虽然自定义标准化层看起来非常复杂，其实本质代码只有call函数中的几行而已，而且<strong>根据不同的Normalization，只需要修改求均值和方差的轴即可</strong>。<strong>Normalization是卷积神经网络的Trick(小技巧)</strong>，自从Normalization被提出以后，几乎各个网络都能看到它的身影，灵活掌握不同Normalization，是小伙伴们需要达成的目标。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>Upsampling黑科技</title>
    <url>/2020/05/06/deep%20learning%20upsampling/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Upsampling</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Upsampling(上采样)</strong>:简单的说就是放大图像，获得更大的分辨率，上采样对于卷积神经网络任务来说并不是必须的，但是在某些场合中却必须要使用，尤其是在<strong>语义分割</strong>任务中，如何选择上采样的方式可能决定着语义分割效果。可能小伙伴们对上采样不是很熟悉，但是对于下采样一定都不陌生，典型的下采样步骤就是池化。因此上采样也可被看作是<strong>池化的逆过程</strong>。<br><a id="more"></a></p>
<p><img src="/images/Semantic_segmentation/SegNet_U.png" alt="upsampling"></p>
<h1 id="Maxpooling-Indices-最大池化索引-与Upsampling-上采样-和Deconvolution-反卷积-之间的区别"><a href="#Maxpooling-Indices-最大池化索引-与Upsampling-上采样-和Deconvolution-反卷积-之间的区别" class="headerlink" title="Maxpooling-Indices(最大池化索引)与Upsampling(上采样)和Deconvolution(反卷积)之间的区别"></a><font size="5" color="red">Maxpooling-Indices(最大池化索引)与Upsampling(上采样)和Deconvolution(反卷积)之间的区别</font></h1><p>  <font size="3"><strong>Maxpooling-Indices(最大池化索引)</strong>：又称为<strong>Unpooling(反池化)</strong>，池化后<strong>记录最大值所在的位置</strong>，在反池化的过程中，给相应位置上写入值，<strong>其他位置为0</strong>。这个方法没有参数，<strong>但是这个方法并不常用，因为存在大量的稀疏数据，使模型收敛速度大大降低。</strong></font><br>  <font size="3"><strong>Upsampling(上采样)</strong>：将输入<strong>resize到设置大小</strong>，然后利用指定的插值方法<strong>对周围的值进行插值</strong>，常用<strong>最近邻插值</strong>和<strong>双线性插值</strong>。因为相邻区域的像素和特征应该是相似的，因此这个方法特别常用，<strong>既没有参数，也不会存在稀疏数据。</strong></font><br>  <font size="3"><strong>Deconvolution(反卷积)</strong>：<strong>本质是卷积</strong>，注意<strong>反卷积并不能从卷积的结果返回到卷积前的数据，只能返回到卷积前的尺寸</strong>。卷积通过设置kernel_size卷积核大小，strides步长和padding填充方式可以将图像的分辨率降低，相反的反卷积可以通过设置kernel_size卷积核大小，strides步长和padding填充方式<strong>先对数据进行填充，然后再进行卷积操作</strong>，可以将图像的分辨率增加。<strong>这个方法不推荐经常使用，因为存在大量参数，而且可能会存在棋盘格效应，可以参考<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">棋盘格可视化</a></strong>。</font></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  由于CNN经常使用池化来缩小图像尺寸，方便提取更深层次的特征，因此下采样是CNN网络重要的组成部分，但是在某些特殊场景需要<strong>对图像大小进行复原</strong>，因此上采样应运而生，所以要想系统的学习神经网络，上采样知识点是小伙伴们必不可少的。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>SSD</title>
    <url>/2020/05/05/Object%20detection%20SSD/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">SSD</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>SSD(Single Shot MultiBox Detector)</strong>:于<strong>2016年发表在ECCV</strong>上。Single Shot MultiBox Detector的字面意思为：单次多框检测器，顾名思义，属于目标检测算法中一步法的思想，而且利用到多个先验框的一种算法，是一步法的典型代表。<a id="more"></a></p>
<p><img src="/images/Object_detection/SSD.png" alt="SSD"></p>
<h1 id="SSD特点"><a href="#SSD特点" class="headerlink" title="SSD特点"></a><font size="5" color="red">SSD特点</font></h1><p>  <font size="3">特征提取网络为<strong>VGG</strong>，构建特征提取网络较为简单。</font><br>  <font size="3">针对于不同尺度的特征层设计不同大小的先验框，融合不同特征层的检测信息对先验框中是否包含物体进行分类。</font></p>
<h1 id="SSD图像分析"><a href="#SSD图像分析" class="headerlink" title="SSD图像分析"></a><font size="5" color="red">SSD图像分析</font></h1><p><img src="/images/Object_detection/SSD_A.png" alt="SSD"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class L2_Normalize(keras.layers.Layer):</span><br><span class="line">    def __init__(self, scale, **kwargs):</span><br><span class="line">        super(L2_Normalize, self).__init__(kwargs)</span><br><span class="line">        self.scale = scale</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.gamma = tf.Variable(self.scale * np.ones((input_shape[3],), dtype='float32'))</span><br><span class="line"></span><br><span class="line">    def call(self, x, mask=None):</span><br><span class="line">        output = tf.nn.l2_normalize(x, axis=3)</span><br><span class="line">        output *= self.gamma</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ssd(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='conv1_1'),</span><br><span class="line">                keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='conv1_2'),</span><br><span class="line">                keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool1'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='conv2_1'),</span><br><span class="line">                keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='conv2_2'),</span><br><span class="line">                keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool2'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='conv3_1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='conv3_2'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='conv3_3'),</span><br><span class="line">                keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool3'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(512, (3, 3), (1, 1), 'same', activation='relu', name='conv4_1'),</span><br><span class="line">                keras.layers.Conv2D(512, (3, 3), (1, 1), 'same', activation='relu', name='conv4_2'),</span><br><span class="line">                keras.layers.Conv2D(512, (3, 3), (1, 1), 'same', activation='relu', name='conv4_3'))(x)</span><br><span class="line"></span><br><span class="line">    l2_norm = L2_Normalize(20, name='l2_norm')(x)</span><br><span class="line"></span><br><span class="line">    feature1_reg = compose(keras.layers.Conv2D(4 * 4, (3, 3), (1, 1), 'same', name='feature1_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature1_reg_flatten'))(l2_norm)</span><br><span class="line">    feature1_cls = compose(keras.layers.Conv2D(4 * 21, (3, 3), (1, 1), 'same', name='feature1_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature1_cls_flatten'))(l2_norm)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool4'),</span><br><span class="line">                keras.layers.Conv2D(512, (3, 3), (1, 1), 'same', activation='relu', name='conv5_1'),</span><br><span class="line">                keras.layers.Conv2D(512, (3, 3), (1, 1), 'same', activation='relu', name='conv5_2'),</span><br><span class="line">                keras.layers.Conv2D(512, (3, 3), (1, 1), 'same', activation='relu', name='conv5_3'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (1, 1), 'same', name='maxpool5'),</span><br><span class="line">                keras.layers.Conv2D(1024, (3, 3), (1, 1), 'same', activation='relu', dilation_rate=(6, 6), name='conv5_4'),</span><br><span class="line">                keras.layers.Conv2D(1024, (1, 1), (1, 1), 'same', activation='relu', name='conv5_5'))(x)</span><br><span class="line"></span><br><span class="line">    feature2_reg = compose(keras.layers.Conv2D(6 * 4, (3, 3), (1, 1), 'same', name='feature2_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature2_reg_flatten'))(x)</span><br><span class="line">    feature2_cls = compose(keras.layers.Conv2D(6 * 21, (3, 3), (1, 1), 'same', name='feature2_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature2_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(256, (1, 1), (1, 1), 'same', activation='relu', name='conv6_1'),</span><br><span class="line">                keras.layers.Conv2D(512, (3, 3), (2, 2), 'same', activation='relu', name='conv6_2'))(x)</span><br><span class="line"></span><br><span class="line">    feature3_reg = compose(keras.layers.Conv2D(6 * 4, (3, 3), (1, 1), 'same', name='feature3_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature3_reg_flatten'))(x)</span><br><span class="line">    feature3_cls = compose(keras.layers.Conv2D(6 * 21, (3, 3), (1, 1), 'same', name='feature3_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature3_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(128, (1, 1), (1, 1), 'same', activation='relu', name='conv7_1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (2, 2), 'same', activation='relu', name='conv7_2'))(x)</span><br><span class="line"></span><br><span class="line">    feature4_reg = compose(keras.layers.Conv2D(6 * 4, (3, 3), (1, 1), 'same', name='feature4_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature4_reg_flatten'))(x)</span><br><span class="line">    feature4_cls = compose(keras.layers.Conv2D(6 * 21, (3, 3), (1, 1), 'same', name='feature4_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature4_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(128, (1, 1), (1, 1), 'same', activation='relu', name='conv8_1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='conv8_2'))(x)</span><br><span class="line"></span><br><span class="line">    feature5_reg = compose(keras.layers.Conv2D(4 * 4, (3, 3), (1, 1), 'same', name='feature5_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature5_reg_flatten'))(x)</span><br><span class="line">    feature5_cls = compose(keras.layers.Conv2D(4 * 21, (3, 3), (1, 1), 'same', name='feature5_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature5_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(128, (1, 1), (1, 1), 'same', activation='relu', name='conv9_1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='conv9_2'))(x)</span><br><span class="line"></span><br><span class="line">    feature6_reg = compose(keras.layers.Conv2D(4 * 4, (3, 3), (1, 1), 'same', name='feature6_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature6_reg_flatten'))(x)</span><br><span class="line">    feature6_cls = compose(keras.layers.Conv2D(4 * 21, (3, 3), (1, 1), 'same', name='feature6_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature6_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    concatenate_reg = keras.layers.Concatenate(name='concatenate_reg')([feature1_reg, feature2_reg, feature3_reg, feature4_reg, feature5_reg, feature6_reg])</span><br><span class="line">    concatenate_cls = keras.layers.Concatenate(name='concatenate_cls')([feature1_cls, feature2_cls, feature3_cls, feature4_cls, feature5_cls, feature6_cls])</span><br><span class="line"></span><br><span class="line">    reshape_reg = keras.layers.Reshape((8732, 4), name='reshape_reg')(concatenate_reg)</span><br><span class="line">    reshape_cls = keras.layers.Reshape((8732, 21), name='reshape_cls')(concatenate_cls)</span><br><span class="line"></span><br><span class="line">    softmax_cls = keras.layers.Softmax(name='softmax_cls')(reshape_cls)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Concatenate(name='concatenate')([reshape_reg, softmax_cls])</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='SSD')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = ssd(input_shape=(300, 300, 3))</span><br><span class="line">    model.build(input_shape=(None, 300, 300, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Object_detection/SSD_R.png" alt="SSD"></p>
<h1 id="Shape数据集完整实战"><a href="#Shape数据集完整实战" class="headerlink" title="Shape数据集完整实战"></a><font size="5" color="red">Shape数据集完整实战</font></h1><h2 id="文件路径关系说明"><a href="#文件路径关系说明" class="headerlink" title="文件路径关系说明"></a>文件路径关系说明</h2><ul>
<li>project<ul>
<li>shape<ul>
<li>train_imgs(训练集图像文件夹)</li>
<li>annotations(训练集标签文件夹)</li>
<li>test_imgs(测试集图像文件夹)</li>
</ul>
</li>
<li>SSD_weight(模型权重文件夹)</li>
<li>SSD_test_result(测试集结果文件夹)</li>
<li>SSD.py</li>
</ul>
</li>
</ul>
<h2 id="实战步骤说明"><a href="#实战步骤说明" class="headerlink" title="实战步骤说明"></a>实战步骤说明</h2><ol>
<li>目标检测和语义分割是两种不同类型的工程项目，目标检测实战处理比语义分割困难的多，首先要<strong>读取真实框信息</strong>，将其保存下来，为了后面编码使用。</li>
<li><strong>建立先验框</strong>，根据网络结构，在不同特征层上建立不同的先验框，先验框的总个数为每个回归分类特征层的像素点个数x每个像素点上的先验框个数。以论文中的先验框为例，特征层有6个，大小分别为38x38，19x19，10x10，5x5，3x3，1x1，特征层上每个像素点的先验框个数分别为4，6，6，6，4，4。<br><img src="/images/Object_detection/SSD_P.png" alt="anchor"><script type="math/tex; mode=display">38^2 \times 4+19^2 \times 6+10^2 \times 6+5^2 \times 6+3^2 \times 4+1^2 \times 4=8732</script>故先验框总数为8732个。</li>
<li>根据真实框的信息，和所有先验框计算IOU，将IOU大于设定值的记录下来，作为正样本。然后进行<strong>编码</strong>，在所属类别的置信度上面置1，其他类别置信度置0，并计算正样本先验框的中心坐标与宽高和真实框的中心坐标与宽高之间的差异。输出(batch_size, num_prior, 4 + 1 + num_class)，num_prior为先验框的个数，每个先验框有4 + 1 + num_class个值，4代表中心坐标和宽高相对真实框的差异，1代表属于背景的置信度，num_class代表属于某一个类别的置信度。编码的目的是得到真实框对应的神经网络的输出应该是什么样子，然后让两者尽可能的接近。<br><strong>IOU(Intersection Over Union，交并比)</strong>：用于<strong>评估语义分割算法性能的指标是平均IOU</strong>，交并比也非常好理解，算法的结果与真实物体进行<strong>交运算的结果除以进行并运算的结果</strong>。通过下图可以直观的看出IOU的计算方法。<br><img src="/images/Semantic_segmentation/Dataset_I.png" alt="IOU"></li>
<li><strong>设计损失函数</strong>，因为先验框中大部分都是负样本，因此不能直接计算损失函数，首先要对<strong>正负样本进行比例调整。一般选择正负样本比例为1：3</strong>，然后使用<strong>交叉熵损失函数</strong>计算正负样本的分类损失，使用<strong>smooth L1 loss</strong>计算正样本的定位损失。</li>
<li>搭建神经网络，<strong>设置合适参数</strong>，进行训练。</li>
<li>预测时，需要根据神经网络的输出进行<strong>逆向解码(编码的反过程)</strong>，根据置信度，选择<strong>非背景置信度大于设定值的先验框作为候选框</strong>，并且该框的<strong>类别设为置信度最大索引对应的类别</strong>，如最大值的索引为2，则该预测框预测的物体类别是第二类。然后<strong>根据先验框的坐标和4个回归参数确定候选框的左上角和右下角坐标</strong>。对<strong>每一类候选框进行NMS得到预测框</strong>，并且在图像上<strong>画出预测框</strong>，并且<strong>标出置信度</strong>即可完成目标检测任务。<br><strong>NMS(Non-Maximum Suppression，非极大值抑制)</strong>：简单地说，<strong>不是最大的我不要</strong>，在目标检测中，往往图像上存在大量先验框，会导致很多附近的框都会预测出同一个物体，但是我们<strong>只保留最大的一个预测结果</strong>，这就是非极大值抑制。<br>步骤：<br>(1)<strong>从最大概率矩形框F开始</strong>，分别判断A~E与F的IOU是否大于某个设定的阈值，<strong>假设B、D与F的重叠度超过阈值，那么就扔掉B、D</strong>；并<strong>标记第一个矩形框F</strong>，是我们保留下来的。<br>(2)<strong>从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框</strong>。<br>(3)<strong>重复步骤(2)，直到所有的框都被抛弃或者保留</strong>。<br><img src="/images/Object_detection/Dataset_N.png" alt="NMS"></li>
</ol>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>神经网络的输出维度为(batch_size, num_prior, 4 + 1 + num_class)，<strong>此数据集为3类，因此最后一个维度是8</strong>。每个先验框有8个索引，前面4个索引代表先验框的回归参数，用来对先验框进行调整得到预测框，索引为4代表背景，索引为5代表圆形，索引为6代表三角形，索引为7代表正方形。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
<li>设置了<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li>使用<strong>yield</strong>关键字，产生可迭代对象，不用将所有的数据都保存下来，大大节约内存。</li>
<li>其中将1000个数据，分成800个训练集，100个验证集和100个测试集，小伙伴们可以自行修改。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>SSD的<strong>特征提取网络为VGG</strong>，小伙伴们可以参考特征提取网络部分内容，选择其他的网络进行特征提取，比较不同网络参数量，运行速度，最终结果之间的差异。</li>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li><strong>根据实际的图像大小，选择合适的特征层数，先验框的形状，先验框数量，以及各种阈值</strong></li>
<li><strong>anchor尺寸的确定</strong>，anchor一般是正方形或者长方形，每个特征层上设置最大尺寸max_size和最小尺寸min_size，如果先验框为4个，则代表两个正方形和两个长方形，一个正方形的边长为min_size，另一个为$\sqrt{max \underline{} size \times min \underline{} size}$，一个长方形的边长为$(min \underline{} size \times \sqrt2，min \underline{} size \div \sqrt2)$，另一个长方形的边长为$(min \underline{} size \div \sqrt2，min \underline{} size \times \sqrt2)$，如果先验框为6个，则添加两个长方形，将上面的$\sqrt2$改成$\sqrt3$即可。</li>
<li>因为这个博客是对学习的一些总结和记录，意在和学习者探讨和交流，并且给准备入门的同学一些手把手的教学，因此关于目标检测的算法参数设计，我都是自己尝试的，不是针对于这个数据集最优的参数，大家可以根据自己的实际需要修改网络结构。</li>
</ol>
<h2 id="完整实战代码"><a href="#完整实战代码" class="headerlink" title="完整实战代码"></a>完整实战代码</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import colorsys</span><br><span class="line">import os</span><br><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取先验框函数</span><br><span class="line">def get_prior(layer_id):</span><br><span class="line">    layer_id = layer_id - 1</span><br><span class="line"></span><br><span class="line">    box_widths = []</span><br><span class="line">    box_heights = []</span><br><span class="line"></span><br><span class="line">    current_ratios = [1, 1]</span><br><span class="line">    for ratio in ratios[layer_id]:</span><br><span class="line">        current_ratios.extend([ratio, 1 / ratio])</span><br><span class="line"></span><br><span class="line">    for ratio in current_ratios:</span><br><span class="line">        if ratio == 1 and len(box_widths) == 0:</span><br><span class="line">            box_widths.append(min_size[layer_id])</span><br><span class="line">            box_heights.append(min_size[layer_id])</span><br><span class="line">        elif ratio == 1 and len(box_widths) &gt; 0:</span><br><span class="line">            box_widths.append((min_size[layer_id] * max_size[layer_id]) ** 0.5)</span><br><span class="line">            box_heights.append((min_size[layer_id] * max_size[layer_id]) ** 0.5)</span><br><span class="line">        elif ratio != 1:</span><br><span class="line">            box_widths.append(min_size[layer_id] * ratio ** 0.5)</span><br><span class="line">            box_heights.append(min_size[layer_id] / ratio ** 0.5)</span><br><span class="line"></span><br><span class="line">    step_x = img_size[1] / feature_map[layer_id]</span><br><span class="line">    step_y = img_size[0] / feature_map[layer_id]</span><br><span class="line">    linx = np.linspace(0.5 * step_x, img_size[1] - 0.5 * step_x, feature_map[layer_id])</span><br><span class="line">    liny = np.linspace(0.5 * step_y, img_size[0] - 0.5 * step_y, feature_map[layer_id])</span><br><span class="line"></span><br><span class="line">    centers_x, centers_y = np.meshgrid(linx, liny)</span><br><span class="line">    centers_x = centers_x.reshape(-1, 1)</span><br><span class="line">    centers_y = centers_y.reshape(-1, 1)</span><br><span class="line"></span><br><span class="line">    # 获得先验框的中心坐标</span><br><span class="line">    prior_center = np.concatenate((centers_x, centers_y), axis=1)</span><br><span class="line">    prior_center = np.tile(prior_center, (1, prior[layer_id] * 2))</span><br><span class="line"></span><br><span class="line">    prior_lt_rb = prior_center.copy()</span><br><span class="line"></span><br><span class="line">    # 获得先验框的左上右下</span><br><span class="line">    prior_lt_rb[:, ::4] -= box_widths</span><br><span class="line">    prior_lt_rb[:, 1::4] -= box_heights</span><br><span class="line">    prior_lt_rb[:, 2::4] += box_widths</span><br><span class="line">    prior_lt_rb[:, 3::4] += box_heights</span><br><span class="line"></span><br><span class="line">    # 归一化到[0, 1]</span><br><span class="line">    prior_lt_rb[:, ::2] /= img_size[1]</span><br><span class="line">    prior_lt_rb[:, 1::2] /= img_size[0]</span><br><span class="line">    prior_lt_rb = prior_lt_rb.reshape(-1, 4)</span><br><span class="line">    prior_lt_rb = np.minimum(np.maximum(prior_lt_rb, 0.0), 1.0)</span><br><span class="line"></span><br><span class="line">    prior_center_wh = np.zeros_like(prior_lt_rb)</span><br><span class="line">    # 获得先验框的宽和高</span><br><span class="line">    prior_center_wh[:, 0] = 0.5 * (prior_lt_rb[:, 2] + prior_lt_rb[:, 0])</span><br><span class="line">    prior_center_wh[:, 1] = 0.5 * (prior_lt_rb[:, 3] + prior_lt_rb[:, 1])</span><br><span class="line">    prior_center_wh[:, 2] = prior_lt_rb[:, 2] - prior_lt_rb[:, 0]</span><br><span class="line">    prior_center_wh[:, 3] = prior_lt_rb[:, 3] - prior_lt_rb[:, 1]</span><br><span class="line"></span><br><span class="line">    return prior_center_wh.astype(np.float32), prior_lt_rb.astype(np.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 从xml文件中获取bounding-box信息</span><br><span class="line">def get_bbox(image_id, bbox_path, annotations_path):</span><br><span class="line">    with open(bbox_path, 'w') as f:</span><br><span class="line">        for id in image_id:</span><br><span class="line">            # 图片路径</span><br><span class="line">            info = os.getcwd() + imgs_path[1:] + '\\' + str(id) + '.jpg'</span><br><span class="line">            in_file = open(annotations_path + '\\' + str(id) + '.xml', encoding='utf-8')</span><br><span class="line">            tree = ET.parse(in_file)</span><br><span class="line">            root = tree.getroot()</span><br><span class="line"></span><br><span class="line">            for obj in root.iter('object'):</span><br><span class="line">                difficult = obj.find('difficult').text</span><br><span class="line">                cls = obj.find('name').text</span><br><span class="line">                if cls not in classes or int(difficult) == 1:</span><br><span class="line">                    continue</span><br><span class="line">                cls_id = classes.index(cls)</span><br><span class="line">                xmlbox = obj.find('bndbox')</span><br><span class="line">                b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))</span><br><span class="line">                info += " " + ",".join([str(x) for x in b]) + ',' + str(cls_id)</span><br><span class="line">            f.writelines(info + '\n')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class L2_Normalize(keras.layers.Layer):</span><br><span class="line">    def __init__(self, scale, **kwargs):</span><br><span class="line">        super(L2_Normalize, self).__init__(kwargs)</span><br><span class="line">        self.scale = scale</span><br><span class="line"></span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.gamma = tf.Variable(self.scale * np.ones((input_shape[3],), dtype='float32'))</span><br><span class="line"></span><br><span class="line">    def call(self, x, mask=None):</span><br><span class="line">        output = tf.nn.l2_normalize(x, axis=3)</span><br><span class="line">        output *= self.gamma</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def small_ssd(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='conv1_1'),</span><br><span class="line">                keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool1'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='conv2_1'),</span><br><span class="line">                keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool2'))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='conv3_1')(x)</span><br><span class="line"></span><br><span class="line">    l2_norm = L2_Normalize(20, name='l2_norm')(x)</span><br><span class="line"></span><br><span class="line">    feature1_reg = compose(keras.layers.Conv2D(prior[0] * 4, (3, 3), (1, 1), 'same', name='feature1_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature1_reg_flatten'))(l2_norm)</span><br><span class="line">    feature1_cls = compose(keras.layers.Conv2D(prior[0] * num_class, (3, 3), (1, 1), 'same', name='feature1_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature1_cls_flatten'))(l2_norm)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.MaxPool2D((2, 2), (2, 2), 'same', name='maxpool3'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='conv4_1'),)(x)</span><br><span class="line"></span><br><span class="line">    feature2_reg = compose(keras.layers.Conv2D(prior[1] * 4, (3, 3), (1, 1), 'same', name='feature2_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature2_reg_flatten'))(x)</span><br><span class="line">    feature2_cls = compose(keras.layers.Conv2D(prior[1] * num_class, (3, 3), (1, 1), 'same', name='feature2_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature2_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(512, (3, 3), (2, 2), 'valid', activation='relu', name='conv5_1'))(x)</span><br><span class="line"></span><br><span class="line">    feature3_reg = compose(keras.layers.Conv2D(prior[2] * 4, (3, 3), (1, 1), 'same', name='feature3_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature3_reg_flatten'))(x)</span><br><span class="line">    feature3_cls = compose(keras.layers.Conv2D(prior[2] * num_class, (3, 3), (1, 1), 'same', name='feature3_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature3_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(128, (1, 1), (1, 1), 'same', activation='relu', name='conv6_1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (2, 2), 'valid', activation='relu', name='conv6_2'))(x)</span><br><span class="line"></span><br><span class="line">    feature4_reg = compose(keras.layers.Conv2D(prior[3] * 4, (3, 3), (1, 1), 'same', name='feature4_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature4_reg_flatten'))(x)</span><br><span class="line">    feature4_cls = compose(keras.layers.Conv2D(prior[3] * num_class, (3, 3), (1, 1), 'same', name='feature4_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature4_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(128, (1, 1), (1, 1), 'same', activation='relu', name='conv7_1'),</span><br><span class="line">                keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='conv7_2'))(x)</span><br><span class="line"></span><br><span class="line">    feature5_reg = compose(keras.layers.Conv2D(prior[4] * 4, (3, 3), (1, 1), 'same', name='feature5_reg_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature5_reg_flatten'))(x)</span><br><span class="line">    feature5_cls = compose(keras.layers.Conv2D(prior[4] * num_class, (3, 3), (1, 1), 'same', name='feature5_cls_conv'),</span><br><span class="line">                           keras.layers.Flatten(name='feature5_cls_flatten'))(x)</span><br><span class="line"></span><br><span class="line">    concatenate_reg = keras.layers.Concatenate(name='concatenate_reg')([feature1_reg, feature2_reg, feature3_reg, feature4_reg, feature5_reg])</span><br><span class="line">    concatenate_cls = keras.layers.Concatenate(name='concatenate_cls')([feature1_cls, feature2_cls, feature3_cls, feature4_cls, feature5_cls])</span><br><span class="line"></span><br><span class="line">    reshape_reg = keras.layers.Reshape((num_prior, 4), name='reshape_reg')(concatenate_reg)</span><br><span class="line">    reshape_cls = keras.layers.Reshape((num_prior, num_class), name='reshape_cls')(concatenate_cls)</span><br><span class="line"></span><br><span class="line">    softmax_cls = keras.layers.Softmax(name='softmax_cls')(reshape_cls)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Concatenate(name='concatenate')([reshape_reg, softmax_cls])</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='Small_SSD')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 计算IOU函数</span><br><span class="line">def iou(box):</span><br><span class="line">    inter_upleft = np.maximum(prior_lt_rb[:, :2], box[:2])</span><br><span class="line">    inter_botright = np.minimum(prior_lt_rb[:, 2:4], box[2:])</span><br><span class="line"></span><br><span class="line">    inter_wh = inter_botright - inter_upleft</span><br><span class="line">    inter_wh = np.maximum(inter_wh, 0)</span><br><span class="line">    inter = inter_wh[:, 0] * inter_wh[:, 1]</span><br><span class="line">    # 真实框的面积</span><br><span class="line">    area_true = (box[2] - box[0]) * (box[3] - box[1])</span><br><span class="line">    # 先验框的面积</span><br><span class="line">    area_gt = (prior_lt_rb[:, 2] - prior_lt_rb[:, 0]) * (prior_lt_rb[:, 3] - prior_lt_rb[:, 1])</span><br><span class="line">    # 计算iou</span><br><span class="line">    union = area_true + area_gt - inter</span><br><span class="line"></span><br><span class="line">    iou = inter / union</span><br><span class="line"></span><br><span class="line">    return iou</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 根据真实框bounding-box编码函数</span><br><span class="line">def encoder(box):</span><br><span class="line">    iou_val = iou(box)</span><br><span class="line">    encoded_box = np.zeros((num_prior, 5))</span><br><span class="line"></span><br><span class="line">    # 找到每一个真实框，重合程度较高的先验框</span><br><span class="line">    assign_mask = iou_val &gt; overlap_threshold</span><br><span class="line">    encoded_box[:, -1][assign_mask] = iou_val[assign_mask]</span><br><span class="line"></span><br><span class="line">    # 找到对应的先验框</span><br><span class="line">    assigned_priors = prior_center_wh[assign_mask]</span><br><span class="line"></span><br><span class="line">    # 先计算真实框的中心与长宽</span><br><span class="line">    box_center = 0.5 * (box[:2] + box[2:])</span><br><span class="line">    box_wh = box[2:] - box[:2]</span><br><span class="line"></span><br><span class="line">    # 再计算重合度较高的先验框的中心与长宽</span><br><span class="line">    assigned_priors_center = assigned_priors[:, :2]</span><br><span class="line">    assigned_priors_wh = assigned_priors[:, 2:4]</span><br><span class="line"></span><br><span class="line">    # 根据真实框求ssd应该有的预测结果</span><br><span class="line">    encoded_box[:, :2][assign_mask] = box_center - assigned_priors_center</span><br><span class="line">    encoded_box[:, :2][assign_mask] /= assigned_priors_wh</span><br><span class="line"></span><br><span class="line">    # 除以0.1</span><br><span class="line">    encoded_box[:, :2][assign_mask] /= variances[:2]</span><br><span class="line"></span><br><span class="line">    encoded_box[:, 2:4][assign_mask] = np.log(box_wh / assigned_priors_wh)</span><br><span class="line">    # 除以0.2</span><br><span class="line">    encoded_box[:, 2:4][assign_mask] /= variances[2:]</span><br><span class="line"></span><br><span class="line">    return encoded_box</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取网络输出标签数据，即作为损失函数的真实输入y_true</span><br><span class="line">def assign_boxes(boxes):</span><br><span class="line">    # 大小为num_box * (4 + num_class)，4代表4个位置回归</span><br><span class="line">    assignment = np.zeros((num_prior, 4 + num_class))</span><br><span class="line">    assignment[:, 4] = 1.0</span><br><span class="line">    if len(boxes) == 0:</span><br><span class="line">        return assignment</span><br><span class="line">    # 对每一个真实框都进行iou计算</span><br><span class="line">    encoded_boxes = np.apply_along_axis(f_encode, 1, boxes[:, :4])</span><br><span class="line">    # 每一个真实框的编码后的值，和iou</span><br><span class="line">    encoded_boxes = encoded_boxes.reshape(-1, num_prior, 5)</span><br><span class="line">    # 取重合程度最大的先验框，并且获取这个先验框的index</span><br><span class="line">    best_iou = encoded_boxes[:, :, -1].max(axis=0)</span><br><span class="line">    best_iou_idx = encoded_boxes[:, :, -1].argmax(axis=0)</span><br><span class="line">    best_iou_mask = best_iou &gt; 0</span><br><span class="line">    best_iou_idx = best_iou_idx[best_iou_mask]</span><br><span class="line"></span><br><span class="line">    # 保留重合程度最大的先验框的应该有的预测结果</span><br><span class="line">    encoded_boxes = encoded_boxes[:, best_iou_mask, :]</span><br><span class="line">    assignment[:, :4][best_iou_mask] = encoded_boxes[best_iou_idx, np.arange(len(best_iou_idx)), :4]</span><br><span class="line">    # 4代表为背景的概率，为0</span><br><span class="line">    assignment[:, 4:][best_iou_mask] = boxes[best_iou_idx, 4:]</span><br><span class="line">    # 通过assign_boxes我们就获得了，输入进来的这张图片，应该有的预测结果是什么样子的</span><br><span class="line">    return assignment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 通过yield获取可迭代对象</span><br><span class="line">def generate_arrays_from_file(train_data, batch_size):</span><br><span class="line">    # 获取总长度</span><br><span class="line">    n = len(train_data)</span><br><span class="line">    i = 0</span><br><span class="line">    while True:</span><br><span class="line">        X_train = []</span><br><span class="line">        Y_train = []</span><br><span class="line">        # 获取一个batch_size大小的数据</span><br><span class="line">        while len(X_train) &lt; batch_size:</span><br><span class="line">            if i == 0:</span><br><span class="line">                np.random.shuffle(train_data)</span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            # train_data[i] = 2</span><br><span class="line">            img = cv.imread(imgs_path + '\\' + str(train_data[i]) + '.jpg')</span><br><span class="line">            # print(str(train_data[i]))</span><br><span class="line">            img = img / 127.5 - 1</span><br><span class="line">            info = np.array([list(map(int, x.split(','))) for x in bounding_info[train_data[i]].split()[3:]])</span><br><span class="line">            if not len(info):</span><br><span class="line">                i = (i + 1) % n</span><br><span class="line">                continue</span><br><span class="line">            box = (info[:, :4] + 1).astype(np.float32)</span><br><span class="line">            box[:, [0, 2]] = box[:, [0, 2]] / img_size[1]</span><br><span class="line">            box[:, [1, 3]] = box[:, [1, 3]] / img_size[0]</span><br><span class="line">            label = np.eye(num_class)[np.array(info[:, 4] + 1, np.int32)]</span><br><span class="line">            if ((box[:, 0] - box[:, 2]) &gt;= 0).any() or ((box[:, 1] - box[:, 3]) &gt;= 0).any():</span><br><span class="line">                i = (i + 1) % n</span><br><span class="line">                continue</span><br><span class="line">            box = np.concatenate([box, label], axis=-1)</span><br><span class="line">            X_train.append(img)</span><br><span class="line">            y = assign_boxes(box)</span><br><span class="line">            Y_train.append(y)</span><br><span class="line">            i = (i + 1) % n</span><br><span class="line">        yield tf.constant(X_train), tf.constant(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义损失函数</span><br><span class="line">class Loss:</span><br><span class="line">    def l1_smooth_loss(self, y_true, y_pred):</span><br><span class="line">        abs_loss = tf.abs(y_true - y_pred)</span><br><span class="line">        sq_loss = 0.5 * (y_true - y_pred) ** 2</span><br><span class="line">        l1_loss = tf.where(tf.less(abs_loss, 1.0), sq_loss, abs_loss - 0.5)</span><br><span class="line">        return tf.reduce_sum(l1_loss, axis=-1)</span><br><span class="line"></span><br><span class="line">    def softmax_loss(self, y_true, y_pred):</span><br><span class="line">        y_pred = tf.maximum(y_pred, 1e-7)</span><br><span class="line">        softmax_loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)</span><br><span class="line">        return softmax_loss</span><br><span class="line"></span><br><span class="line">    def compute_loss(self, y_true, y_pred):</span><br><span class="line">        # 每一张图的pos的个数，shape为batch_size</span><br><span class="line">        y_pos = 1 - y_true[:, :, 4]</span><br><span class="line">        num_pos = tf.reduce_sum(y_pos, axis=-1)</span><br><span class="line">        # 获取一定的负样本</span><br><span class="line">        num_neg = tf.minimum(neg_pos_ratio * num_pos, num_prior - num_pos)</span><br><span class="line">        # 找到了哪些值是大于0的</span><br><span class="line">        pos_num_neg_mask = tf.greater(num_neg, 0)</span><br><span class="line">        # 求平均每个图片要取多少个负样本</span><br><span class="line">        has_min = tf.cast(tf.reduce_any(pos_num_neg_mask), tf.float32)</span><br><span class="line">        num_neg = tf.concat([num_neg, [(1 - has_min) * negatives_for_hard]], axis=0)</span><br><span class="line">        num_neg_batch = tf.reduce_mean(tf.boolean_mask(num_neg, tf.greater(num_neg, 0)))</span><br><span class="line">        num_neg_batch = tf.cast(num_neg_batch, tf.int32)</span><br><span class="line"></span><br><span class="line">        # 找到实际上在该位置不应该有预测结果的框，求他们最大的置信度。</span><br><span class="line">        max_confs = tf.reduce_max(y_pred[:, :, 5:5 + num_class - 1], axis=2)</span><br><span class="line"></span><br><span class="line">        # 取top_k个置信度，作为负样本</span><br><span class="line">        _, indices = tf.nn.top_k(max_confs * y_true[:, :, 4], k=num_neg_batch)</span><br><span class="line"></span><br><span class="line">        # 找到负样本的一维索引</span><br><span class="line">        batch_idx = tf.expand_dims(tf.range(0, batch_size), 1)</span><br><span class="line">        batch_idx = tf.tile(batch_idx, (1, num_neg_batch))</span><br><span class="line">        full_indices = (tf.reshape(batch_idx, [-1]) * num_prior + tf.reshape(indices, [-1]))</span><br><span class="line"></span><br><span class="line">        y_true_pos = y_true[tf.equal(y_true[:, :, 4], 0)]</span><br><span class="line">        y_pred_pos = y_pred[tf.equal(y_true[:, :, 4], 0)]</span><br><span class="line">        y_true_neg = tf.gather(tf.reshape(y_true, (-1, 8)), axis=0, indices=full_indices)</span><br><span class="line">        y_pred_neg = tf.gather(tf.reshape(y_pred, (-1, 8)), axis=0, indices=full_indices)</span><br><span class="line"></span><br><span class="line">        y_true_valid = tf.concat([y_true_pos, y_true_neg], axis=0)</span><br><span class="line">        y_pred_valid = tf.concat([y_pred_pos, y_pred_neg], axis=0)</span><br><span class="line"></span><br><span class="line">        loc_loss = self.l1_smooth_loss(y_true_pos[:, :4], y_pred_pos[:, :4])</span><br><span class="line">        conf_loss = self.softmax_loss(y_true_valid[:, 4:], y_pred_valid[:, 4:])</span><br><span class="line"></span><br><span class="line">        return tf.reduce_mean(loc_loss) + tf.reduce_mean(conf_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 根据网络预测解码函数，获得候选框</span><br><span class="line">def decoder(loc):</span><br><span class="line">    # 获得先验框的中心与宽高</span><br><span class="line">    prior_center_x = prior_center_wh[:, 0]</span><br><span class="line">    prior_center_y = prior_center_wh[:, 1]</span><br><span class="line">    prior_width = prior_center_wh[:, 2]</span><br><span class="line">    prior_height = prior_center_wh[:, 3]</span><br><span class="line"></span><br><span class="line">    # 获得真实框的中心与宽高</span><br><span class="line">    decode_bbox_center_x = loc[:, 0] * prior_width * variances[0] + prior_center_x</span><br><span class="line">    decode_bbox_center_y = loc[:, 1] * prior_height * variances[1] + prior_center_y</span><br><span class="line">    decode_bbox_width = np.exp(loc[:, 2] * variances[2]) * prior_width</span><br><span class="line">    decode_bbox_height = np.exp(loc[:, 3] * variances[3]) * prior_height</span><br><span class="line"></span><br><span class="line">    # 获取真实框的左上角与右下角</span><br><span class="line">    decode_bbox_xmin = decode_bbox_center_x - 0.5 * decode_bbox_width</span><br><span class="line">    decode_bbox_ymin = decode_bbox_center_y - 0.5 * decode_bbox_height</span><br><span class="line">    decode_bbox_xmax = decode_bbox_center_x + 0.5 * decode_bbox_width</span><br><span class="line">    decode_bbox_ymax = decode_bbox_center_y + 0.5 * decode_bbox_height</span><br><span class="line"></span><br><span class="line">    # 真实框的左上角与右下角进行堆叠</span><br><span class="line">    decode_bbox = np.concatenate((decode_bbox_xmin[:, np.newaxis], decode_bbox_ymin[:, np.newaxis], decode_bbox_xmax[:, np.newaxis], decode_bbox_ymax[:, np.newaxis]), axis=-1)</span><br><span class="line">    # 防止超出0与1</span><br><span class="line">    decode_bbox = np.minimum(np.maximum(decode_bbox, 0.0), 1.0)</span><br><span class="line">    return decode_bbox</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 将候选框进行非极大值抑制，获得最终的预测框</span><br><span class="line">def detection_out(pred):</span><br><span class="line">    # 回归网络预测结果</span><br><span class="line">    mbox_loc = pred[:, :4]</span><br><span class="line">    # 分类网络预测结果</span><br><span class="line">    mbox_conf = pred[:, 4:]</span><br><span class="line">    results = []</span><br><span class="line">    # 对每一个图像进行处理</span><br><span class="line">    decode_bbox = decoder(mbox_loc)</span><br><span class="line">    for c in range(1, num_class):</span><br><span class="line">        c_confs = mbox_conf[:, c]</span><br><span class="line">        c_confs_mask = c_confs &gt; confidence_threshold</span><br><span class="line">        if len(c_confs[c_confs_mask]) &gt; 0:</span><br><span class="line">            # 取出得分高于confidence_threshold的框</span><br><span class="line">            boxes_to_process = decode_bbox[c_confs_mask]</span><br><span class="line">            confs_to_process = c_confs[c_confs_mask]</span><br><span class="line">            # 进行iou的非极大抑制</span><br><span class="line">            idx = tf.image.non_max_suppression(boxes_to_process, confs_to_process, max_output_size=keep_top_k, iou_threshold=nms_thresh)</span><br><span class="line">            idx = idx.numpy()</span><br><span class="line">            # 取出在非极大抑制中效果较好的内容</span><br><span class="line">            box = boxes_to_process[idx]</span><br><span class="line">            confs = confs_to_process[idx][:, np.newaxis]</span><br><span class="line">            # 将label、置信度、框的位置进行堆叠。</span><br><span class="line">            labels = c * np.ones((len(idx), 1))</span><br><span class="line">            c_pred = np.concatenate((labels, confs, box), axis=1)</span><br><span class="line">            # 添加进result里</span><br><span class="line">            results.extend(c_pred)</span><br><span class="line">    if len(results) &gt; 0:</span><br><span class="line">        # 按照置信度进行排序</span><br><span class="line">        results = np.array(results)</span><br><span class="line">        arg = np.argsort(results[:, 1])[::-1][:keep_top_k]</span><br><span class="line">        results = results[arg]</span><br><span class="line">    return results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 将图像进行预测并画框</span><br><span class="line">def detect_image(filename):</span><br><span class="line"></span><br><span class="line">    test_img = cv.imread(filename)</span><br><span class="line">    preds = tf.squeeze(model.predict(tf.constant([test_img / 127.5 - 1])), axis=0).numpy()</span><br><span class="line"></span><br><span class="line">    # 将预测结果进行解码</span><br><span class="line">    results = detection_out(preds)</span><br><span class="line"></span><br><span class="line">    if len(results) &lt;= 0:</span><br><span class="line">        return test_img</span><br><span class="line">    print(filename)</span><br><span class="line">    # 筛选出其中得分高于confidence的框</span><br><span class="line">    det_label = results[:, 0]</span><br><span class="line">    det_conf = results[:, 1]</span><br><span class="line">    det_xmin, det_ymin, det_xmax, det_ymax = results[:, 2], results[:, 3], results[:, 4], results[:, 5]</span><br><span class="line">    indices = [index for index, conf in enumerate(det_conf) if conf &gt;= confidence_threshold]</span><br><span class="line">    top_conf = det_conf[indices]</span><br><span class="line">    top_label_indices = det_label[indices].tolist()</span><br><span class="line">    top_xmin = np.expand_dims(det_xmin[indices], -1) * img_size[1]</span><br><span class="line">    top_ymin = np.expand_dims(det_ymin[indices], -1) * img_size[0]</span><br><span class="line">    top_xmax = np.expand_dims(det_xmax[indices], -1) * img_size[1]</span><br><span class="line">    top_ymax = np.expand_dims(det_ymax[indices], -1) * img_size[0]</span><br><span class="line">    boxes = np.concatenate([top_xmin, top_ymin, top_xmax, top_ymax], axis=-1)</span><br><span class="line"></span><br><span class="line">    font = cv.FONT_HERSHEY_SIMPLEX</span><br><span class="line"></span><br><span class="line">    for i, c in enumerate(top_label_indices):</span><br><span class="line">        cls = int(c) - 1</span><br><span class="line">        predicted_class = classes[cls]</span><br><span class="line">        score = top_conf[i]</span><br><span class="line"></span><br><span class="line">        left, top, right, bottom = boxes[i]</span><br><span class="line">        left = left - expand</span><br><span class="line">        top = top - expand</span><br><span class="line">        right = right + expand</span><br><span class="line">        bottom = bottom + expand</span><br><span class="line"></span><br><span class="line">        left = max(0, np.floor(left + 0.5).astype('int32'))</span><br><span class="line">        top = max(0, np.floor(top + 0.5).astype('int32'))</span><br><span class="line">        right = min(img_size[1], np.floor(right + 0.5).astype('int32'))</span><br><span class="line">        bottom = min(img_size[0], np.floor(bottom + 0.5).astype('int32'))</span><br><span class="line"></span><br><span class="line">        # 画框</span><br><span class="line">        label = '{} {:.2f}'.format(predicted_class, score)</span><br><span class="line"></span><br><span class="line">        cv.rectangle(test_img, (left, top), (right, bottom), colors[cls], 1)</span><br><span class="line">        cv.putText(test_img, label, (left, top - int(label_size * 10)), font, label_size, colors[cls], 1)</span><br><span class="line">    return test_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # 包括背景的类别数目</span><br><span class="line">    num_class = 4</span><br><span class="line">    train_data = list(range(800))</span><br><span class="line">    validation_data = list(range(800, 900))</span><br><span class="line">    test_data = range(900, 1000)</span><br><span class="line">    epochs = 100</span><br><span class="line">    batch_size = 8</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    classes = ["circle", "triangle", "square"]</span><br><span class="line">    # 每个特征图上每个像素先验框的个数</span><br><span class="line">    prior = [4, 4, 4, 4, 4]</span><br><span class="line">    # 特征图的大小</span><br><span class="line">    feature_map = [32, 16, 7, 3, 1]</span><br><span class="line">    # 特征图上anchor的最小尺寸</span><br><span class="line">    min_size = [4, 8, 16, 32, 64]</span><br><span class="line">    # 特征图上anchor的最大尺寸</span><br><span class="line">    max_size = [8, 16, 32, 64, 80]</span><br><span class="line">    # anchor的长宽比</span><br><span class="line">    ratios = [[2], [2], [2], [2], [2]]</span><br><span class="line">    # 先验框的个数</span><br><span class="line">    num_prior = sum([prior[x] * feature_map[x] ** 2 for x in range(len(prior))])</span><br><span class="line">    # 先验框与预测框的解码方差</span><br><span class="line">    variances = [0.1, 0.1, 0.2, 0.2]</span><br><span class="line">    # 获取所有先验框</span><br><span class="line">    prior_center_wh = []</span><br><span class="line">    prior_lt_rb = []</span><br><span class="line">    for i in range(len(prior)):</span><br><span class="line">        c_wh, tl_br = get_prior(i + 1)</span><br><span class="line">        prior_center_wh.append(c_wh)</span><br><span class="line">        prior_lt_rb.append(tl_br)</span><br><span class="line">    prior_center_wh = np.vstack(prior_center_wh)</span><br><span class="line">    prior_lt_rb = np.vstack(prior_lt_rb)</span><br><span class="line"></span><br><span class="line">    # IOU超过阈值的视为正样本</span><br><span class="line">    overlap_threshold = 0.5</span><br><span class="line">    # 负样本与正样本的比例</span><br><span class="line">    neg_pos_ratio = 3</span><br><span class="line">    # 回归损失函数的比例</span><br><span class="line">    alpha = 1</span><br><span class="line">    # 如果图像中不存在正样本，则指定最低负样本个数</span><br><span class="line">    negatives_for_hard = 10</span><br><span class="line">    # 编码函数</span><br><span class="line">    f_encode = encoder</span><br><span class="line">    # 画框设置不同的颜色</span><br><span class="line">    hsv_tuples = [(x / (num_class - 1), 1., 1.) for x in range(num_class - 1)]</span><br><span class="line">    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))</span><br><span class="line">    colors = list(map(lambda x: (int(x[1] * 255), int(x[2] * 255), int(x[0] * 255)), colors))</span><br><span class="line">    # 设置图像检测最多的框数目</span><br><span class="line">    keep_top_k = 5</span><br><span class="line">    # 设置检测置信度，大于该值认为有物体</span><br><span class="line">    confidence_threshold = 0.5</span><br><span class="line">    # 非极大值抑制阈值，重叠度不得大于该值</span><br><span class="line">    nms_thresh = 0.5</span><br><span class="line">    # 预测框不要紧贴物体，向外扩展像素大小</span><br><span class="line">    expand = 5</span><br><span class="line">    # 标签大小</span><br><span class="line">    label_size = 0.3</span><br><span class="line"></span><br><span class="line">    imgs_path = r'.\shape\train_imgs'</span><br><span class="line">    annotations_path = r'.\shape\annotations'</span><br><span class="line">    test_path = r'.\shape\test_imgs'</span><br><span class="line">    save_path = r'.\SSD_test_result'</span><br><span class="line">    weight_path = r'.\SSD_weight'</span><br><span class="line">    bbox_path = r'.\shape\bbox.txt'</span><br><span class="line"></span><br><span class="line">    # 将xml存储的bbox转换为bbox.txt文件，内容为file_path + bbox + class_id</span><br><span class="line">    if 'bbox.txt' not in os.listdir(r'.\shape'):</span><br><span class="line">        get_bbox(train_data + validation_data, bbox_path, annotations_path)</span><br><span class="line"></span><br><span class="line">    with open(bbox_path, 'r') as f:</span><br><span class="line">        bounding_info = f.readlines()</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(save_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(save_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(weight_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(weight_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    model = small_ssd(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(batch_size, img_size[0], img_size[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizor = keras.optimizers.Adam(lr=1e-4)</span><br><span class="line">    lossor = Loss().compute_loss</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizor, loss=lossor)</span><br><span class="line"></span><br><span class="line">    # 保存的方式，3世代保存一次</span><br><span class="line">    checkpoint_period = keras.callbacks.ModelCheckpoint(</span><br><span class="line">        weight_path + '\\' + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        save_weights_only=True,</span><br><span class="line">        save_best_only=True,</span><br><span class="line">        period=3</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 学习率下降的方式，val_loss3次不下降就下降学习率继续训练</span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        factor=0.5,</span><br><span class="line">        patience=3,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        min_delta=0,</span><br><span class="line">        patience=10,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model.fit_generator(generate_arrays_from_file(train_data, batch_size),</span><br><span class="line">                        steps_per_epoch=max(1, len(train_data) // batch_size),</span><br><span class="line">                        validation_data=generate_arrays_from_file(validation_data, batch_size),</span><br><span class="line">                        validation_steps=max(1, len(validation_data) // batch_size),</span><br><span class="line">                        epochs=epochs,</span><br><span class="line">                        callbacks=[checkpoint_period, reduce_lr, early_stopping])</span><br><span class="line"></span><br><span class="line">    for name in test_data:</span><br><span class="line">        test_img_path = test_path + '\\' + str(name) + '.jpg'</span><br><span class="line">        save_img_path = save_path + '\\' + str(name) + '.png'</span><br><span class="line">        test_img = detect_image(test_img_path)</span><br><span class="line">        cv.imwrite(save_img_path, test_img)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Object_detection/SSD_T.png" alt="SSD"></p>
<h1 id="SSD小结"><a href="#SSD小结" class="headerlink" title="SSD小结"></a><font size="5" color="red">SSD小结</font></h1><p>  SSD是一种简单的目标检测网络，从上图可以看出SSD模型的参数量只有26M，由于其<strong>结构简单，效果稳定</strong>，因此很多场合仍然使用SSD作为目标检测算法。SSD作为一步法目标检测的元老级模型，是小伙伴们需要掌握的一个模型。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>目标检测网络</category>
      </categories>
  </entry>
  <entry>
    <title>Convolution黑科技</title>
    <url>/2020/05/04/deep%20learning%20convolution/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Convolution</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Convolution</strong>:在这个博客中，我们谈论的卷积并不是实际意义中的卷积，而是神经网络中的卷积。小伙伴们可能会有疑问，两个卷积有区别吗？学过信号处理或者图像处理的小伙伴们应该很熟悉，卷积是要<strong>首先将核翻转180°</strong>，然后再应用于信号或者图像上，而<strong>相关则不需要翻转</strong>。因此<strong>神经网络中的卷积实际上是一种相关操作</strong>。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/convolution.png" alt="convolution"></p>
<h1 id="Receptive-Field感受野"><a href="#Receptive-Field感受野" class="headerlink" title="Receptive Field感受野"></a><font size="5" color="red">Receptive Field感受野</font></h1><p>  <font size="3">在二维卷积中不得不提到一个重要名词：<strong>感受野</strong>，在这里我只是作为科普，说一说<strong>感受野和二维卷积的关系</strong>，不从生命科学的角度具体描述感受野和神经元的关系，感兴趣的小伙伴可以去网上搜索。</font><br>  <font size="3">想象一下，当我们看一场足球比赛，或者看一场精彩的电影时，我们的注意力集中于某个点，比如足球的运动轨迹，电影中任务的细节描写。我们的眼睛只是关注一个像素吗？答案是否定的，我们<strong>关注的是周围了一部分区域</strong>，这个<strong>区域可以称之为感受野</strong>。当我们看这个人的眼神细节时，我们还会注意到面部的动作，而很难注意到耳朵或者其他部位的变化。而卷积操作也是相同，对于某个中心点求卷积，只是计算这个点周围的值，而不去计算距离很远的像素点。意在<strong>让计算机根据人类的视觉行为做出类似的判断</strong>。</font><br><img src="/images/deep_learning/field.png" alt="field"></p>
<h1 id="CNN卷积神经网络"><a href="#CNN卷积神经网络" class="headerlink" title="CNN卷积神经网络"></a><font size="5" color="red">CNN卷积神经网络</font></h1><p>  <font size="3">CNN是目前深度学习领域中非常具有代表性的神经网络之一，在<strong>图像分析和处理领域</strong>取得了众多突破性的进展，包括<strong>图像识别</strong>，<strong>语义分割</strong>，<strong>目标检测</strong>等等。</font><br>  <font size="3">关于卷积的计算过程，小伙伴们应该都比较了解，通过最上面的图也可以直观的看出。随着CNN的发展，尤其是2012年AlexNet网络在ImageNet上大放异彩以后，卷积神经网络持续火爆。渐渐的一些黑科技卷积也被陆续发现。这个博客目的是向大家介绍各种卷积之间的差异。</font><br><img src="/images/deep_learning/cnn.png" alt="cnn"></p>
<h1 id="Depthwise-Convolution"><a href="#Depthwise-Convolution" class="headerlink" title="Depthwise Convolution"></a><font size="5" color="red">Depthwise Convolution</font></h1><p><img src="/images/deep_learning/depthwise.png" alt="depthwise"><br>  <font size="3"><strong>Depthwise Convolution(深度卷积)</strong>：在<strong>每一个通道上单独进行卷积</strong></font><br>  <font size="3">参数<strong>depth_multiplier默认为1</strong>，代表每个通道数进行一次单独卷积，<strong>输出的通道数和输入通道数相等</strong>，设置<strong>depth_multiplier=n</strong>，则代表每个通道数进行n次单独卷积，<strong>输出通道数是输入通道数的n倍</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，主要用于<strong>轻量级深度学习网络</strong>，在<strong>MobileNet，EfficientNet，ShuffleNet</strong>网络中都有大量使用。如果一个8x8x1024的特征图，经过5x5的卷积核后变为8x8x1024的图像，经过普通卷积的参数量为1024x(1024x5x5+1)=26215424，而深度卷积参数量为1024x(1x5x5+1)=26624，参数量缩小了约1024倍。</font></p>
<h1 id="Pointwise-Convolution"><a href="#Pointwise-Convolution" class="headerlink" title="Pointwise Convolution"></a><font size="5" color="red">Pointwise Convolution</font></h1><p><img src="/images/deep_learning/pointwise.png" alt="pointwise"><br>  <font size="3"><strong>Pointwise Convolution(点卷积)</strong>：很好理解，卷积核的大小为1x1，小伙伴们可能产生疑问？1x1卷积有什么作用呢？</font></p>
<ol>
<li><strong>改变通道数</strong>，可以实现<strong>升维</strong>或者<strong>降维</strong>，在<strong>ResNet，MobileNet</strong>网络中有重要作用。</li>
<li><strong>增加非线性关系</strong>，在保持特征图尺度的前提下，可以<strong>利用非线性激活函数增加网络深度</strong>。</li>
<li><strong>实现跨通道信息交互</strong>，往往和Depthwise Convolution结合使用。</li>
</ol>
<h1 id="Separable-Convolution"><a href="#Separable-Convolution" class="headerlink" title="Separable Convolution"></a><font size="5" color="red">Separable Convolution</font></h1><p><img src="/images/Feature_extraction/Xception_D.png" alt="Xception"><br>  <font size="3"><strong>Separable Convolution(深度可分离卷积)</strong>：是上面两个卷积合二为一的卷积操作。</font><br>  <font size="3"><strong>第一步：DepthwiseConv，对每一个通道进行卷积</strong></font><br>  <font size="3"><strong>第二步：PointwiseConv，对第一步得到的结果进行1x1卷积，实现通道融合</strong></font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，并且可以<strong>调整为任意合适的通道数</strong>，在<strong>Xception，MobileNet，EfficientNet，ShuffleNet</strong>网络中有大量使用。第一步的<strong>目的是减少参数量</strong>，第二步是<strong>调整通道数</strong>，因此将两个卷积操作结合，组成深度可分离卷积。</font></p>
<h1 id="Spatial-Separable-Convolution"><a href="#Spatial-Separable-Convolution" class="headerlink" title="Spatial Separable Convolution"></a><font size="5" color="red">Spatial Separable Convolution</font></h1><p><img src="/images/deep_learning/spatial.png" alt="spatial"><br>  <font size="3"><strong>Spatial Separable Convolution(空间可分离卷积)</strong>：将3x3的卷积分解为3x1的卷积核1x3的卷积，将7x7的卷积分解为7x1的卷积核1x7的卷积.。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，在<strong>Inception类型</strong>的网络中有大量使用。如果一个64x64x256的特征图，经过7x7的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x7x7+1)=3211520，而空间可分离卷积参数量为2x256x(256x7x1+1)=918016，参数量缩小了约3.5倍。</font></p>
<h1 id="Atrous-Convolution"><a href="#Atrous-Convolution" class="headerlink" title="Atrous Convolution"></a><font size="5" color="red">Atrous Convolution</font></h1><p><img src="/images/Semantic_segmentation/PSPNet_D.png" alt="PSPNet"><br>  <font size="3"><strong>Atrous Convolution(空洞卷积)</strong>：又称<strong>膨胀卷积(Dilated Convolution)</strong>，在卷积层引入了一个<strong>膨胀率(dilation rate)</strong>参数，定义了卷积核的间隔数量，普通卷积的卷积核dilation rate=1。</font><br>  <font size="3">优点：<strong>扩大感受野</strong>，相邻的像素点可能存在大量冗余信息，扩大感受野可能会获取多尺度信息，这在视觉任务上非常重要，且<strong>不需要引入额外参数</strong>，如果增加分辨率或者采用大尺寸的卷积核则会大大增加模型的参数量，在<strong>PSPNet，DeepLab-V3+</strong>网络中有大量使用。</font><br>  <font size="3">缺点：由于空洞卷积的<strong>计算方式类似于棋盘格式，因此可能产生棋盘格效应，可以参考<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">棋盘格可视化</a>。如果膨胀率太大卷积结果之间没有相关性，可能会丢失局部信息。</strong></font></p>
<h1 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a><font size="5" color="red">Group Convolution</font></h1><p><img src="/images/Feature_extraction/ShuffleNet_V2_G.png" alt="ShuffleNet_V2"><br>  <font size="3"><strong>Group Convolution(分组卷积)</strong>：<strong>传统卷积是采用一种卷积全连接的思想</strong>，特征图中的每一个像素点都结合了图像中所有通道的信息。而分组卷积特征图像<strong>每一个像素点只利用到一部分原始图像的通道</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，在<strong>ResNeXt，ShuffleNet-V2</strong>网络中有大量使用。如果一个64x64x256的图像，经过5x5的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x5x5+1)=1638656，而分成32组的分组卷积的参数量为256x(8*5x5+1)=51456，参数量缩小了约32倍，当组数变成通道数时，则类似于Depthwise Convolution深度卷积</font></p>
<h1 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a><font size="5" color="red">Deconvolution</font></h1><p><img src="/images/deep_learning/deconvolution.png" alt="deconvolution"><br>  <font size="3"><strong>Deconvolution(反卷积)</strong>：<strong>本质是卷积</strong>，注意<strong>反卷积并不能从卷积的结果返回到卷积前的数据，只能返回到卷积前的尺寸</strong>。卷积通过设置kernel_size卷积核大小，strides步长和padding填充方式可以将图像的分辨率降低，相反的反卷积可以通过设置kernel_size卷积核大小，strides步长和padding填充方式<strong>先对数据进行填充，然后再进行卷积操作</strong>，可以将图像的分辨率增加。<strong>这个方法不推荐经常使用，因为存在大量参数，而且可能会存在棋盘格效应，可以参考<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">棋盘格可视化</a></strong>。</font></p>
<h1 id="Squeeze-and-Excitation"><a href="#Squeeze-and-Excitation" class="headerlink" title="Squeeze-and-Excitation"></a><font size="5" color="red">Squeeze-and-Excitation</font></h1><p><img src="/images/Feature_extraction/SENet_S.png" alt="SENet"><br>  <font size="3"><strong>Squeeze-and-Excitation</strong>：又称为<strong>特征重标定卷积</strong>，或者<strong>注意力机制</strong>。具体来说，就是通过<strong>学习的方式来自动获取到每个特征通道的重要程度</strong>，然后依照这个重要程度去<strong>提升有用的特征并抑制对当前任务用处不大的特征</strong>,在<strong>SENet，MobileNet-V3，EfficientNet</strong>网络中有大量使用。</font><br>  <font size="3">首先是 <strong>Squeeze操作</strong>，先<strong>进行全局池化，具有全局的感受野</strong>，并且输出的维度和输入的特征通道数相匹配，它表征着在特征通道上响应的全局分布。</font><br>  <font size="3">然后是<strong>Excitation操作</strong>，<strong>通过全连接层为每个特征通道生成权重，建立通道间的相关性</strong>，<strong>输出的权重看做是进过特征选择后的每个特征通道的重要性</strong>，然后通过<strong>乘法逐通道加权到先前的特征上</strong>，完成在通道维度上的对原始特征的重标定。</font></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  卷积操作是CNN的核心，因此在学习时常常会和它们打交道，因此系统的学习各种卷积的优缺点以及利用场景，对今后的学习工作是非常有帮助的，希望小伙伴们都可以学习和掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>寻找最远的关系(某大厂手撕面试题)</title>
    <url>/2020/05/03/program%20Interview1/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/interview1.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目思路很清晰，首先想到两种方法，DFS和BFS，但是要注意如何去解决关系中出现环的情况。</p>
<a id="more"></a>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>深度优先搜索，就是从那个人开始，一直往下搜索，如果找不到可以联系的人，则记录当前的关系并和已知最远关系进行比较，如果大于最远关系，则赋值给最远关系，并回溯。如果在搜索的过程中发现下一个人出现在已经搜索到的人之中，则回溯，防止出现死循环。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dfs(current_people, current_relationship):</span><br><span class="line">    global result</span><br><span class="line"></span><br><span class="line">    for neighbor in range(1, n + 1):</span><br><span class="line">        if relationship[current_people][neighbor] == 1 and str(neighbor) not in current_relationship:</span><br><span class="line">            dfs(neighbor, current_relationship + str(neighbor))</span><br><span class="line"></span><br><span class="line">    if len(current_relationship) &gt; len(result):</span><br><span class="line">        result = current_relationship</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n, m = [int(x) for x in line.strip().split()]</span><br><span class="line">    relationship = [[0 for _ in range(n + 1)] for _ in range(n + 1)]</span><br><span class="line">    for i in range(m):</span><br><span class="line">        a, b = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        relationship[a][b] = 1</span><br><span class="line">        relationship[b][a] = 1</span><br><span class="line">    p = int(sys.stdin.readline().strip())</span><br><span class="line">    result = ''</span><br><span class="line">    dfs(p, str(p))</span><br><span class="line">    print(result)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>广度优先搜索，就是从那个人开始，将他可以联系到的所有人都记录下来，并称之为朋友，然后再寻找他朋友的朋友，即将和他朋友的朋友都记录下来，然后再寻找他朋友的朋友的朋友。如果再搜索时发现某个朋友已经出现在寻找的路径之中，则不继续搜索这个路径，每次迭代后关系就会增加一轮，直到最远的关系被找到为止。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n, m = [int(x) for x in line.strip().split()]</span><br><span class="line">    relationship = [[0 for _ in range(n + 1)] for _ in range(n + 1)]</span><br><span class="line">    for i in range(m):</span><br><span class="line">        a, b = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        relationship[a][b] = 1</span><br><span class="line">        relationship[b][a] = 1</span><br><span class="line">    p = int(sys.stdin.readline().strip())</span><br><span class="line">    result = ''</span><br><span class="line">    queue = [[p, str(p)]]</span><br><span class="line">    while queue:</span><br><span class="line">        result = queue[-1]</span><br><span class="line">        current_people, current_relationship = queue.pop(0)</span><br><span class="line">        for neighbor in range(1, n + 1):</span><br><span class="line">            if relationship[current_people][neighbor] == 1 and str(neighbor) not in current_relationship:</span><br><span class="line">                queue.append([neighbor, current_relationship + str(neighbor)])</span><br><span class="line">    print(result[-1])</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  BFS和DFS是两种重要的路径搜索方法，在绝大多数情况下，两种方法可以相互转换，小伙伴们一定要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
      </categories>
  </entry>
  <entry>
    <title>Activation黑科技</title>
    <url>/2020/05/02/deep%20learning%20activation/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Activation</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Activation(激活函数)</strong>:在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数。如果不用激活函数每一层节点的输入都是上层输出的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这样会导致网络的逼近能力大大降低，所以需要引入非线性函数作为激活函数，这样可以提高神经网络的表达能力，可以逼近任意函数，不再是输入的线性组合。<br><a id="more"></a></p>
<p><img src="/images/deep_learning/activation.png" alt="activation"></p>
<h1 id="Sigmoid激活函数"><a href="#Sigmoid激活函数" class="headerlink" title="Sigmoid激活函数"></a><font size="5" color="red">Sigmoid激活函数</font></h1><script type="math/tex; mode=display">f(z) = \frac{1}{1+e^{-z}}</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.sigmoid(x)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/sigmoid.png" alt="sigmoid"></p>
<h1 id="tanh激活函数"><a href="#tanh激活函数" class="headerlink" title="tanh激活函数"></a><font size="5" color="red">tanh激活函数</font></h1><script type="math/tex; mode=display">f(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.tanh(x)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/tanh.png" alt="tanh"></p>
<h1 id="ReLU激活函数"><a href="#ReLU激活函数" class="headerlink" title="ReLU激活函数"></a><font size="5" color="red">ReLU激活函数</font></h1><script type="math/tex; mode=display">f(x) = \max(0, x)</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.relu(x)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/relu.png" alt="relu"></p>
<h1 id="Leaky-ReLU激活函数"><a href="#Leaky-ReLU激活函数" class="headerlink" title="Leaky-ReLU激活函数"></a><font size="5" color="red">Leaky-ReLU激活函数</font></h1><script type="math/tex; mode=display">f(x) = \max(\alpha x, x), \alpha=0.01</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.relu(x, alpha=0.01)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/leaky_relu.png" alt="leaky_relu"></p>
<h1 id="PReLU激活函数"><a href="#PReLU激活函数" class="headerlink" title="PReLU激活函数"></a><font size="5" color="red">PReLU激活函数</font></h1><script type="math/tex; mode=display">f(x) = \max(\alpha x, x)</script><p><strong>PReLU和Leaky-ReLU的表达式是相同的</strong>，区别在于<strong>Leaky-ReLU中的<script type="math/tex">\alpha</script>是预先设定的</strong>，而<strong>PReLU中的参数是根据数据，通过网络自身学习的</strong>。TensorFlow2.0中直接提供了PReLU层<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">keras.layers.layers.PReLU()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/leaky_relu.png" alt="prelu"></p>
<h1 id="ReLU6激活函数"><a href="#ReLU6激活函数" class="headerlink" title="ReLU6激活函数"></a><font size="5" color="red">ReLU6激活函数</font></h1><script type="math/tex; mode=display">f(x) = \min(6, \max(0, x))</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.relu(x, max_value=6)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/relu6.png" alt="relu6"></p>
<h1 id="ELU激活函数"><a href="#ELU激活函数" class="headerlink" title="ELU激活函数"></a><font size="5" color="red">ELU激活函数</font></h1><script type="math/tex; mode=display">f(x) = \begin{cases}  x &  x > 0 \\\\ \alpha(e^{x} - 1) & x \le 0 \end{cases}, \alpha=1</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.elu(x, alpha=1)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/elu.png" alt="elu"></p>
<h1 id="SELU激活函数"><a href="#SELU激活函数" class="headerlink" title="SELU激活函数"></a><font size="5" color="red">SELU激活函数</font></h1><script type="math/tex; mode=display">f(x) = \lambda \begin{cases}  x &  x > 0 \\\\ \alpha(e^{x} - 1) & x \le 0 \end{cases}</script><script type="math/tex; mode=display">\begin{cases} \lambda=1.0507009873554804934193349852946 \\\\ \alpha=1.6732632423543772848170429916717 \end{cases}</script><p>在TensorFlow2.0中的实现，在SELU函数中，经过大量论证后，<strong>两个参数都为定值，因此不需要设置参数</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.selu(x)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/selu.png" alt="selu"></p>
<h1 id="Mish激活函数"><a href="#Mish激活函数" class="headerlink" title="Mish激活函数"></a><font size="5" color="red">Mish激活函数</font></h1><script type="math/tex; mode=display">f(x) = x * tanh(\ln{(1+e^x)})</script><p>综合了tanh和Softplus的优点，类似于ReLU函数，但是对负值有轻微的梯度，其平滑的特点可能允许更好的信息深入神经网络，几乎在所有的问题上都有很好的表现，在TensorFlow2.0中的实现。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = x * keras.activations.tanh(keras.activations.softplus(x))</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/mish.png" alt="mish"></p>
<h1 id="Softplus激活函数"><a href="#Softplus激活函数" class="headerlink" title="Softplus激活函数"></a><font size="5" color="red">Softplus激活函数</font></h1><script type="math/tex; mode=display">f(x) = \ln{(1+e^x)}</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = keras.activations.softplus(x)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/softplus.png" alt="softplus"></p>
<h1 id="Swish激活函数"><a href="#Swish激活函数" class="headerlink" title="Swish激活函数"></a><font size="5" color="red">Swish激活函数</font></h1><script type="math/tex; mode=display">f(x) = x * sigmoid(x)</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = x * keras.activations.sigmoid(x)</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/swish.png" alt="swish"></p>
<h1 id="H-Swish激活函数"><a href="#H-Swish激活函数" class="headerlink" title="H-Swish激活函数"></a><font size="5" color="red">H-Swish激活函数</font></h1><script type="math/tex; mode=display">f(x) = x * \frac{ReLU6(x + 3)}{6}</script><p>在TensorFlow2.0中的实现<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot(x, y):</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">x = np.linspace(-10, 10, 201)</span><br><span class="line">y = x * keras.activations.relu(x + 3, max_value=6) / 6</span><br><span class="line">plot(x, y)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/h_swish.png" alt="h_swish"></p>
<h1 id="Softmax激活函数"><a href="#Softmax激活函数" class="headerlink" title="Softmax激活函数"></a><font size="5" color="red">Softmax激活函数</font></h1><script type="math/tex; mode=display">\sigma_{i}(z) = \frac{e^{z_i}}{\sum_{j=1}^{m}{e^{z_j}}}</script><p>在TensorFlow2.0中的实现，和其他的激活函数不同，<strong>Softmax激活函数需要指定一个维度，而且使用时也必须先转化为大于一维的tensor形式，numpy格式的数据无法直接使用</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = tf.constant([[10, 1, 1, 1]], tf.float32)</span><br><span class="line">y = keras.activations.softmax(x)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/deep_learning/softmax.png" alt="softmax"></p>
<h1 id="优缺点比较"><a href="#优缺点比较" class="headerlink" title="优缺点比较"></a><font size="5" color="red">优缺点比较</font></h1><p><strong>Sigmoid</strong>函数优点：Sigmoid函数处处连续，处处可导。且<strong>能够控制数值的幅度</strong>，不会产生很大的变化，可以<strong>作为二分类任务的输出</strong>，而ReLU类型的激活函数对大于0的值几乎没有约束。<br><strong>Sigmoid</strong>函数缺点：饱和区的神经元会产生<strong>梯度消失</strong>现象，使得<strong>学习速度大大下降</strong>，并且指数函数计算耗时。<br><strong>tanh</strong>函数优点：tanh函数和Sigmoid类似，但是可以发现<strong>tanh的导数的值域为(0, 1]，而Sigmoid的导数的值域为(0, 0.25]</strong>，因此相当于<strong>延迟了饱和周期</strong>。<br><strong>tanh</strong>函数缺点：tanh函数和Sigmoid类似，也具有<strong>梯度消失</strong>问题，和指数计算耗时问题。<br><strong>ReLU</strong>类函数优点：ReLU类型函数(<strong>ReLU6，Leaky_ReLU，PReLU，SELU，ELU，Mish，Softplus</strong>)会使一部分神经元为0或者非常小，使得网络具有<strong>稀疏性</strong>，<strong>减少了参数的相互依赖关系</strong>，<strong>缓解了过拟合</strong>，而且ReLU函数及其导数的计算非常简单。<br><strong>ReLU</strong>类函数缺点：可能<strong>存在神经元坏死</strong>现象，在x&lt;0的时候，梯度为0，可能会使这个神经元<strong>很难再被激活</strong>，且ReLU函数不能控制参数的幅度，可能会产生<strong>梯度爆炸</strong>现象。<br><strong>Swish</strong>类函数优点：Swish函数是<strong>介于ReLU函数和Sigmoid函数之间的一种平滑函数</strong>，<strong>具有两者的优点</strong>，不会像Sigmoid函数一样产生饱和区，也不会像ReLU函数一样存在坏死神经元。<br><strong>Swish类</strong>函数缺点：Swish函数也<strong>具有两者的缺点</strong>，类似于Sigmoid函数计算耗时，类似于ReLU函数难以控制参数幅度，但整体表现较好。<br><strong>Softmax</strong>函数特点：Softmax函数和其他的激活函数不同，Softmax主要用于<strong>多分类任务</strong>中，如<strong>图像分割</strong>，<strong>目标检测</strong>，需要判断某一个像素或者某一个预测框属于哪一个类别。<strong>Softmax将输入归一化到[0, 1]之间，并且保证和为1</strong>，使人能够联想到概率的条件，也是属于[0, 1]，并且和为1。加上指数的作用是<strong>增加样本之间的差距</strong>，如果输入为90个1和1个10，则直接归一化的结果为90个0.01和1个0.1，如果10是对应的类别，即使已经分类的较好，仍然会使得误差较大。加上指数运算后，归一化的结果为90个0.000122，1个0.989，这样误差就会较小，更加接近于真实的情况。</p>
<h1 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a><font size="5" color="red">激活函数的选择</font></h1><ol>
<li>首先<strong>判断任务类型</strong>，是分类任务，回归任务，还是作为隐藏层非线性单元，如果是<strong>多分类任务则考虑Softmax激活函数</strong>，如果是<strong>二分类任务则考虑Sigmoid，tanh激活函数</strong>，如果是<strong>回归任务则可以考虑不加激活函数，因为激活函数可能会对回归的数据产生限制</strong>，如果是<strong>隐藏层非线性单元则考虑Sigmoid，tanh，ReLU，Swish</strong>等等。</li>
<li>如果是隐藏层非线性单元，<strong>首先尝试ReLU激活函数</strong>，如果<strong>ReLU效果欠佳则考虑ReLU变种激活函数</strong>，ReLU6，Leaky_ReLU，SELU，ELU，Mish，Softplus等等</li>
<li>如果效果不好，<strong>再考虑Swish类函数和Sigmoid，tanh函数</strong>，但是如果<strong>发现梯度消失问题，则避免使用Sigmoid和tanh函数</strong>。</li>
<li>如果都不好用，则<strong>考虑是否网络结构，超参数，损失函数设计出现问题</strong>。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  深度学习工程问题是一类非常复杂的问题，往往需要<strong>网络结构</strong>，<strong>超参数</strong>，<strong>损失函数</strong>，<strong>激活函数相互配合</strong>工作，可能某个结构或者某个参数适合某个激活函数，而另外的结构适合其他激活函数。因此需要小伙伴们在实际的工程任务中慢慢摸索，多多尝试。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>常用技巧</category>
      </categories>
  </entry>
  <entry>
    <title>目标检测数据集</title>
    <url>/2020/04/30/Object%20detection%20Dataset/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Data Set</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>目标检测:</strong>是计算机视觉的<strong>基础任务</strong>，近几年来，目标检测算法取得了很大的突破，主流趋势是两种，一种是<strong>one-stage</strong>算法，以<strong>SSD，YOLO</strong>为代表，另一类是<strong>two-stage</strong>算法，以<strong>Faster R-CNN</strong>为代表。广泛应用于生活之中，包括<strong>人脸检测</strong>，<strong>自动驾驶</strong>等等方面，在近期的疫情之中也发挥了巨大的作用，在火车站，地铁口都应用到了人脸检测方法，检测到人脸后利用红外对体温进行测量，因此能<strong>手动搭建一些目标检测网络</strong>，对今后的学习工作都是非常有帮助的。<br><a id="more"></a></p>
<p><img src="/images/Object_detection/Dataset.png" alt="Dataset"></p>
<h1 id="一步法和两步法的区别"><a href="#一步法和两步法的区别" class="headerlink" title="一步法和两步法的区别"></a><font size="5" color="red">一步法和两步法的区别</font></h1><p>一步法：在原图像上面铺设大量锚点框(anchor)，然后在<strong>特征提取的时候对锚点框进行一次回归和分类</strong>，得到最终的检测结果<br>两步法：在原图像上面铺设大量锚点框(anchor)，然后<strong>先利用一个网络对锚点框进行一次分类和回归(粗筛选)</strong>，得到<strong>建议框</strong>，然后再<strong>对建议框进行一次回归和分类</strong>得到最终的检测结果。<br>优缺点：经过上面的描述，容易看出，一步法的优点是<strong>效率高</strong>，只需要一步即可完成最终检测，没有耗时的第二步，但是缺点也很明显，因为没有粗筛选，导致<strong>正负样本极端不平衡</strong>，因此<strong>检测精度略低于两步法</strong>。两步法虽然<strong>检测速度慢</strong>，但是检测<strong>精度略高于一步法</strong>。随着网络的发展，硬件水平的提高，两类算法都在不断的进步之中，速度和精度都可以取得较好的结果。</p>
<h1 id="数据集以及IOU，NMS介绍"><a href="#数据集以及IOU，NMS介绍" class="headerlink" title="数据集以及IOU，NMS介绍"></a><font size="5" color="red">数据集以及IOU，NMS介绍</font></h1><p><strong>数据集</strong>：为了方便模型调试的方便，我的博客中介绍的数据集是一种简单的Shape数据集，只有1000个训练样本，为了加快训练速度，数据集的大小我也调整为128x128，这个数据集只有三类物体，分别是圆形，三角形和正方形，图像数据为jpg文件，标签数据为xml文件，其中记录了物体出现的左上角和右下角坐标。<br><strong>IOU(Intersection Over Union，交并比)</strong>：用于<strong>评估语义分割算法性能的指标是平均IOU</strong>，交并比也非常好理解，算法的结果与真实物体进行<strong>交运算的结果除以进行并运算的结果</strong>。通过下图可以直观的看出IOU的计算方法。<br><img src="/images/Semantic_segmentation/Dataset_I.png" alt="IOU"><br><strong>NMS(Non-Maximum Suppression，非极大值抑制)</strong>：简单地说，<strong>不是最大的我不要</strong>，在目标检测中，往往图像上存在大量先验框，会导致很多附近的框都会预测出同一个物体，但是我们<strong>只保留最大的一个预测结果</strong>，这就是非极大值抑制。<br>步骤：<br>(1)<strong>从最大概率矩形框F开始</strong>，分别判断A~E与F的IOU是否大于某个设定的阈值，<strong>假设B、D与F的重叠度超过阈值，那么就扔掉B、D</strong>；并<strong>标记第一个矩形框F</strong>，是我们保留下来的。<br>(2)<strong>从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框</strong>。<br>(3)<strong>重复步骤(2)，直到所有的框都被抛弃或者保留</strong>。<br><img src="/images/Object_detection/Dataset_N.png" alt="NMS"></p>
<h1 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a><font size="5" color="red">一些说明</font></h1><ol>
<li>在学习的时候，小伙伴可能会遇到一些代码上的困难，如<strong>tensorflow</strong>，<strong>numpy</strong>，<strong>opencv</strong>的用法，可以查看我的深度学习框架和Python常用库相关文章，里面会有一些简单的介绍，小伙伴们可以进行学习，最好是手动敲一敲，看一看。</li>
<li>因为这个博客是对学习的一些总结和记录，意在和学习者探讨和交流，并且给准备入门的同学一些手把手的教学，因此关于目标检测的算法参数设计，我都是自己尝试的，不是针对于这个数据集最优的参数，大家可以根据自己的实际需要修改网络结构。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
<li>为了让学习者看的方便和清晰，我没有使用多个文件对程序进行封装，因为我在刚开始学习模型的时候，查看GitHub代码，一个模型可能需要好几个文件夹，每个文件夹里面又有很多的代码文件，其中很多文件互相调用。虽然这样的工程项目是非常好管理和运行的，但是给初学者一种丈二和尚摸不着头脑的感觉，对此我深有体会。所以我就使用一个.py文件来封装，因此代码可能会有几百行，但是其中的各个函数和类都有自己的名字，可以保证学习者不会被纸老虎吓住。</li>
<li>在目标检测学习中，我会列举出一些经典的目标检测模型，因为模型太多，并且仍在不断的更新进步之中，所以大家可以联系我，和我进行沟通和交流，或者推荐给我一些优秀的模型。</li>
<li>关于问题的交流，图像的数据，需要的同学可以到主页查看我的QQ或者邮箱，我会非常荣幸的提供力所能及的帮助，小伙伴加好友的时候一定要记得备注，不然我可能会忽视一些粗心的小伙伴。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  目标检测是计算机视觉的<strong>基础任务</strong>，也是非常重要的任务之一，自从深度学习的时代到来，各种神经网络结构百花齐放，很难说出最好的目标检测方法，可能一个方法适用于很多数据，但也<strong>不能说明某一个算法一定优于另一个算法</strong>，我们要做的就是尽可能多的<strong>学习各种各样的深度学习模型</strong>，然后<strong>吸取这些模型成功的原因</strong>，投入到自己的工程应用之中。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>目标检测网络</category>
      </categories>
  </entry>
  <entry>
    <title>DeepLab-V3+</title>
    <url>/2020/04/27/Semantic_segmentation%20DeepLab_V3+/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">DeepLab-V3+</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>DeepLab-V3+</strong>:于<strong>2018年发表在CVPR</strong>上，应用<strong>改进的Xception作为特征提取网络</strong>，并将<strong>深度可分离卷积</strong>与<strong>ASPP(Atrous Spatial Pyramid Pooling，空洞空间卷积池化金字塔)</strong>结合，大量缩小模型参数，被认为是现在<strong>语义分割模型的新高峰</strong>。<a id="more"></a></p>
<p><img src="/images/Semantic_segmentation/DeepLab_V3+.png" alt="DeepLab-V3+"></p>
<h1 id="DeepLab-V3-特点"><a href="#DeepLab-V3-特点" class="headerlink" title="DeepLab-V3+特点"></a><font size="5" color="red">DeepLab-V3+特点</font></h1><p>  <font size="3">改进了Xception，将<strong>Middle Flow从8层变为16层</strong>，加深网络层数，且将<strong>池化层替换为深度可分离卷积层</strong>，并且在<strong>3x3深度可分离卷积层后添加BN层和ReLU层</strong>。</font><br>  <font size="3">使用ASPP结构，其中<strong>设置不同的dilation_rate提取不同尺度的特征</strong>。</font><br>  <font size="3">从<strong>Xception浅层网络中提取出一个分支</strong>，作为浅层特征，和ASPP结构产生的深层特征进行融合</font></p>
<h1 id="空洞卷积-atrous-convolutions-和普通卷积之间的区别"><a href="#空洞卷积-atrous-convolutions-和普通卷积之间的区别" class="headerlink" title="空洞卷积(atrous convolutions)和普通卷积之间的区别"></a><font size="5" color="red">空洞卷积(atrous convolutions)和普通卷积之间的区别</font></h1><p>  <font size="3"><strong>空洞卷积(atrous convolutions)又称膨胀卷积(dilated convolutions)</strong>，在卷积层引入了一个<strong>膨胀率(dilation rate)</strong>参数，定义了卷积核的间隔数量，普通卷积的卷积核dilation rate=1</font><br>  <font size="3">优点：<strong>扩大感受野</strong>，相邻的像素点可能存在大量冗余信息，扩大感受野可能会获取多尺度信息，这在视觉任务上非常重要，且<strong>不需要引入额外参数</strong>，如果增加分辨率或者采用大尺寸的卷积核则会大大增加模型的参数量。</font><br>  <font size="3">缺点：由于空洞卷积的<strong>计算方式类似于棋盘格式，因此可能产生棋盘格效应，可以参考<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">棋盘格可视化</a>。如果膨胀率太大卷积结果之间没有相关性，可能会丢失局部信息。</strong></font><br><img src="/images/Semantic_segmentation/PSPNet_D.png" alt="PSPNet"></p>
<h1 id="DeepLab-V3-图像分析"><a href="#DeepLab-V3-图像分析" class="headerlink" title="DeepLab-V3+图像分析"></a><font size="5" color="red">DeepLab-V3+图像分析</font></h1><p><img src="/images/Semantic_segmentation/DeepLab_V3+_A.png" alt="DeepLab-V3+"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">        super(Conv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters, kernel_size, strides, padding='same', dilation_rate=dilation_rate))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('relu') != -1:</span><br><span class="line">            self.blocks.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Depthwiseconv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">        super(Depthwiseconv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding='same', dilation_rate=dilation_rate))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.ReLU())</span><br><span class="line">        self.blocks.add(Conv_Bn_ReLU(filters, (1, 1), (1, 1), name=name))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, filters, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">    x1 = Depthwiseconv_Bn_ReLU(filters[0], (3, 3), (1, 1), name='{}_depthwiseconv_bn_relu1'.format(name), dilation_rate=dilation_rate)(x)</span><br><span class="line">    x2 = Depthwiseconv_Bn_ReLU(filters[1], (3, 3), (1, 1), name='{}_depthwiseconv_bn_relu2'.format(name), dilation_rate=dilation_rate)(x1)</span><br><span class="line">    x3 = Depthwiseconv_Bn_ReLU(filters[2], (3, 3), strides, name='{}_depthwiseconv_bn3'.format(name), dilation_rate=dilation_rate)(x2)</span><br><span class="line">    if name.find('sum') != -1:</span><br><span class="line">        output = keras.layers.Add(name='{}_add'.format(name))([x3, x])</span><br><span class="line">    elif name.find('none') != -1:</span><br><span class="line">        output = x3</span><br><span class="line">    else:</span><br><span class="line">        short_cut = compose(keras.layers.Conv2D(filters[-1], (1, 1), strides=strides, name='{}_shortcut_conv'.format(name)),</span><br><span class="line">                            keras.layers.BatchNormalization(name='{}_shortcut_bn'.format(name)))(x)</span><br><span class="line">        output = keras.layers.Add(name='{}_add'.format(name))([x3, short_cut])</span><br><span class="line">    output = keras.layers.ReLU(name='{}_relu'.format(name))(output)</span><br><span class="line">    if name.find('skip') != -1:</span><br><span class="line">        output = output, x1</span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def aspp(x, filters, dilation_rate, name):</span><br><span class="line">    x1 = compose(keras.layers.GlobalAveragePooling2D(name='{}_part1_globalaveragepool'.format(name)),</span><br><span class="line">                 keras.layers.Reshape((1, 1, x.shape[-1]), name='{}_part1_reshape'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(filters, (1, 1), (1, 1), name='{}_part1_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    x1 = tf.image.resize(x1, (x.shape[1], x.shape[2]), name='{}_part1_reshape'.format(name))</span><br><span class="line">    x2 = Conv_Bn_ReLU(filters, (1, 1), (1, 1), name='{}_part2_conv_bn_relu'.format(name))(x)</span><br><span class="line">    x3 = Depthwiseconv_Bn_ReLU(filters, (3, 3), (1, 1), name='{}_part3_depthwiseconv_bn_relu'.format(name), dilation_rate=dilation_rate[0])(x)</span><br><span class="line">    x4 = Depthwiseconv_Bn_ReLU(filters, (3, 3), (1, 1), name='{}_part4_depthwiseconv_bn_relu'.format(name), dilation_rate=dilation_rate[1])(x)</span><br><span class="line">    x5 = Depthwiseconv_Bn_ReLU(filters, (3, 3), (1, 1), name='{}_part5_depthwiseconv_bn_relu'.format(name), dilation_rate=dilation_rate[2])(x)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x1, x2, x3, x4, x5])</span><br><span class="line"></span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def deeplab_v3_plus(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(32, (3, 3), (2, 2), name='conv_bn_relu1'),</span><br><span class="line">                Conv_Bn_ReLU(64, (3, 3), (1, 1), name='conv_bn_relu2'))(x)</span><br><span class="line"></span><br><span class="line">    x = block(x, [128, 128, 128], (2, 2), name='entryflow1_conv')</span><br><span class="line">    x, skip = block(x, [256, 256, 256], (2, 2), name='entryflow2_skip_conv')</span><br><span class="line">    x = block(x, [728, 728, 728], (2, 2), name='entryflow3_conv')</span><br><span class="line"></span><br><span class="line">    for i in range(16):</span><br><span class="line">        x = block(x, [728, 728, 728], (1, 1), name='middleflow{}_sum'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    x = block(x, [728, 1024, 1024], (1, 1), name='exitflow1_conv')</span><br><span class="line">    x = block(x, [1536, 1536, 2048], (1, 1), name='exitflow2_none', dilation_rate=(2, 2))</span><br><span class="line"></span><br><span class="line">    x = aspp(x, 256, [6, 12, 18], name='aspp')</span><br><span class="line">    x = compose(Conv_Bn_ReLU(256, (1, 1), (1, 1), name='conv_bn_relu3'),</span><br><span class="line">                keras.layers.Dropout(0.1, name='dropout'))(x)</span><br><span class="line">    x = tf.image.resize(x, (input_shape[0] // 4, input_shape[1] // 4), name='resize1')</span><br><span class="line">    skip = Conv_Bn_ReLU(48, (1, 1), (1, 1), name='skip_conv_bn_relu')(skip)</span><br><span class="line">    concatenate = keras.layers.Concatenate(name='concatenate')([x, skip])</span><br><span class="line"></span><br><span class="line">    output = compose(Depthwiseconv_Bn_ReLU(256, (3, 3), (1, 1), name='depthwiseconv_bn_relu4'),</span><br><span class="line">                     Depthwiseconv_Bn_ReLU(256, (3, 3), (1, 1), name='depthwiseconv_bn_relu5'),</span><br><span class="line">                     keras.layers.Conv2D(21, (1, 1), (1, 1), 'same', name='conv6'))(concatenate)</span><br><span class="line"></span><br><span class="line">    output = tf.image.resize(output, (input_shape[0], input_shape[1]), name='resize2')</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Softmax(name='softmax')(output)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='DeepLab-V3+')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = deeplab_v3_plus(input_shape=(512, 512, 3))</span><br><span class="line">    model.build(input_shape=(None, 512, 512, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Semantic_segmentation/DeepLab_V3+_R.png" alt="DeepLab-V3+"></p>
<h1 id="Shape数据集完整实战"><a href="#Shape数据集完整实战" class="headerlink" title="Shape数据集完整实战"></a><font size="5" color="red">Shape数据集完整实战</font></h1><h2 id="文件路径关系说明"><a href="#文件路径关系说明" class="headerlink" title="文件路径关系说明"></a>文件路径关系说明</h2><ul>
<li>project<ul>
<li>shape<ul>
<li>train_imgs(训练集图像文件夹)</li>
<li>train_mask(训练集掩模文件夹)</li>
<li>test_imgs(测试集图像文件夹)</li>
</ul>
</li>
<li>DeepLab-V3+_weight(模型权重文件夹)</li>
<li>DeepLab-V3+_test_result(测试集结果文件夹)</li>
<li>DeepLab-V3+.py</li>
</ul>
</li>
</ul>
<h2 id="实战步骤说明"><a href="#实战步骤说明" class="headerlink" title="实战步骤说明"></a>实战步骤说明</h2><ol>
<li>语义分割实战运行较为简单，因为它的输入的训练数据为图像，输入的标签数据也是图像，首先<strong>要对输入的标签数据进行编码，转换为类别信息</strong>，要和网络的输出维度相匹配，从(batch_size, height, width, 1)转换为(batch_size, height, width, num_class + 1)，<strong>某个像素点为哪一个类别，则在该通道上置1，其余通道置0</strong>。即神经网络的输入大小为(batch_size, height, width, 3)，输出大小为(batch_size, height, width, num_class + 1)。</li>
<li>设计损失函数，简单情况设置交叉熵损失函数即可达到较好效果。</li>
<li>搭建神经网络，<strong>设置合适参数</strong>，进行训练。</li>
<li>预测时，需要根据神经网络的输出进行<strong>逆向解码(编码的反过程)</strong>，寻找<strong>每一个像素点，哪一个通道上值最大则归为哪一个类别</strong>，即可完成实战的过程。</li>
</ol>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>设置的图像<strong>类别数为实际类别数+1</strong>，1代表背景类别，<strong>此数据集为3类，最后的通道数为4，每一个通道预测一类物体</strong>。在通道方向求Softmax，并且求出最大的索引，索引为0则代表背景，索引为1则代表圆形，索引为2则代表三角形，索引为3则代表正方形。</li>
<li>ASPP模块中的膨胀率，可以<strong>根据需要进行调整</strong>，论文中膨胀率分别为6， 12， 18，在这个简单数据集中，输入尺寸为16，因此我选择的膨胀率是2，4，8。</li>
<li>设置了<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li>使用<strong>yield</strong>关键字，产生可迭代对象，不用将所有的数据都保存下来，大大节约内存。</li>
<li>其中将1000个数据，分成800个训练集，100个验证集和100个测试集，小伙伴们可以自行修改。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>DeepLab-V3+的<strong>特征提取网络为改进的Xception</strong>，论文中也比较了ResNet特征提取网络的性能。实战中我选择的是Middle Flow为8的Xception，小伙伴们可以参考特征提取网络部分内容，选择其他的网络进行特征提取，比较不同网络参数量，运行速度，最终结果之间的差异。</li>
<li>关于特征提取网络的输出，论文中给出原尺寸缩小16倍的和缩小8倍的，两者结构差异<strong>仅在缩小16倍的Entry Flow中有一个模块strides=(2, 2)</strong>，性能差异不大，但是缩小8倍的网络参数量大大增加。在实战中，数据集的尺寸较小，因此我选择了缩小8倍的网络参数，小伙伴们在使用时可以酌情修改。</li>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
</ol>
<h2 id="完整实战代码"><a href="#完整实战代码" class="headerlink" title="完整实战代码"></a>完整实战代码</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">        super(Conv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters, kernel_size, strides, padding='same', dilation_rate=dilation_rate))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('relu') != -1:</span><br><span class="line">            self.blocks.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Depthwiseconv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">        super(Depthwiseconv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding='same', dilation_rate=dilation_rate))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.ReLU())</span><br><span class="line">        self.blocks.add(Conv_Bn_ReLU(filters, (1, 1), (1, 1), name=name))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, filters, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">    x1 = Depthwiseconv_Bn_ReLU(filters[0], (3, 3), (1, 1), name='{}_depthwiseconv_bn_relu1'.format(name), dilation_rate=dilation_rate)(x)</span><br><span class="line">    x2 = Depthwiseconv_Bn_ReLU(filters[1], (3, 3), (1, 1), name='{}_depthwiseconv_bn_relu2'.format(name), dilation_rate=dilation_rate)(x1)</span><br><span class="line">    x3 = Depthwiseconv_Bn_ReLU(filters[2], (3, 3), strides, name='{}_depthwiseconv_bn3'.format(name), dilation_rate=dilation_rate)(x2)</span><br><span class="line">    if name.find('sum') != -1:</span><br><span class="line">        output = keras.layers.Add(name='{}_add'.format(name))([x3, x])</span><br><span class="line">    elif name.find('none') != -1:</span><br><span class="line">        output = x3</span><br><span class="line">    else:</span><br><span class="line">        short_cut = compose(keras.layers.Conv2D(filters[-1], (1, 1), strides=strides, name='{}_shortcut_conv'.format(name)),</span><br><span class="line">                            keras.layers.BatchNormalization(name='{}_shortcut_bn'.format(name)))(x)</span><br><span class="line">        output = keras.layers.Add(name='{}_add'.format(name))([x3, short_cut])</span><br><span class="line">    output = keras.layers.ReLU(name='{}_relu'.format(name))(output)</span><br><span class="line">    if name.find('skip') != -1:</span><br><span class="line">        output = output, x1</span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def aspp(x, filters, dilation_rate, name):</span><br><span class="line">    x1 = compose(keras.layers.GlobalAveragePooling2D(name='{}_part1_globalaveragepool'.format(name)),</span><br><span class="line">                 keras.layers.Reshape((1, 1, x.shape[-1]), name='{}_part1_reshape'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(filters, (1, 1), (1, 1), name='{}_part1_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    x1 = tf.image.resize(x1, (x.shape[1], x.shape[2]), name='{}_part1_reshape'.format(name))</span><br><span class="line">    x2 = Conv_Bn_ReLU(filters, (1, 1), (1, 1), name='{}_part2_conv_bn_relu'.format(name))(x)</span><br><span class="line">    x3 = Depthwiseconv_Bn_ReLU(filters, (3, 3), (1, 1), name='{}_part3_depthwiseconv_bn_relu'.format(name), dilation_rate=dilation_rate[0])(x)</span><br><span class="line">    x4 = Depthwiseconv_Bn_ReLU(filters, (3, 3), (1, 1), name='{}_part4_depthwiseconv_bn_relu'.format(name), dilation_rate=dilation_rate[1])(x)</span><br><span class="line">    x5 = Depthwiseconv_Bn_ReLU(filters, (3, 3), (1, 1), name='{}_part5_depthwiseconv_bn_relu'.format(name), dilation_rate=dilation_rate[2])(x)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x1, x2, x3, x4, x5])</span><br><span class="line"></span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def small_deeplab_v3_plus(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(32, (3, 3), (2, 2), name='conv_bn_relu'))(x)</span><br><span class="line"></span><br><span class="line">    x = block(x, [128, 128, 128], (2, 2), name='entryflow1_conv')</span><br><span class="line">    x, skip = block(x, [256, 256, 728], (2, 2), name='entryflow2_skip_conv')</span><br><span class="line"></span><br><span class="line">    for i in range(8):</span><br><span class="line">        x = block(x, [728, 728, 728], (1, 1), name='middleflow{}_sum'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    x = block(x, [728, 1024, 1024], (1, 1), name='exitflow1_conv')</span><br><span class="line">    x = block(x, [1536, 1536, 2048], (1, 1), name='exitflow2_none', dilation_rate=(2, 2))</span><br><span class="line"></span><br><span class="line">    x = aspp(x, 256, [2, 4, 8], name='aspp')</span><br><span class="line">    x = compose(Conv_Bn_ReLU(256, (1, 1), (1, 1), name='conv_bn_relu3'),</span><br><span class="line">                keras.layers.Dropout(0.1, name='dropout'))(x)</span><br><span class="line">    x = tf.image.resize(x, (input_shape[0] // 4, input_shape[1] // 4), name='resize1')</span><br><span class="line">    skip = Conv_Bn_ReLU(24, (1, 1), (1, 1), name='skip_conv_bn_relu')(skip)</span><br><span class="line">    concatenate = keras.layers.Concatenate(name='concatenate')([x, skip])</span><br><span class="line"></span><br><span class="line">    output = compose(Depthwiseconv_Bn_ReLU(256, (3, 3), (1, 1), name='depthwiseconv_bn_relu4'),</span><br><span class="line">                     Depthwiseconv_Bn_ReLU(256, (3, 3), (1, 1), name='depthwiseconv_bn_relu5'),</span><br><span class="line">                     keras.layers.Conv2D(num_class, (1, 1), (1, 1), 'same', name='conv6'))(concatenate)</span><br><span class="line"></span><br><span class="line">    output = tf.image.resize(output, (input_shape[0], input_shape[1]), name='resize2')</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Softmax(name='softmax')(output)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='Small_DeepLab-V3+')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generate_arrays_from_file(train_data, batch_size):</span><br><span class="line">    # 获取总长度</span><br><span class="line">    n = len(train_data)</span><br><span class="line">    i = 0</span><br><span class="line">    while 1:</span><br><span class="line">        X_train = []</span><br><span class="line">        Y_train = []</span><br><span class="line">        # 获取一个batch_size大小的数据</span><br><span class="line">        for _ in range(batch_size):</span><br><span class="line">            if i == 0:</span><br><span class="line">                np.random.shuffle(train_data)</span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(imgs_path + '\\' + str(train_data[i]) + '.jpg')</span><br><span class="line">            img = img / 127.5 - 1</span><br><span class="line">            X_train.append(img)</span><br><span class="line"></span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(mask_path + '\\' + str(train_data[i]) + '.png')</span><br><span class="line">            seg_labels = np.zeros((img_size[0], img_size[1], num_class))</span><br><span class="line">            for c in range(num_class):</span><br><span class="line">                seg_labels[:, :, c] = (img[:, :, 0] == c).astype(int)</span><br><span class="line">            Y_train.append(seg_labels)</span><br><span class="line"></span><br><span class="line">            # 读完一个周期后重新开始</span><br><span class="line">            i = (i + 1) % n</span><br><span class="line">        yield tf.constant(X_train), tf.constant(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # 包括背景</span><br><span class="line">    num_class = 4</span><br><span class="line">    train_data = list(range(800))</span><br><span class="line">    validation_data = list(range(800, 900))</span><br><span class="line">    test_data = range(900, 1000)</span><br><span class="line">    epochs = 50</span><br><span class="line">    batch_size = 16</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    colors = [[0, 0, 0], [0, 0, 128], [0, 128, 0], [128, 0, 0]]</span><br><span class="line"></span><br><span class="line">    mask_path = r'.\shape\train_mask'</span><br><span class="line">    imgs_path = r'.\shape\train_imgs'</span><br><span class="line">    test_path = r'.\shape\test_imgs'</span><br><span class="line">    save_path = r'.\DeepLab_V3_Plus_test_result'</span><br><span class="line">    weight_path = r'.\DeepLab_V3_Plus_weight'</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(save_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(save_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(weight_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(weight_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    model = small_deeplab_v3_plus(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line"></span><br><span class="line">    model.build(input_shape=(None, img_size[0], img_size[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizor = keras.optimizers.Adam(lr=1e-3)</span><br><span class="line">    lossor = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizor, loss=lossor, metrics=['accuracy'])</span><br><span class="line"></span><br><span class="line">    # 保存的方式，3世代保存一次</span><br><span class="line">    checkpoint_period = keras.callbacks.ModelCheckpoint(</span><br><span class="line">        weight_path + '\\' + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        save_weights_only=True,</span><br><span class="line">        save_best_only=True,</span><br><span class="line">        period=3</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 学习率下降的方式，val_loss3次不下降就下降学习率继续训练</span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        factor=0.5,</span><br><span class="line">        patience=3,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        min_delta=0,</span><br><span class="line">        patience=10,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model.fit_generator(generate_arrays_from_file(train_data, batch_size),</span><br><span class="line">                        steps_per_epoch=max(1, len(train_data) // batch_size),</span><br><span class="line">                        validation_data=generate_arrays_from_file(validation_data, batch_size),</span><br><span class="line">                        validation_steps=max(1, len(validation_data) // batch_size),</span><br><span class="line">                        epochs=epochs,</span><br><span class="line">                        callbacks=[checkpoint_period, reduce_lr, early_stopping])</span><br><span class="line"></span><br><span class="line">    for name in test_data:</span><br><span class="line">        test_img_path = test_path + '\\' + str(name) + '.jpg'</span><br><span class="line">        save_img_path = save_path + '\\' + str(name) + '.png'</span><br><span class="line">        test_img = cv.imread(test_img_path)</span><br><span class="line">        test_img = tf.constant([test_img / 127.5 - 1])</span><br><span class="line">        test_mask = model.predict(test_img)</span><br><span class="line">        test_mask = np.reshape(test_mask, (img_size[0], img_size[1], num_class))</span><br><span class="line">        test_mask = np.argmax(test_mask, axis=-1)</span><br><span class="line">        seg_img = np.zeros((img_size[0], img_size[1], 3))</span><br><span class="line">        for c in range(num_class):</span><br><span class="line">            seg_img[:, :, 0] += ((test_mask == c) * (colors[c][0]))</span><br><span class="line">            seg_img[:, :, 1] += ((test_mask == c) * (colors[c][1]))</span><br><span class="line">            seg_img[:, :, 2] += ((test_mask == c) * (colors[c][2]))</span><br><span class="line">        seg_img = seg_img.astype(np.uint8)</span><br><span class="line">        cv.imwrite(save_img_path, seg_img)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Semantic_segmentation/DeepLab_V3+_T.png" alt="DeepLab-V3+"></p>
<h1 id="DeepLab-V3-小结"><a href="#DeepLab-V3-小结" class="headerlink" title="DeepLab-V3+小结"></a><font size="5" color="red">DeepLab-V3+小结</font></h1><p>  DeepLab-V3+是一种高效的语义分割网络，从上图可以看出DeepLab-V3+模型的参数量只有41M，就目前来说，DeepLab-V3+是<strong>语义分割公认的最高峰</strong>，主要来源于<strong>ASPP网络结构和深浅层特征融合</strong>，是小伙伴们需要掌握的一个模型。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>语义分割网络</category>
      </categories>
  </entry>
  <entry>
    <title>PSPNet</title>
    <url>/2020/04/24/Semantic_segmentation%20PSPNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">PSPNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>PSPNet</strong>:由香港中文大学和商汤科技提出，获得<strong>2016年ImageNet场景解析挑战的冠军</strong>，于<strong>2017发表在CVPR</strong>，通过使用<strong>金字塔池化模块</strong>完成图像分割，是一种高效的语义分割模型。<a id="more"></a></p>
<p><img src="/images/Semantic_segmentation/PSPNet.png" alt="PSPNet"></p>
<h1 id="PSPNet特点"><a href="#PSPNet特点" class="headerlink" title="PSPNet特点"></a><font size="5" color="red">PSPNet特点</font></h1><p>  <font size="3">特征提取网络选择施加<strong>空洞卷积(atrous convolutions)的ResNet</strong>，并且选择<strong>AL(auxiliary loss, 辅助损失)</strong>对ResNet进行训练，通常在某一层后接着几个转换层和全连接层，最后分类预测，并且给予<strong>损失小于1的权重</strong>，完成辅助损失，目的是<strong>缓解深度神经网络中梯度消失的问题。</strong></font><br>  <font size="3">使用<strong>金字塔池化模块聚合信息，根据不同内核的池化层，获取不同尺度的图像信息</strong>，然后再Concatenate，完成信息的融合。</font></p>
<h1 id="空洞卷积-atrous-convolutions-和普通卷积之间的区别"><a href="#空洞卷积-atrous-convolutions-和普通卷积之间的区别" class="headerlink" title="空洞卷积(atrous convolutions)和普通卷积之间的区别"></a><font size="5" color="red">空洞卷积(atrous convolutions)和普通卷积之间的区别</font></h1><p>  <font size="3"><strong>空洞卷积(atrous convolutions)又称膨胀卷积(dilated convolutions)</strong>，在卷积层引入了一个<strong>膨胀率(dilation rate)</strong>参数，定义了卷积核的间隔数量，普通卷积的卷积核dilation rate=1</font><br>  <font size="3">优点：<strong>扩大感受野</strong>，相邻的像素点可能存在大量冗余信息，扩大感受野可能会获取多尺度信息，这在视觉任务上非常重要，且<strong>不需要引入额外参数</strong>，如果增加分辨率或者采用大尺寸的卷积核则会大大增加模型的参数量。</font><br>  <font size="3">缺点：由于空洞卷积的<strong>计算方式类似于棋盘格式，因此可能产生棋盘格效应，可以参考<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">棋盘格可视化</a>。如果膨胀率太大卷积结果之间没有相关性，可能会丢失局部信息。</strong></font><br><img src="/images/Semantic_segmentation/PSPNet_D.png" alt="PSPNet"></p>
<h1 id="PSPNet图像分析"><a href="#PSPNet图像分析" class="headerlink" title="PSPNet图像分析"></a><font size="5" color="red">PSPNet图像分析</font></h1><p><img src="/images/Semantic_segmentation/PSPNet_A.png" alt="PSPNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">        super(Conv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters, kernel_size, strides, padding='same', dilation_rate=dilation_rate))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def res_block(x, filters, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(filters // 4, (1, 1), (1, 1), name='{}_conv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_ReLU(filters // 4, (3, 3), strides, name='{}_conv_bn_relu2'.format(name), dilation_rate=dilation_rate),</span><br><span class="line">                keras.layers.Conv2D(filters, (1, 1), name='{}_conv3'.format(name)),</span><br><span class="line">                keras.layers.BatchNormalization(name='{}_bn3'.format(name)))(x)</span><br><span class="line">    if name.find('conv_block') != -1:</span><br><span class="line">        shortcut = keras.layers.Conv2D(filters, (1, 1), strides, name='{}_shortcut_conv'.format(name))(shortcut)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line">    output = keras.layers.ReLU(name='{}_relu'.format(name))(output)</span><br><span class="line"></span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def psp_block(x, name):</span><br><span class="line"></span><br><span class="line">    p1 = compose(keras.layers.MaxPool2D((60, 60), name='{}_part1_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(512, (1, 1), (1, 1), name='{}_part1_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    p2 = compose(keras.layers.MaxPool2D((30, 30), name='{}_part2_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(512, (1, 1), (1, 1), name='{}_part2_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    p3 = compose(keras.layers.MaxPool2D((20, 20), name='{}_part3_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(512, (1, 1), (1, 1), name='{}_part3_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    p4 = compose(keras.layers.MaxPool2D((10, 10), name='{}_part4_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(512, (1, 1), (1, 1), name='{}_part4_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    input_size = (x.shape[1], x.shape[2])</span><br><span class="line">    p1 = tf.image.resize(p1, input_size, name='{}_resize1'.format(name))</span><br><span class="line">    p2 = tf.image.resize(p2, input_size, name='{}_resize2'.format(name))</span><br><span class="line">    p3 = tf.image.resize(p3, input_size, name='{}_resize3'.format(name))</span><br><span class="line">    p4 = tf.image.resize(p4, input_size, name='{}_resize4'.format(name))</span><br><span class="line">    output = keras.layers.Concatenate(name='{}_concatenate'.format(name))([p1, p2, p3, p4, x])</span><br><span class="line"></span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pspnet(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(64, (3, 3), (2, 2), name='conv_bn_relu1'),</span><br><span class="line">                Conv_Bn_ReLU(64, (3, 3), (1, 1), name='conv_bn_relu2'),</span><br><span class="line">                Conv_Bn_ReLU(128, (3, 3), (1, 1), name='conv_bn_relu3'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), 'same', name='maxpool1'))(x)</span><br><span class="line"></span><br><span class="line">    filters = [256, 512, 1024, 2048]</span><br><span class="line">    strides = [(1, 1), (2, 2), (1, 1), (1, 1)]</span><br><span class="line">    dilation_rate = [(1, 1), (1, 1), (2, 2), (4, 4)]</span><br><span class="line">    times = [2, 3, 22, 2]</span><br><span class="line">    for i in range(len(filters)):</span><br><span class="line">        x = res_block(x, filters[i], strides=strides[i], name='conv_block{}'.format(i + 1))</span><br><span class="line">        for j in range(times[i]):</span><br><span class="line">            x = res_block(x, filters[i], strides=(1, 1), name='identity_block{}_{}'.format(i + 1, j + 1), dilation_rate=dilation_rate[i])</span><br><span class="line"></span><br><span class="line">    x = psp_block(x, name='psp_block')</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(512, (1, 1), (1, 1), name='conv_bn_relu4'),</span><br><span class="line">                keras.layers.Dropout(0.1, name='dropout'),</span><br><span class="line">                keras.layers.Conv2D(21, (1, 1), (1, 1), 'same', name='conv5'))(x)</span><br><span class="line">    x = tf.image.resize(x, (input_shape[0], input_shape[1]), name='resize')</span><br><span class="line">    output = keras.layers.Softmax(name='softmax')(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='PSPNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = pspnet(input_shape=(473, 473, 3))</span><br><span class="line">    model.build(input_shape=(None, 473, 473, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Semantic_segmentation/PSPNet_R.png" alt="PSPNet"></p>
<h1 id="Shape数据集完整实战"><a href="#Shape数据集完整实战" class="headerlink" title="Shape数据集完整实战"></a><font size="5" color="red">Shape数据集完整实战</font></h1><h2 id="文件路径关系说明"><a href="#文件路径关系说明" class="headerlink" title="文件路径关系说明"></a>文件路径关系说明</h2><ul>
<li>project<ul>
<li>shape<ul>
<li>train_imgs(训练集图像文件夹)</li>
<li>train_mask(训练集掩模文件夹)</li>
<li>test_imgs(测试集图像文件夹)</li>
</ul>
</li>
<li>PSPNet_weight(模型权重文件夹)</li>
<li>PSPNet_test_result(测试集结果文件夹)</li>
<li>PSPNet.py</li>
</ul>
</li>
</ul>
<h2 id="实战步骤说明"><a href="#实战步骤说明" class="headerlink" title="实战步骤说明"></a>实战步骤说明</h2><ol>
<li>语义分割实战运行较为简单，因为它的输入的训练数据为图像，输入的标签数据也是图像，首先<strong>要对输入的标签数据进行编码，转换为类别信息</strong>，要和网络的输出维度相匹配，从(batch_size, height, width, 1)转换为(batch_size, height, width, num_class + 1)，<strong>某个像素点为哪一个类别，则在该通道上置1，其余通道置0</strong>。即神经网络的输入大小为(batch_size, height, width, 3)，输出大小为(batch_size, height, width, num_class + 1)。</li>
<li>设计损失函数，简单情况设置交叉熵损失函数即可达到较好效果。</li>
<li>搭建神经网络，<strong>设置合适参数</strong>，进行训练。</li>
<li>预测时，需要根据神经网络的输出进行<strong>逆向解码(编码的反过程)</strong>，寻找<strong>每一个像素点，哪一个通道上值最大则归为哪一个类别</strong>，即可完成实战的过程。</li>
</ol>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>设置的图像<strong>类别数为实际类别数+1</strong>，1代表背景类别，<strong>此数据集为3类，最后的通道数为4，每一个通道预测一类物体</strong>。在通道方向求Softmax，并且求出最大的索引，索引为0则代表背景，索引为1则代表圆形，索引为2则代表三角形，索引为3则代表正方形。</li>
<li>在PSPNet中只使用ResNet101的最后一层，<strong>可以借鉴UNet的思想，可以使用多层输出，实现多尺度特征融合。</strong></li>
<li>设置了<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li>使用<strong>yield</strong>关键字，产生可迭代对象，不用将所有的数据都保存下来，大大节约内存。</li>
<li>其中将1000个数据，分成800个训练集，100个验证集和100个测试集，小伙伴们可以自行修改。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>金字塔池化模块中的池化核，可以<strong>根据需要进行调整</strong>，论文中金字塔池化模块的输入尺寸为60x60，因此可以进行60x60，30x30，20x20，10x10的池化核，在这个简单数据集中，输入尺寸为8，因此我选择的是8x8，4x4，2x2，1x1的池化核。</li>
<li>PSPNet的<strong>特征提取网络为ResNet101</strong>，实战中我选择的是ResNet50，小伙伴们可以参考特征提取网络部分内容，选择其他的网络进行特征提取，比较不同网络参数量，运行速度，最终结果之间的差异。</li>
<li>在论文中提到的AL(辅助损失)是在构建ResNet101特征提取网络时使用的，在这里我们为了简单起见，直接使用ResNet50。</li>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
</ol>
<h2 id="完整实战代码"><a href="#完整实战代码" class="headerlink" title="完整实战代码"></a>完整实战代码</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_ReLU(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">        super(Conv_Bn_ReLU, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters, kernel_size, strides, padding='same', dilation_rate=dilation_rate))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def res_block(x, filters, strides, name, dilation_rate=(1, 1)):</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(filters // 4, (1, 1), (1, 1), name='{}_conv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_ReLU(filters // 4, (3, 3), strides, name='{}_conv_bn_relu2'.format(name), dilation_rate=dilation_rate),</span><br><span class="line">                keras.layers.Conv2D(filters, (1, 1), name='{}_conv3'.format(name)),</span><br><span class="line">                keras.layers.BatchNormalization(name='{}_bn3'.format(name)))(x)</span><br><span class="line">    if name.find('conv_block') != -1:</span><br><span class="line">        shortcut = keras.layers.Conv2D(filters, (1, 1), strides, name='{}_shortcut_conv'.format(name))(shortcut)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line">    output = keras.layers.ReLU(name='{}_relu'.format(name))(output)</span><br><span class="line"></span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def psp_block(x, name):</span><br><span class="line"></span><br><span class="line">    p1 = compose(keras.layers.MaxPool2D((x.shape[1], x.shape[2]), name='{}_part1_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(x.shape[-1] // 4, (1, 1), (1, 1), name='{}_part1_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    p2 = compose(keras.layers.MaxPool2D((x.shape[1] // 2, x.shape[2] // 2), name='{}_part2_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(x.shape[-1] // 4, (1, 1), (1, 1), name='{}_part2_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    p3 = compose(keras.layers.MaxPool2D((x.shape[1] // 4, x.shape[2] // 4), name='{}_part3_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(x.shape[-1] // 4, (1, 1), (1, 1), name='{}_part3_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    p4 = compose(keras.layers.MaxPool2D((x.shape[1] // 8, x.shape[2] // 8), name='{}_part4_maxpool'.format(name)),</span><br><span class="line">                 Conv_Bn_ReLU(x.shape[-1] // 4, (1, 1), (1, 1), name='{}_part4_conv_bn_relu'.format(name)))(x)</span><br><span class="line">    input_size = (x.shape[1], x.shape[2])</span><br><span class="line">    p1 = tf.image.resize(p1, input_size, name='{}_resize1'.format(name))</span><br><span class="line">    p2 = tf.image.resize(p2, input_size, name='{}_resize2'.format(name))</span><br><span class="line">    p3 = tf.image.resize(p3, input_size, name='{}_resize3'.format(name))</span><br><span class="line">    p4 = tf.image.resize(p4, input_size, name='{}_resize4'.format(name))</span><br><span class="line">    output = keras.layers.Concatenate(name='{}_concatenate'.format(name))([p1, p2, p3, p4, x])</span><br><span class="line"></span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def small_pspnet(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_ReLU(32, (3, 3), (2, 2), name='conv_bn_relu1'),</span><br><span class="line">                Conv_Bn_ReLU(32, (3, 3), (1, 1), name='conv_bn_relu2'),</span><br><span class="line">                Conv_Bn_ReLU(64, (3, 3), (1, 1), name='conv_bn_relu3'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), 'same', name='maxpool1'))(x)</span><br><span class="line"></span><br><span class="line">    x1 = res_block(x, 128, strides=(1, 1), name='conv_block1')</span><br><span class="line">    for j in range(2):</span><br><span class="line">        x1 = res_block(x1, 128, strides=(1, 1), name='identity_block1_{}'.format(j + 1), dilation_rate=(1, 1))</span><br><span class="line"></span><br><span class="line">    x2 = res_block(x1, 256, strides=(2, 2), name='conv_block2')</span><br><span class="line">    for j in range(2):</span><br><span class="line">        x2 = res_block(x2, 256, strides=(1, 1), name='identity_block2_{}'.format(j + 1), dilation_rate=(1, 1))</span><br><span class="line"></span><br><span class="line">    x3 = res_block(x2, 512, strides=(2, 2), name='conv_block3')</span><br><span class="line">    for j in range(2):</span><br><span class="line">        x3 = res_block(x3, 512, strides=(1, 1), name='identity_block3_{}'.format(j + 1), dilation_rate=(1, 1))</span><br><span class="line"></span><br><span class="line">    x4 = res_block(x3, 1024, strides=(1, 1), name='conv_block4')</span><br><span class="line">    for j in range(2):</span><br><span class="line">        x4 = res_block(x4, 1024, strides=(1, 1), name='identity_block4_{}'.format(j + 1), dilation_rate=(2, 2))</span><br><span class="line"></span><br><span class="line">    psp4 = psp_block(x4, name='psp_block4')</span><br><span class="line">    upsampling4 = keras.layers.UpSampling2D(name='upsampling4')(psp4)</span><br><span class="line">    y2 = keras.layers.Concatenate(name='concatenate4')([x2, upsampling4])</span><br><span class="line">    y2 = Conv_Bn_ReLU(512, (1, 1), (1, 1), name='conv_bn_relu4')(y2)</span><br><span class="line">    psp2 = psp_block(y2, name='psp_block2')</span><br><span class="line"></span><br><span class="line">    y = compose(Conv_Bn_ReLU(128, (1, 1), (1, 1), name='conv_bn_relu5'),</span><br><span class="line">                keras.layers.Dropout(0.1, name='dropout'),</span><br><span class="line">                keras.layers.Conv2D(num_class, (1, 1), (1, 1), 'same', name='conv6'))(psp2)</span><br><span class="line">    y = tf.image.resize(y, (input_shape[0], input_shape[1]), name='resize')</span><br><span class="line">    output = keras.layers.Softmax(name='softmax')(y)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='Small_PSPNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generate_arrays_from_file(train_data, batch_size):</span><br><span class="line">    # 获取总长度</span><br><span class="line">    n = len(train_data)</span><br><span class="line">    i = 0</span><br><span class="line">    while 1:</span><br><span class="line">        X_train = []</span><br><span class="line">        Y_train = []</span><br><span class="line">        # 获取一个batch_size大小的数据</span><br><span class="line">        for _ in range(batch_size):</span><br><span class="line">            if i == 0:</span><br><span class="line">                np.random.shuffle(train_data)</span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(imgs_path + '\\' + str(train_data[i]) + '.jpg')</span><br><span class="line">            img = img / 127.5 - 1</span><br><span class="line">            X_train.append(img)</span><br><span class="line"></span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(mask_path + '\\' + str(train_data[i]) + '.png')</span><br><span class="line">            seg_labels = np.zeros((img_size[0], img_size[1], num_class))</span><br><span class="line">            for c in range(num_class):</span><br><span class="line">                seg_labels[:, :, c] = (img[:, :, 0] == c).astype(int)</span><br><span class="line">            Y_train.append(seg_labels)</span><br><span class="line"></span><br><span class="line">            # 读完一个周期后重新开始</span><br><span class="line">            i = (i + 1) % n</span><br><span class="line">        yield tf.constant(X_train), tf.constant(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # 包括背景</span><br><span class="line">    num_class = 4</span><br><span class="line">    train_data = list(range(800))</span><br><span class="line">    validation_data = list(range(800, 900))</span><br><span class="line">    test_data = range(900, 1000)</span><br><span class="line">    epochs = 50</span><br><span class="line">    batch_size = 16</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    colors = [[0, 0, 0], [0, 0, 128], [0, 128, 0], [128, 0, 0]]</span><br><span class="line"></span><br><span class="line">    mask_path = r'.\shape\train_mask'</span><br><span class="line">    imgs_path = r'.\shape\train_imgs'</span><br><span class="line">    test_path = r'.\shape\test_imgs'</span><br><span class="line">    save_path = r'.\PSPNet_test_result'</span><br><span class="line">    weight_path = r'.\PSPNet_weight'</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(save_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(save_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(weight_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(weight_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    model = small_pspnet(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model.build(input_shape=(None, img_size[0], img_size[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizor = keras.optimizers.Adam(lr=1e-3)</span><br><span class="line">    lossor = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizor, loss=lossor, metrics=['accuracy'])</span><br><span class="line"></span><br><span class="line">    # 保存的方式，3世代保存一次</span><br><span class="line">    checkpoint_period = keras.callbacks.ModelCheckpoint(</span><br><span class="line">        weight_path + '\\' + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        save_weights_only=True,</span><br><span class="line">        save_best_only=True,</span><br><span class="line">        period=3</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 学习率下降的方式，val_loss3次不下降就下降学习率继续训练</span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        factor=0.5,</span><br><span class="line">        patience=3,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        min_delta=0,</span><br><span class="line">        patience=10,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model.fit_generator(generate_arrays_from_file(train_data, batch_size),</span><br><span class="line">                        steps_per_epoch=max(1, len(train_data) // batch_size),</span><br><span class="line">                        validation_data=generate_arrays_from_file(validation_data, batch_size),</span><br><span class="line">                        validation_steps=max(1, len(validation_data) // batch_size),</span><br><span class="line">                        epochs=epochs,</span><br><span class="line">                        callbacks=[checkpoint_period, reduce_lr, early_stopping])</span><br><span class="line"></span><br><span class="line">    for name in test_data:</span><br><span class="line">        test_img_path = test_path + '\\' + str(name) + '.jpg'</span><br><span class="line">        save_img_path = save_path + '\\' + str(name) + '.png'</span><br><span class="line">        test_img = cv.imread(test_img_path)</span><br><span class="line">        test_img = tf.constant([test_img / 127.5 - 1])</span><br><span class="line">        test_mask = model.predict(test_img)</span><br><span class="line">        test_mask = np.reshape(test_mask, (img_size[0], img_size[1], num_class))</span><br><span class="line">        test_mask = np.argmax(test_mask, axis=-1)</span><br><span class="line">        seg_img = np.zeros((img_size[0], img_size[1], 3))</span><br><span class="line">        for c in range(num_class):</span><br><span class="line">            seg_img[:, :, 0] += ((test_mask == c) * (colors[c][0]))</span><br><span class="line">            seg_img[:, :, 1] += ((test_mask == c) * (colors[c][1]))</span><br><span class="line">            seg_img[:, :, 2] += ((test_mask == c) * (colors[c][2]))</span><br><span class="line">        seg_img = seg_img.astype(np.uint8)</span><br><span class="line">        cv.imwrite(save_img_path, seg_img)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Semantic_segmentation/PSPNet_T.png" alt="PSPNet"></p>
<h1 id="PSPNet小结"><a href="#PSPNet小结" class="headerlink" title="PSPNet小结"></a><font size="5" color="red">PSPNet小结</font></h1><p>  PSPNet是一种高效的语义分割网络，从上图可以看出PSPNet模型的参数量有49M，PSPNet不同于SegNet和UNet，没有很对称的编码解码结构，在编码过程中，使用<strong>不同尺寸金字塔池化核完成对不同尺寸特征的融合</strong>，在解码过程中，直接使用<strong>简单的resize完成对图像信息的恢复</strong>，对后面的深度学习网络的发展有重要的影响。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>语义分割网络</category>
      </categories>
  </entry>
  <entry>
    <title>UNet</title>
    <url>/2020/04/21/Semantic_segmentation%20UNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">UNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>UNet</strong>:于<strong>2015年发表于MICCA</strong>，设计的就是应用于<strong>医学图像</strong>的分割，由于医学影响本身的性质，语义较为简单，结构较为固定，数据量较少且具有多模态的性质，根据CT灌注方法不同，具有不同的模态。UNet实现了使用<strong>少量数据集进行大尺寸图像</strong>的有效算法，因为<strong>结构类似U型，故称之为UNet。</strong><a id="more"></a></p>
<p><img src="/images/Semantic_segmentation/UNet.png" alt="UNet"></p>
<h1 id="UNet特点"><a href="#UNet特点" class="headerlink" title="UNet特点"></a><font size="5" color="red">UNet特点</font></h1><p>  <font size="3">网络结构简单，易于实现</font><br>  <font size="3">使用<strong>Over-tile</strong>策略，因为医学图像处理的图像尺寸较大，我们针对于某一区域进行分割时，可以<strong>获取周围更大尺寸的信息作为上下文</strong>，在卷积时只使用有效部分，这样<strong>防止padding=same时添加无效信息</strong>。因此图像的尺寸会缩小，在网络中需要<strong>对浅层特征进行Crop</strong>之后才可以与深层特征进行Concatenate。</font><br>  <font size="3">使用<strong>随机弹性变形对数据进行增强</strong>，增加模型的鲁棒性。</font><br>  <font size="3">使用<strong>加权Loss</strong>，对于某一点到边界的距离呈高斯关系的权重，距离边界越近权重越大，距离越远权重越小。</font></p>
<h1 id="UNet图像分析"><a href="#UNet图像分析" class="headerlink" title="UNet图像分析"></a><font size="5" color="red">UNet图像分析</font></h1><p><img src="/images/Semantic_segmentation/UNet_A.png" alt="UNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def unet(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = compose(keras.layers.Conv2D(64, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv1_1'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv1_2'))(x)</span><br><span class="line">    x2 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool1'),</span><br><span class="line">                 keras.layers.Conv2D(128, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv2_1'),</span><br><span class="line">                 keras.layers.Conv2D(128, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv2_2'))(x1)</span><br><span class="line">    x3 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool2'),</span><br><span class="line">                 keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv3_1'),</span><br><span class="line">                 keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv3_2'))(x2)</span><br><span class="line">    x4 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool3'),</span><br><span class="line">                 keras.layers.Conv2D(512, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv4_1'),</span><br><span class="line">                 keras.layers.Conv2D(512, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv4_2'))(x3)</span><br><span class="line">    x5 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool4'),</span><br><span class="line">                 keras.layers.Conv2D(1024, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv5_1'),</span><br><span class="line">                 keras.layers.Conv2D(1024, (3, 3), (1, 1), 'valid', activation='relu', name='encoder_conv5_2'))(x4)</span><br><span class="line"></span><br><span class="line">    crop1 = keras.layers.Cropping2D(((88, 88), (88, 88)), name='crop1')(x1)</span><br><span class="line">    crop2 = keras.layers.Cropping2D(((40, 40), (40, 40)), name='crop2')(x2)</span><br><span class="line">    crop3 = keras.layers.Cropping2D(((16, 16), (16, 16)), name='crop3')(x3)</span><br><span class="line">    crop4 = keras.layers.Cropping2D(((4, 4), (4, 4)), name='crop4')(x4)</span><br><span class="line"></span><br><span class="line">    y4 = keras.layers.UpSampling2D((2, 2), name='decoder_upsampling4')(x5)</span><br><span class="line">    concatenate4 = keras.layers.Concatenate(name='decoder_concatenate4')([crop4, y4])</span><br><span class="line">    y3 = compose(keras.layers.Conv2D(512, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv4_1'),</span><br><span class="line">                 keras.layers.Conv2D(512, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv4_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling3'))(concatenate4)</span><br><span class="line">    concatenate3 = keras.layers.Concatenate(name='decoder_concatenate3')([crop3, y3])</span><br><span class="line">    y2 = compose(keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv3_1'),</span><br><span class="line">                 keras.layers.Conv2D(256, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv3_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling2'))(concatenate3)</span><br><span class="line">    concatenate4 = keras.layers.Concatenate(name='decoder_concatenate2')([crop2, y2])</span><br><span class="line">    y1 = compose(keras.layers.Conv2D(128, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv2_1'),</span><br><span class="line">                 keras.layers.Conv2D(128, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv2_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling1'))(concatenate4)</span><br><span class="line">    concatenate4 = keras.layers.Concatenate(name='decoder_concatenate1')([crop1, y1])</span><br><span class="line">    y0 = compose(keras.layers.Conv2D(64, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv1_1'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'valid', activation='relu', name='decoder_conv1_2'))(concatenate4)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Conv2D(21, (1, 1), (1, 1), 'same', activation='softmax', name='conv_softmax')(y0)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='UNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = unet(input_shape=(572, 572, 3))</span><br><span class="line">    model.build(input_shape=(None, 572, 572, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Semantic_segmentation/UNet_R.png" alt="UNet"></p>
<h1 id="Shape数据集完整实战"><a href="#Shape数据集完整实战" class="headerlink" title="Shape数据集完整实战"></a><font size="5" color="red">Shape数据集完整实战</font></h1><h2 id="文件路径关系说明"><a href="#文件路径关系说明" class="headerlink" title="文件路径关系说明"></a>文件路径关系说明</h2><ul>
<li>project<ul>
<li>shape<ul>
<li>train_imgs(训练集图像文件夹)</li>
<li>train_mask(训练集掩模文件夹)</li>
<li>test_imgs(测试集图像文件夹)</li>
</ul>
</li>
<li>UNet_weight(模型权重文件夹)</li>
<li>UNet_test_result(测试集结果文件夹)</li>
<li>UNet.py</li>
</ul>
</li>
</ul>
<h2 id="实战步骤说明"><a href="#实战步骤说明" class="headerlink" title="实战步骤说明"></a>实战步骤说明</h2><ol>
<li>语义分割实战运行较为简单，因为它的输入的训练数据为图像，输入的标签数据也是图像，首先<strong>要对输入的标签数据进行编码，转换为类别信息</strong>，要和网络的输出维度相匹配，从(batch_size, height, width, 1)转换为(batch_size, height, width, num_class + 1)，<strong>某个像素点为哪一个类别，则在该通道上置1，其余通道置0</strong>。即神经网络的输入大小为(batch_size, height, width, 3)，输出大小为(batch_size, height, width, num_class + 1)。</li>
<li>设计损失函数，简单情况设置交叉熵损失函数即可达到较好效果。</li>
<li>搭建神经网络，<strong>设置合适参数</strong>，进行训练。</li>
<li>预测时，需要根据神经网络的输出进行<strong>逆向解码(编码的反过程)</strong>，寻找<strong>每一个像素点，哪一个通道上值最大则归为哪一个类别</strong>，即可完成实战的过程。</li>
</ol>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>设置的图像<strong>类别数为实际类别数+1</strong>，1代表背景类别，<strong>此数据集为3类，最后的通道数为4，每一个通道预测一类物体</strong>。在通道方向求Softmax，并且求出最大的索引，索引为0则代表背景，索引为1则代表圆形，索引为2则代表三角形，索引为3则代表正方形。</li>
<li>实际中用到的图像的尺寸一般都不是特别大，因此<strong>不需要将图像进行Crop，所以卷积的padding修改为same</strong>。</li>
<li>损失函数使用交叉熵即可，使用加权Loss，计算量较大，而且需要计算边缘操作。</li>
<li>设置了<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li>使用<strong>yield</strong>关键字，产生可迭代对象，不用将所有的数据都保存下来，大大节约内存。</li>
<li>其中将1000个数据，分成800个训练集，100个验证集和100个测试集，小伙伴们可以自行修改。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>UNet的<strong>特征提取网络类似于VGG</strong>，小伙伴们可以参考特征提取网络部分内容，选择其他的网络进行特征提取，比较不同网络参数量，运行速度，最终结果之间的差异。</li>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
</ol>
<h2 id="完整实战代码"><a href="#完整实战代码" class="headerlink" title="完整实战代码"></a>完整实战代码</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def small_unet(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = compose(keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv1_1'),</span><br><span class="line">                 keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv1_2'))(x)</span><br><span class="line">    x2 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool1'),</span><br><span class="line">                 keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv2_1'),</span><br><span class="line">                 keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv2_2'))(x1)</span><br><span class="line">    x3 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool2'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv3_1'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv3_2'))(x2)</span><br><span class="line">    x4 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool3'),</span><br><span class="line">                 keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv4_1'),</span><br><span class="line">                 keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv4_2'))(x3)</span><br><span class="line">    x5 = compose(keras.layers.MaxPool2D((2, 2), name='encoder_maxpool4'),</span><br><span class="line">                 keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv5_1'),</span><br><span class="line">                 keras.layers.Conv2D(256, (3, 3), (1, 1), 'same', activation='relu', name='encoder_conv5_2'))(x4)</span><br><span class="line"></span><br><span class="line">    y4 = keras.layers.UpSampling2D((2, 2), name='decoder_upsampling4')(x5)</span><br><span class="line">    concatenate4 = keras.layers.Concatenate(name='decoder_concatenate4')([x4, y4])</span><br><span class="line">    y3 = compose(keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv4_1'),</span><br><span class="line">                 keras.layers.Conv2D(128, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv4_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling3'))(concatenate4)</span><br><span class="line">    concatenate3 = keras.layers.Concatenate(name='decoder_concatenate3')([x3, y3])</span><br><span class="line">    y2 = compose(keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv3_1'),</span><br><span class="line">                 keras.layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv3_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling2'))(concatenate3)</span><br><span class="line">    concatenate4 = keras.layers.Concatenate(name='decoder_concatenate2')([x2, y2])</span><br><span class="line">    y1 = compose(keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv2_1'),</span><br><span class="line">                 keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv2_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling1'))(concatenate4)</span><br><span class="line">    concatenate4 = keras.layers.Concatenate(name='decoder_concatenate1')([x1, y1])</span><br><span class="line">    y0 = compose(keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv1_1'),</span><br><span class="line">                 keras.layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu', name='decoder_conv1_2'))(concatenate4)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Conv2D(num_class, (1, 1), (1, 1), 'same', activation='softmax', name='conv_softmax')(y0)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='Small_UNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generate_arrays_from_file(train_data, batch_size):</span><br><span class="line">    # 获取总长度</span><br><span class="line">    n = len(train_data)</span><br><span class="line">    i = 0</span><br><span class="line">    while 1:</span><br><span class="line">        X_train = []</span><br><span class="line">        Y_train = []</span><br><span class="line">        # 获取一个batch_size大小的数据</span><br><span class="line">        for _ in range(batch_size):</span><br><span class="line">            if i == 0:</span><br><span class="line">                np.random.shuffle(train_data)</span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(imgs_path + '\\' + str(train_data[i]) + '.jpg')</span><br><span class="line">            img = img / 127.5 - 1</span><br><span class="line">            X_train.append(img)</span><br><span class="line"></span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(mask_path + '\\' + str(train_data[i]) + '.png')</span><br><span class="line">            seg_labels = np.zeros((img_size[0], img_size[1], num_class))</span><br><span class="line">            for c in range(num_class):</span><br><span class="line">                seg_labels[:, :, c] = (img[:, :, 0] == c).astype(int)</span><br><span class="line">            Y_train.append(seg_labels)</span><br><span class="line"></span><br><span class="line">            # 读完一个周期后重新开始</span><br><span class="line">            i = (i + 1) % n</span><br><span class="line">        yield tf.constant(X_train), tf.constant(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # 包括背景</span><br><span class="line">    num_class = 4 </span><br><span class="line">    train_data = list(range(800))</span><br><span class="line">    validation_data = list(range(800, 900))</span><br><span class="line">    test_data = range(900, 1000)</span><br><span class="line">    epochs = 50</span><br><span class="line">    batch_size = 16</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    colors = [[0, 0, 0], [0, 0, 128], [0, 128, 0], [128, 0, 0]]</span><br><span class="line"></span><br><span class="line">    mask_path = r'.\shape\train_mask'</span><br><span class="line">    imgs_path = r'.\shape\train_imgs'</span><br><span class="line">    test_path = r'.\shape\test_imgs'</span><br><span class="line">    save_path = r'.\UNet_test_result'</span><br><span class="line">    weight_path = r'.\UNet_weight'</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(save_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(save_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(weight_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(weight_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    model = small_unet(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model.build(input_shape=(None, img_size[0], img_size[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizor = keras.optimizers.Adam(lr=1e-3)</span><br><span class="line">    lossor = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizor, loss=lossor, metrics=['accuracy'])</span><br><span class="line"></span><br><span class="line">    # 保存的方式，3世代保存一次</span><br><span class="line">    checkpoint_period = keras.callbacks.ModelCheckpoint(</span><br><span class="line">        weight_path + '\\' + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        save_weights_only=True,</span><br><span class="line">        save_best_only=True,</span><br><span class="line">        period=3</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 学习率下降的方式，val_loss3次不下降就下降学习率继续训练</span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        factor=0.5,</span><br><span class="line">        patience=3,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        min_delta=0,</span><br><span class="line">        patience=10,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model.fit_generator(generate_arrays_from_file(train_data, batch_size),</span><br><span class="line">                        steps_per_epoch=max(1, len(train_data) // batch_size),</span><br><span class="line">                        validation_data=generate_arrays_from_file(validation_data, batch_size),</span><br><span class="line">                        validation_steps=max(1, len(validation_data) // batch_size),</span><br><span class="line">                        epochs=epochs,</span><br><span class="line">                        callbacks=[checkpoint_period, reduce_lr, early_stopping])</span><br><span class="line"></span><br><span class="line">    for name in test_data:</span><br><span class="line">        test_img_path = test_path + '\\' + str(name) + '.jpg'</span><br><span class="line">        save_img_path = save_path + '\\' + str(name) + '.png'</span><br><span class="line">        test_img = cv.imread(test_img_path)</span><br><span class="line">        test_img = tf.constant([test_img / 127.5 - 1])</span><br><span class="line">        test_mask = model.predict(test_img)</span><br><span class="line">        test_mask = np.reshape(test_mask, (img_size[0], img_size[1], num_class))</span><br><span class="line">        test_mask = np.argmax(test_mask, axis=-1)</span><br><span class="line">        seg_img = np.zeros((img_size[0], img_size[1], 3))</span><br><span class="line">        for c in range(num_class):</span><br><span class="line">            seg_img[:, :, 0] += ((test_mask == c) * (colors[c][0]))</span><br><span class="line">            seg_img[:, :, 1] += ((test_mask == c) * (colors[c][1]))</span><br><span class="line">            seg_img[:, :, 2] += ((test_mask == c) * (colors[c][2]))</span><br><span class="line">        seg_img = seg_img.astype(np.uint8)</span><br><span class="line">        cv.imwrite(save_img_path, seg_img)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Semantic_segmentation/UNet_T.png" alt="UNet"></p>
<h1 id="UNet小结"><a href="#UNet小结" class="headerlink" title="UNet小结"></a><font size="5" color="red">UNet小结</font></h1><p>  UNet是一种简单的语义分割网络，在输入图像尺寸为572x572时，参数量为31M。因为其<strong>padding方式使其图像尺寸缩小，适合于大尺寸图像的分割</strong>，并且采用<strong>加权损失函数</strong>和优秀的<strong>图像增强</strong>操作，使得其在医学图像处理中有良好的表现。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>语义分割网络</category>
      </categories>
  </entry>
  <entry>
    <title>SegNet</title>
    <url>/2020/04/18/Semantic_segmentation%20SegNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">SegNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>SegNet</strong>:由剑桥大学提出，2015年被提交到CVPR，但是最后没有发表，反而在<strong>2017年发表在TPAMI</strong>上。是一种简单高效的语义分割模型。<a id="more"></a></p>
<p><img src="/images/Semantic_segmentation/SegNet.png" alt="SegNet"></p>
<h1 id="SegNet特点"><a href="#SegNet特点" class="headerlink" title="SegNet特点"></a><font size="5" color="red">SegNet特点</font></h1><p>  <font size="3">网络分为两个部分，<strong>编码(Encoder)</strong>和<strong>解码(Decoder)</strong>，结构简单，网络易于实现</font><br>  <font size="3">使用了<strong>Maxpooling-Indices(最大池化索引)</strong>来进行图像分辨率的提高，而不是采用上采样或者反卷积。</font></p>
<h1 id="Maxpooling-Indices-最大池化索引-与Upsampling-上采样-和Deconvolution-反卷积-之间的区别"><a href="#Maxpooling-Indices-最大池化索引-与Upsampling-上采样-和Deconvolution-反卷积-之间的区别" class="headerlink" title="Maxpooling-Indices(最大池化索引)与Upsampling(上采样)和Deconvolution(反卷积)之间的区别"></a><font size="5" color="red">Maxpooling-Indices(最大池化索引)与Upsampling(上采样)和Deconvolution(反卷积)之间的区别</font></h1><p>  <font size="3"><strong>Maxpooling-Indices(最大池化索引)</strong>：又称为<strong>Unpooling(反池化)</strong>，池化后<strong>记录最大值所在的位置</strong>，在反池化的过程中，给相应位置上写入值，<strong>其他位置为0</strong>。这个方法没有参数，<strong>但是这个方法并不常用，因为存在大量的稀疏数据，使模型收敛速度大大降低。</strong></font><br>  <font size="3"><strong>Upsampling(上采样)</strong>：将输入<strong>resize到设置大小</strong>，然后利用指定的插值方法<strong>对周围的值进行插值</strong>，常用<strong>最近邻插值</strong>和<strong>双线性插值</strong>。因为相邻区域的像素和特征应该是相似的，因此这个方法特别常用，<strong>既没有参数，也不会存在稀疏数据。</strong></font><br>  <font size="3"><strong>Deconvolution(反卷积)</strong>：<strong>本质是卷积</strong>，注意<strong>反卷积并不能从卷积的结果返回到卷积前的数据，只能返回到卷积前的尺寸</strong>。卷积通过设置kernel_size卷积核大小，strides步长和padding填充方式可以将图像的分辨率降低，相反的反卷积可以通过设置kernel_size卷积核大小，strides步长和padding填充方式<strong>先对数据进行填充，然后再进行卷积操作</strong>，可以将图像的分辨率增加。<strong>这个方法不推荐经常使用，因为存在大量参数，而且可能会存在棋盘格效应，可以参考<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">棋盘格可视化</a></strong>。</font><br><img src="/images/Semantic_segmentation/SegNet_U.png" alt="SegNet"></p>
<h1 id="SegNet图像分析"><a href="#SegNet图像分析" class="headerlink" title="SegNet图像分析"></a><font size="5" color="red">SegNet图像分析</font></h1><p><img src="/images/Semantic_segmentation/SegNet_A.png" alt="SegNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Indices_Maxpool(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(Indices_Maxpool, self).__init__(name=name)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        val, index = inputs</span><br><span class="line">        input_size = index.shape</span><br><span class="line">        output_size = [x * 2 if i == 0 or i == 1 else x for i, x in enumerate(input_size[1:])]</span><br><span class="line">        output = tf.reshape(tf.scatter_nd(tf.reshape(index, (-1, 1)), tf.reshape(val, (-1,)), (batch_size * np.prod(output_size),)), [-1] + output_size)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Convs(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, name):</span><br><span class="line">        super(Convs, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters, (3, 3), (1, 1), padding='same'))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def segnet(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, batch_size=batch_size, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = compose(Convs(64, name='encoder_conv1_1'),</span><br><span class="line">                 Convs(64, name='encoder_conv1_2'))(x)</span><br><span class="line">    val_1, index_1 = tf.nn.max_pool_with_argmax(x1, (2, 2), (2, 2), 'VALID', name='maxpool1')</span><br><span class="line">    x2 = compose(Convs(128, name='encoder_conv2_1'),</span><br><span class="line">                 Convs(128, name='encoder_conv2_2'))(val_1)</span><br><span class="line">    val_2, index_2 = tf.nn.max_pool_with_argmax(x2, (2, 2), (2, 2), 'VALID', name='maxpool2')</span><br><span class="line">    x3 = compose(Convs(256, name='encoder_conv3_1'),</span><br><span class="line">                 Convs(256, name='encoder_conv3_2'),</span><br><span class="line">                 Convs(256, name='encoder_conv3_3'))(val_2)</span><br><span class="line">    val_3, index_3 = tf.nn.max_pool_with_argmax(x3, (2, 2), (2, 2), 'VALID', name='maxpool3')</span><br><span class="line">    x4 = compose(Convs(512, name='encoder_conv4_1'),</span><br><span class="line">                 Convs(512, name='encoder_conv4_2'),</span><br><span class="line">                 Convs(512, name='encoder_conv4_3'))(val_3)</span><br><span class="line">    val_4, index_4 = tf.nn.max_pool_with_argmax(x4, (2, 2), (2, 2), 'VALID', name='maxpool4')</span><br><span class="line">    x5 = compose(Convs(512, name='encoder_conv5_1'),</span><br><span class="line">                 Convs(512, name='encoder_conv5_2'),</span><br><span class="line">                 Convs(512, name='encoder_conv5_3'))(val_4)</span><br><span class="line">    val_5, index_5 = tf.nn.max_pool_with_argmax(x5, (2, 2), (2, 2), 'VALID', name='maxpool5')</span><br><span class="line"></span><br><span class="line">    indices_maxpool5 = Indices_Maxpool(name='indices_maxpool5')([val_5, index_5])</span><br><span class="line">    y5 = compose(Convs(512, name='decoder_conv5_1'),</span><br><span class="line">                 Convs(512, name='decoder_conv5_2'),</span><br><span class="line">                 Convs(512, name='decoder_conv5_3'))(indices_maxpool5)</span><br><span class="line">    indices_maxpool4 = Indices_Maxpool(name='indices_maxpool4')([y5, index_4])</span><br><span class="line">    y4 = compose(Convs(512, name='decoder_conv4_1'),</span><br><span class="line">                 Convs(512, name='decoder_conv4_2'),</span><br><span class="line">                 Convs(256, name='decoder_conv4_3'))(indices_maxpool4)</span><br><span class="line">    indices_maxpool3 = Indices_Maxpool(name='indices_maxpool3')([y4, index_3])</span><br><span class="line">    y3 = compose(Convs(256, name='decoder_conv3_1'),</span><br><span class="line">                 Convs(256, name='decoder_conv3_2'),</span><br><span class="line">                 Convs(128, name='decoder_conv3_3'))(indices_maxpool3)</span><br><span class="line">    indices_maxpool2 = Indices_Maxpool(name='indices_maxpool2')([y3, index_2])</span><br><span class="line">    y2 = compose(Convs(128, name='decoder_conv2_1'),</span><br><span class="line">                 Convs(64, name='decoder_conv2_2'))(indices_maxpool2)</span><br><span class="line">    indices_maxpool1 = Indices_Maxpool(name='indices_maxpool1')([y2, index_1])</span><br><span class="line">    y1 = compose(Convs(64, name='decoder_conv1_1'),</span><br><span class="line">                 Convs(21, name='decoder_conv1_2'))(indices_maxpool1)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Softmax(name='softmax')(y1)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='SegNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    batch_size = 16</span><br><span class="line">    model = segnet(input_shape=(512, 512, 3))</span><br><span class="line">    model.build(input_shape=(512, 512, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Semantic_segmentation/SegNet_R.png" alt="SegNet"></p>
<h1 id="Shape数据集完整实战"><a href="#Shape数据集完整实战" class="headerlink" title="Shape数据集完整实战"></a><font size="5" color="red">Shape数据集完整实战</font></h1><h2 id="文件路径关系说明"><a href="#文件路径关系说明" class="headerlink" title="文件路径关系说明"></a>文件路径关系说明</h2><ul>
<li>project<ul>
<li>shape<ul>
<li>train_imgs(训练集图像文件夹)</li>
<li>train_mask(训练集掩模文件夹)</li>
<li>test_imgs(测试集图像文件夹)</li>
</ul>
</li>
<li>SegNet_weight(模型权重文件夹)</li>
<li>SegNet_test_result(测试集结果文件夹)</li>
<li>SegNet.py</li>
</ul>
</li>
</ul>
<h2 id="实战步骤说明"><a href="#实战步骤说明" class="headerlink" title="实战步骤说明"></a>实战步骤说明</h2><ol>
<li>语义分割实战运行较为简单，因为它的输入的训练数据为图像，输入的标签数据也是图像，首先<strong>要对输入的标签数据进行编码，转换为类别信息</strong>，要和网络的输出维度相匹配，从(batch_size, height, width, 1)转换为(batch_size, height, width, num_class + 1)，<strong>某个像素点为哪一个类别，则在该通道上置1，其余通道置0</strong>。即神经网络的输入大小为(batch_size, height, width, 3)，输出大小为(batch_size, height, width, num_class + 1)。</li>
<li>设计损失函数，简单情况设置交叉熵损失函数即可达到较好效果。</li>
<li>搭建神经网络，<strong>设置合适参数</strong>，进行训练。</li>
<li>预测时，需要根据神经网络的输出进行<strong>逆向解码(编码的反过程)</strong>，寻找<strong>每一个像素点，哪一个通道上值最大则归为哪一个类别</strong>，即可完成实战的过程。</li>
</ol>
<h2 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h2><ol>
<li>设置的图像<strong>类别数为实际类别数+1</strong>，1代表背景类别，<strong>此数据集为3类，最后的通道数为4，每一个通道预测一类物体</strong>。在通道方向求Softmax，并且求出最大的索引，索引为0则代表背景，索引为1则代表圆形，索引为2则代表三角形，索引为3则代表正方形。</li>
<li><strong>最大池化收敛速度较慢，因此换成上采样，不但可以使模型更加简单，而且可以加快网络的收敛速度。</strong></li>
<li>设置了<strong>权重的保存方式</strong>，<strong>学习率的下降方式</strong>和<strong>早停方式</strong>。</li>
<li>使用<strong>yield</strong>关键字，产生可迭代对象，不用将所有的数据都保存下来，大大节约内存。</li>
<li>其中将1000个数据，分成800个训练集，100个验证集和100个测试集，小伙伴们可以自行修改。</li>
<li>注意其中的一些维度变换和<strong>numpy</strong>，<strong>tensorflow</strong>常用操作，否则在阅读代码时可能会产生一些困难。</li>
<li>SegNet的<strong>特征提取网络(编码网络)类似于VGG</strong>，小伙伴们可以参考特征提取网络部分内容，选择其他的网络进行特征提取，比较不同网络参数量，运行速度，最终结果之间的差异。</li>
<li>图像输入可以先将其<strong>归一化到0-1之间或者-1-1之间</strong>，因为网络的参数一般都比较小，所以归一化后计算方便，收敛较快。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
</ol>
<h2 id="完整实战代码"><a href="#完整实战代码" class="headerlink" title="完整实战代码"></a>完整实战代码</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from functools import reduce</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Convs(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, name):</span><br><span class="line">        super(Convs, self).__init__(name=name)</span><br><span class="line">        self.blocks = keras.Sequential()</span><br><span class="line">        self.blocks.add(keras.layers.Conv2D(filters, (3, 3), (1, 1), padding='same'))</span><br><span class="line">        self.blocks.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.blocks.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        output = self.blocks(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def small_segnet(input_shape):</span><br><span class="line"></span><br><span class="line">    input_tensor = keras.layers.Input(shape=input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x1 = compose(Convs(32, name='encoder_conv1_1'),</span><br><span class="line">                 Convs(32, name='encoder_conv1_2'),</span><br><span class="line">                 keras.layers.MaxPool2D((2, 2), name='encoder_maxpool1'))(x)</span><br><span class="line">    x2 = compose(Convs(64, name='encoder_conv2_1'),</span><br><span class="line">                 Convs(64, name='encoder_conv2_2'),</span><br><span class="line">                 keras.layers.MaxPool2D((2, 2), name='encoder_maxpool2'))(x1)</span><br><span class="line">    x3 = compose(Convs(128, name='encoder_conv3_1'),</span><br><span class="line">                 Convs(128, name='encoder_conv3_2'),</span><br><span class="line">                 keras.layers.MaxPool2D((2, 2), name='encoder_maxpool3'))(x2)</span><br><span class="line">    x4 = compose(Convs(256, name='encoder_conv4_1'),</span><br><span class="line">                 Convs(256, name='encoder_conv4_2'),</span><br><span class="line">                 keras.layers.MaxPool2D((2, 2), name='encoder_maxpool4'))(x3)</span><br><span class="line"></span><br><span class="line">    y4 = compose(Convs(256, name='decoder_conv4_1'),</span><br><span class="line">                 Convs(256, name='decoder_conv4_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling4'))(x4)</span><br><span class="line">    y3 = compose(Convs(128, name='decoder_conv3_1'),</span><br><span class="line">                 Convs(128, name='decoder_conv3_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling3'))(y4)</span><br><span class="line">    y2 = compose(Convs(64, name='decoder_conv2_1'),</span><br><span class="line">                 Convs(64, name='decoder_conv2_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling2'))(y3)</span><br><span class="line">    y1 = compose(Convs(32, name='decoder_conv1_1'),</span><br><span class="line">                 Convs(32, name='decoder_conv1_2'),</span><br><span class="line">                 keras.layers.UpSampling2D((2, 2), name='decoder_upsampling1'))(y2)</span><br><span class="line"></span><br><span class="line">    output = keras.layers.Conv2D(num_class, (3, 3), (1, 1), 'same', activation='softmax', name='conv_softmax')(y1)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, output, name='Small_SegNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generate_arrays_from_file(train_data, batch_size):</span><br><span class="line">    # 获取总长度</span><br><span class="line">    n = len(train_data)</span><br><span class="line">    i = 0</span><br><span class="line">    while 1:</span><br><span class="line">        X_train = []</span><br><span class="line">        Y_train = []</span><br><span class="line">        # 获取一个batch_size大小的数据</span><br><span class="line">        for _ in range(batch_size):</span><br><span class="line">            if i == 0:</span><br><span class="line">                np.random.shuffle(train_data)</span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(imgs_path + '\\' + str(train_data[i]) + '.jpg')</span><br><span class="line">            img = img / 127.5 - 1</span><br><span class="line">            X_train.append(img)</span><br><span class="line"></span><br><span class="line">            # 从文件中读取图像</span><br><span class="line">            img = cv.imread(mask_path + '\\' + str(train_data[i]) + '.png')</span><br><span class="line">            seg_labels = np.zeros((img_size[0], img_size[1], num_class))</span><br><span class="line">            for c in range(num_class):</span><br><span class="line">                seg_labels[:, :, c] = (img[:, :, 0] == c).astype(int)</span><br><span class="line">            Y_train.append(seg_labels)</span><br><span class="line"></span><br><span class="line">            # 读完一个周期后重新开始</span><br><span class="line">            i = (i + 1) % n</span><br><span class="line">        yield tf.constant(X_train), tf.constant(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # 包括背景</span><br><span class="line">    num_class = 4</span><br><span class="line">    train_data = list(range(800))</span><br><span class="line">    validation_data = list(range(800, 900))</span><br><span class="line">    test_data = range(900, 1000)</span><br><span class="line">    epochs = 50</span><br><span class="line">    batch_size = 16</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    img_size = (128, 128)</span><br><span class="line">    colors = [[0, 0, 0], [0, 0, 128], [0, 128, 0], [128, 0, 0]]</span><br><span class="line"></span><br><span class="line">    mask_path = r'.\shape\train_mask'</span><br><span class="line">    imgs_path = r'.\shape\train_imgs'</span><br><span class="line">    test_path = r'.\shape\test_imgs'</span><br><span class="line">    save_path = r'.\SegNet_test_result'</span><br><span class="line">    weight_path = r'.\SegNet_weight'</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(save_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(save_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        os.mkdir(weight_path)</span><br><span class="line">    except FileExistsError:</span><br><span class="line">        print(weight_path + 'has been exist')</span><br><span class="line"></span><br><span class="line">    model = small_segnet(input_shape=(img_size[0], img_size[1], 3))</span><br><span class="line">    model.build(input_shape=(None, img_size[0], img_size[1], 3))</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    optimizor = keras.optimizers.Adam(lr=1e-3)</span><br><span class="line">    lossor = keras.losses.BinaryCrossentropy()</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=optimizor, loss=lossor, metrics=['accuracy'])</span><br><span class="line"></span><br><span class="line">    # 保存的方式，3世代保存一次</span><br><span class="line">    checkpoint_period = keras.callbacks.ModelCheckpoint(</span><br><span class="line">        weight_path + '\\' + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        save_weights_only=True,</span><br><span class="line">        save_best_only=True,</span><br><span class="line">        period=3</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 学习率下降的方式，val_loss3次不下降就下降学习率继续训练</span><br><span class="line">    reduce_lr = keras.callbacks.ReduceLROnPlateau(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        factor=0.5,</span><br><span class="line">        patience=3,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止</span><br><span class="line">    early_stopping = keras.callbacks.EarlyStopping(</span><br><span class="line">        monitor='val_loss',</span><br><span class="line">        min_delta=0,</span><br><span class="line">        patience=10,</span><br><span class="line">        verbose=1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    model.fit_generator(generate_arrays_from_file(train_data, batch_size),</span><br><span class="line">                        steps_per_epoch=max(1, len(train_data) // batch_size),</span><br><span class="line">                        validation_data=generate_arrays_from_file(validation_data, batch_size),</span><br><span class="line">                        validation_steps=max(1, len(validation_data) // batch_size),</span><br><span class="line">                        epochs=epochs,</span><br><span class="line">                        callbacks=[checkpoint_period, reduce_lr, early_stopping])</span><br><span class="line"></span><br><span class="line">    for name in test_data:</span><br><span class="line">        test_img_path = test_path + '\\' + str(name) + '.jpg'</span><br><span class="line">        save_img_path = save_path + '\\' + str(name) + '.png'</span><br><span class="line">        test_img = cv.imread(test_img_path)</span><br><span class="line">        test_img = tf.constant([test_img / 127.5 - 1])</span><br><span class="line">        test_mask = model.predict(test_img)</span><br><span class="line">        test_mask = np.reshape(test_mask, (img_size[0], img_size[1], num_class))</span><br><span class="line">        test_mask = np.argmax(test_mask, axis=-1)</span><br><span class="line">        seg_img = np.zeros((img_size[0], img_size[1], 3))</span><br><span class="line">        for c in range(num_class):</span><br><span class="line">            seg_img[:, :, 0] += ((test_mask == c) * (colors[c][0]))</span><br><span class="line">            seg_img[:, :, 1] += ((test_mask == c) * (colors[c][1]))</span><br><span class="line">            seg_img[:, :, 2] += ((test_mask == c) * (colors[c][2]))</span><br><span class="line">        seg_img = seg_img.astype(np.uint8)</span><br><span class="line">        cv.imwrite(save_img_path, seg_img)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="模型运行结果"><a href="#模型运行结果" class="headerlink" title="模型运行结果"></a>模型运行结果</h2><p><img src="/images/Semantic_segmentation/SegNet_T.png" alt="SegNet"></p>
<h1 id="SegNet小结"><a href="#SegNet小结" class="headerlink" title="SegNet小结"></a><font size="5" color="red">SegNet小结</font></h1><p>  SegNet是一种简单的语义分割网络，从上图可以看出SegNet模型的参数量只有29M，虽然现在SegNet网络不是最好的语义分割网络，但是其编码解码结构的思想，对后面的深度学习网络的发展有重要的影响。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>语义分割网络</category>
      </categories>
  </entry>
  <entry>
    <title>岛屿数量(Leetcode 200)</title>
    <url>/2020/04/17/program%20Leetcode200/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode200.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   岛屿数量问题是一个经典的问题，与朋友圈问题(Leetcode 547)类似，只不过朋友圈问题中的矩阵是对称的，而岛屿数量中的矩阵是非对称的。此题可以使用DFS，BFS和并查集进行求解。</p>
<a id="more"></a>
<h1 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a><font size="5" color="red">DFS</font></h1><p>DFS是先找到一块岛屿，然后对这个岛屿进行深度优先搜索，已知沿着某一个路径走下去，如果没用路可以走则回溯。直到所有的路径都走完，说明将这个岛屿探索完毕，将其剔除，从剩余的地图上继续寻找，直到所有的岛屿都找到，则算法结束，有关DFS的知识可以参考我的另一篇博客深度优先搜索(Depth-First-Search)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def numIslands(self, grid):</span><br><span class="line">        row = len(grid)</span><br><span class="line">        if row == 0:</span><br><span class="line">            return 0</span><br><span class="line">        col = len(grid[0])</span><br><span class="line"></span><br><span class="line">        def dfs(x, y):</span><br><span class="line">            grid[x][y] = 0</span><br><span class="line">            for new_x, new_y in [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]:</span><br><span class="line">                if 0 &lt;= new_x &lt; row and 0 &lt;= new_y &lt; col and grid[new_x][new_y] == '1':</span><br><span class="line">                    dfs(new_x, new_y)</span><br><span class="line"></span><br><span class="line">        num_islands = 0</span><br><span class="line">        for r in range(row):</span><br><span class="line">            for c in range(col):</span><br><span class="line">                if grid[r][c] == "1":</span><br><span class="line">                    num_islands += 1</span><br><span class="line">                    dfs(r, c)</span><br><span class="line">        return num_islands</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a><font size="5" color="red">BFS</font></h1><p>BFS是先找到一块岛屿，然后对这个岛屿进行广度优先搜索，以某个点为中心，先寻找距离该点为1的所有陆地，然后再寻找与该点距离为2的所有陆地，依次进性，直到将与该点连通的所有陆地都寻找完毕，说明将这个岛屿探索完毕，将其剔除，从剩余的地图上继续寻找，直到所有的岛屿都找到，则算法结束，有关BFS的知识可以参考我的另一篇博客广度优先搜索(Breadth-First-Search)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def numIslands(self, grid):</span><br><span class="line">        row = len(grid)</span><br><span class="line">        if row == 0:</span><br><span class="line">            return 0</span><br><span class="line">        col = len(grid[0])</span><br><span class="line"></span><br><span class="line">        num_islands = 0</span><br><span class="line">        for r in range(row):</span><br><span class="line">            for c in range(col):</span><br><span class="line">                if grid[r][c] == "1":</span><br><span class="line">                    num_islands += 1</span><br><span class="line">                    grid[r][c] = "0"</span><br><span class="line">                    neighbors = deque([(r, c)])</span><br><span class="line">                    while neighbors:</span><br><span class="line">                        i, j = neighbors.popleft()</span><br><span class="line">                        for x, y in [(i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)]:</span><br><span class="line">                            if 0 &lt;= x &lt; row and 0 &lt;= y &lt; col and grid[x][y] == "1":</span><br><span class="line">                                neighbors.append((x, y))</span><br><span class="line">                                grid[x][y] = "0"</span><br><span class="line"></span><br><span class="line">        return num_islands</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a><font size="5" color="red">并查集</font></h1><p>并查集算法不是很常用，但是思路很清晰，初始设每个陆地都是一个岛屿，比较两个相邻的岛屿是否为同一个岛屿，如果不是同一个岛屿则合并这两个岛屿，并将岛屿数量减1，最后剩余的岛屿数量就是本题的解。难点在于如何判断两个相邻岛屿为同一个岛屿，而且如何合并两个岛屿？每一个岛屿设定一个首都即可，如果两个岛屿的首都相同，则在同一个岛屿上，否则不在同一个岛屿，合并时直接选择某一个首都最为总首都即可实现岛屿合并。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class UnionFind:</span><br><span class="line">    def __init__(self, grid):</span><br><span class="line">        m, n = len(grid), len(grid[0])</span><br><span class="line">        self.count = 0</span><br><span class="line">        self.parent = [-1] * (m * n)</span><br><span class="line">        self.rank = [0] * (m * n)</span><br><span class="line">        for i in range(m):</span><br><span class="line">            for j in range(n):</span><br><span class="line">                if grid[i][j] == "1":</span><br><span class="line">                    self.parent[i * n + j] = i * n + j</span><br><span class="line">                    self.count += 1</span><br><span class="line"></span><br><span class="line">    def find(self, i):</span><br><span class="line">        if self.parent[i] != i:</span><br><span class="line">            self.parent[i] = self.find(self.parent[i])</span><br><span class="line">        return self.parent[i]</span><br><span class="line"></span><br><span class="line">    def union(self, x, y):</span><br><span class="line">        rootx = self.find(x)</span><br><span class="line">        rooty = self.find(y)</span><br><span class="line">        if rootx != rooty:</span><br><span class="line">            self.parent[rooty] = rootx</span><br><span class="line">            self.count -= 1</span><br><span class="line"></span><br><span class="line">    def getCount(self):</span><br><span class="line">        return self.count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def numIslands(self, grid):</span><br><span class="line">        nr = len(grid)</span><br><span class="line">        if nr == 0:</span><br><span class="line">            return 0</span><br><span class="line">        nc = len(grid[0])</span><br><span class="line"></span><br><span class="line">        uf = UnionFind(grid)</span><br><span class="line">        for r in range(nr):</span><br><span class="line">            for c in range(nc):</span><br><span class="line">                if grid[r][c] == "1":</span><br><span class="line">                    grid[r][c] = "0"</span><br><span class="line">                    for x, y in [(r - 1, c), (r + 1, c), (r, c - 1), (r, c + 1)]:</span><br><span class="line">                        if 0 &lt;= x &lt; nr and 0 &lt;= y &lt; nc and grid[x][y] == "1":</span><br><span class="line">                            uf.union(r * nc + c, x * nc + y)</span><br><span class="line"></span><br><span class="line">        return uf.getCount()</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  朋友圈问题是一类经典的面试问题，因此小伙伴们务必掌握基本的DFS和BFS算法，至于并查集问题，大家理解即可，因为并查集实现也没用DFS和BFS容易，而且时间复杂度也并没有提升，只需要小伙伴们能够说出并查集思路。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>深度优先搜索</category>
        <category>广度优先搜索</category>
        <category>并查集</category>
      </categories>
  </entry>
  <entry>
    <title>语义分割数据集</title>
    <url>/2020/04/15/Semantic_segmentation%20Dataset/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Data Set</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>语义分割:</strong>是计算机视觉的<strong>基础任务</strong>，在语义分割中我们需要将视觉输入分为不同的<strong>可解释类别</strong>，和聚类分割方法不同点在于此，其类别在真实世界中是有意义的，而聚类分割是可以将物体分成若干部分，但是每一部分不一定是有语义的，在<strong>自动驾驶</strong>，<strong>图像搜索</strong>等等领域都是非常重要的。<br><a id="more"></a></p>
<p><img src="/images/Semantic_segmentation/Dataset.png" alt="Dataset"></p>
<h1 id="数据集以及IOU介绍"><a href="#数据集以及IOU介绍" class="headerlink" title="数据集以及IOU介绍"></a><font size="5" color="red">数据集以及IOU介绍</font></h1><p><strong>数据集</strong>：为了方便模型调试的方便，我的博客中介绍的数据集是一种简单的Shape数据集，只有1000个训练样本，为了加快训练速度，数据集的大小我也调整为128x128，这个数据集只有三类物体，分别是圆形，三角形和正方形，图像数据为jpg文件，掩模数据为png文件。<br><strong>mask图像</strong>：mask图像给初学者第一眼看上去是懵逼的，当然包括我也是，这不是全黑的图像吗？这有何意义呢？掩模图像的保存是使用8位二进制数，因此它的值为0-255，称之为灰度值。每一个类别用一个数替代，为了使用方便则按顺序<strong>使用1，2，3来分别代表圆形，三角形和正方形，其中背景用0表示</strong>。在图像中，0为黑色，255为白色，灰度值越接近0，则图像越黑，越接近255则图像越白。因此在这个三类问题中，图像灰度最大为3，当然看起来是黑色的。不信可以对mask乘85则可以看到颜色。<br><strong>IOU(Intersection Over Union，交并比)</strong>：用于<strong>评估语义分割算法性能的指标是平均IOU</strong>，交并比也非常好理解，算法的结果与真实物体进行<strong>交运算的结果除以进行并运算的结果</strong>。通过下图可以直观的看出IOU的计算方法。<br><img src="/images/Semantic_segmentation/Dataset_I.png" alt="IOU"></p>
<h1 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a><font size="5" color="red">一些说明</font></h1><ol>
<li>在学习的时候，小伙伴可能会遇到一些代码上的困难，如<strong>tensorflow</strong>，<strong>numpy</strong>，<strong>opencv</strong>的用法，可以查看我的深度学习框架和Python常用库相关文章，里面会有一些简单的介绍，小伙伴们可以进行学习，最好是手动敲一敲，看一看。</li>
<li>因为这个博客是对学习的一些总结和记录，意在和学习者探讨和交流，并且给准备入门的同学一些手把手的教学，因此关于图像分割的算法参数设计，我都是自己尝试的，不是针对于这个数据集最优的参数，大家可以<strong>根据自己的实际需要修改网络结构</strong>。</li>
<li>实际的工程应用中，常常还需要对数据集进行<strong>大小调整和增强</strong>，在这里为了简单起见，没有进行复杂的操作，小伙伴们应用中要记得根据自己的需要，对图像进行<strong>resize或者padding</strong>，然后<strong>旋转</strong>，<strong>对比度增强</strong>，<strong>仿射运算</strong>等等操作，增加模型的鲁棒性，并且实际中的图像不一定按照顺序命名的，因此应用中也要注意图像读取的文件名。</li>
<li>为了让学习者看的方便和清晰，我没有使用多个文件对程序进行封装，因为我在刚开始学习模型的时候，查看GitHub代码，一个模型可能需要好几个文件夹，每个文件夹里面又有很多的代码文件，其中很多文件互相调用。虽然这样的工程项目是非常好管理和运行的，但是给初学者一种丈二和尚摸不着头脑的感觉，对此我深有体会。所以我就使用一个.py文件来封装，因此代码可能会有几百行，但是其中的各个函数和类都有自己的名字，可以保证学习者不会被纸老虎吓住。</li>
<li>在语义分割学习中，我会列举出一些经典的语义分割模型，因为模型太多，并且仍在不断的更新进步之中，所以大家可以联系我，和我进行沟通和交流，或者推荐给我一些优秀的模型。</li>
<li>关于问题的交流，图像的数据，需要的同学可以到主页查看我的QQ或者邮箱，我会非常荣幸的提供力所能及的帮助，小伙伴加好友的时候一定要记得备注，不然我可能会忽视一些粗心的小伙伴。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>语义分割</strong>是计算机视觉的<strong>基础任务</strong>，也是非常重要的任务之一，自从深度学习的时代到来，各种神经网络结构百花齐放，很难说出最好的语义分割方法，可能一个方法适用于很多数据，但也<strong>不能说明某一个算法一定优于另一个算法</strong>，我们要做的就是尽可能多的<strong>学习各种各样的深度学习模型</strong>，然后<strong>吸取这些模型成功的原因</strong>，投入到自己的工程应用之中。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>语义分割网络</category>
      </categories>
  </entry>
  <entry>
    <title>GhostNet</title>
    <url>/2020/04/08/feature_extraction%20GhostNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">GhostNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>GhostNet:</strong>来自<strong>华为诺亚方舟实验室</strong>，于<strong>2020年被CVPR</strong>接受，借鉴了大量优秀神经网络的特点，提出了一种新型的神经网络架构。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/GhostNet.png" alt="GhostNet"></p>
<h1 id="GhostNet特点"><a href="#GhostNet特点" class="headerlink" title="GhostNet特点"></a><font size="5" color="red">GhostNet特点</font></h1><p>  <font size="3">在Ghost Module中引入<strong>瓶颈结构</strong>和<strong>GroupConv分组卷积</strong></font><br>  <font size="3">在Ghost Bottleneck中引入<strong>DepthwiseConv深度可分离卷积</strong>和<strong>Squeeze-and-Excitation模块</strong></font></p>
<h1 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a><font size="5" color="red">Group Convolution</font></h1><p><img src="/images/Feature_extraction/ShuffleNet_V2_G.png" alt="ShuffleNet_V2"><br>  <font size="3"><strong>Group Convolution(分组卷积)</strong>：<strong>传统卷积是采用一种卷积全连接的思想</strong>，特征图中的每一个像素点都结合了图像中所有通道的信息。而分组卷积特征图像<strong>每一个像素点只利用到一部分原始图像的通道</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个64x64x256的图像，经过5x5的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x5x5+1)=1638656，而分成32组的分组卷积的参数量为256x(8*5x5+1)=51456，参数量缩小了约32倍，当组数变成通道数时，则类似于Depthwise Convolution深度卷积</font></p>
<h1 id="Depthwise-Convolution"><a href="#Depthwise-Convolution" class="headerlink" title="Depthwise Convolution"></a><font size="5" color="red">Depthwise Convolution</font></h1><p><img src="/images/deep_learning/depthwise.png" alt="depthwise"><br>  <font size="3"><strong>Depthwise Convolution(深度卷积)：在</strong>每一个通道上单独进行卷积**</font><br>  <font size="3">参数<strong>depth_multiplier默认为1</strong>，代表每个通道数进行一次单独卷积，<strong>输出的通道数和输入通道数相等</strong>，设置<strong>depth_multiplier=n</strong>，则代表每个通道数进行n次单独卷积，<strong>输出通道数是输入通道数的n倍</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个8x8x1024的特征图，经过5x5的卷积核后变为8x8x1024的图像，经过普通卷积的参数量为1024x(1024x5x5+1)=26215424，而深度卷积参数量为1024x(1x5x5+1)=26624，参数量缩小了约1024倍。</font></p>
<h1 id="Squeeze-and-Excitation"><a href="#Squeeze-and-Excitation" class="headerlink" title="Squeeze-and-Excitation"></a><font size="5" color="red">Squeeze-and-Excitation</font></h1><p><img src="/images/Feature_extraction/SENet_S.png" alt="SENet"><br>  <font size="3"><strong>Squeeze-and-Excitation</strong>：又称为<strong>特征重标定卷积</strong>，或者<strong>注意力机制</strong>。具体来说，就是通过<strong>学习的方式来自动获取到每个特征通道的重要程度</strong>，然后依照这个重要程度去<strong>提升有用的特征并抑制对当前任务用处不大的特征</strong>。</font><br>  <font size="3">首先是 <strong>Squeeze操作</strong>，先<strong>进行全局池化，具有全局的感受野</strong>，并且输出的维度和输入的特征通道数相匹配，它表征着在特征通道上响应的全局分布。</font><br>  <font size="3">然后是<strong>Excitation操作</strong>，<strong>通过全连接层为每个特征通道生成权重，建立通道间的相关性</strong>，<strong>输出的权重看做是进过特征选择后的每个特征通道的重要性</strong>，然后通过<strong>乘法逐通道加权到先前的特征上</strong>，完成在通道维度上的对原始特征的重标定。</font></p>
<h1 id="GhostNet图像分析"><a href="#GhostNet图像分析" class="headerlink" title="GhostNet图像分析"></a><font size="5" color="red">GhostNet图像分析</font></h1><p><img src="/images/Feature_extraction/GhostNet_A.png" alt="GhostNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('relu') != -1:</span><br><span class="line">            self.block.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ghost_module(x, out_channel, relu, name):</span><br><span class="line">    shortcut = Conv_Bn_Relu(out_channel // 2, (1, 1), (1, 1), 'same', name='{}_conv_bn'.format(name) + '_relu' if relu else '{}_conv_bn'.format(name))(x)</span><br><span class="line">    x = Conv_Bn_Relu(None, (3, 3), (1, 1), 'same', name='{}_depthwiseconv_bn'.format(name) + '_relu' if relu else '{}_depthwiseconv_bn'.format(name))(shortcut)</span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def se_block(x, filters, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='{}_global_averagepool'.format(name)),</span><br><span class="line">                keras.layers.Dense(filters // 4, name='{}_dense1'.format(name)),</span><br><span class="line">                keras.layers.ReLU(name='{}_relu'.format(name)),</span><br><span class="line">                keras.layers.Dense(filters, name='{}_dense2'.format(name)),</span><br><span class="line">                keras.layers.Activation('sigmoid', name='{}_sigmoid'.format(name)),</span><br><span class="line">                keras.layers.Reshape((1, 1, filters), name='{}_reshape'.format(name)))(x)</span><br><span class="line">    x = keras.layers.Multiply(name='{}_multiply'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ghost_bneck(x, out_channel, exp_channel, kernel_size, strides, se, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = ghost_module(x, exp_channel, relu=True, name='{}_module1'.format(name))</span><br><span class="line">    if strides == (2, 2):</span><br><span class="line">        x = Conv_Bn_Relu(None, kernel_size, strides, 'same', name='{}_depthwiseconv_bn_relu'.format(name))(x)</span><br><span class="line">    if se:</span><br><span class="line">        x = se_block(x, exp_channel, name='{}_se_block'.format(name))</span><br><span class="line">    x = ghost_module(x, out_channel, relu=False, name='{}_module2'.format(name))</span><br><span class="line">    if shortcut.shape[-1] == out_channel and strides == (1, 1):</span><br><span class="line">        x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ghostnet(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu(16, (3, 3), (2, 2), 'same', name='conv_bn_relu1')(x)</span><br><span class="line"></span><br><span class="line">    x = ghost_bneck(x, out_channel=16, exp_channel=16, kernel_size=(3, 3), strides=(1, 1), se=False, name='bneck1_1')</span><br><span class="line">    x = ghost_bneck(x, out_channel=24, exp_channel=48, kernel_size=(3, 3), strides=(2, 2), se=False, name='bneck1_2')</span><br><span class="line"></span><br><span class="line">    x = ghost_bneck(x, out_channel=24, exp_channel=72, kernel_size=(3, 3), strides=(1, 1), se=False, name='bneck2_1')</span><br><span class="line">    x = ghost_bneck(x, out_channel=40, exp_channel=72, kernel_size=(5, 5), strides=(2, 2), se=True, name='bneck2_2')</span><br><span class="line"></span><br><span class="line">    x = ghost_bneck(x, out_channel=40, exp_channel=120, kernel_size=(5, 5), strides=(1, 1), se=True, name='bneck3_1')</span><br><span class="line">    x = ghost_bneck(x, out_channel=80, exp_channel=240, kernel_size=(3, 3), strides=(2, 2), se=False, name='bneck3_2')</span><br><span class="line"></span><br><span class="line">    x = ghost_bneck(x, out_channel=80, exp_channel=200, kernel_size=(3, 3), strides=(1, 1), se=False, name='bneck4_1')</span><br><span class="line">    x = ghost_bneck(x, out_channel=80, exp_channel=184, kernel_size=(3, 3), strides=(1, 1), se=False, name='bneck4_2')</span><br><span class="line">    x = ghost_bneck(x, out_channel=80, exp_channel=184, kernel_size=(3, 3), strides=(1, 1), se=False, name='bneck4_3')</span><br><span class="line">    x = ghost_bneck(x, out_channel=112, exp_channel=480, kernel_size=(3, 3), strides=(1, 1), se=True, name='bneck4_4')</span><br><span class="line">    x = ghost_bneck(x, out_channel=112, exp_channel=672, kernel_size=(3, 3), strides=(1, 1), se=True, name='bneck4_5')</span><br><span class="line">    x = ghost_bneck(x, out_channel=160, exp_channel=672, kernel_size=(5, 5), strides=(2, 2), se=True, name='bneck4_6')</span><br><span class="line"></span><br><span class="line">    x = ghost_bneck(x, out_channel=160, exp_channel=960, kernel_size=(5, 5), strides=(1, 1), se=False, name='bneck5_1')</span><br><span class="line">    x = ghost_bneck(x, out_channel=160, exp_channel=960, kernel_size=(5, 5), strides=(1, 1), se=True, name='bneck5_2')</span><br><span class="line">    x = ghost_bneck(x, out_channel=160, exp_channel=960, kernel_size=(5, 5), strides=(1, 1), se=False, name='bneck5_3')</span><br><span class="line">    x = ghost_bneck(x, out_channel=160, exp_channel=960, kernel_size=(5, 5), strides=(1, 1), se=True, name='bneck5_4')</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu(960, (1, 1), (1, 1), 'same', name='conv_bn_relu2'),</span><br><span class="line">                keras.layers.AveragePooling2D((7, 7), (7, 7), name='averagepool'),</span><br><span class="line">                Conv_Bn_Relu(1280, (1, 1), (1, 1), 'same', name='conv_bn_relu3'),</span><br><span class="line">                keras.layers.Conv2D(1000, (1, 1), (1, 1), 'same', activation='softmax', name='conv'),</span><br><span class="line">                keras.layers.Reshape((1000,), name='reshape'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='GhostNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = ghostnet(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/GhostNet_R.png" alt="GhostNet"></p>
<h1 id="GhostNet小结"><a href="#GhostNet小结" class="headerlink" title="GhostNet小结"></a><font size="5" color="red">GhostNet小结</font></h1><p>  GhostNet是一种复杂的轻量级深度学习网络，参数量为5M，其借鉴了大量优秀的深度学习网络的精髓，如<strong>MobileNet的深度可分离卷积</strong>思想，<strong>AlexNet的分组卷积</strong>思想，<strong>SENet的注意力机制</strong>，因此获得了较好的效果。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>排序数组(Leetcode 912)</title>
    <url>/2020/04/05/program%20Leetcode912/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode912.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这个题目非常简单，初学语言的小伙伴们都应该可以求解。排序也是算法中最基础最核心的问题之一，今天不是讲解这一道题目，而是给小伙伴们讲解常见的十种排序算法，就按照题目的要求，升序排列。</p>
<a id="more"></a>
<h1 id="稳定排序和不稳定排序"><a href="#稳定排序和不稳定排序" class="headerlink" title="稳定排序和不稳定排序"></a><font size="5" color="red">稳定排序和不稳定排序</font></h1><p>在排序算法性能的比较中，除了时间复杂度和空间复杂度外，还有一个因素是排序是否稳。什么是稳定呢？简单来说，稳定是两个相同的数字不会因为排序算法而导致顺序调换，如1，3(1)，5，3(2)排序后为1，3(2)，3(1)，5，本来第一个3和第二个3交换了顺序，那么这个排序就是不稳定的。对于纯数字来说，稳定和不稳定没有太大意义，但是如果对于某个类，将某个属性进行排序，则就非常有必要了。举个例子，有100个人到银行排队，它们都是普通客户，这时候来了一个VIP客户，这时需要对数据进行排序，将VIP客户的优先级提高，但是如果排序是不稳定的，则后面100个人的顺序将会被打乱，这时，之前排在第一个的人肯定是不愿意的。这就是不稳定排序造成的后果。</p>
<h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a><font size="5" color="red">冒泡排序</font></h1><p><img src="/images/ALGORITHM/bubble.gif" alt="bubble"><br>冒泡排序可能是我们最早接触的排序算法之一了，什么是冒泡排序呢？比较相邻的两个数值，如果前一个数大于后一个数，则交换两个数，就像吐泡泡一样，每一轮迭代会将最大的数放在最后，而且可以添加一个监视器，如果某一轮迭代都没有发生任何依次交换，说明这个序列已经是有序的，则可以提前停止。冒泡排序算法的时间复杂度为$O(n^2)$，最好情况为$O(n)$，最坏情况为$O(n^2)$，空间复杂度$O(1)$，稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def bubble_sort(self, nums):</span><br><span class="line">        for i in range(len(nums) - 1):</span><br><span class="line">             # 改进后的冒泡，设置一个交换标志位</span><br><span class="line">            flag = False </span><br><span class="line">            for j in range(len(nums) - i - 1):</span><br><span class="line">                if nums[j] &gt; nums[j + 1]:</span><br><span class="line">                    nums[j], nums[j + 1] = nums[j + 1], nums[j]</span><br><span class="line">                    flag = True</span><br><span class="line">            if not flag:</span><br><span class="line">                return nums</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a><font size="5" color="red">选择排序</font></h1><p><img src="/images/ALGORITHM/selection.gif" alt="select"><br>选择排序思路也非常简单，每次从剩余数组中选择一个最小的放在当前位置上，选择排序算法的时间复杂度为$O(n^2)$，最好情况为$O(n^2)$，最坏情况为$O(n^2)$，空间复杂度$O(1)$，不稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def selection_sort(self, nums):</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            min_idx = i</span><br><span class="line">            for j in range(i + 1, len(nums)):</span><br><span class="line">                if nums[min_idx] &gt; nums[j]:</span><br><span class="line">                    min_idx = j</span><br><span class="line"></span><br><span class="line">            nums[i], nums[min_idx] = nums[min_idx], nums[i]</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a><font size="5" color="red">插入排序</font></h1><p><img src="/images/ALGORITHM/insert.gif" alt="insert"><br>插入排序类似于冒泡排序，插入排序保证当前位置以前的都是有序的，将当前位置从后向前通过交换的方式，插入到之前有序的位置中，插入排序算法的时间复杂度为$O(n^2)$，最好情况为$O(n)$，最坏情况为$O(n^2)$，空间复杂度$O(1)$，稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def insertion_sort(self, nums):</span><br><span class="line">        # 第一层for表示循环插入的遍数</span><br><span class="line">        for i in range(1, len(nums)):</span><br><span class="line">            for j in range(i, 0, -1):</span><br><span class="line">                if nums[j] &lt; nums[j - 1]:</span><br><span class="line">                    nums[j], nums[j - 1] = nums[j - 1], nums[j]</span><br><span class="line">                else:</span><br><span class="line">                    break</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a><font size="5" color="red">快速排序</font></h1><p><img src="/images/ALGORITHM/quick.gif" alt="quick"><br>快速排序是一种面试常问的排序方法，其思想是每次选择一个基准值，将小于等于基准值的放在左边，大于基准值的放在右边，然后递归左边和右边两个子序列，快速排序算法的时间复杂度为$O(nlog(n))$，最好情况为$O(nlog(n))$，最坏情况为$O(n^2)$，空间复杂度$O(log(n))$，不稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def quick_sort(self, nums):</span><br><span class="line"></span><br><span class="line">        def quicksort(nums, begin, end):</span><br><span class="line">            if begin &lt; end:</span><br><span class="line">                base_element, head, tail = nums[begin], begin, end</span><br><span class="line">                while head &lt; tail:</span><br><span class="line">                    while head &lt; tail and nums[tail] &gt; base_element:</span><br><span class="line">                        tail -= 1</span><br><span class="line">                    while head &lt; tail and nums[head] &lt;= base_element:</span><br><span class="line">                        head += 1</span><br><span class="line">                    nums[head], nums[tail] = nums[tail], nums[head]</span><br><span class="line">                nums[tail], nums[begin] = nums[begin], nums[tail]</span><br><span class="line">                quicksort(nums, begin, head - 1)</span><br><span class="line">                quicksort(nums, head + 1, end)</span><br><span class="line">        quicksort(nums, 0, len(nums) - 1)</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a><font size="5" color="red">归并排序</font></h1><p><img src="/images/ALGORITHM/merge.gif" alt="merge"><br>归并排序利用了一种分治的思想，先对序列进行分解，分解成长度为1的n个子序列，这n个子序列因为长度为1，故都是有序的，然后再进行合并，合并的时候就是两个有序数组进行合并，因此排序速度会大大提升，归并排序算法的时间复杂度为$O(nlog(n))$，最好情况为$O(nlog(n))$，最坏情况为$O(nlog(n))$，空间复杂度$O(n)$，稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def merge_sort(self, nums):</span><br><span class="line"></span><br><span class="line">        def merge(nums, begin, mid, end):</span><br><span class="line">            new_list = []</span><br><span class="line">            p_1, p_2 = begin, mid + 1</span><br><span class="line">            while p_1 &lt;= mid and p_2 &lt;= end:</span><br><span class="line">                new_list, p_1, p_2 = [new_list + [nums[p_1]], p_1 + 1, p_2 + 0] if nums[p_1] &lt;= nums[p_2] else [new_list + [nums[p_2]], p_1 + 0, p_2 + 1]</span><br><span class="line">            new_list += nums[p_2:end + 1] if p_1 &gt; mid else nums[p_1:mid + 1]</span><br><span class="line">            nums[begin:end + 1] = new_list</span><br><span class="line"></span><br><span class="line">        def mergesort(nums, begin, end):</span><br><span class="line">            if begin &lt; end:</span><br><span class="line">                mergesort(nums, begin, (begin + end) // 2)</span><br><span class="line">                mergesort(nums, (begin + end) // 2 + 1, end)</span><br><span class="line">                merge(nums, begin, (begin + end) // 2, end)</span><br><span class="line"></span><br><span class="line">        mergesort(nums, 0, len(nums) - 1)</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a><font size="5" color="red">桶排序</font></h1><p><img src="/images/ALGORITHM/bucket.png" alt="bucket"><br>桶排序首先建立k个桶，每个桶有一定的范围，将原始序列分桶装入，这样排序时只要每个桶是有序的，则整体是有序的，可以降低时间复杂度。桶排序算法的时间复杂度为$O(n + k)$，最好情况为$O(n + k)$，最坏情况为$O(n^2)$，空间复杂度$O(n + k)$，稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def bucket_sort(self, nums):</span><br><span class="line">        min_num = min(nums)</span><br><span class="line">        max_num = max(nums)</span><br><span class="line">        # 桶的大小</span><br><span class="line">        bucket_range = (max_num - min_num) / len(nums)</span><br><span class="line">        # 桶数组</span><br><span class="line">        count_list = [[] for i in range(len(nums) + 1)]</span><br><span class="line">        # 向桶数组填数</span><br><span class="line">        for i in nums:</span><br><span class="line">            count_list[int((i - min_num) // bucket_range)].append(i)</span><br><span class="line">        nums.clear()</span><br><span class="line">        # 回填，这里桶内部排序直接调用了sorted</span><br><span class="line">        for i in count_list:</span><br><span class="line">            for j in sorted(i):</span><br><span class="line">                nums.append(j)</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a><font size="5" color="red">计数排序</font></h1><p><img src="/images/ALGORITHM/count.gif" alt="count"><br>计数排序的原理也很简单，用数组下标统计元素出现的个数即可，因为数组下标是升序排列的，因此输出时只需要按照数组下标顺序依次输出即可，缺点也很明显，对非整数数组进行排序不太方便。计数排序算法的时间复杂度为$O(n + k)$，最好情况为$O(n + k)$，最坏情况为$O(n + k)$，空间复杂度$O(n)$，稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def count_sort(self, nums):</span><br><span class="line">        # 找到最大最小值</span><br><span class="line">        min_num = min(nums)</span><br><span class="line">        max_num = max(nums)</span><br><span class="line">        # 计数列表</span><br><span class="line">        count_list = [0] * (max_num - min_num + 1)</span><br><span class="line">        # 计数</span><br><span class="line">        for i in nums:</span><br><span class="line">            count_list[i - min_num] += 1</span><br><span class="line">        nums.clear()</span><br><span class="line">        # 填回</span><br><span class="line">        for ind, i in enumerate(count_list):</span><br><span class="line">            while i != 0:</span><br><span class="line">                nums.append(ind + min_num)</span><br><span class="line">                i -= 1</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a><font size="5" color="red">希尔排序</font></h1><p><img src="/images/ALGORITHM/shell.gif" alt="shell"><br>希尔排序类似于插入排序，但是不同点是插入排序增量为1，要插入的值从后向前，一个一个比较，而希尔排序是从后向前有间隔的比较，间隔不同时间复杂度不同，一般按照总长度二分的方式设置间隔。希尔排序算法的时间复杂度为$O(n^{1.3})$，最好情况为$O(n)$，最坏情况为$O(n^2)$，空间复杂度$O(1)$，不稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def shell_sort(self, nums):</span><br><span class="line">        # 初始步长设置为总长度的一半</span><br><span class="line">        gap = len(nums) // 2</span><br><span class="line">        while gap:</span><br><span class="line">            for i in range(gap, len(nums)):</span><br><span class="line">                # 在每一组里面进行直接插入排序</span><br><span class="line">                for j in range(i, gap - 1, -gap):</span><br><span class="line">                    if nums[j] &lt; nums[j - gap]:</span><br><span class="line">                        nums[j], nums[j - gap] = nums[j - gap], nums[j]</span><br><span class="line">                    else:</span><br><span class="line">                        break</span><br><span class="line">            # 更新步长</span><br><span class="line">            gap //= 2</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a><font size="5" color="red">堆排序</font></h1><p><img src="/images/ALGORITHM/heap.gif" alt="heap"><br>堆排序使用了最大堆的概念，指父节点的值大于孩子节点的值，首先建立一个最大堆，然后交换最后一个元素与堆顶元素的值，接着对最大堆进行下沉操作，如果交换进去的值小于孩子节点，则使其下沉，更新最大堆，然后继续交换得到第二大的值，并重复上面的操作即可得到升序的数组。堆排序算法的时间复杂度为$O(nlog(n))$，最好情况为$O(nlog(n))$，最坏情况为$O(nlog(n))$，空间复杂度$O(1)$，不稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def heap_sort(self, nums):</span><br><span class="line"></span><br><span class="line">        def heapify(arr, n, i):</span><br><span class="line">            largest = i</span><br><span class="line">            left = 2 * i + 1</span><br><span class="line">            right = 2 * i + 2</span><br><span class="line">            if left &lt; n and arr[i] &lt; arr[left]:</span><br><span class="line">                largest = left</span><br><span class="line">            if right &lt; n and arr[largest] &lt; arr[right]:</span><br><span class="line">                largest = right</span><br><span class="line">            if largest != i:</span><br><span class="line">                arr[i], arr[largest] = arr[largest], arr[i]</span><br><span class="line">                heapify(arr, n, largest)</span><br><span class="line"></span><br><span class="line">        n = len(nums)</span><br><span class="line">        # 创建一个长度为n的最大堆</span><br><span class="line">        for i in range(n, -1, -1):</span><br><span class="line">            heapify(nums, n, i)</span><br><span class="line">        for i in range(n - 1, 0, -1):</span><br><span class="line">            # 将大顶堆的堆顶元素和最后一个元素交换</span><br><span class="line">            nums[i], nums[0] = nums[0], nums[i]</span><br><span class="line">            # 创建一个长度为n - 1的最大堆</span><br><span class="line">            heapify(nums, i, 0)</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a><font size="5" color="red">基数排序</font></h1><p><img src="/images/ALGORITHM/radix.gif" alt="radix"><br>基数排序类似于桶排序和计数排序，这个排序方式先设置10个桶，按照十进制位进行排序，先排个位，将个位按照升序放入桶内，然后将桶内的数字依次取出，然后排十位，百位，依次下取直到最高位为止，最后将最高位排序后的元素从桶内依次取出即可完成升序排列，缺点和计数排序相同，对非整数数组进行排序不太方便。基数排序算法的时间复杂度为$O(nk)$，最好情况为$O(nk)$，最坏情况为$O(nk)$，空间复杂度$O(n)$，稳定排序。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def radix_sort(self, nums):</span><br><span class="line">        # 记录当前正在排哪一位，最低位为1</span><br><span class="line">        i = 0</span><br><span class="line">        j = len(str(max(nums)))</span><br><span class="line">        while i &lt; j:</span><br><span class="line">            # 初始化桶数组</span><br><span class="line">            bucket_list = [[] for _ in range(10)]</span><br><span class="line">            for x in nums:</span><br><span class="line">                # 找到位置放入桶数组</span><br><span class="line">                bucket_list[(x // (10 ** i)) % 10].append(x)</span><br><span class="line">            nums.clear()</span><br><span class="line">            # 放回原序列</span><br><span class="line">            for x in bucket_list:</span><br><span class="line">                for y in x:</span><br><span class="line">                    nums.append(y)</span><br><span class="line">            i += 1</span><br><span class="line">        return nums</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  排序问题是算法经久不衰的考点之一，这十种方法各有利弊，没有绝对的好与不好，只有不同的适用场景罢了，其中最重要的几个排序方法是冒泡排序，快速排序，归并排序，堆排序。由于其面试出题过于频繁，很多公司已经不考这个简单的算法问题，但是小伙伴们也必须要掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>堆</category>
        <category>数组</category>
        <category>排序</category>
        <category>分治</category>
      </categories>
  </entry>
  <entry>
    <title>ShuffleNet-V2</title>
    <url>/2020/04/02/feature_extraction%20ShuffleNet_V2/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">ShuffleNet-V2</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>ShuffleNet-V2</strong>:<strong>2018年发表于ECCV</strong>，是一种高效的轻量级深度学习模型，在<strong>同等复杂度下，ShuffleNet-V2比ShuffleNet和MobileNet更准确</strong>。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/ShuffleNet_V2.png" alt="ShuffleNet_V2"></p>
<h1 id="ShuffleNet-V2特点"><a href="#ShuffleNet-V2特点" class="headerlink" title="ShuffleNet-V2特点"></a><font size="5" color="red">ShuffleNet-V2特点</font></h1><p>  <font size="3"><strong>借鉴了AlexNet分组卷积的概念</strong>，引入了<strong>通道分离</strong>和<strong>通道洗牌</strong>，在<strong>减少参数量的同时，增加了通道之间的联系</strong>，并且<strong>对最后的结果进行通道合并，完成特征融合</strong>。</font><br>  <font size="3">在Block中使用深度可分离卷积思想，减少模型参数量</font></p>
<h1 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a><font size="5" color="red">Group Convolution</font></h1><p><img src="/images/Feature_extraction/ShuffleNet_V2_G.png" alt="ShuffleNet_V2"><br>  <font size="3"><strong>Group Convolution(分组卷积)</strong>：<strong>传统卷积是采用一种卷积全连接的思想</strong>，特征图中的每一个像素点都结合了图像中所有通道的信息。而分组卷积特征图像<strong>每一个像素点只利用到一部分原始图像的通道</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个64x64x256的图像，经过5x5的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x5x5+1)=1638656，而分成32组的分组卷积的参数量为256x(8*5x5+1)=51456，参数量缩小了约32倍，当组数变成通道数时，则类似于Depthwise Convolution深度卷积</font></p>
<h1 id="Separable-Convolution"><a href="#Separable-Convolution" class="headerlink" title="Separable Convolution"></a><font size="5" color="red">Separable Convolution</font></h1><p><img src="/images/Feature_extraction/Xception_D.png" alt="Xception"><br>  <font size="3"><strong>Separable Convolution(深度可分离卷积)</strong>：是上面两个卷积合二为一的卷积操作。</font><br>  <font size="3"><strong>第一步：DepthwiseConv，对每一个通道进行卷积</strong></font><br>  <font size="3"><strong>第二步：PointwiseConv，对第一步得到的结果进行1x1卷积，实现通道融合</strong></font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，并且可以<strong>调整为任意合适的通道数</strong>。第一步的<strong>目的是减少参数量</strong>，第二步是<strong>调整通道数</strong>，因此将两个卷积操作结合，组成深度可分离卷积。</font></p>
<h1 id="不同尺寸ShuffleNet-V2网络结构"><a href="#不同尺寸ShuffleNet-V2网络结构" class="headerlink" title="不同尺寸ShuffleNet-V2网络结构"></a><font size="5" color="red">不同尺寸ShuffleNet-V2网络结构</font></h1><p><img src="/images/Feature_extraction/ShuffleNet_V2_C.png" alt="ShuffleNet_V2"></p>
<h1 id="ShuffleNet-V2图像分析"><a href="#ShuffleNet-V2图像分析" class="headerlink" title="ShuffleNet-V2图像分析"></a><font size="5" color="red">ShuffleNet-V2图像分析</font></h1><p><img src="/images/Feature_extraction/ShuffleNet_V2_A.png" alt="ShuffleNet_V2"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Channel_Split(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(Channel_Split, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return inputs[..., :inputs.shape[-1] // 2], inputs[..., inputs.shape[-1] // 2:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Channel_Shuffle(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(Channel_Shuffle, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        channel = inputs.shape[-1]</span><br><span class="line">        output = compose(keras.layers.Reshape((inputs.shape[1], inputs.shape[2], 2, channel // 2)),</span><br><span class="line">                           keras.layers.Permute([1, 2, 4, 3]),</span><br><span class="line">                           keras.layers.Reshape((inputs.shape[1], inputs.shape[2], channel)))(inputs)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('relu') != -1:</span><br><span class="line">            self.block.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, out_channel, strides, name):</span><br><span class="line">    if strides == (1, 1):</span><br><span class="line">        split1, split2 = Channel_Split(name='{}_channel_split'.format(name))(x)</span><br><span class="line">    else:</span><br><span class="line">        split1 = split2 = x</span><br><span class="line"></span><br><span class="line">    split1 = compose(Conv_Bn_Relu(out_channel // 2, (1, 1), (1, 1), 'same', name='{}_part1_conv_bn_relu1'.format(name)),</span><br><span class="line">                    Conv_Bn_Relu(None, (3, 3), strides, 'same', name='{}_part1_depthwiseconv_bn'.format(name)),</span><br><span class="line">                    Conv_Bn_Relu(out_channel // 2, (1, 1), (1, 1), 'same', name='{}_part1_conv_bn_relu2'.format(name)))(split1)</span><br><span class="line"></span><br><span class="line">    if strides == (2, 2):</span><br><span class="line">        split2 = compose(Conv_Bn_Relu(None, (3, 3), strides, 'same', name='{}_part2_depthwiseconv_bn'.format(name)),</span><br><span class="line">                         Conv_Bn_Relu(out_channel // 2, (1, 1), (1, 1), 'same', name='{}_part2_conv_bn_relu'.format(name)))(split2)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([split1, split2])</span><br><span class="line">    x = Channel_Shuffle(name='{}_channel_shuffle'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def add_block(x, filters, n, name):</span><br><span class="line">    x = block(x, filters, (2, 2), name='{}_1'.format(name))</span><br><span class="line">    for i in range(n):</span><br><span class="line">        x = block(x, filters, (1, 1), name='{}_{}'.format(name, i + 2))</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def shufflenet_v2(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(24, (3, 3), (2, 2), padding='same', activation='relu', name='conv_relu1'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), padding='same', name='maxpool'))(x)</span><br><span class="line"></span><br><span class="line">    x = add_block(x, 116, 3, name='block1')</span><br><span class="line">    x = add_block(x, 232, 7, name='block2')</span><br><span class="line">    x = add_block(x, 464, 3, name='block3')</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(1024, (1, 1), (1, 1), padding='same', activation='relu', name='conv_relu2'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='ShuffleNet-V2')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = shufflenet_v2(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/ShuffleNet_V2_R.png" alt="ShuffleNet_V2"></p>
<h1 id="ShuffleNet-V2小结"><a href="#ShuffleNet-V2小结" class="headerlink" title="ShuffleNet-V2小结"></a><font size="5" color="red">ShuffleNet-V2小结</font></h1><p>  ShuffleNet-V2是一种有效的轻量级深度学习网络，参数量只有2M，其从AlexNet中借鉴了<strong>分组卷积</strong>的思想，并且运用了<strong>通道分离</strong>和<strong>洗牌</strong>的思想，不但可以大大降低模型参数量，并且可以<strong>提高模型的鲁棒性</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>EfficientNet</title>
    <url>/2020/03/31/feature_extraction%20EfficientNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">EfficientNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>EfficientNet:</strong>是<strong>谷歌公司于2019年提出</strong>的高效神经网络，故得名为EfficientNet，<strong>大幅度的缩小了参数的同时提高了预测准确度</strong>。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/EfficientNet.png" alt="EfficientNet"></p>
<h1 id="EfficientNet特点"><a href="#EfficientNet特点" class="headerlink" title="EfficientNet特点"></a><font size="5" color="red">EfficientNet特点</font></h1><p>  <font size="3">和MobileNet_V3类似，在Block中<strong>先进行1x1卷积提升通道数</strong>，然后<strong>进行DepthwiseConv深度卷积</strong>减少参数量，并且在<strong>Block中引入残差结构和Squeeze-and-Excitation模块</strong></font><br>  <font size="3">建立<strong>多个网络深度，网络宽度，图像分辨率不同的模型</strong>，从<strong>三个方面拓展网络性能</strong></font></p>
<h1 id="Depthwise-Convolution"><a href="#Depthwise-Convolution" class="headerlink" title="Depthwise Convolution"></a><font size="5" color="red">Depthwise Convolution</font></h1><p><img src="/images/deep_learning/depthwise.png" alt="depthwise"><br>  <font size="3"><strong>Depthwise Convolution(深度卷积)：在</strong>每一个通道上单独进行卷积**</font><br>  <font size="3">参数<strong>depth_multiplier默认为1</strong>，代表每个通道数进行一次单独卷积，<strong>输出的通道数和输入通道数相等</strong>，设置<strong>depth_multiplier=n</strong>，则代表每个通道数进行n次单独卷积，<strong>输出通道数是输入通道数的n倍</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个8x8x1024的特征图，经过5x5的卷积核后变为8x8x1024的图像，经过普通卷积的参数量为1024x(1024x5x5+1)=26215424，而深度卷积参数量为1024x(1x5x5+1)=26624，参数量缩小了约1024倍。</font></p>
<h1 id="Squeeze-and-Excitation"><a href="#Squeeze-and-Excitation" class="headerlink" title="Squeeze-and-Excitation"></a><font size="5" color="red">Squeeze-and-Excitation</font></h1><p><img src="/images/Feature_extraction/SENet_S.png" alt="SENet"><br>  <font size="3"><strong>Squeeze-and-Excitation</strong>：又称为<strong>特征重标定卷积</strong>，或者<strong>注意力机制</strong>。具体来说，就是通过<strong>学习的方式来自动获取到每个特征通道的重要程度</strong>，然后依照这个重要程度去<strong>提升有用的特征并抑制对当前任务用处不大的特征</strong>。</font><br>  <font size="3">首先是 <strong>Squeeze操作</strong>，先<strong>进行全局池化，具有全局的感受野</strong>，并且输出的维度和输入的特征通道数相匹配，它表征着在特征通道上响应的全局分布。</font><br>  <font size="3">然后是<strong>Excitation操作</strong>，<strong>通过全连接层为每个特征通道生成权重，建立通道间的相关性</strong>，<strong>输出的权重看做是进过特征选择后的每个特征通道的重要性</strong>，然后通过<strong>乘法逐通道加权到先前的特征上</strong>，完成在通道维度上的对原始特征的重标定。</font></p>
<h1 id="EfficientNet基模型B0图像分析"><a href="#EfficientNet基模型B0图像分析" class="headerlink" title="EfficientNet基模型B0图像分析"></a><font size="5" color="red">EfficientNet基模型B0图像分析</font></h1><p><img src="/images/Feature_extraction/EfficientNet_A.png" alt="EfficientNet"></p>
<h1 id="基模型B0的TensorFlow2-0实现"><a href="#基模型B0的TensorFlow2-0实现" class="headerlink" title="基模型B0的TensorFlow2.0实现"></a><font size="4">基模型B0的TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Swish(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name='swish'):</span><br><span class="line">        super(Swish, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return inputs * keras.activations.sigmoid(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def se_block(x, down_filters, up_filters, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='{}_global_averagepool'.format(name)),</span><br><span class="line">                keras.layers.Reshape((1, 1, up_filters), name='{}_reshape'.format(name)),</span><br><span class="line">                keras.layers.Conv2D(down_filters, (1, 1), activation=Swish(name='{}_swish'.format(name)), name='{}_conv1'.format(name)),</span><br><span class="line">                keras.layers.Conv2D(up_filters, (1, 1), activation='sigmoid', name='{}_conv2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Multiply(name='{}_multiply'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Swish(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Swish, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('swish') != -1:</span><br><span class="line">            self.block.add(Swish())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, in_channel, out_channel, times1, times2, kernel_size, strides, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_Bn_Swish(in_channel * times1, (1, 1), (1, 1), 'same', name='{}_conv_bn_swish'.format(name)),</span><br><span class="line">                Conv_Bn_Swish(None, kernel_size, strides, 'same', name='{}_depthwiseconv_bn_swish'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = se_block(x, in_channel // times2, in_channel * times1, name='{}_se_block'.format(name))</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Swish(out_channel, (1, 1), (1, 1), 'same', name='{}_conv_bn'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    if in_channel == out_channel and strides == (1, 1):</span><br><span class="line">        x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def efficientnet(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D(name='zeropadding'),</span><br><span class="line">                Conv_Bn_Swish(32, (3, 3), (2, 2), 'valid', name='conv_bn_swish1'))(x)</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=32, out_channel=16, times1=1, times2=4, kernel_size=(3, 3), strides=(1, 1), name='block1')</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=16, out_channel=24, times1=6, times2=4, kernel_size=(3, 3), strides=(2, 2), name='block2_1')</span><br><span class="line">    x = block(x, in_channel=24, out_channel=24, times1=6, times2=4, kernel_size=(3, 3), strides=(1, 1), name='block2_2')</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=24, out_channel=40, times1=6, times2=4, kernel_size=(5, 5), strides=(2, 2), name='block3_1')</span><br><span class="line">    x = block(x, in_channel=40, out_channel=40, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block3_2')</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=40, out_channel=80, times1=6, times2=4, kernel_size=(3, 3), strides=(2, 2), name='block4_1')</span><br><span class="line">    x = block(x, in_channel=80, out_channel=80, times1=6, times2=4, kernel_size=(3, 3), strides=(1, 1), name='block4_2')</span><br><span class="line">    x = block(x, in_channel=80, out_channel=80, times1=6, times2=4, kernel_size=(3, 3), strides=(1, 1), name='block4_3')</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=80, out_channel=112, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block5_1')</span><br><span class="line">    x = block(x, in_channel=112, out_channel=112, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block5_2')</span><br><span class="line">    x = block(x, in_channel=112, out_channel=112, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block5_3')</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=112, out_channel=192, times1=6, times2=4, kernel_size=(5, 5), strides=(2, 2), name='block6_1')</span><br><span class="line">    x = block(x, in_channel=192, out_channel=192, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block6_2')</span><br><span class="line">    x = block(x, in_channel=192, out_channel=192, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block6_3')</span><br><span class="line">    x = block(x, in_channel=192, out_channel=192, times1=6, times2=4, kernel_size=(5, 5), strides=(1, 1), name='block6_4')</span><br><span class="line"></span><br><span class="line">    x = block(x, in_channel=192, out_channel=320, times1=6, times2=4, kernel_size=(3, 3), strides=(1, 1), name='block7')</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Swish(1280, (1, 1), (1, 1), 'same', name='conv_bn_swish2'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dropout(0.2, name='dropout'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='EfficientNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = efficientnet(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/EfficientNet_R.png" alt="EfficientNet"></p>
<h1 id="EfficientNet小结"><a href="#EfficientNet小结" class="headerlink" title="EfficientNet小结"></a><font size="5" color="red">EfficientNet小结</font></h1><p>  EfficientNet是一种复杂的深度学习网络，从上图可以看出EfficientNet基模型B0的参数量有5M，其考虑<strong>网络深度</strong>，<strong>网络宽度</strong>，<strong>图像分辨率</strong>等因素的思想值得我们学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>EffNet</title>
    <url>/2020/03/28/feature_extraction%20EffNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">EffNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>EffNet</strong>:<strong>2018年发表于ICIP</strong>，提出一种<strong>新颖的卷积块设计</strong>，能够显著<strong>减轻计算负担</strong>，且性能远胜当前的最好的模型(对比MobileNet,ShuffleNet)。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/EffNet.png" alt="EffNet"></p>
<h1 id="EffNet特点"><a href="#EffNet特点" class="headerlink" title="EffNet特点"></a><font size="5" color="red">EffNet特点</font></h1><p>  <font size="3">借鉴了<strong>Depthwise Convolution(深度卷积)</strong>的思想，并且将Inception中<strong>spatial separable convolutions(空间可分离卷积)的思想推广到池化分解</strong>。采用<strong>深度可分离卷积</strong>代替<strong>传统的卷积</strong>，并且<strong>卷积核采用1x3和3x1代替3x3</strong>，两次卷积核之间<strong>插入一维池化核</strong>，可以进一步减少参数量。</font></p>
<h1 id="Depthwise-Convolution"><a href="#Depthwise-Convolution" class="headerlink" title="Depthwise Convolution"></a><font size="5" color="red">Depthwise Convolution</font></h1><p><img src="/images/deep_learning/depthwise.png" alt="depthwise"><br>  <font size="3"><strong>Depthwise Convolution(深度卷积)：在</strong>每一个通道上单独进行卷积**</font><br>  <font size="3">参数<strong>depth_multiplier默认为1</strong>，代表每个通道数进行一次单独卷积，<strong>输出的通道数和输入通道数相等</strong>，设置<strong>depth_multiplier=n</strong>，则代表每个通道数进行n次单独卷积，<strong>输出通道数是输入通道数的n倍</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个8x8x1024的特征图，经过5x5的卷积核后变为8x8x1024的图像，经过普通卷积的参数量为1024x(1024x5x5+1)=26215424，而深度卷积参数量为1024x(1x5x5+1)=26624，参数量缩小了约1024倍。</font></p>
<h1 id="Spatial-Separable-Convolution"><a href="#Spatial-Separable-Convolution" class="headerlink" title="Spatial Separable Convolution"></a><font size="5" color="red">Spatial Separable Convolution</font></h1><p><img src="/images/deep_learning/spatial.png" alt="spatial"><br>  <font size="3"><strong>Spatial Separable Convolution(空间可分离卷积)</strong>：将3x3的卷积分解为3x1的卷积核1x3的卷积，将7x7的卷积分解为7x1的卷积核1x7的卷积.。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个64x64x256的特征图，经过7x7的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x7x7+1)=3211520，而空间可分离卷积参数量为2x256x(256x7x1+1)=918016，参数量缩小了约3.5倍。</font></p>
<h1 id="EffNet图像分析"><a href="#EffNet图像分析" class="headerlink" title="EffNet图像分析"></a><font size="5" color="red">EffNet图像分析</font></h1><p><img src="/images/Feature_extraction/EffNet_A.png" alt="EffNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_LeakyRelu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_LeakyRelu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.block.add(keras.layers.LeakyReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(inchannel, outchannel, name):</span><br><span class="line"></span><br><span class="line">    return compose(Conv_Bn_LeakyRelu(inchannel, (1, 1), (1, 1), 'same', name='{}_conv_bn_leakyrelu1'.format(name)),</span><br><span class="line">                   Conv_Bn_LeakyRelu(None, (1, 3), (1, 1), 'same', name='{}_depthwiseconv_bn_leakyrelu1'.format(name)),</span><br><span class="line">                   keras.layers.MaxPool2D((1, 2), (1, 2), name='{}_maxpool'.format(name)),</span><br><span class="line">                   Conv_Bn_LeakyRelu(None, (3, 1), (1, 1), 'same', name='{}_depthwiseconv_bn_leakyrelu2'.format(name)),</span><br><span class="line">                   Conv_Bn_LeakyRelu(outchannel, (1, 1), (2, 1), 'same', name='{}_conv_bn_leakyrelu2'.format(name)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def effnet(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(block(32, 64, name='block1'),</span><br><span class="line">                block(64, 128, name='block2'),</span><br><span class="line">                block(128, 256, name='block3'))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(10, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='EffNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = effnet(input_shape=(32, 32, 3))</span><br><span class="line">    model.build(input_shape=(None, 32, 32, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/EffNet_R.png" alt="EffNet"></p>
<h1 id="EffNet小结"><a href="#EffNet小结" class="headerlink" title="EffNet小结"></a><font size="5" color="red">EffNet小结</font></h1><p>  EffNet给我们<strong>提供了一种一维池化的思路</strong>，虽然论文中以Cifar10作为数据集，参数量无法和其他模型进行直接的对比，但是模型的使用效果却优于MobileNet和ShuffleNet。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>MobileNet-V3</title>
    <url>/2020/03/26/feature_extraction%20MobileNet_V3/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">MobileNet-V3</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>MobileNet-V3:</strong>是Google继MobileNet-V2之后的又一力作，于<strong>2019年提出</strong>，效果较MobileNet-V2有所提升。MobileNet-V3提供了<strong>两个版本</strong>，分别为<strong>MobileNet-V3-Large</strong>以及<strong>MobileNet-V3-Small</strong>，分别适用于对资源不同要求的情况。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/MobileNet_V3.png" alt="MobileNet_V3"></p>
<h1 id="MobileNet-V3特点"><a href="#MobileNet-V3特点" class="headerlink" title="MobileNet-V3特点"></a><font size="5" color="red">MobileNet-V3特点</font></h1><p>  <font size="3"><strong>保留MobileNet-V2的SeparableConv深度可分离结构和残差结构</strong></font><br>  <font size="3"><strong>引入SE结构，具有轻量级的注意力模型</strong></font><br>  <font size="3"><strong>对MobileNet-V2的头部结构进行优化</strong>，MobileNet-V2中第二层得到的特征图大小为112x112x32，而在MobileNet-V3中，只需要112x112x16即可保证精度，并且提升运行速度。</font><br>  <font size="3"><strong>对MobileNet-V2的尾部结构进行优化</strong>，MobileNet-V2中对7x7的特征图进行1x1的卷积提升通道数，然后再进行全局平均池化，而在MobileNet-V3中，先对7x7的特征图进行全局平均池化，然后再进行1x1的卷积提升通道数，节约了49倍的参数量。</font><br>  <font size="3">激活函数使用<strong>h-swish</strong>和<strong>ReLU6</strong>并存的方式，加快了运行的速度</font></p>
<h1 id="Separable-Convolution"><a href="#Separable-Convolution" class="headerlink" title="Separable Convolution"></a><font size="5" color="red">Separable Convolution</font></h1><p><img src="/images/Feature_extraction/Xception_D.png" alt="Xception"><br>  <font size="3"><strong>Separable Convolution(深度可分离卷积)</strong>：是上面两个卷积合二为一的卷积操作。</font><br>  <font size="3"><strong>第一步：DepthwiseConv，对每一个通道进行卷积</strong></font><br>  <font size="3"><strong>第二步：PointwiseConv，对第一步得到的结果进行1x1卷积，实现通道融合</strong></font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，并且可以<strong>调整为任意合适的通道数</strong>。第一步的<strong>目的是减少参数量</strong>，第二步是<strong>调整通道数</strong>，因此将两个卷积操作结合，组成深度可分离卷积。</font></p>
<h1 id="Squeeze-and-Excitation"><a href="#Squeeze-and-Excitation" class="headerlink" title="Squeeze-and-Excitation"></a><font size="5" color="red">Squeeze-and-Excitation</font></h1><p><img src="/images/Feature_extraction/SENet_S.png" alt="SENet"><br>  <font size="3"><strong>Squeeze-and-Excitation</strong>：又称为<strong>特征重标定卷积</strong>，或者<strong>注意力机制</strong>。具体来说，就是通过<strong>学习的方式来自动获取到每个特征通道的重要程度</strong>，然后依照这个重要程度去<strong>提升有用的特征并抑制对当前任务用处不大的特征</strong>。</font><br>  <font size="3">首先是 <strong>Squeeze操作</strong>，先<strong>进行全局池化，具有全局的感受野</strong>，并且输出的维度和输入的特征通道数相匹配，它表征着在特征通道上响应的全局分布。</font><br>  <font size="3">然后是<strong>Excitation操作</strong>，<strong>通过全连接层为每个特征通道生成权重，建立通道间的相关性</strong>，<strong>输出的权重看做是进过特征选择后的每个特征通道的重要性</strong>，然后通过<strong>乘法逐通道加权到先前的特征上</strong>，完成在通道维度上的对原始特征的重标定。</font></p>
<h1 id="不同尺寸MobileNet-V3网络结构"><a href="#不同尺寸MobileNet-V3网络结构" class="headerlink" title="不同尺寸MobileNet-V3网络结构"></a><font size="5" color="red">不同尺寸MobileNet-V3网络结构</font></h1><p><img src="/images/Feature_extraction/MobileNet_V3_C.png" alt="MobileNet_V3"></p>
<h1 id="MobileNet-V3图像分析"><a href="#MobileNet-V3图像分析" class="headerlink" title="MobileNet-V3图像分析"></a><font size="5" color="red">MobileNet-V3图像分析</font></h1><p><img src="/images/Feature_extraction/MobileNet_V3_A.png" alt="MobileNet_V3"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class H_Swish(keras.layers.Layer):</span><br><span class="line">    def __init__(self, name='h_swish'):</span><br><span class="line">        super(H_Swish, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return inputs * keras.activations.relu(inputs + 3, max_value=6) / 6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def se_block(x, filters, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='{}_global_averagepool'.format(name)),</span><br><span class="line">                keras.layers.Dense(filters // 4, name='{}_dense1'.format(name)),</span><br><span class="line">                keras.layers.ReLU(6, name='{}_relu6'.format(name)),</span><br><span class="line">                keras.layers.Dense(filters, name='{}_dense2'.format(name)),</span><br><span class="line">                H_Swish(name='{}_h_swish'.format(name)),</span><br><span class="line">                keras.layers.Reshape((1, 1, filters), name='{}_reshape'.format(name)))(x)</span><br><span class="line">    x = keras.layers.Multiply(name='{}_multiply'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def bneck(x, filters, up_dim, kernel_size, strides, squeeze, activation, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_Bn_Relu6(up_dim, (1, 1), (1, 1), 'same', name='{}_conv_bn_{}'.format(name, activation)),</span><br><span class="line">                Conv_Bn_Relu6(None, kernel_size, strides, 'same', name='{}_depthwiseconv_bn_{}'.format(name, activation)))(x)</span><br><span class="line"></span><br><span class="line">    if squeeze:</span><br><span class="line">        x = se_block(x, up_dim, name='{}_se_block'.format(name))</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu6(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    if shortcut.shape[-1] == filters and strides == (1, 1):</span><br><span class="line">        x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu6(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu6, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('h_swish') != -1:</span><br><span class="line">            self.block.add(H_Swish())</span><br><span class="line">        elif name.find('relu6') != -1:</span><br><span class="line">            self.block.add(keras.layers.ReLU(6))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def mobilenet_v3(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu6(16, (3, 3), (2, 2), 'same', name='conv_bn_h_swish1')(x)</span><br><span class="line"></span><br><span class="line">    x = bneck(x, 16, 16, (3, 3), (1, 1), squeeze=False, activation='relu6', name='bneck1')</span><br><span class="line"></span><br><span class="line">    x = bneck(x, 24, 64, (3, 3), (2, 2), squeeze=False, activation='relu6', name='bneck2_1')</span><br><span class="line">    x = bneck(x, 24, 72, (3, 3), (1, 1), squeeze=False, activation='relu6', name='bneck2_2')</span><br><span class="line"></span><br><span class="line">    x = bneck(x, 40, 72, (5, 5), (2, 2), squeeze=True, activation='relu6', name='bneck3_1')</span><br><span class="line">    x = bneck(x, 40, 120, (5, 5), (1, 1), squeeze=True, activation='relu6', name='bneck3_2')</span><br><span class="line">    x = bneck(x, 40, 120, (5, 5), (1, 1), squeeze=True, activation='relu6', name='bneck3_3')</span><br><span class="line"></span><br><span class="line">    x = bneck(x, 80, 240, (3, 3), (2, 2), squeeze=False, activation='h_swish', name='bneck4_1')</span><br><span class="line">    x = bneck(x, 80, 200, (3, 3), (1, 1), squeeze=False, activation='h_swish', name='bneck4_2')</span><br><span class="line">    x = bneck(x, 80, 184, (3, 3), (1, 1), squeeze=False, activation='h_swish', name='bneck4_3')</span><br><span class="line">    x = bneck(x, 80, 184, (3, 3), (1, 1), squeeze=False, activation='h_swish', name='bneck4_4')</span><br><span class="line"></span><br><span class="line">    x = bneck(x, 112, 480, (3, 3), (1, 1), squeeze=True, activation='h_swish', name='bneck5_1')</span><br><span class="line">    x = bneck(x, 112, 672, (3, 3), (1, 1), squeeze=True, activation='h_swish', name='bneck5_2')</span><br><span class="line"></span><br><span class="line">    x = bneck(x, 160, 672, (5, 5), (2, 2), squeeze=True, activation='h_swish', name='bneck6_1')</span><br><span class="line">    x = bneck(x, 160, 960, (5, 5), (1, 1), squeeze=True, activation='h_swish', name='bneck6_2')</span><br><span class="line">    x = bneck(x, 160, 960, (5, 5), (1, 1), squeeze=True, activation='h_swish', name='bneck6_3')</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu6(960, (1, 1), (1, 1), 'same', name='conv_bn_h_swish2'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Reshape((1, 1, 960), name='reshape1'),</span><br><span class="line">                Conv_Bn_Relu6(1280, (1, 1), (1, 1), 'same', name='conv_bn_h_swish3'),</span><br><span class="line">                keras.layers.Conv2D(1000, (1, 1), activation='softmax', name='conv'),</span><br><span class="line">                keras.layers.Reshape((1000,), name='reshape2'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='MobileNet-V3')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = mobilenet_v3(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/MobileNet_V3_R.png" alt="MobileNet_V3"></p>
<h1 id="MobileNet-V3小结"><a href="#MobileNet-V3小结" class="headerlink" title="MobileNet-V3小结"></a><font size="5" color="red">MobileNet-V3小结</font></h1><p>  MobileNet-V3是一种复杂的轻量级深度学习网络，从上图可以看出MobileNet-V3模型的参数量为5M，其在MobileNet-V2的基础上加入了大量黑科技，因此获得了更好的效果。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>MobileNet-V2</title>
    <url>/2020/03/22/feature_extraction%20MobileNet_V2/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">MobileNet-V2</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>MobileNet-V2:</strong>是MobileNet的升级版本，<strong>Google公司于2018年</strong>提出，是一个结构简单，参数量较少的轻量级深度学习网络模型。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/MobileNet_V2.png" alt="MobileNet_V2"></p>
<h1 id="MobileNet-V2特点"><a href="#MobileNet-V2特点" class="headerlink" title="MobileNet-V2特点"></a><font size="5" color="red">MobileNet-V2特点</font></h1><p>  <font size="3"><strong>保留MobileNet的SeparableConv深度可分离卷积结构，并且在深度可分离卷积前通过1x1卷积提升通道数。</strong></font><br>  <font size="3">引入了<strong>反残差结构</strong>，借鉴了ResNet的思想，联系了不同尺度的特征</font><br>  <font size="3">引入了<strong>线性瓶颈结构</strong>，在残差相加前不使用ReLU6激活函数，避免破坏特征</font></p>
<h1 id="Separable-Convolution"><a href="#Separable-Convolution" class="headerlink" title="Separable Convolution"></a><font size="5" color="red">Separable Convolution</font></h1><p><img src="/images/Feature_extraction/Xception_D.png" alt="Xception"><br>  <font size="3"><strong>Separable Convolution(深度可分离卷积)</strong>：是上面两个卷积合二为一的卷积操作。</font><br>  <font size="3"><strong>第一步：DepthwiseConv，对每一个通道进行卷积</strong></font><br>  <font size="3"><strong>第二步：PointwiseConv，对第一步得到的结果进行1x1卷积，实现通道融合</strong></font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，并且可以<strong>调整为任意合适的通道数</strong>。第一步的<strong>目的是减少参数量</strong>，第二步是<strong>调整通道数</strong>，因此将两个卷积操作结合，组成深度可分离卷积。</font></p>
<h1 id="MobileNet-V2图像分析"><a href="#MobileNet-V2图像分析" class="headerlink" title="MobileNet-V2图像分析"></a><font size="5" color="red">MobileNet-V2图像分析</font></h1><p><img src="/images/Feature_extraction/MobileNet_V2_A.png" alt="MobileNet_V2"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu6(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu6, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('relu') != -1:</span><br><span class="line">            self.block.add(keras.layers.ReLU(6))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(x, filters, t, strides, name):</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu6(t * filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu6'.format(name)),</span><br><span class="line">                Conv_Bn_Relu6(None, (3, 3), strides, 'same', name='{}_depthwiseconv_bn_relu6'.format(name)),</span><br><span class="line">                Conv_Bn_Relu6(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    if shortcut.shape[-1] == filters and strides == (1, 1):</span><br><span class="line">        x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def add_block(x, filters, t, strides, n, name):</span><br><span class="line">    x = block(x, filters, t, strides, name='{}_1'.format(name))</span><br><span class="line">    for i in range(n - 1):</span><br><span class="line">        x = block(x, filters, t, (1, 1), name='{}_{}'.format(name, i + 2))</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def mobilenet_v2(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((1, 1), name='zeropadding'),</span><br><span class="line">                Conv_Bn_Relu6(32, (3, 3), (2, 2), 'valid', name='conv1'))(x)</span><br><span class="line"></span><br><span class="line">    x = add_block(x, 16, 1, (1, 1), 1, 'block1')</span><br><span class="line">    x = add_block(x, 24, 6, (2, 2), 2, 'block2')</span><br><span class="line">    x = add_block(x, 32, 6, (2, 2), 3, 'block3')</span><br><span class="line">    x = add_block(x, 64, 6, (2, 2), 4, 'block4')</span><br><span class="line">    x = add_block(x, 96, 6, (1, 1), 3, 'block5')</span><br><span class="line">    x = add_block(x, 160, 6, (2, 2), 3, 'block6')</span><br><span class="line">    x = add_block(x, 320, 6, (1, 1), 1, 'block7')</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu6(1280, (1, 1), (1, 1), 'same', name='conv2'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='MobileNet-V2')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = mobilenet_v2(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/MobileNet_V2_R.png" alt="MobileNet_V2"></p>
<h1 id="MobileNet-V2小结"><a href="#MobileNet-V2小结" class="headerlink" title="MobileNet-V2小结"></a><font size="5" color="red">MobileNet-V2小结</font></h1><p>  MobileNet-V2是一种高效的轻量级深度学习网络，<strong>MobileNet-V2模型的参数量和MobileNet几乎相同</strong>，都是4M的参数量，因为其<strong>结合了不同尺度的特征</strong>，因此效果优于MobileNet。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>Turing Reward in 2019</title>
    <url>/2020/03/22/TuringReward-2019/</url>
    <content><![CDATA[<p>  2020 年 3 月 18 日，ACM 宣布，计算机图形学领域的两位大牛 Patrick M. Hanrahan和 Edwin E. Catmull 获得了 2018 年的图灵奖，以表彰他们对3D计算机图形学的贡献，以及这些技术对电影制作和计算机生成图像(CGI)等应用的革命性影响。</p>
<a id="more"></a>
<p>他们通过概念创新从根本上影响了计算机图形学的领域，推动了3D动画电影的发展，而且对于视频游戏行业的发展，如VR(Virtual Reality，虚拟现实)，AR(Augmented Reality，增强现实)也起到了重要的作用，不仅如此，他们在GPU上的见解对人工智能领域产生了巨大的推动作用。</p>
<p>让我们来看看两位大佬所作出的主要贡献：<br><strong>艾德·卡姆尔(Edwin Catmull)</strong><br><img src="/images/TURING/ed.png" alt="Edwin Catmull"><br>   计算机科学家，迪士尼动画工作室主席，皮克斯动画工作室主席，1954年生，Catmull 于 1974 年在犹他大学获得计算机科学博士学位。他的导师包括计算机图形学之父，1988年ACM图灵奖获得者Ivan Sutherland。在他的博士学位论文中，Catmull引入两种突破性的技术来显示曲面补丁而不是多边形：用于管理计算机图形学中图像深度坐标的 Z 缓冲(Z-buffering)；以及将二维表面纹理映射在三维对象上的纹理映射(texture mapping)。</p>
<p>   在犹他大学期间，Catmull 还创建了一种通过指定一个粗糙多边形网格来表示一个平滑曲面的新方法。Catmull 的技术在发展真实感图形和消除 “锯齿”(原始计算机图形学的一个特征，图形周围的粗糙边缘)方面发挥了重要作用。</p>
<p>   离开犹他大学后， Catmull 成立了纽约理工学院(NYIT)计算机图形实验室，这是美国最早的专用计算机图形实验室之一。在那个时候，Catmull 就梦想着制作一部计算机动画电影。</p>
<p>   1979 年，《星球大战》的导演 George Lucas 聘请了 Catmull，使得他离自己的动画电影梦又近了一步。在 Lucas 电影公司(LucasFilm)，Catmull 及其同事继续开发 3D 计算机图形动画的创新技术，而当时这个行业仍然被传统的 2D 技术所主导。</p>
<p>   1986 年，史蒂夫乔布斯(Steve Jobs)收购了卢卡斯电影公司(LucasFilm)的计算机动画部门，并将其更名为皮克斯，Catmull 担任总裁。</p>
<p><strong>Patrick M. Hanrahan</strong><br><img src="/images/TURING/han.png" alt="Hanrahan"><br>  **Hanrahan 于 1985 年获得了威斯康星大学麦迪逊分校的生物物理学博士学位，加入皮克斯动画工作室之前，还曾在NYIT的计算机图形学实验室短暂工作过。</p>
<p>   在皮克斯动画工作室期间，Hanrahan 是一种新型图形系统的首席架构师，该技术可以使用真实的材料属性和光线来渲染曲线形状。此系统(后来称为 RenderMan)的一个关键思想是着色器(用于着色 CGI 图像)。RenderMan 的功能将光反射行为与几何形状分开，并计算形状上各点的颜色、透明度和纹理。RenderMan 系统还结合了 Catmull 早前在该领域做出的贡献的 Z 缓冲和细分曲面创新。</p>
<p>   在皮克斯工作期间， Hanrahan 还开发了体绘图(volume rendering)技术，该技术使 CGI 艺术家可以渲染 3D 数据集的 2D 投影，例如抽烟。</p>
<p>   在 Hanrahan 最常被引用的论文中，Hanrahan 与合著者 Marc Levoy 一起介绍了一种光场渲染技术，这种方法可通过从任意点生成新视图而没有深度信息或特征匹配，从而使观看者感觉它们正在穿越场景。Hanrahan 还开发了使用次表面散射来描绘皮肤和头发的技术，并使用蒙特卡洛射线追踪技术来渲染复杂的照明效果(所谓的全局照明或 GI)。</p>
<p>   1990 年，Hanrahan 在一篇开创性论文中发表了他的 RenderMan 研究。此时，距离计算机硬件发展到可以使用 Hanrahan 的 RenderMan 系统制作完整的 3D 计算机动画电影《玩具总动员》，还有五年的时间。</p>
<p><img src="/images/TURING/afan.png" alt="Avatar"> </p>
<p>   在 Catmull 的领导下，皮克斯使用 RenderMan 技术制作了一系列成功的电影。皮克斯还将 RenderMan 授权给其他电影公司，在过去 47 部获得奥斯卡最佳视觉效果提名的电影中，有 44 部使用了该软件，其中包括《阿凡达》、《泰坦尼克号》、《美女与野兽》、《指环王》三部曲以及《星球大战前传》等。</p>
<p>   1989 年，Hanrahan 在离开皮克斯之后进入普林斯顿大学和斯坦福大学担任学术职务。从 20 世纪 90 年代开始，他和他的研究团队扩展了 RenderMan 着色语言，使其可以在更强大的 GPU 上实时工作。Hanrahan 和他的学生开发的 GPUs 编程语言，也引起了商业版本(包括 OpenGL 阴影语言)的开发，并彻底改变了视频游戏的编写。</p>
<p>   GPUs 上广泛使用的各种着色语言，最终要求 GPUs 硬件设计人员开发更灵活的体系结构。这些架构又反过来使 GPUs 可以用于各种计算环境，包括为高性能计算应用程序运行算法，以及为人工智能应用程序在海量数据集上训练机器学习算法。特别一提的是，Hanrahan 和他的学生还开发了一种用于 GPU 的语言：Brook，并最终催生了NVIDIA的 CUDA。</p>
<p><img src="/images/TURING/cuda.png" alt="cuda"> </p>
<p>   Catmull 在皮克斯呆了 30 多年，皮克斯后来也成为迪斯尼动画工作室的子公司。在他的领导下，实验室的数十名研究人员发明并发布了对计算机动画电影和计算机图形产生重大贡献的基础技术，包括图像合成(image compositing)、运动模糊(motion blur)、布料模拟(cloth simulation)等。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Turing Reward</category>
      </categories>
  </entry>
  <entry>
    <title>MobileNet</title>
    <url>/2020/03/20/feature_extraction%20MobileNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">MobileNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>MobileNet:</strong>是<strong>2017年Google针对手机等嵌入式设备提出的一种轻量级的深层神经网络</strong>，故称之为MobileNet，由于其网络结构简单，现在仍然具有很好的适用性。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/MobileNet.png" alt="MobileNet"></p>
<h1 id="MobileNet特点"><a href="#MobileNet特点" class="headerlink" title="MobileNet特点"></a><font size="5" color="red">MobileNet特点</font></h1><p>  <font size="3"><strong>结构和VGG类似，只是将标准卷积换成SeparableConv深度可分离卷积</strong></font><br>  <font size="3">引入<strong>ReLU6</strong>代替ReLU，使得大于0的数值也具有非线性</font></p>
<h1 id="Separable-Convolution"><a href="#Separable-Convolution" class="headerlink" title="Separable Convolution"></a><font size="5" color="red">Separable Convolution</font></h1><p><img src="/images/Feature_extraction/Xception_D.png" alt="Xception"><br>  <font size="3"><strong>Separable Convolution(深度可分离卷积)</strong>：是上面两个卷积合二为一的卷积操作。</font><br>  <font size="3"><strong>第一步：DepthwiseConv，对每一个通道进行卷积</strong></font><br>  <font size="3"><strong>第二步：PointwiseConv，对第一步得到的结果进行1x1卷积，实现通道融合</strong></font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，并且可以<strong>调整为任意合适的通道数</strong>。第一步的<strong>目的是减少参数量</strong>，第二步是<strong>调整通道数</strong>，因此将两个卷积操作结合，组成深度可分离卷积。</font></p>
<h1 id="MobileNet图像分析"><a href="#MobileNet图像分析" class="headerlink" title="MobileNet图像分析"></a><font size="5" color="red">MobileNet图像分析</font></h1><p><img src="/images/Feature_extraction/MobileNet_A.png" alt="MobileNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu6(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu6, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('depthwise') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.DepthwiseConv2D(kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        self.block.add(keras.layers.ReLU(6))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def block(filters, strides, name):</span><br><span class="line"></span><br><span class="line">    return compose(Conv_Bn_Relu6(None, (3, 3), strides, 'same', name='{}_depthwiseconv_bn_relu6'.format(name)),</span><br><span class="line">                   Conv_Bn_Relu6(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu6'.format(name)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def mobilenet(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu6(32, (3, 3), (2, 2), 'same', name='conv_bn_relu6')(x)</span><br><span class="line"></span><br><span class="line">    filters = [64, 128, 128, 256, 256, 512, 512, 512, 512, 512, 512, 1024, 1024]</span><br><span class="line">    strides = [(1, 1), (2, 2), (1, 1), (2, 2), (1, 1), (2, 2), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 2), (1, 1)]</span><br><span class="line">    for i in range(len(filters)):</span><br><span class="line">        x = block(filters[i], strides[i], name='block{}'.format(i + 1))(x)</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Reshape((1, 1, 1024), name='reshape1'),</span><br><span class="line">                keras.layers.Dropout(0.2, name='dropout'),</span><br><span class="line">                keras.layers.Conv2D(1000, (1, 1), name='conv'),</span><br><span class="line">                keras.layers.Reshape((1000, ), name='reshape2'),</span><br><span class="line">                keras.layers.Softmax(name='softmax'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='MobileNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = mobilenet(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/MobileNet_R.png" alt="MobileNet"></p>
<h1 id="MobileNet小结"><a href="#MobileNet小结" class="headerlink" title="MobileNet小结"></a><font size="5" color="red">MobileNet小结</font></h1><p>  MobileNet是一种简单的轻量级深度学习网络，从上图可以看出MobileNet模型的参数量只有4M，在移动设备中有良好表现，有时也可<strong>作为替代VGG的特征提取网络</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>SqueezeNet</title>
    <url>/2020/03/18/feature_extraction%20SqueezeNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">SqueezeNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>SqueezeNet:</strong>是一种轻量级深度神经网络模型，在<strong>2017年发表于ICLR</strong>，作者来自Berkeley和Stanford，其<strong>只用1/50的参数量，可以达到与AlexNet相同的精度</strong>，其核心结构为<strong>Fire Module</strong>。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/SqueezeNet.png" alt="SqueezeNet"></p>
<h1 id="SqueezeNet特点"><a href="#SqueezeNet特点" class="headerlink" title="SqueezeNet特点"></a><font size="5" color="red">SqueezeNet特点</font></h1><p>  <font size="3">引入<strong>Fire Module</strong>，根据<strong>降维</strong>思想，先通过1x1的卷积核对参数量进行压缩，然后采用了<strong>Inception</strong>的思想，进行多路融合。</font></p>
<h1 id="SqueezeNet图像分析"><a href="#SqueezeNet图像分析" class="headerlink" title="SqueezeNet图像分析"></a><font size="5" color="red">SqueezeNet图像分析</font></h1><p><img src="/images/Feature_extraction/SqueezeNet_A.png" alt="SqueezeNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def fire_block(x, s1, e1, e3, name):</span><br><span class="line">    x = keras.layers.Conv2D(s1, (1, 1), activation='relu', name='{}_conv'.format(name))(x)</span><br><span class="line">    x1 = keras.layers.Conv2D(e1, (1, 1), activation='relu', name='{}_part1_conv'.format(name))(x)</span><br><span class="line">    x2 = keras.layers.Conv2D(e3, (3, 3), padding='same', activation='relu', name='{}_part2_conv'.format(name))(x)</span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x1, x2])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def squeezenet(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Conv2D(96, (7, 7), (2, 2), padding='same', activation='relu', name='conv1'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), name='maxpool'))(x)</span><br><span class="line"></span><br><span class="line">    x = fire_block(x, 16, 64, 64, 'fire_block1_1')</span><br><span class="line">    x = fire_block(x, 16, 64, 64, 'fire_block1_2')</span><br><span class="line"></span><br><span class="line">    x = fire_block(x, 32, 128, 128, 'fire_block2_1')</span><br><span class="line">    x = keras.layers.MaxPool2D((3, 3), (2, 2), name='fire_block2_maxpool')(x)</span><br><span class="line">    x = fire_block(x, 32, 128, 128, 'fire_block2_2')</span><br><span class="line"></span><br><span class="line">    x = fire_block(x, 48, 192, 192, 'fire_block3_1')</span><br><span class="line">    x = fire_block(x, 48, 192, 192, 'fire_block3_2')</span><br><span class="line"></span><br><span class="line">    x = fire_block(x, 64, 256, 256, 'fire_block4_1')</span><br><span class="line">    x = keras.layers.MaxPool2D((3, 3), (2, 2), name='fire_block4_maxpool')(x)</span><br><span class="line">    x = fire_block(x, 64, 256, 256, 'fire_block4_2')</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.Dropout(0.5, name='dropout'),</span><br><span class="line">                keras.layers.Conv2D(1000, (1, 1), activation='relu', name='conv2'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Softmax(name='softmax'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='SqueezeNet')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = squeezenet(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/SqueezeNet_R.png" alt="SqueezeNet"></p>
<h1 id="SqueezeNet小结"><a href="#SqueezeNet小结" class="headerlink" title="SqueezeNet小结"></a><font size="5" color="red">SqueezeNet小结</font></h1><p>  SqueezeNet是一种简单的轻量级深度学习网络，从上图可以看出SqueezeNet模型的参数量只有1M，因此在某些特殊场合中能够发挥出很好的效果。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>SENet</title>
    <url>/2020/03/17/feature_extraction%20SENet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">SENet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>SENet:</strong>是<strong>2017年发表在CVPR</strong>上的一个模型，也是<strong>最后一届ImageNet 2017竞赛分类任务的冠军</strong>，其创新点是<strong>引入了注意力Squeeze-and-Excitation (SE)模块</strong>。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/SENet.png" alt="SENet"></p>
<h1 id="SENet特点"><a href="#SENet特点" class="headerlink" title="SENet特点"></a><font size="5" color="red">SENet特点</font></h1><p>  <font size="3">引入了<strong>注意力Squeeze-and-Excitation(SE)模块</strong></font><br>  <font size="3">由于SE模块简单有效，因此可以<strong>很容易的和其他模型耦合</strong>，和ResNet耦合变成SE-ResNet，和Inception-V3耦合变成SE-Inception-V3等等</font></p>
<h1 id="Squeeze-and-Excitation"><a href="#Squeeze-and-Excitation" class="headerlink" title="Squeeze-and-Excitation"></a><font size="5" color="red">Squeeze-and-Excitation</font></h1><p><img src="/images/Feature_extraction/SENet_S.png" alt="SENet"><br>  <font size="3"><strong>Squeeze-and-Excitation</strong>：又称为<strong>特征重标定卷积</strong>，或者<strong>注意力机制</strong>。具体来说，就是通过<strong>学习的方式来自动获取到每个特征通道的重要程度</strong>，然后依照这个重要程度去<strong>提升有用的特征并抑制对当前任务用处不大的特征</strong>。</font><br>  <font size="3">首先是 <strong>Squeeze操作</strong>，先<strong>进行全局池化，具有全局的感受野</strong>，并且输出的维度和输入的特征通道数相匹配，它表征着在特征通道上响应的全局分布。</font><br>  <font size="3">然后是<strong>Excitation操作</strong>，<strong>通过全连接层为每个特征通道生成权重，建立通道间的相关性</strong>，<strong>输出的权重看做是进过特征选择后的每个特征通道的重要性</strong>，然后通过<strong>乘法逐通道加权到先前的特征上</strong>，完成在通道维度上的对原始特征的重标定。</font></p>
<h1 id="SE-ResNet50图像分析"><a href="#SE-ResNet50图像分析" class="headerlink" title="SE-ResNet50图像分析"></a><font size="5" color="red">SE-ResNet50图像分析</font></h1><p><img src="/images/Feature_extraction/SENet_A.png" alt="SENet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        output = self.bn(conv)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def res_block(x, filters, strides, type, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_Bn_Relu(filters // 4, (1, 1), (1, 1), padding='same', name='{}{}_conv_bn_relu1'.format(type, name)),</span><br><span class="line">                Conv_Bn_Relu(filters // 4, (3, 3), strides, padding='same', name='{}{}_conv_bn_relu2'.format(type, name)),</span><br><span class="line">                Conv_Bn(filters, (1, 1), (1, 1), padding='same', name='{}{}_conv_bn3'.format(type, name)))(x)</span><br><span class="line">    x = se_block(x, filters, name='{}{}_se'.format(type, name))</span><br><span class="line">    if type == 'conv_block':</span><br><span class="line">        shortcut = keras.layers.Conv2D(filters, (1, 1), strides, name='{}{}_shortcut'.format(type, name))(shortcut)</span><br><span class="line">    x = keras.layers.Add(name='{}{}_add'.format(type, name))([x, shortcut])</span><br><span class="line">    x = keras.layers.ReLU(name='{}{}_relu3'.format(type, name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def se_block(x, filters, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='{}_global_averagepool'.format(name)),</span><br><span class="line">                keras.layers.Dense(filters // 16, name='{}_dense1'.format(name)),</span><br><span class="line">                keras.layers.ReLU(name='{}_relu'.format(name)),</span><br><span class="line">                keras.layers.Dense(filters, name='{}_dense2'.format(name)),</span><br><span class="line">                keras.layers.Activation('sigmoid', name='{}_sigmoid'.format(name)),</span><br><span class="line">                keras.layers.Reshape((1, 1, filters), name='{}_reshape'.format(name)))(x)</span><br><span class="line">    x = keras.layers.Multiply(name='{}_multiply'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def se_resnet50(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((3, 3), name='zeropadding'),</span><br><span class="line">                Conv_Bn_Relu(64, (7, 7), (2, 2), padding='valid', name='conv_bn_relu'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), padding='same', name='maxpool'))(x)</span><br><span class="line">    filters = [256, 512, 1024, 2048]</span><br><span class="line">    strides = [(1, 1), (2, 2), (2, 2), (2, 2)]</span><br><span class="line">    times = [3, 4, 6, 3]</span><br><span class="line">    for i in range(len(times)):</span><br><span class="line">        x = res_block(x, filters[i], strides[i], 'conv_block', i + 1)</span><br><span class="line">        for j in range(times[i] - 1):</span><br><span class="line">            x = res_block(x, filters[i], (1, 1), 'identity_block{}_'.format(i + 1), j + 1)</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line">    model = keras.Model(input_tensor, x, name='SE_ResNet50')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = se_resnet50(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/SENet_R.png" alt="SENet"></p>
<h1 id="SENet小结"><a href="#SENet小结" class="headerlink" title="SENet小结"></a><font size="5" color="red">SENet小结</font></h1><p>  SENet是一种非常好的思路，其模型参数需要根据选择的耦合模型确定，如果耦合模型为SE-ResNet50，则参数量为28M，其<strong>注意力机制非常有效</strong>，为<strong>MobileNet-V3</strong>的发展，<strong>EfficientNet</strong>，<strong>GhostNet</strong>等网络起到了推动作用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>DenseNet</title>
    <url>/2020/03/16/feature_extraction%20DenseNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">DenseNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>DenseNet:</strong>作为<strong>CVPR2017年的Best Paper</strong>，DenseNet<strong>脱离了加深网络层数(ResNet)和加宽网络结构(Inception)来提升网络性能的定式思维</strong>，通过<strong>特征重用和旁路</strong>,既<strong>大幅度减少了网络的参数量</strong>,又在一定程度上<strong>缓解了梯度消失问题</strong>的产生。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/DenseNet.png" alt="DenseNet"></p>
<h1 id="DenseNet特点"><a href="#DenseNet特点" class="headerlink" title="DenseNet特点"></a><font size="5" color="red">DenseNet特点</font></h1><p>  <font size="3"><strong>同样深度的DenseNet所需的参数量相比ResNet大幅减少</strong></font><br>  <font size="3">Dense Block类似于ResNet中的Identity Block，Transition Block类似于ResNet中的Conv Block</font><br>  <font size="3">结构简单，<strong>综合了不同尺度的感受野</strong>，提升网络性能</font></p>
<h1 id="不同尺寸DenseNet网络结构"><a href="#不同尺寸DenseNet网络结构" class="headerlink" title="不同尺寸DenseNet网络结构"></a><font size="5" color="red">不同尺寸DenseNet网络结构</font></h1><p><img src="/images/Feature_extraction/DenseNet_C.png" alt="DenseNet"></p>
<h1 id="DenseNet121图像分析"><a href="#DenseNet121图像分析" class="headerlink" title="DenseNet121图像分析"></a><font size="5" color="red">DenseNet121图像分析</font></h1><p><img src="/images/Feature_extraction/DenseNet_A.png" alt="DenseNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dense_block(x, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_Bn_Relu(128, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(32, (3, 3), (1, 1), 'same', name='{}_conv_bn_relu2'.format(name)))(x)</span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def transition_block(x, filters, name):</span><br><span class="line">    x = compose(Conv_Bn_Relu(filters, (1, 1), (1, 1), 'same', name='{}_conv_bn_relu'.format(name)),</span><br><span class="line">                keras.layers.AveragePooling2D((2, 2), (2, 2), name='{}_averagepool'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def densenet121(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((3, 3), name='zeropadding1'),</span><br><span class="line">                Conv_Bn_Relu(64, (7, 7), (2, 2), 'valid', name='conv_bn_relu'),</span><br><span class="line">                keras.layers.ZeroPadding2D((1, 1), name='zeropadding2'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), name='Max_Pooling'))(x)</span><br><span class="line"></span><br><span class="line">    for i in range(6):</span><br><span class="line">        x = dense_block(x, name='dense_block1_{}'.format(i + 1))</span><br><span class="line">    x = transition_block(x, 128, name='transition_block1')</span><br><span class="line"></span><br><span class="line">    for i in range(12):</span><br><span class="line">        x = dense_block(x, name='dense_block2_{}'.format(i + 1))</span><br><span class="line">    x = transition_block(x, 256, name='transition_block2')</span><br><span class="line"></span><br><span class="line">    for i in range(24):</span><br><span class="line">        x = dense_block(x, name='dense_block3_{}'.format(i + 1))</span><br><span class="line">    x = transition_block(x, 512, name='transition_block3')</span><br><span class="line"></span><br><span class="line">    for i in range(16):</span><br><span class="line">        x = dense_block(x, name='dense_block4_{}'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='DenseNet121')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = densenet121(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/DenseNet_R.png" alt="DenseNet"></p>
<h1 id="DenseNet小结"><a href="#DenseNet小结" class="headerlink" title="DenseNet小结"></a><font size="5" color="red">DenseNet小结</font></h1><p>  DenseNet是一种简单的深度学习网络，也是一种非常有效的特征提取模型。从上图可以看出<strong>DenseNet121模型的参数量只有8M，甚至是ResNet50的参数量的三分之一</strong>，因此实际任务中可以使用DenseNet作为特征提取网络，<strong>既高效又节约内存和计算量</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>实现 strStr()(Leetcode 28)</title>
    <url>/2020/03/15/program%20Leetcode28/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode28.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   这道题目简单来说就是一个字符串匹配问题，看起来很简单，但是想要降低时间复杂度较为困难。可以通过暴力法或者KMP方法求解。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>暴力法很好理解，长度已经给定，穷举所有可能的子串，并且与模板字符串比较，如果相等则输出出现的位置，否则输出-1即可，时间复杂度为O((N-L)L)，空间复杂度为O(1)，其中N为原始字符串长度，L为模板字符串长度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def strStr(self, haystack, needle):</span><br><span class="line">        """</span><br><span class="line">        :haystack: str</span><br><span class="line">        :needle: str</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line">        lens = len(needle)</span><br><span class="line">        for i in range(len(haystack) - lens + 1):</span><br><span class="line">            if haystack[i:i + lens] == needle:</span><br><span class="line">                return i</span><br><span class="line">        return -1</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="KMP"><a href="#KMP" class="headerlink" title="KMP"></a><font size="5" color="red">KMP</font></h1><p>KMP算法是一种专门解决字符串匹配的算法，因为暴力法浪费了太多的比较次数，尤其是前面的字符都匹配正确后，最后一个字符匹配失败，又要从头开始匹配，效率太低，而KMP算法可以完成O(N)的时间复杂度和O(L)的空间复杂度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def strStr(self, haystack, needle):</span><br><span class="line">        """</span><br><span class="line">        :haystack: str</span><br><span class="line">        :needle: str</span><br><span class="line">        :rtype: int</span><br><span class="line">        """</span><br><span class="line"></span><br><span class="line">        def getNext(pattern):</span><br><span class="line">            next = [-1] * len(pattern)</span><br><span class="line">            i, j = 0, -1</span><br><span class="line">            while i &lt; len(pattern) - 1:</span><br><span class="line">                if j == -1 or pattern[i] == pattern[j]:</span><br><span class="line">                    i += 1</span><br><span class="line">                    j += 1</span><br><span class="line">                    next[i] = j</span><br><span class="line">                else:</span><br><span class="line">                    j = next[j]</span><br><span class="line">            return next</span><br><span class="line"></span><br><span class="line">        next = getNext(needle)</span><br><span class="line">        i, j = 0, 0</span><br><span class="line">        while i &lt; len(haystack) and j &lt; len(needle):</span><br><span class="line">            if j == -1 or haystack[i] == needle[j]:</span><br><span class="line">                i += 1</span><br><span class="line">                j += 1</span><br><span class="line">            else:</span><br><span class="line">                j = next[j]</span><br><span class="line">        if j &gt;= len(needle):</span><br><span class="line">            return i - len(needle)</span><br><span class="line">        else:</span><br><span class="line">            return -1</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  字符串匹配问题是一个经典的问题，大多数学校或者数据结构算法课中都作为例子进行讲解，但是很难讲的非常透彻，因为这个问题太抽象，在这里我只能用文字进行描述，所以描述的可能更不清晰，小伙伴们以要理解我举得例子，尤其是j = Next[j]这一步，可以说是KMP问题的精髓，看懂了这一步基本上就可以明白算法具体在做什么了。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>字符串</category>
        <category>特定算法</category>
      </categories>
  </entry>
  <entry>
    <title>Xception</title>
    <url>/2020/03/14/feature_extraction%20Xception/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Xception</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Xception:</strong>是<strong>谷歌公司对Inception-V3的改进</strong>，被<strong>CVPR2017年收录</strong>，是一个很好的图像特征提取模型。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/Xception.png" alt="Xception"></p>
<h1 id="Xception特点"><a href="#Xception特点" class="headerlink" title="Xception特点"></a><font size="5" color="red">Xception特点</font></h1><p>  <font size="3">除了Inception的特点以外，采用了<strong>SeparableConv(深度可分离卷积)代替Inception中的(Conv)卷积操作</strong>，大大节约了参数量</font></p>
<h1 id="Separable-Convolution"><a href="#Separable-Convolution" class="headerlink" title="Separable Convolution"></a><font size="5" color="red">Separable Convolution</font></h1><p><img src="/images/Feature_extraction/Xception_D.png" alt="Xception"><br>  <font size="3"><strong>Separable Convolution(深度可分离卷积)</strong>：是上面两个卷积合二为一的卷积操作。</font><br>  <font size="3"><strong>第一步：DepthwiseConv，对每一个通道进行卷积</strong></font><br>  <font size="3"><strong>第二步：PointwiseConv，对第一步得到的结果进行1x1卷积，实现通道融合</strong></font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>，并且可以<strong>调整为任意合适的通道数</strong>，在<strong>Xception，MobileNet，EfficientNet，ShuffleNet</strong>网络中有大量使用。第一步的<strong>目的是减少参数量</strong>，第二步是<strong>调整通道数</strong>，因此将两个卷积操作结合，组成深度可分离卷积。</font></p>
<h1 id="Xception图像分析"><a href="#Xception图像分析" class="headerlink" title="Xception图像分析"></a><font size="5" color="red">Xception图像分析</font></h1><p><img src="/images/Feature_extraction/Xception_A.png" alt="Xception"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.block = keras.Sequential()</span><br><span class="line">        if name.find('separable') == -1:</span><br><span class="line">            self.block.add(keras.layers.Conv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        else:</span><br><span class="line">            self.block.add(keras.layers.SeparableConv2D(filters, kernel_size, strides, padding=padding))</span><br><span class="line">        self.block.add(keras.layers.BatchNormalization())</span><br><span class="line">        if name.find('relu') != -1:</span><br><span class="line">            self.block.add(keras.layers.ReLU())</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line"></span><br><span class="line">        return self.block(inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def entry_exit_flow(x, filters, relu, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    if relu:</span><br><span class="line">        x = keras.layers.ReLU(name='{}_relu'.format(name))(x)</span><br><span class="line">    x = compose(Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_separableconv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_separableconv_bn2'.format(name)),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), 'same', name='{}_maxpool'.format(name)))(x)</span><br><span class="line">    shortcut = Conv_Bn_Relu(filters, (1, 1), (2, 2), 'same', name='{}_shortcut_conv_bn'.format(name))(shortcut)</span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def middle_flow(x, filters, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = keras.layers.ReLU(name='{}_relu'.format(name))(x)</span><br><span class="line">    x = compose(Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_separableconv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_separableconv_bn_relu2'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(filters, (3, 3), (1, 1), 'same', name='{}_separableconv_bn3'.format(name)),)(x)</span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def xception(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu(32, (3, 3), (2, 2), 'valid', name='conv_bn_relu1'),</span><br><span class="line">                Conv_Bn_Relu(64, (3, 3), (1, 1), 'valid', name='conv_bn_relu2'))(x)</span><br><span class="line"></span><br><span class="line">    entry_filters = [128, 256, 728]</span><br><span class="line">    entry_relu = [False, True, True]</span><br><span class="line">    for i in range(len(entry_filters)):</span><br><span class="line">        x = entry_exit_flow(x, entry_filters[i], entry_relu[i], name='entry_flow{}'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    for i in range(8):</span><br><span class="line">        x = middle_flow(x, 728, name='middle_flow{}'.format(i + 1))</span><br><span class="line"></span><br><span class="line">    x = entry_exit_flow(x, 1024, relu=True, name='exit_flow1')</span><br><span class="line"></span><br><span class="line">    x = compose(Conv_Bn_Relu(1536, (3, 3), (1, 1), 'same', name='separableconv_bn_relu1'),</span><br><span class="line">                Conv_Bn_Relu(2048, (3, 3), (1, 1), 'same', name='separableconv_bn_relu2'),</span><br><span class="line">                keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='Xception')</span><br><span class="line"></span><br><span class="line">    return model</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/Xception_R.png" alt="Xception"></p>
<h1 id="Xception小结"><a href="#Xception小结" class="headerlink" title="Xception小结"></a><font size="5" color="red">Xception小结</font></h1><p>  Xception是一种复杂的深度学习网络，从上图可以看出Xception模型的参数量可达23M，因为其优秀的特征提取能力，并且网络结构相比Inception-V3较为简单。因此实际任务经常使用，如<strong>语义分割网络DeepLab-V3+使用的特征提取网络就是Xception</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>ResNeXt</title>
    <url>/2020/03/13/feature_extraction%20ResNeXt/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">ResNeXt</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>ResNeXt:</strong>是<strong>2017年发表于CVPR</strong>的一个模型，是<strong>ResNet网络的升级版本</strong>。和Inception-ResNet类似，Inception-ResNet可以认为是Inception模型的基础上吸收ResNet残差思想，而ResNext则可以认为是ResNet模型的基础上吸收Inception分块合并思想。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/ResNeXt.png" alt="ResNeXt"></p>
<h1 id="ResNeXt特点"><a href="#ResNeXt特点" class="headerlink" title="ResNeXt特点"></a><font size="5" color="red">ResNeXt特点</font></h1><p>  <font size="3"><strong>网络结构和ResNet相同</strong>，根据ResNet50，则可以修改为ResNeXt50，根据ResNet101，则可以修改为ResNeXt101，等等</font><br>  <font size="3"><strong>引入Inception模型分块合并思想</strong>，将ResNet中Conv Block和Identity Block中的<strong>普通卷积</strong>变成<strong>GroupConv分组卷积</strong>。提出了<strong>cardinality(基数)</strong>名词，基数为32，相当于分组卷积的组数为32，最后将32组卷积结果合并</font></p>
<h1 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a><font size="5" color="red">Group Convolution</font></h1><p><img src="/images/Feature_extraction/ShuffleNet_V2_G.png" alt="ShuffleNet_V2"><br>  <font size="3"><strong>Group Convolution(分组卷积)</strong>：<strong>传统卷积是采用一种卷积全连接的思想</strong>，特征图中的每一个像素点都结合了图像中所有通道的信息。而分组卷积特征图像<strong>每一个像素点只利用到一部分原始图像的通道</strong>。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个64x64x256的图像，经过5x5的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x5x5+1)=1638656，而分成32组的分组卷积的参数量为256x(8*5x5+1)=51456，参数量缩小了约32倍，当组数变成通道数时，则类似于Depthwise Convolution深度卷积</font></p>
<h1 id="ResNeXt50图像分析"><a href="#ResNeXt50图像分析" class="headerlink" title="ResNeXt50图像分析"></a><font size="5" color="red">ResNeXt50图像分析</font></h1><p><img src="/images/Feature_extraction/ResNeXt_A.png" alt="ResNeXt"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GroupConv(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, g_num, name='groupconv'):</span><br><span class="line">        super(GroupConv, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.g_num = g_num</span><br><span class="line">        self.groupconv = [keras.layers.Conv2D(filters // g_num, kernel_size, strides, padding='same', name='{}{}'.format(name, i + 1)) for i in range(g_num)]</span><br><span class="line">        self.concatenate = keras.layers.Concatenate(name='{}_concatenate'.format(name))</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        x_split = tf.split(inputs, self.g_num, axis=-1)</span><br><span class="line">        x = [self.groupconv[i](x_split[i]) for i in range(self.g_num)]</span><br><span class="line">        output = self.concatenate(x)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        if name.find('group') == -1:</span><br><span class="line">            self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        else:</span><br><span class="line">            self.conv = GroupConv(filters, kernel_size, strides, 32)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        output = self.bn(conv)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def res_block(x, filters, strides, type, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_Bn_Relu(filters // 2, (1, 1), (1, 1), padding='same', name='{}{}_conv_bn_relu1'.format(type, name)),</span><br><span class="line">                Conv_Bn_Relu(filters // 2, (3, 3), strides, padding='same', name='{}{}_groupconv_bn_relu2'.format(type, name)),</span><br><span class="line">                Conv_Bn(filters, (1, 1), (1, 1), padding='same', name='{}{}_conv_bn3'.format(type, name)))(x)</span><br><span class="line">    if type == 'conv_block':</span><br><span class="line">        shortcut = keras.layers.Conv2D(filters, (1, 1), strides, name='{}{}_shortcut'.format(type, name))(shortcut)</span><br><span class="line">    x = keras.layers.Add(name='{}{}_add'.format(type, name))([x, shortcut])</span><br><span class="line">    x = keras.layers.ReLU(name='{}{}_relu3'.format(type, name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def resnext50(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((3, 3), name='zeropadding'),</span><br><span class="line">                keras.layers.Conv2D(64, (7, 7), (2, 2), name='conv1'),</span><br><span class="line">                keras.layers.BatchNormalization(name='bn'),</span><br><span class="line">                keras.layers.ReLU(name='relu'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), padding='same', name='maxpool'))(x)</span><br><span class="line">    filters = [256, 512, 1024, 2048]</span><br><span class="line">    strides = [(1, 1), (2, 2), (2, 2), (2, 2)]</span><br><span class="line">    times = [3, 4, 6, 3]</span><br><span class="line">    for i in range(len(times)):</span><br><span class="line">        x = res_block(x, filters[i], strides[i], 'conv_block', i + 1)</span><br><span class="line">        for j in range(times[i] - 1):</span><br><span class="line">            x = res_block(x, filters[i], (1, 1), 'identity_block{}_'.format(i + 1), j + 1)</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line">    model = keras.Model(input_tensor, x, name='ResNeXt50')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = resnext50(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/ResNeXt_R.png" alt="ResNeXt"></p>
<h1 id="ResNeXt小结"><a href="#ResNeXt小结" class="headerlink" title="ResNeXt小结"></a><font size="5" color="red">ResNeXt小结</font></h1><p>  ResNeXt是一种非常有效的特征提取网络，ResNeXt参数量为25M，和相同结构的ResNet几乎相同，但是效果优于ResNet，因此是一种实用的特征提取网络。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>Inception-ResNet-V2</title>
    <url>/2020/03/12/feature_extraction%20Inception-ResNet_V2/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Inception-ResNet-V2</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Inception-ResNet-V2:</strong>和Inception-V4，Inception-ResNet-V1于<strong>2017年发表在AAAI</strong>同一篇文章中，三者的网络结构基本相同。结合了<strong>Inception-V3</strong>和<strong>ResNet</strong>的优点而成的深度学习网络。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/Inception-ResNet_V2.png" alt="Inception-ResNet_V2"></p>
<h1 id="Inception-ResNet-V2特点"><a href="#Inception-ResNet-V2特点" class="headerlink" title="Inception-ResNet-V2特点"></a><font size="5" color="red">Inception-ResNet-V2特点</font></h1><p>  <font size="3"><strong>在Inception-V3的基础上，增加了残差结构</strong></font><br>  <font size="3">对网络的输入<strong>增加了Stem层</strong>，不再是Inception-V3中简单的卷积操作</font></p>
<h1 id="Spatial-Separable-Convolution"><a href="#Spatial-Separable-Convolution" class="headerlink" title="Spatial Separable Convolution"></a><font size="5" color="red">Spatial Separable Convolution</font></h1><p><img src="/images/deep_learning/spatial.png" alt="spatial"><br>  <font size="3"><strong>Spatial Separable Convolution(空间可分离卷积)</strong>：将3x3的卷积分解为3x1的卷积核1x3的卷积，将7x7的卷积分解为7x1的卷积核1x7的卷积.。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个64x64x256的特征图，经过7x7的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x7x7+1)=3211520，而空间可分离卷积参数量为2x256x(256x7x1+1)=918016，参数量缩小了约3.5倍。</font></p>
<h1 id="Inception-ResNet-V2图像分析"><a href="#Inception-ResNet-V2图像分析" class="headerlink" title="Inception-ResNet-V2图像分析"></a><font size="5" color="red">Inception-ResNet-V2图像分析</font></h1><p><font size="4">Inception-ResNet-V2网络结构较大，建议小伙伴们保存到本地放大观看。</font><br><img src="/images/Feature_extraction/Inception-ResNet_V2_A.png" alt="Inception-ResNet_V2"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def reduction_A(x, name):</span><br><span class="line">    x_1 = compose(keras.layers.MaxPooling2D((3, 3), (2, 2), name='{}_part1_maxpool'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(384, (3, 3), (2, 2), padding='valid', name='{}_part2_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(256, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(256, (3, 3), (1, 1), padding='same', name='{}_part3_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(384, (3, 3), (2, 2), padding='valid', name='{}_part3_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def reduction_B(x, name):</span><br><span class="line">    x_1 = compose(keras.layers.MaxPooling2D((3, 3), (2, 2), name='{}_part1_maxpool'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(256, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(384, (3, 3), (2, 2), padding='valid', name='{}_part2_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(256, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(288, (3, 3), (2, 2), padding='valid', name='{}_part3_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_4 = compose(Conv_Bn_Relu(256, (1, 1), (1, 1), padding='same', name='{}_part4_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(288, (3, 3), (1, 1), padding='same', name='{}_part4_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(320, (3, 3), (2, 2), padding='valid', name='{}_part4_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3, x_4])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def stem(x, name):</span><br><span class="line">    x = compose(Conv_Bn_Relu(32, (3, 3), (2, 2), padding='valid', name='{}_conv_bn_relu1'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(32, (3, 3), (1, 1), padding='valid', name='{}_conv_bn_relu2'.format(name)),</span><br><span class="line">                Conv_Bn_Relu(64, (3, 3), (1, 1), padding='same', name='{}_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_1 = keras.layers.MaxPool2D((3, 3), (2, 2), name='{}_4_part1_maxpool'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = Conv_Bn_Relu(96, (3, 3), (2, 2), padding='valid', name='{}_4_part2_conv_bn_relu1'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate1'.format(name))([x_1, x_2])</span><br><span class="line"></span><br><span class="line">    x_1 = compose(Conv_Bn_Relu(64, (1, 1), (1, 1), padding='same', name='{}_5_part1_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(96, (3, 3), (1, 1), padding='valid', name='{}_5_part1_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(64, (1, 1), (1, 1), padding='same', name='{}_5_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(64, (1, 7), (1, 1), padding='same', name='{}_5_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(64, (7, 1), (1, 1), padding='same', name='{}_5_part2_conv_bn_relu3'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(96, (3, 3), (1, 1), padding='valid', name='{}_5_part2_conv_bn_relu4'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate2'.format(name))([x_1, x_2])</span><br><span class="line"></span><br><span class="line">    x_1 = keras.layers.MaxPool2D((3, 3), (2, 2), name='{}_6_part1_maxpool'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = Conv_Bn_Relu(192, (3, 3), (2, 2), padding='valid', name='{}_6_part2_conv_bn_relu1'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate3'.format(name))([x_1, x_2])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_resnet_A(x, name):</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    x_1 = compose(Conv_Bn_Relu(32, (1, 1), (1, 1), padding='same', name='{}_part1_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(32, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(32, (3, 3), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(32, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(48, (3, 3), (1, 1), padding='same', name='{}_part3_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(64, (3, 3), (1, 1), padding='same', name='{}_part3_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3])</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu(384, (1, 1), (1, 1), padding='same', name='{}_conv_bn_relu1'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    x = keras.layers.ReLU(name='{}_relu'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_resnet_B(x, name):</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    x_1 = compose(Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part1_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(128, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(160, (1, 7), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (7, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2])</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu(1152, (1, 1), (1, 1), padding='same', name='{}_conv_bn_relu1'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    x = keras.layers.ReLU(name='{}_relu'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_resnet_C(x, name):</span><br><span class="line">    shortcut = x</span><br><span class="line"></span><br><span class="line">    x_1 = compose(Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part1_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(224, (1, 7), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(256, (7, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2])</span><br><span class="line"></span><br><span class="line">    x = Conv_Bn_Relu(2144, (1, 1), (1, 1), padding='same', name='{}_conv_bn_relu1'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Add(name='{}_add'.format(name))([x, shortcut])</span><br><span class="line"></span><br><span class="line">    x = keras.layers.ReLU(name='{}_relu'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_resnet_v2(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line">    x = stem(x, 'stem')</span><br><span class="line">    for i in range(10):</span><br><span class="line">        x = inception_resnet_A(x, 'inception_resnet_A_{}'.format(i + 1))</span><br><span class="line">    x = reduction_A(x, 'reduction_A')</span><br><span class="line">    for i in range(20):</span><br><span class="line">        x = inception_resnet_B(x, 'inception_resnet_B_{}'.format(i + 1))</span><br><span class="line">    x = reduction_B(x, 'reduction_B')</span><br><span class="line">    for i in range(10):</span><br><span class="line">        x = inception_resnet_C(x, 'inception_resnet_C_{}'.format(i + 1))</span><br><span class="line">    x = compose(keras.layers.AveragePooling2D((8, 8), (8, 8), name='averagepool'),</span><br><span class="line">                keras.layers.Dropout(0.2, name='dropout'),</span><br><span class="line">                keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='Inception_ResNet_V2')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = inception_resnet_v2(input_shape=(299, 299, 3))</span><br><span class="line">    model.build(input_shape=(None, 299, 299, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/Inception-ResNet_V2_R.png" alt="Inception-ResNet_V2"></p>
<h1 id="Inception-ResNet-V2小结"><a href="#Inception-ResNet-V2小结" class="headerlink" title="Inception-ResNet-V2小结"></a><font size="5" color="red">Inception-ResNet-V2小结</font></h1><p>  Inception-ResNet-V2是一种集<strong>Inception-V3</strong>和<strong>ResNet</strong>所长的深度学习网络，从上图可以看出Inception-ResNet-V2模型的参数量达到60M，但是<strong>由于其网络结构太复杂，比Inception-V3要复杂得多，因此在实际中也较少使用其作为特征提取网络</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>Inception-V3</title>
    <url>/2020/03/10/feature_extraction%20Inception_V3/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Inception-V3</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Inception-V3:</strong>由<strong>谷歌公司2015年</strong>提出，初始版本是GoogleNet，是<strong>2014年ILSVRC竞赛的第一名</strong>，是一个较为复杂的图像特征提取模型。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/Inception_V3.png" alt="Inception_V3"></p>
<h1 id="Inception-V3特点"><a href="#Inception-V3特点" class="headerlink" title="Inception-V3特点"></a><font size="5" color="red">Inception-V3特点</font></h1><p>  <font size="3">采用<strong>不同大小的卷积核</strong>，意味着<strong>不同大小的感受野</strong>，得到<strong>不同尺度的特征</strong>，最后将不同尺度的特征进行<strong>拼接融合</strong></font><br>  <font size="3">提出<strong>卷积分解</strong>思想，将<strong>一个5x5的卷积，分解为两个3x3的卷积</strong>，而且将<strong>3x3的卷积分解成一个1x3的卷积和一个3*1的卷积</strong></font></p>
<h1 id="Spatial-Separable-Convolution"><a href="#Spatial-Separable-Convolution" class="headerlink" title="Spatial Separable Convolution"></a><font size="5" color="red">Spatial Separable Convolution</font></h1><p><img src="/images/deep_learning/spatial.png" alt="spatial"><br>  <font size="3"><strong>Spatial Separable Convolution(空间可分离卷积)</strong>：将3x3的卷积分解为3x1的卷积核1x3的卷积，将7x7的卷积分解为7x1的卷积核1x7的卷积.。</font><br>  <font size="3">主要作用是<strong>大大降低网络的参数量</strong>。如果一个64x64x256的特征图，经过7x7的卷积核后变为64x64x256的图像，经过普通卷积的参数量为256x(256x7x7+1)=3211520，而空间可分离卷积参数量为2x256x(256x7x1+1)=918016，参数量缩小了约3.5倍。</font></p>
<h1 id="Inception-V3图像分析"><a href="#Inception-V3图像分析" class="headerlink" title="Inception-V3图像分析"></a><font size="5" color="red">Inception-V3图像分析</font></h1><p><font size="4">Inception-V3网络结构较大，建议小伙伴们保存到本地放大观看。</font><br><img src="/images/Feature_extraction/Inception_V3_A.png" alt="Inception_V3"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def reduction_A(x, name):</span><br><span class="line">    x_1 = compose(keras.layers.MaxPooling2D((3, 3), (2, 2), name='{}_part1_maxpool'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(64, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(96, (3, 3), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(96, (3, 3), (2, 2), padding='valid', name='{}_part2_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(384, (3, 3), (2, 2), padding='valid', name='{}_part3_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def reduction_B(x, name):</span><br><span class="line">    x_1 = compose(keras.layers.MaxPooling2D((3, 3), (2, 2), name='{}_part1_maxpool'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (1, 7), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (7, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu3'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (3, 3), (2, 2), padding='valid', name='{}_part2_conv_bn_relu4'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(320, (3, 3), (2, 2), padding='valid', name='{}_part3_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_A(x, filters, name):</span><br><span class="line">    x_1 = compose(keras.layers.AveragePooling2D((3, 3), (1, 1), padding='same', name='{}_averagepool'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(filters, (1, 1), (1, 1), padding='same', name='{}_part1_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(64, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(96, (3, 3), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(96, (3, 3), (1, 1), padding='same', name='{}_part2_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(48, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(64, (5, 5), (1, 1), padding='same', name='{}_part3_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_4 = compose(Conv_Bn_Relu(64, (1, 1), (1, 1), padding='same', name='{}_part4_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3, x_4])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_B(x, name):</span><br><span class="line">    x_1 = compose(keras.layers.AveragePooling2D((3, 3), (1, 1), padding='same', name='{}_averagepool'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part1_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(128, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(128, (1, 7), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(128, (7, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu3'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(128, (1, 7), (1, 1), padding='same', name='{}_part2_conv_bn_relu4'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (7, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu5'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(128, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(128, (1, 7), (1, 1), padding='same', name='{}_part3_conv_bn_relu2'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (7, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu3'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_4 = compose(Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part4_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3, x_4])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_C(x, name):</span><br><span class="line">    x_1 = compose(keras.layers.AveragePooling2D((3, 3), (1, 1), padding='same', name='{}_averagepool'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(192, (1, 1), (1, 1), padding='same', name='{}_part1_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2 = compose(Conv_Bn_Relu(448, (1, 1), (1, 1), padding='same', name='{}_part2_conv_bn_relu1'.format(name)),</span><br><span class="line">                  Conv_Bn_Relu(384, (3, 3), (1, 1), padding='same', name='{}_part2_conv_bn_relu2'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_2_1 = compose(Conv_Bn_Relu(384, (1, 3), (1, 1), padding='same', name='{}_part2_1_conv_bn_relu1'.format(name)))(x_2)</span><br><span class="line"></span><br><span class="line">    x_2_2 = compose(Conv_Bn_Relu(384, (3, 1), (1, 1), padding='same', name='{}_part2_2_conv_bn_relu1'.format(name)))(x_2)</span><br><span class="line"></span><br><span class="line">    x_2 = keras.layers.Concatenate(name='{}_concatenate_2'.format(name))([x_2_1, x_2_2])</span><br><span class="line"></span><br><span class="line">    x_3 = compose(Conv_Bn_Relu(384, (1, 1), (1, 1), padding='same', name='{}_part3_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x_3_1 = compose(Conv_Bn_Relu(384, (1, 3), (1, 1), padding='same', name='{}_part3_1_conv_bn_relu1'.format(name)))(x_3)</span><br><span class="line"></span><br><span class="line">    x_3_2 = compose(Conv_Bn_Relu(384, (3, 1), (1, 1), padding='same', name='{}_part3_2_conv_bn_relu1'.format(name)))(x_3)</span><br><span class="line"></span><br><span class="line">    x_3 = keras.layers.Concatenate(name='{}_concatenate_3'.format(name))([x_3_1, x_3_2])</span><br><span class="line"></span><br><span class="line">    x_4 = compose(Conv_Bn_Relu(320, (1, 1), (1, 1), padding='same', name='{}_part4_conv_bn_relu1'.format(name)))(x)</span><br><span class="line"></span><br><span class="line">    x = keras.layers.Concatenate(name='{}_concatenate'.format(name))([x_1, x_2, x_3, x_4])</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def inception_v3(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line">    x = compose(Conv_Bn_Relu(32, (3, 3), (2, 2), padding='valid', name='conv_bn_relu1'),</span><br><span class="line">                Conv_Bn_Relu(32, (3, 3), (1, 1), padding='valid', name='conv_bn_relu2'),</span><br><span class="line">                Conv_Bn_Relu(64, (3, 3), (1, 1), padding='same', name='conv_bn_relu3'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), name='maxpool1'),</span><br><span class="line">                Conv_Bn_Relu(80, (1, 1), (1, 1), padding='same', name='conv_bn_relu4'),</span><br><span class="line">                Conv_Bn_Relu(192, (3, 3), (1, 1), padding='valid', name='conv_bn_relu5'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), name='maxpool2'))(x)</span><br><span class="line">    inception_A_part1_filters = [32, 64, 64]</span><br><span class="line">    for i in range(3):</span><br><span class="line">        x = inception_A(x, inception_A_part1_filters[i], name='inception_A_{}'.format(i + 1))</span><br><span class="line">    x = reduction_A(x, name='reduction_A')</span><br><span class="line">    for i in range(4):</span><br><span class="line">        x = inception_B(x, name='inception_B_{}'.format(i + 1))</span><br><span class="line">    x = reduction_B(x, name='reduction_B')</span><br><span class="line">    for i in range(2):</span><br><span class="line">        x = inception_C(x, name='inception_C_{}'.format(i + 1))</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='Inception-V3')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = inception_v3(input_shape=(299, 299, 3))</span><br><span class="line">    model.build(input_shape=(None, 299, 299, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/Inception_V3_R.png" alt="Inception_V3"></p>
<h1 id="Inception-V3小结"><a href="#Inception-V3小结" class="headerlink" title="Inception-V3小结"></a><font size="5" color="red">Inception-V3小结</font></h1><p>  Inception-V3是一种复杂的深度学习网络，参数量为22M，<strong>由于其结构过于复杂，很少被其他网络所使用</strong>，但是其<strong>不同感受野和卷积分解的思想给其他网络提供了思路</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>ResNet</title>
    <url>/2020/03/09/feature_extraction%20ResNet/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">ResNet</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>ResNet:</strong>由<strong>华人学者何凯明大神于2015年提出</strong>，其主要体现出了残差相连的优势，故简称ResNet，是<strong>2015年ILSVRC竞赛的第一名</strong>，是一个很好的图像特征提取模型。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/ResNet.png" alt="ResNet"></p>
<h1 id="ResNet特点"><a href="#ResNet特点" class="headerlink" title="ResNet特点"></a><font size="5" color="red">ResNet特点</font></h1><p>  <font size="3">使用<strong>残差块结构</strong>，使得网络能够更多获取之前的信息，并且使<strong>学习结果对于权重的变化更加敏感</strong></font><br>  <font size="3">使用<strong>瓶颈结构</strong>，先使用1x1的卷积核进行降维，最后再次使用1x1的卷积核升维，可以降低模型的参数量</font><br>  <font size="3"><strong>Conv Block</strong>：作用是<strong>改变图像大小</strong>，输入和输出的尺寸不同，因此<strong>无法直接残差相连</strong>，</font><br>  <font size="3"><strong>Identity Block</strong>：作用是<strong>增加网络深度</strong>，输入和输出的尺寸相同，可以<strong>直接残差相连</strong></font></p>
<h1 id="不同尺寸ResNet网络结构"><a href="#不同尺寸ResNet网络结构" class="headerlink" title="不同尺寸ResNet网络结构"></a><font size="5" color="red">不同尺寸ResNet网络结构</font></h1><p><img src="/images/Feature_extraction/ResNet_C.png" alt="ResNet"></p>
<h1 id="ResNet50图像分析"><a href="#ResNet50图像分析" class="headerlink" title="ResNet50图像分析"></a><font size="5" color="red">ResNet50图像分析</font></h1><p><img src="/images/Feature_extraction/ResNet_A.png" alt="ResNet"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn_Relu(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn_Relu, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line">        self.relu = keras.layers.ReLU()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        bn = self.bn(conv)</span><br><span class="line">        output = self.relu(bn)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Conv_Bn(keras.layers.Layer):</span><br><span class="line">    def __init__(self, filters, kernel_size, strides, padding, name):</span><br><span class="line">        super(Conv_Bn, self).__init__()</span><br><span class="line">        self._name = name</span><br><span class="line">        self.conv = keras.layers.Conv2D(filters, kernel_size, strides, padding)</span><br><span class="line">        self.bn = keras.layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, **kwargs):</span><br><span class="line">        conv = self.conv(inputs)</span><br><span class="line">        output = self.bn(conv)</span><br><span class="line"></span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def res_block(x, filters, strides, type, name):</span><br><span class="line">    shortcut = x</span><br><span class="line">    x = compose(Conv_Bn_Relu(filters // 4, (1, 1), (1, 1), padding='same', name='{}{}_conv_bn_relu1'.format(type, name)),</span><br><span class="line">                Conv_Bn_Relu(filters // 4, (3, 3), strides, padding='same', name='{}{}_conv_bn_relu2'.format(type, name)),</span><br><span class="line">                Conv_Bn(filters, (1, 1), (1, 1), padding='same', name='{}{}_conv_bn3'.format(type, name)))(x)</span><br><span class="line">    if type == 'conv_block':</span><br><span class="line">        shortcut = keras.layers.Conv2D(filters, (1, 1), strides, name='{}{}_shortcut'.format(type, name))(shortcut)</span><br><span class="line">    x = keras.layers.Add(name='{}{}_add'.format(type, name))([x, shortcut])</span><br><span class="line">    x = keras.layers.ReLU(name='{}{}_relu3'.format(type, name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ResNet50(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line">    x = compose(keras.layers.ZeroPadding2D((3, 3), name='zeropadding'),</span><br><span class="line">                Conv_Bn_Relu(64, (7, 7), (2, 2), padding='valid', name='conv_bn_relu'),</span><br><span class="line">                keras.layers.MaxPool2D((3, 3), (2, 2), padding='same', name='maxpool'))(x)</span><br><span class="line">    filters = [256, 512, 1024, 2048]</span><br><span class="line">    strides = [(1, 1), (2, 2), (2, 2), (2, 2)]</span><br><span class="line">    times = [3, 4, 6, 3]</span><br><span class="line">    for i in range(len(times)):</span><br><span class="line">        x = res_block(x, filters[i], strides[i], 'conv_block', i + 1)</span><br><span class="line">        for j in range(times[i] - 1):</span><br><span class="line">            x = res_block(x, filters[i], (1, 1), 'identity_block{}_'.format(i + 1), j + 1)</span><br><span class="line">    x = compose(keras.layers.GlobalAveragePooling2D(name='global_averagepool'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense'))(x)</span><br><span class="line">    model = keras.Model(input_tensor, x, name='ResNet50')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line"></span><br><span class="line">    model = resnet50(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/ResNet_R.png" alt="ResNet"></p>
<h1 id="ResNet小结"><a href="#ResNet小结" class="headerlink" title="ResNet小结"></a><font size="5" color="red">ResNet小结</font></h1><p>  ResNet是一种非常有效的特征提取网络，由于减少了Dense层的数量，因此参数量<strong>相比于VGG大大减少</strong>，参数量只有25M，因此实际任务经常使用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>VGG</title>
    <url>/2020/03/08/feature_extraction%20VGG/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">VGG</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>VGG:</strong>来源于<strong>牛津大学视觉几何组Visual Geometry Group</strong>，故简称VGG，是<strong>2014年ILSVRC竞赛的第二名</strong>，是一个很好的图像特征提取模型。<br><a id="more"></a></p>
<p><img src="/images/Feature_extraction/VGG.png" alt="VGG"></p>
<h1 id="VGG特点"><a href="#VGG特点" class="headerlink" title="VGG特点"></a><font size="5" color="red">VGG特点</font></h1><p>  <font size="3">卷积核：VGG全由3x3小卷积核构成，步长为1，填充方式为same</font><br>  <font size="3">池化核：VGG全由2x2池化核构成，步长为2</font><br>  <font size="3">网络层：VGG具有较深的网络层，可以根据需要进行调整</font><br>  <font size="3">参数量：VGG具有较大参数量，主要来源于Flatten层后面的全连接层</font></p>
<h1 id="不同尺寸VGG网络结构"><a href="#不同尺寸VGG网络结构" class="headerlink" title="不同尺寸VGG网络结构"></a><font size="5" color="red">不同尺寸VGG网络结构</font></h1><p><img src="/images/Feature_extraction/VGG_C.png" alt="VGG"></p>
<h1 id="VGG16图像分析"><a href="#VGG16图像分析" class="headerlink" title="VGG16图像分析"></a><font size="5" color="red">VGG16图像分析</font></h1><p><img src="/images/Feature_extraction/VGG_A.png" alt="VGG"></p>
<h1 id="TensorFlow2-0实现"><a href="#TensorFlow2-0实现" class="headerlink" title="TensorFlow2.0实现"></a><font size="4">TensorFlow2.0实现</font></h1><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from functools import reduce</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compose(*funcs):</span><br><span class="line">    if funcs:</span><br><span class="line">        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError('Composition of empty sequence not supported.')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def conv_block(x, filters, times, name):</span><br><span class="line">    for i in range(times):</span><br><span class="line">        x = keras.layers.Conv2D(filters, (3, 3), (1, 1), 'same', activation='relu', name='conv{}_{}'.format(name, i + 1))(x)</span><br><span class="line">    x = keras.layers.MaxPool2D((2, 2), (2, 2), name='maxpool{}'.format(name))(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def vgg16(input_shape):</span><br><span class="line">    input_tensor = keras.layers.Input(input_shape, name='input')</span><br><span class="line">    x = input_tensor</span><br><span class="line">    times = [2, 2, 3, 3, 5]</span><br><span class="line">    filters = [64, 128, 256, 512, 512]</span><br><span class="line">    for i in range(len(times)):</span><br><span class="line">        x = conv_block(x, filters[i], times[i], i + 1)</span><br><span class="line">    x = compose(keras.layers.Flatten(name='flatten'),</span><br><span class="line">                keras.layers.Dense(4096, activation='relu', name='dense1'),</span><br><span class="line">                keras.layers.Dense(4096, activation='relu', name='dense2'),</span><br><span class="line">                keras.layers.Dense(1000, activation='softmax', name='dense3'))(x)</span><br><span class="line"></span><br><span class="line">    model = keras.Model(input_tensor, x, name='VGG16')</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    model = vgg16(input_shape=(224, 224, 3))</span><br><span class="line">    model.build(input_shape=(None, 224, 224, 3))</span><br><span class="line">    model.summary()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/Feature_extraction/VGG_R.png" alt="VGG"></p>
<h1 id="VGG小结"><a href="#VGG小结" class="headerlink" title="VGG小结"></a><font size="5" color="red">VGG小结</font></h1><p>  VGG是<strong>最简单的一种深度学习网络</strong>，也是一种<strong>非常有效的特征提取模型</strong>。从上图可以看出VGG16模型的参数量达到143M，<strong>因为特征提取时不需要后面的Dense层，可以大大降低网络的规模</strong>。因此实际任务所使用，如<strong>目标检测算法SSD的特征提取网络就是VGG</strong>。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>特征提取网络</category>
      </categories>
  </entry>
  <entry>
    <title>最长回文字符串(Leetcode 5)</title>
    <url>/2020/02/13/program%20Leetcode5/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode5.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   最长回文子串问题是一个经典的字符串处理问题，这道题有四种不同的解决思路，当然它们的时间复杂度和空间复杂度也都不相同。</p>
<a id="more"></a>
<h1 id="暴力法"><a href="#暴力法" class="headerlink" title="暴力法"></a><font size="5" color="red">暴力法</font></h1><p>暴力法很好理解，遍历所有子串，需要$O(n^2)$的时间复杂度，每个子串比较是否为回文串，需要O(n)的时间复杂度，因此总的时间复杂度为$O(n^3)$，空间复杂度上，如果使用一个临时变量存储子串则需要O(n)，如果直接使用索引则空间复杂度为O(1)，使用临时变量思路更加清晰，在这里我就使用O(n)的空间复杂度。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def longestPalindrome(self, s):</span><br><span class="line">        """</span><br><span class="line">        :s: str</span><br><span class="line">        :rtype: str</span><br><span class="line">        """</span><br><span class="line">        lens = len(s)</span><br><span class="line">        if lens == 0:</span><br><span class="line">            return ''</span><br><span class="line">        for i in range(lens, 0, -1):</span><br><span class="line">            for j in range(lens - i + 1):</span><br><span class="line">                tmp = s[j:j + i]</span><br><span class="line">                for k in range(i // 2):</span><br><span class="line">                    if tmp[k] != tmp[-k - 1]:</span><br><span class="line">                        break</span><br><span class="line">                else:</span><br><span class="line">                    return tmp</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="DP"><a href="#DP" class="headerlink" title="DP"></a><font size="5" color="red">DP</font></h1><p>DP是(Dynamic Programming，动态规划)的简称，动态规划的核心问题是如何建立状态转移方程，而本题有一个天然的状态，即回文状态，如果某个字符串是回文字符串，那么去掉首尾的一个字符，仍然满足回文字符串，因此可以容易的建立状态转移方程，其时间复杂度为$O(n^2)$，空间复杂度也是$O(n^2)$。<br><img src="/images/ALGORITHM/leetcode5_dp.png" alt="dp"><br>有关DP的知识可以参考我的另一篇博客动态规划(Dynamic Programming)。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def longestPalindrome(self, s):</span><br><span class="line">        """</span><br><span class="line">        :s: str</span><br><span class="line">        :rtype: str</span><br><span class="line">        """</span><br><span class="line">        lens = len(s)</span><br><span class="line">        if lens == 0:</span><br><span class="line">            return ''</span><br><span class="line">        result = s[0]</span><br><span class="line">        dp = [[True if col &lt;= row else False for col in range(lens)] for row in range(lens)]</span><br><span class="line">        for length in range(2, lens + 1):</span><br><span class="line">            for j in range(lens - length + 1):</span><br><span class="line">                dp[j][j + length - 1] = dp[j + 1][j + length - 2] and (s[j] == s[j + length - 1])</span><br><span class="line">                if dp[j][j + length - 1] and length &gt; len(result):</span><br><span class="line">                    result = s[j:j + length]</span><br><span class="line">        return result</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="中心扩展算法"><a href="#中心扩展算法" class="headerlink" title="中心扩展算法"></a><font size="5" color="red">中心扩展算法</font></h1><p>中心扩展算法不是一类通用算法，是针对于特定回文字符串的问题的解法，分析如下图，时间复杂度为$O(n^2)$，如果采用一个临时变量存储子串则需要O(n)，如果直接使用索引则空间复杂度为O(1)，使用临时变量思路更加清晰，在这里我就使用O(n)的空间复杂度。<br><img src="/images/ALGORITHM/leetcode5_center.png" alt="center"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def expandAroundCenter(self, s, left, right):</span><br><span class="line">        while left &gt;= 0 and right &lt; len(s) and s[left] == s[right]:</span><br><span class="line">            left -= 1</span><br><span class="line">            right += 1</span><br><span class="line">        return left + 1, right - 1</span><br><span class="line"></span><br><span class="line">    def longestPalindrome(self, s: str) -&gt; str:</span><br><span class="line">        start, end = 0, 0</span><br><span class="line">        for i in range(len(s)):</span><br><span class="line">            left1, right1 = self.expandAroundCenter(s, i, i)</span><br><span class="line">            left2, right2 = self.expandAroundCenter(s, i, i + 1)</span><br><span class="line">            if right1 - left1 &gt; end - start:</span><br><span class="line">                start, end = left1, right1</span><br><span class="line">            if right2 - left2 &gt; end - start:</span><br><span class="line">                start, end = left2, right2</span><br><span class="line">        return s[start: end + 1]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="manacher-马拉车-算法"><a href="#manacher-马拉车-算法" class="headerlink" title="manacher(马拉车)算法"></a><font size="5" color="red">manacher(马拉车)算法</font></h1><p>马拉车算法是专门解决回文字符串的问题，其算法的时间复杂度和空间复杂度都可以缩小到O(n)的量级，在长字符串中具有非常显著的优势。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def longestPalindrome(self, s):</span><br><span class="line">        """</span><br><span class="line">        :s: str</span><br><span class="line">        :rtype: str</span><br><span class="line">        """</span><br><span class="line">        new_s = '#'</span><br><span class="line">        for i in s:</span><br><span class="line">            new_s += (i + '#')</span><br><span class="line">        C, p1, R = 0, 0, 0</span><br><span class="line">        len_ns = len(new_s)</span><br><span class="line">        radius = [1] * len_ns</span><br><span class="line">        while R &lt; len_ns - 1:</span><br><span class="line">            p1 += 1</span><br><span class="line">            if p1 &gt; R:</span><br><span class="line">                C = p1</span><br><span class="line">                R += 1</span><br><span class="line">                while 2 * C - (R + 1) &gt;= 0 and R + 1 &lt; len_ns and new_s[R + 1] == new_s[2 * C - (R + 1)]:</span><br><span class="line">                    R += 1</span><br><span class="line">                radius[C] = R - C + 1</span><br><span class="line">            else:</span><br><span class="line">                p2 = 2 * C - p1</span><br><span class="line">                pL = p2 - radius[p2] + 1</span><br><span class="line">                CL = C - radius[C] + 1</span><br><span class="line">                if CL &lt; pL:</span><br><span class="line">                    radius[p1] = radius[p2]</span><br><span class="line">                elif CL &gt; pL:</span><br><span class="line">                    radius[p1] = R - p1 + 1</span><br><span class="line">                else:</span><br><span class="line">                    C = p1</span><br><span class="line">                    while 2 * C - (R + 1) &gt;= 0 and R + 1 &lt; len_ns and new_s[R + 1] == new_s[2 * C - (R + 1)]:</span><br><span class="line">                        R += 1</span><br><span class="line">                    radius[C] = R - C + 1</span><br><span class="line">        longest = max(radius)</span><br><span class="line">        index = radius.index(longest)</span><br><span class="line">        begin_index, end_index = index - longest + 1, index + longest - 1</span><br><span class="line">        return new_s[begin_index:end_index + 1:2] if new_s[begin_index] != '#' else new_s[begin_index + 1:end_index + 1:2]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  马拉车算法是解决最长回文串的最佳方法，在面试中问到回文串，如果能答出马拉车算法，那是非常给力的，但是动态规划的方法大家也要学会，因为动态规划问题也是面试常考的知识点之一。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>字符串</category>
        <category>特定算法</category>
      </categories>
  </entry>
  <entry>
    <title>寻找两个正序数组的中位数(Leetcode 4)</title>
    <url>/2020/02/11/program%20Leetcode4/</url>
    <content><![CDATA[<p><img src="/images/ALGORITHM/leetcode4.png" alt="1"></p>
<h1 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a><font size="5" color="red">题目分析</font></h1><p>   寻找两个正序数组的中位数，这道题本身并不难，但是如何使用O(log(m + n))的时间复杂度求解是这道题目的难点。</p>
<a id="more"></a>
<h1 id="合并数组"><a href="#合并数组" class="headerlink" title="合并数组"></a><font size="5" color="red">合并数组</font></h1><p>合并有序数组的方法是最容易想到的方法，在归并排序中就用到了这种思想，将两个有序的数组合并为一个，然后直接索引寻找中位数，时间复杂度为$O(m+n)$，空间复杂度为$O(m+n)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findMedianSortedArrays(self, nums1, nums2):</span><br><span class="line">        """</span><br><span class="line">        :nums1: List[int]</span><br><span class="line">        :nums2: List[int]</span><br><span class="line">        :rtype: float</span><br><span class="line">        """</span><br><span class="line">        nums = []</span><br><span class="line">        len1, len2 = len(nums1), len(nums2)</span><br><span class="line">        if len1 == 0:</span><br><span class="line">            nums = nums2[:]</span><br><span class="line">        elif len2 == 0:</span><br><span class="line">            nums = nums1[:]</span><br><span class="line">        else:</span><br><span class="line">            p1 = p2 = 0</span><br><span class="line">            while p1 &lt; len1 and p2 &lt; len2:</span><br><span class="line">                if nums1[p1] &lt; nums2[p2]:</span><br><span class="line">                    nums.append(nums1[p1])</span><br><span class="line">                    p1 += 1</span><br><span class="line">                else:</span><br><span class="line">                    nums.append(nums2[p2])</span><br><span class="line">                    p2 += 1</span><br><span class="line">            nums += nums2[p2:] if p1 == len1 else nums1[p1:]</span><br><span class="line">        return nums[(len1 + len2) // 2] if (len1 + len2) % 2 else (nums[(len1 + len2) // 2 - 1] + nums[(len1 + len2) // 2]) / 2</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a><font size="5" color="red">双指针</font></h1><p>因为不需要其他的数据，因此我们不需要引入一个新数组保存所有数据，只需要记录当前索引即。时间复杂度为$O(m+n)$，空间复杂度为$O(1)$。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findMedianSortedArrays(self, nums1, nums2):</span><br><span class="line">        """</span><br><span class="line">        :nums1: List[int]</span><br><span class="line">        :nums2: List[int]</span><br><span class="line">        :rtype: float</span><br><span class="line">        """</span><br><span class="line">        p1 = p2 = 0</span><br><span class="line">        len1, len2 = len(nums1), len(nums2)</span><br><span class="line">        prior, current = 0, 0</span><br><span class="line">        for i in range((len1 + len2) // 2 + 1):</span><br><span class="line">            prior = current</span><br><span class="line">            if p1 &lt; len1 and (p2 &gt;= len2 or nums1[p1] &lt; nums2[p2]):</span><br><span class="line">                current = nums1[p1]</span><br><span class="line">                p1 += 1</span><br><span class="line">            else:</span><br><span class="line">                current = nums2[p2]</span><br><span class="line">                p2 += 1</span><br><span class="line">        return current if (len1 + len2) % 2 else (current + prior) / 2</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="中位数算法"><a href="#中位数算法" class="headerlink" title="中位数算法"></a><font size="5" color="red">中位数算法</font></h1><p>这道题还有更优的算法，利用中位数的性质和二分查找的思想，将两个数组分成左右两个部分，这种方法参考windliang在Leetcode题解中的思想。时间复杂度为$O(log(min(m+n)))$，空间复杂度为$O(1)$。<br><img src="/images/ALGORITHM/leetcode4_search.png" alt="search"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findMedianSortedArrays(self, nums1, nums2):</span><br><span class="line">        """</span><br><span class="line">        :nums1: List[int]</span><br><span class="line">        :nums2: List[int]</span><br><span class="line">        :rtype: float</span><br><span class="line">        """</span><br><span class="line">        if len(nums1) &gt; len(nums2):</span><br><span class="line">            nums1, nums2 = nums2, nums1</span><br><span class="line">        len1, len2 = len(nums1), len(nums2)</span><br><span class="line">        min_index, max_index = 0, len1</span><br><span class="line">        while 1:</span><br><span class="line">            i = (min_index + max_index) // 2</span><br><span class="line">            j = (len1 + len2 + 1) // 2 - i</span><br><span class="line">            if i != len1 and nums2[j - 1] &gt; nums1[i]:</span><br><span class="line">                min_index = i + 1</span><br><span class="line">            elif i != 0 and nums1[i - 1] &gt; nums2[j]:</span><br><span class="line">                max_index = i - 1</span><br><span class="line">            else:</span><br><span class="line">                if i == 0:</span><br><span class="line">                    left_max = nums2[j - 1]</span><br><span class="line">                elif j == 0:</span><br><span class="line">                    left_max = nums1[i - 1]</span><br><span class="line">                else:</span><br><span class="line">                    left_max = max(nums1[i - 1], nums2[j - 1])</span><br><span class="line">                if (len1 + len2) % 2 == 1:</span><br><span class="line">                    return left_max</span><br><span class="line">                if i == len1:</span><br><span class="line">                    right_min = nums2[j]</span><br><span class="line">                elif j == len2:</span><br><span class="line">                    right_min = nums1[i]</span><br><span class="line">                else:</span><br><span class="line">                    right_min = min(nums1[i], nums2[j])</span><br><span class="line">                return (left_max + right_min) / 2</span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="刷题总结"><a href="#刷题总结" class="headerlink" title="刷题总结"></a><font size="5" color="red">刷题总结</font></h1><p>  后面跟两种方法，我也是参考别人的题解，不仅思路清晰，而且代码简单，可以说膜拜了。这道题的难点在于二分法的应用，小伙伴们要多刷题，多见一见世面，比较不同算法之间的区别，增强自己的Coding能力。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>刷题记录</category>
        <category>数组</category>
        <category>二分查找</category>
        <category>排序</category>
        <category>双指针</category>
      </categories>
  </entry>
  <entry>
    <title>Garbage Collection(垃圾回收)</title>
    <url>/2019/11/05/python_garbage%20collection/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/gc.png" alt="gc"></p>
<h1 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a><font size="5" color="red">Garbage Collection</font></h1><p>  <strong>Garbage Collection(GC，垃圾回收)</strong>：不是Python特有的，而是现在<strong>许多高级语言自带的机制，可以帮助我们更高效的管理我们的内存</strong>，在<strong>C/C++的学习过程中，最重要的两个部分是指针和内存管理，其中内存管理就是指垃圾回收机制，在C/C++中，无法自动帮我们管理内存，如果我们缺少内存则需要申请，但是申请多了会导致内存不足，这时候需要我们手动释放一些内存</strong>。但是<strong>在Python中不需要，系统会自动帮我们释放内存</strong>，这个知识点不需要我们熟练掌握，只需要我们了解即可，运行代码时会自动启用垃圾回收机制。<br><a id="more"></a></p>
<h1 id="小整数对象池"><a href="#小整数对象池" class="headerlink" title="小整数对象池"></a><font size="5" color="red">小整数对象池</font></h1><p>因为<strong>一些小整数会被我们经常使用，所以在Python中[-5, 256]之间的整数会被固定在某一内存中</strong>，只要是这些整数赋值给某一变量，则那个变量的地址是固定的。<strong>在字符串中也有相似的表现，没有特殊字符的字符串也具有固定的地址</strong>。<br><img src="/images/LANGUAGE/gc1.png" alt="gc1"></p>
<h1 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a><font size="5" color="red">引用计数</font></h1><p><strong>Python里每一个东西都是对象，它们的核心就是一个结构体：PyObject，是使用C语言来定义的</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">typedef struct_object {</span><br><span class="line">    int ob_refcnt;</span><br><span class="line">    struct_typeobject *ob_type;</span><br><span class="line">} PyObject;</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><strong>其中ob_refcnt就是引用计数，当一个对象有新的引用时，这个值会增加，当引用它的对象被删除时，这个值会减少，使用sys.getrefcount()函数可以查看对象的引用计数。当引用计数为0时，该对象的生命就结束了</strong>。</p>
<p><strong>导致引用计数增加的情况</strong>：</p>
<ol>
<li><strong>对象被创建</strong></li>
<li><strong>对象被引用</strong></li>
<li><strong>对象作为参数被传入到一个函数中</strong></li>
<li><strong>对象作为元素，存储在容器中</strong></li>
</ol>
<p><strong>导致引用计数减少的情况</strong>：</p>
<ol>
<li><strong>对象被销毁</strong></li>
<li><strong>对象被赋予新的对象</strong></li>
<li><strong>对象离开作用域</strong></li>
<li><strong>对象所在容器被销毁</strong></li>
</ol>
<p><img src="/images/LANGUAGE/gc2.png" alt="gc2"><br>为什么创建时引用为2呢？因为调用sys.getrefcount(a)时，a作为参数传入到函数中，引用计数又加了1，所以sys,getrefcount()-1才是真正的引用计数次数。</p>
<p><strong>引用计数的优点</strong>：</p>
<ol>
<li><strong>简单</strong></li>
<li><strong>实时性，当引用计数为0，内存直接释放</strong></li>
</ol>
<p><strong>引用计数的缺点</strong>：</p>
<ol>
<li><strong>需要一个额外的内存存放引用计数</strong></li>
<li><strong>存在循环引用的致命缺点</strong></li>
</ol>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class MyClass:</span><br><span class="line">  pass</span><br><span class="line"></span><br><span class="line">a = MyClass()</span><br><span class="line">b = MyClass()</span><br><span class="line">a.next = b</span><br><span class="line">b.next = a</span><br><span class="line">del a</span><br><span class="line">del b</span><br></pre></td></tr></tbody></table></figure>
<p>a和b我们都已经不想使用了，因此使用了del，但是<strong>a和b的引用计数都为1，内存仍然没有被释放，这就是循环引用的致命缺点，会导致内存的严重泄漏</strong>。</p>
<h1 id="隔代回收"><a href="#隔代回收" class="headerlink" title="隔代回收"></a><font size="5" color="red">隔代回收</font></h1><p>在这里不想过多的探讨隔代回收，简单地说<strong>Python中会引入3个链表，所有新创建的对象都会加入到0代链表中，在一定的时间内检查并且扫描所有的循环引用，如果发现了两个对象的循环引用，则将引用计数-1，并且将0代链表中引用计数不为0的对象加入到1代链表中，当0代链表检查一定次数后，检查一次1代链表，重复上述动作，并将1代链表中引用计数不为0的对象加入到2代链表中，当1代链表检查一定次数后，检查一次2代链表</strong>。这就是隔代回收的大致思路。<br><img src="/images/LANGUAGE/gc3.png" alt="gc3"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  关于垃圾回收，不需要小伙伴们过多掌握，<strong>Python中默认开启垃圾回收机制</strong>，小伙伴们只要适当了解，就可以愉快的写代码啦。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Dynamic &amp; Static(动态图与静态图)</title>
    <url>/2019/10/28/frame%20dynamic%20vs%20static/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Dynamic &amp; Static</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>Dynamic &amp; Static(动态图与静态图):</strong>根据深度学习框架的不同，可以分成静态图框架和动态图框架，其中静态图框架的代表是<strong>TensorFlow1.x，Caffe2</strong>等，而动态图的代表是<strong>TensorFlow2.x，PyTorch</strong>等等。<br><a id="more"></a></p>
<p><img src="/images/FRAME/frame.png" alt="frame"></p>
<h1 id="动态图和静态图的区别"><a href="#动态图和静态图的区别" class="headerlink" title="动态图和静态图的区别"></a><font size="5" color="red">动态图和静态图的区别</font></h1><p><strong>静态图：先定义计算图，不断使用，相同类型的数据只定义一次计算图，之后再次运行时不需要重新定义，也不需要重复执行代码，只需要将数据送入数据流即可</strong>。<br><strong>特点：静态图保存了网络结构并且进行图优化，更加高效，但是弊端就是出错时很难进行单步调试，而且代码风格非常繁琐</strong>。</p>
<p><strong>动态图：每次计算需要重复之前的代码</strong>。<br><strong>特点：更加符合Python的代码风格，便于调试，弊端是效率较低</strong>。</p>
<h1 id="动态图和静态图的转换"><a href="#动态图和静态图的转换" class="headerlink" title="动态图和静态图的转换"></a><font size="5" color="red">动态图和静态图的转换</font></h1><p><color=red>以TensorFlow2.0为例，因为既可以使用静态图也可以使用动态图，<strong>TensorFlow2.0默认使用动态图机制，如果想使用静态图提高计算效率，可以在函数前加上@tf.function装饰器</strong>。&lt;/font&gt;</color=red></p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras as keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def preprocess(x, y):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / 255.</span><br><span class="line">    x = tf.reshape(x, (28, 28, 1))</span><br><span class="line">    y = tf.one_hot(y, depth=10)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    return x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def lenet_5():</span><br><span class="line"></span><br><span class="line">    return keras.models.Sequential([keras.layers.Input(shape=(28, 28, 1), name='input'),</span><br><span class="line">                                     keras.layers.Conv2D(6, kernel_size=(5, 5), padding='same', activation='relu', name='conv1'),</span><br><span class="line">                                     keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool1'),</span><br><span class="line">                                     keras.layers.Conv2D(16, kernel_size=(5, 5), padding='valid', activation='relu', name='conv2'),</span><br><span class="line">                                     keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool2'),</span><br><span class="line">                                     keras.layers.Flatten(name='flatten'),</span><br><span class="line">                                     keras.layers.Dense(120, activation='relu', name='dense1'),</span><br><span class="line">                                     keras.layers.Dense(84, activation='relu', name='dense2'),</span><br><span class="line">                                     keras.layers.Dense(10, activation='softmax', name='dense3')], name='LeNet-5')</span><br><span class="line"></span><br><span class="line">@tf.function</span><br><span class="line">def dynamic_gradient_descent(train_x, train_y):</span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        y_pred = model(train_x, training=True)</span><br><span class="line">        loss = lossor(train_y, y_pred)</span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line">    train_loss.update_state(loss)</span><br><span class="line">    train_metrics.update_state(train_y, y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def static_gradient_descent(train_x, train_y):</span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        y_pred = model(train_x, training=True)</span><br><span class="line">        loss = lossor(train_y, y_pred)</span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line">    train_loss.update_state(loss)</span><br><span class="line">    train_metrics.update_state(train_y, y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    (x, y), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">    batch_size = 256</span><br><span class="line">    tf.random.set_seed(22)</span><br><span class="line">    max_epoch = 5</span><br><span class="line"></span><br><span class="line">    db = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    db = db.map(preprocess).shuffle(10000).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">    db_test = db_test.map(preprocess).batch(batch_size)</span><br><span class="line"></span><br><span class="line">    model = lenet_5()</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(1e-3)</span><br><span class="line">    lossor = keras.losses.CategoricalCrossentropy()</span><br><span class="line">    train_loss = keras.metrics.Mean()</span><br><span class="line">    train_metrics = keras.metrics.CategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">    start = time.clock()</span><br><span class="line">    for epoch in range(max_epoch):</span><br><span class="line">        it_train = iter(db)</span><br><span class="line">        it_test = iter(db_test)</span><br><span class="line">        for train_x, train_y in db:</span><br><span class="line">            dynamic_gradient_descent(train_x, train_y)</span><br><span class="line"></span><br><span class="line">        print('Epoch: %d, Train loss: %.6f, Train acc: %.6f' % (epoch, train_loss.result(), train_metrics.result()))</span><br><span class="line"></span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_metrics.reset_states()</span><br><span class="line">    print('dynamic graph time is : %.3f' % (time.clock() - start))</span><br><span class="line"></span><br><span class="line">    model = lenet_5()</span><br><span class="line"></span><br><span class="line">    optimizer = keras.optimizers.Adam(1e-3)</span><br><span class="line"></span><br><span class="line">    start = time.clock()</span><br><span class="line">    for epoch in range(max_epoch):</span><br><span class="line">        it_train = iter(db)</span><br><span class="line">        it_test = iter(db_test)</span><br><span class="line">        for train_x, train_y in db:</span><br><span class="line">            static_gradient_descent(train_x, train_y)</span><br><span class="line"></span><br><span class="line">        print('Epoch: %d, Train loss: %.6f, Train acc: %.6f' % (epoch, train_loss.result(), train_metrics.result()))</span><br><span class="line"></span><br><span class="line">        train_loss.reset_states()</span><br><span class="line">        train_metrics.reset_states()</span><br><span class="line">    print('static graph time is : %.3f' % (time.clock() - start))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/frame1.png" alt="case1"><br>从上面这个例子可以看出，<strong>使用静态图计算和使用动态图计算达到了相同的效果，但是动态图的计算速度却比静态图慢很多，但是在静态图函数中加入断点无法进入函数，动态图可以加入断点进行调试</strong>，因此需要小伙伴们自行选择。当然也可以<strong>选择fit或者train_on_batch进行训练，它们都是使用静态图进行计算的</strong>。</p>
<p><color=red>下面我们探究为什么静态图无法加入断点进行调试？&lt;/font&gt;<br></color=red></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dynamic():</span><br><span class="line">    tf.print('tf.print in dynamic graph')</span><br><span class="line">    print('print in dynamic graph')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@tf.function</span><br><span class="line">def static():</span><br><span class="line">    tf.print('tf.print in static graph')</span><br><span class="line">    print('print in static graph')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(3):</span><br><span class="line">    static()</span><br><span class="line"></span><br><span class="line">print('*' * 20)</span><br><span class="line"></span><br><span class="line">for i in range(3):</span><br><span class="line">    dynamic()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/FRAME/frame2.png" alt="case2"><br>从这个例子中可以看出，<strong>在调用@tf.function修饰的函数时分为两步，第一步是建立图的过程，第二步是输入数据的过程</strong>。<strong>第一步建立图的过程是静态执行模式</strong>，执行普通的Python语言，对<strong>其中的数据Tensor数据是没有数值的，类似于TensorFlow1.x中的placeholder，建立图时的计算只是建立运算关系和节点</strong>，因此会输出print in static graph一次，<strong>第二步输入数据时，才会将数据送入各个节点之中进行计算</strong>，在这个例子中没有输入数据，但是tf.print函数也是一个节点，因此在节点计算时会输出三次tf.print中的内容，而print函数不是节点，因此<strong>只会在第一步执行一次，以后无论执行多少次相同运算图的内容，print函数都不会执行，除非重新建立运算图</strong>。而<strong>动态图执行过程中，每一次都要进入dynamic函数中输出tf.print函数和print函数</strong>，因此每一个都会输出三次。</p>
<p><color=red>我们验证一下上面的思想，如何重新建立运算图，而且是否重新建立运算图会重新执行print语句&lt;/font&gt;<br></color=red></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@tf.function</span><br><span class="line">def static(x):</span><br><span class="line">    tf.print(x)</span><br><span class="line">    print(x)</span><br><span class="line">    tf.print('tf.print in static graph')</span><br><span class="line">    print('print in static graph')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print('inputs type is tensor—int32'.center(40, '-'))</span><br><span class="line">static(tf.constant(1, dtype=tf.int32))</span><br><span class="line">static(tf.constant(2, dtype=tf.int32))</span><br><span class="line"></span><br><span class="line">print('inputs type is tensor-float32'.center(40, '-'))</span><br><span class="line">static(tf.constant(1.1, dtype=tf.float32))</span><br><span class="line">static(tf.constant(2.2, dtype=tf.float32))</span><br><span class="line"></span><br><span class="line">print('inputs type is tensor—int32'.center(40, '-'))</span><br><span class="line">static(tf.constant(3, dtype=tf.int32))</span><br><span class="line"></span><br><span class="line">print('inputs type is int32'.center(40, '-'))</span><br><span class="line">static(1)</span><br><span class="line"></span><br><span class="line">print('inputs type is int32'.center(40, '-'))</span><br><span class="line">static(2)</span><br><span class="line"></span><br><span class="line">print('inputs type is variable—int32'.center(40, '-'))</span><br><span class="line">static(tf.Variable(1, name='x', dtype=tf.int32))</span><br><span class="line"></span><br><span class="line">print('inputs type is variable—int32'.center(40, '-'))</span><br><span class="line">static(tf.Variable(1, name='x', dtype=tf.int32))</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/FRAME/frame3.png" alt="case3"><br>从这个例子可以明显看出<strong>同种类型和维度的常量输入只会建立一次运算图，并且保存到字典中，如果发现相同类型和维度的输入，则会调用之前建立好的运算图</strong>。第一次传入值为1的张量时，建立了一次运算图，所以会出现print in static graph的输出，而且print这个张量时，不显示数值，只显示s类型，维度和名称，因此第二次传入值为2的张量时，不需要重新建立运算图。但是当第三次传入一个值为1.1的float类型张量时，因为<strong>数据的类型不同，因此会重新建立运算图，当然之前的运算图也会保存下来</strong>，因为再次传入值为3的张量时，也没有重新建立运算图，而是调用了之前保存的运算图。但<strong>值得注意的是，python中的常数和Tensor变量，即使这个变量名称，类型和维度都相同，每次也都需要重新建立运算图，因此传入参数时尽量传入常量Tensor类型</strong>。</p>
<p><color=red><strong>使用tf.executing_eagerly()可以查看此时是静态执行模式还是动态执行模式，如果是静态执行模式，则正在搭建静态图或者数据在静态图中进行流动</strong>。&lt;/font&gt;<br></color=red></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dynamic():</span><br><span class="line">    tf.print(tf.executing_eagerly())</span><br><span class="line">    print(tf.executing_eagerly())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@tf.function</span><br><span class="line">def static():</span><br><span class="line">    tf.print(tf.executing_eagerly())</span><br><span class="line">    print(tf.executing_eagerly())</span><br><span class="line"></span><br><span class="line">for i in range(3):</span><br><span class="line">    static()</span><br><span class="line"></span><br><span class="line">print('*' * 20)</span><br><span class="line"></span><br><span class="line">for i in range(3):</span><br><span class="line">    dynamic()</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/FRAME/frame4.png" alt="case4"><br>从这个例子可以看出，执行static函数时，白色的False是在搭建静态图中显示的print函数的内容，因此<strong>搭建静态图时处于静态执行模式中</strong>，红色的三次False是在数据流动中执行tf.print函数中的内容，说明在<strong>数据流的过程中也是处于静态执行模式</strong>。而白色的True和红色的True都表明在<strong>没有@tf.function装饰下，都是处于动态的执行模式</strong>。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  深度学习框架种类繁多，但是都大同小异，本枚菜鸟喜欢使用TensorFlow2版本，因为<strong>可以实现动态图和静态图的自由切换，让使用者学习一种框架就可以了解各种框架的不同，而且有很多的社区和官方文档，对于TensorFlow1.x版本有很多的改进，也是现在最主流的框架之一</strong>，推荐小伙伴们认真学习学习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>深度学习框架</category>
      </categories>
  </entry>
  <entry>
    <title>Closure &amp; Decorators(闭包和装饰器)</title>
    <url>/2019/10/28/python_closure%20Decorators/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/close.png" alt="close"></p>
<h1 id="Closure-amp-Decorators"><a href="#Closure-amp-Decorators" class="headerlink" title="Closure &amp; Decorators"></a><font size="5" color="red">Closure &amp; Decorators</font></h1><p>  <strong>Closure &amp; Decorators(闭包和装饰器)</strong>：是Python中非常重要的组成部分，其实它们是属于函数的内容，有关函数的内容，可以参考我的另一篇博客Function(函数)，但是装饰器实在是太高级，太重要了，为了让小伙伴们能够轻松的找到，因此我单独写一篇博客谈一谈什么是闭包和装饰器。<br><a id="more"></a></p>
<h1 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a><font size="5" color="red">闭包</font></h1><p><strong>Closure(闭包)：指在一个函数体的内部定义另一个函数，并且将这个函数的引用返回，使用该函数时的使用方式和普通函数相同，里面定义的函数称之为闭包</strong>。闭包函数<strong>总是可以访问其所在的外部函数中声明的参数和变量</strong>。<br><img src="/images/LANGUAGE/python105.png" alt="closure"></p>
<p>闭包实现求y=kx+b和函数实现y=kx+b的区别，从下图可以看出，使用闭包时，调用时给k和b赋值，这样以后只需要对x赋值即可，而使用函数，每次调用都需要对k，b，x同时赋值。<br><img src="/images/LANGUAGE/close1.png" alt="closure"></p>
<h1 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a><font size="5" color="red">装饰器</font></h1><p><strong>Decorators(装饰器)：实质上就是一个闭包，把一个函数作为参数，返回一个替代版本的函数，其本质就是一个返回函数的函数，可以在原函数之前或者之后增加内容。装饰器等价于函数名=闭包函数(函数名)</strong>。<br><img src="/images/LANGUAGE/python106.png" alt="Decorators"></p>
<p>通用装饰器是一种重要的装饰器，因为<strong>被装饰的函数可能需要输入参数和返回值，而且可能不同的函数需要不同个数不同种类的输入参数和返回值，因此一般情况下我们不在装饰器函数中将其写死，这里直接提供一种通用的装饰器形式</strong>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def func(functionName):</span><br><span class="line">  def func_in(*args, **kwargs):</span><br><span class="line">    ret = functionName(*args, **kwargs)</span><br><span class="line">    return ret</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><strong>多个装饰器共同装饰某个函数时，按照从下到上的顺序层层装饰，调用时按照从上到下的顺序层层解装饰</strong>。而且我们可以发现，在装饰函数时装饰器函数中的内容已经被执行，即执行到@d2时，d2函数中的print已经被执行，而warpped函数和say函数没有被执行。<br><img src="/images/LANGUAGE/close2.png" alt="Decorators"></p>
<p><strong>装饰器也可以具有参数，可以在内部根据其参数选择不同的装饰方式</strong>，这要涉及到多重函数闭包。<br><img src="/images/LANGUAGE/close3.png" alt="Decorators"></p>
<p><strong>类当作装饰器</strong>，需要重写$\underline{}\underline{}init \underline{}\underline{}$方法和$\underline{}\underline{}call\underline{} \underline{}$方法，<strong>@类名时会执行构造函数中的内容，调用函数时会执行call函数中的内容</strong>。<br><img src="/images/LANGUAGE/close4.png" alt="Decorators"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  关于闭包和装饰器，<strong>在某些特殊的场合，或者多人集成开发时会有使用</strong>，有时看别人的代码时会遇到装饰器，为了方便小伙伴们更快速的看懂别人写的代码，所以科普一下装饰器的使用，小伙伴们在自己写代码时可能不需要过多掌握，但是了解之后会使你的Python水平得到提升。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Iterator &amp; Generator(迭代器和生成器)</title>
    <url>/2019/10/23/python_Iterator%20Generator/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/iterator.png" alt="iterator"></p>
<h1 id="Iterator-amp-Generator"><a href="#Iterator-amp-Generator" class="headerlink" title="Iterator &amp; Generator"></a><font size="5" color="red">Iterator &amp; Generator</font></h1><p>  <strong>Iterator &amp; Generator(迭代器和生成器)</strong>：是Python中非常重要的组成部分，很多小伙伴搞不清迭代器和生成器到底是什么？如何创建迭代器和生成器？今天给小伙伴们具体讲解一下。<br><a id="more"></a></p>
<h1 id="Iterator-amp-Iterable"><a href="#Iterator-amp-Iterable" class="headerlink" title="Iterator &amp; Iterable"></a><font size="5" color="red">Iterator &amp; Iterable</font></h1><p>虽然今天是第一次提到Iterable(可迭代对象)和Iterator(迭代器对象)，但是我们一定都使用过可迭代对象。<strong>可迭代对象可以理解为一个实例对象，具有<strong>iter</strong>方法</strong>。而<strong>迭代器对象可以理解为一个实例对象，既有<strong>iter</strong>方法，又有<strong>next</strong>方法</strong>。<strong>一个可迭代对象通过<strong>iter</strong>方法可以转换为一个迭代器对象，而迭代器对象始终是一个可迭代对象，调用<strong>iter</strong>方法等于其自身</strong>。简单地说，可以使用for循环遍历的都是可迭代对象，我们<strong>常见的list，tuple，set，dict，str等容器都是可迭代对象，但是不是迭代器对象。通过<strong>iter</strong>方法可以转换为迭代器对象</strong>。</p>
<p>通过collection库下面的Iterator类和Iterable可以判定对象是否为迭代器对象还是可迭代对象。<br><img src="/images/LANGUAGE/iterator1.png" alt="iterator"></p>
<p>根据上面的分析可以知道，我们创建的类只要定义了<strong>next</strong>方法和<strong>iter</strong>方法，就是一个迭代器。<br><img src="/images/LANGUAGE/iterator2.png" alt="iterator"></p>
<p>我们还需要掌握一个知识点，<strong>迭代器对象是一次性消费对象</strong>，因为它们没有把所有的值存在内存中，而是在运行时产生值，当我们使用迭代器对象时，迭代器对象的内容就会消失。如下例，使用了列表容器产生一个可迭代对象a=[1, 2, 3, 4, 5]，并且使用<strong>iter</strong>方法产生了迭代器对象b，当next(b)时，会输出1，此时1就会从b中消失，同理再次使用next(b)时，2就会从b中消失，当list(b)时，所有数据都会从b中消失，但是a时不会变化的，因此我们需要另一个迭代器对象时，需要使用iter(a)再次产生一个。<br><img src="/images/LANGUAGE/iterator3.png" alt="iterator"></p>
<h1 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a><font size="5" color="red">生成器</font></h1><p><strong>Generator(生成器)也是一种迭代器，也是一次性消费对象</strong>，在写代码的时候，尤其是深度学习领域，具有大量的数据集输入，<strong>如果将数据全部保存，会受到内存的限制</strong>，而且很多数据本次用不到，这时候生成器就发挥了巨大的作用，每次使用时生成值。<strong>其实现一般有两种方式，一个是生成式，注意生成式不是列表生成式，而是将列表生成式中的中括号改成小括号，一个是使用关键字yield的函数</strong>。<br><img src="/images/LANGUAGE/iterator4.png" alt="generator"></p>
<p><strong>在调用带有yield的函数生成器时，返回的是一个生成器对象，当函数运行到yield时，将yield的值返回，程序会暂停，并且保存当前函数的所有运行信息，当使用next方法时，程序从上次停留的地方继续执行</strong>。<br><img src="/images/LANGUAGE/iterator5.png" alt="generator"></p>
<p><strong>生成器函数也可以接收输入值，通过send方法可以向生成器中传值</strong>。注意第一次只能通过send传入None，或者调用next方法，如果使用send不写输入参数则会报错，如果使用send传入某个非None的值也会报错。<br><img src="/images/LANGUAGE/iterator6.png" alt="generator"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  <strong>迭代器和生成器是Python中非常重要的内容，能够在特殊的情况下发挥出巨大的优势</strong>，小伙伴们务必掌握它。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>二叉树的遍历</title>
    <url>/2019/09/28/data%20traverse%20tree/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">二叉树的遍历</font></strong></center><p></p>
<h1 id="二叉树介绍"><a href="#二叉树介绍" class="headerlink" title="二叉树介绍"></a><font size="5" color="red">二叉树介绍</font></h1><p>  <strong>二叉树(Binary tree):是一种常见的数据结构，也是学习计算机必须要掌握的一种模型</strong>，与之相关的概念有很多，完全二叉树，二叉搜索树，二叉排序树，红黑树等等，相关的算法也有很多，深度优先搜索，广度优先搜索等等，今天的主要内容不在于此。有个朋友问我，二叉树有3种遍历方式，给出两种如何计算第三种，今天给小伙伴们理一理。<br><a id="more"></a></p>
<h1 id="先序遍历-preorder-traversal"><a href="#先序遍历-preorder-traversal" class="headerlink" title="先序遍历(preorder traversal)"></a><font size="5" color="red">先序遍历(preorder traversal)</font></h1><p><img src="/images/SKILL/tree_preorder.png" alt="0"><br>  <font size="3">（1）访问根节点</font><br>  <font size="3">（2）遍历左子树(在遍历左子树的时候也按照先序遍历)</font><br>  <font size="3">（3）遍历右子树(在遍历右子树的时候也按照先序遍历)</font></p>
<h1 id="中序遍历-inorder-traversal"><a href="#中序遍历-inorder-traversal" class="headerlink" title="中序遍历(inorder traversal)"></a><font size="5" color="red">中序遍历(inorder traversal)</font></h1><p><img src="/images/SKILL/tree_inorder.png" alt="0"><br>  <font size="3">（1）遍历左子树(在遍历左子树的时候也按照中序遍历)</font><br>  <font size="3">（2）访问根节点</font><br>  <font size="3">（3）遍历右子树(在遍历右子树的时候也按照中序遍历)</font></p>
<h1 id="后序遍历-postorder-traversal"><a href="#后序遍历-postorder-traversal" class="headerlink" title="后序遍历(postorder traversal)"></a><font size="5" color="red">后序遍历(postorder traversal)</font></h1><p><img src="/images/SKILL/tree_postorder.png" alt="0"><br>  <font size="3">（1）遍历左子树(在遍历左子树的时候也按照后序遍历)</font><br>  <font size="3">（2）遍历右子树(在遍历右子树的时候也按照后序遍历)</font><br>  <font size="3">（3）访问根节点</font></p>
<h1 id="给定先序和中序，求解后序遍历"><a href="#给定先序和中序，求解后序遍历" class="headerlink" title="给定先序和中序，求解后序遍历"></a><font size="5" color="red">给定先序和中序，求解后序遍历</font></h1><p>  先序遍历，因为先访问根节点，因此可以得出第一个节点就是根节点。<br>  中序遍历，先访问左子树，然后访问根节点，因此根节点之前的都是根节点的左子树，根节点之后的都是根节点的右子树。<br>  从根节点的左子树中进行迭代，重复上述过程。</p>
<p>  就以上面这个情况为例，先序遍历的结果是ABHFDECKG，中序遍历的结果是HBDFAEKCG，我们进行分析。</p>
<ol>
<li>先序可以知道根节点A，在中序遍历中A之前为HBDF是A的左子树，A之后为EKCG为A的右子树。</li>
<li>从HBDF中寻找根节点，在先序遍历中，B是HBDF中第一个出现的节点，因此B是根节点，在中序遍历中B之前为H是B的左子树，B之后为DF是B的右子树。</li>
<li>从DF中寻找根节点，在先序遍历中，F是DF中第一个出现的节点，因此F是根节点，在中序遍历中F之前为D是F的左子树。F没有右子树。此时A的左子树全部遍历完毕。</li>
<li>从EKCG中寻找根节点，在先序遍历中，E是EKCG中第一个出现的节点，因此E是根节点，在中序遍历中E之前没有节点，E没有左子树，E之后为KCG是E的右子树。</li>
<li>从KCG中寻找根节点，在先序遍历中，C是KCG中第一个出现的节点，因此C是根节点，在中序遍历中C之前为K是左子树，C之后为G是右子树。此时遍历结束。</li>
<li>通过之前的遍历，可以重建出这个树的全貌，因此再通过后序遍历读出节点顺序即可。结果为HDFBKGCEA，小伙伴们可以进行尝试能否推导出来。</li>
</ol>
<h1 id="给定中序和后序，求解先序遍历"><a href="#给定中序和后序，求解先序遍历" class="headerlink" title="给定中序和后序，求解先序遍历"></a><font size="5" color="red">给定中序和后序，求解先序遍历</font></h1><p>  后序遍历，因为最后访问根节点，因此可以得出最后一个节点就是根节点。<br>  中序遍历，先访问左子树，然后访问根节点，因此根节点之前的都是根节点的左子树，根节点之后的都是根节点的右子树。<br>  从根节点的左子树中进行迭代，重复上述过程。</p>
<p>  就以上面这个情况为例，中序遍历的结果是HBDFAEKCG，后序遍历的结果是HDFBKGCEA，我们进行分析。</p>
<ol>
<li>后序可以知道根节点A，在中序遍历中A之前为HBDF是A的左子树，A之后为EKCG为A的右子树。</li>
<li>从HBDF中寻找根节点，在后序遍历中，B是HBDF中最后一个出现的节点，因此B是根节点，在中序遍历中B之前为H是B的左子树，B之后为DF是B的右子树。</li>
<li>从DF中寻找根节点，在后序遍历中，F是DF中最后一个出现的节点，因此F是根节点，在中序遍历中F之前为D是F的左子树。F没有右子树。此时A的左子树全部遍历完毕。</li>
<li>从EKCG中寻找根节点，在后序遍历中，E是EKCG中第一个出现的节点，因此E是根节点，在中序遍历中E之前没有节点，E没有左子树，E之后为KCG是E的右子树。</li>
<li>从KCG中寻找根节点，在后序遍历中，C是KCG中第一个出现的节点，因此C是根节点，在中序遍历中C之前为K是左子树，C之后为G是右子树。此时遍历结束。</li>
<li>通过之前的遍历，可以重建出这个树的全貌，因此再通过先序遍历读出节点顺序即可。结果为ABHFDECKG，小伙伴们也可以进行尝试能否推导出来。</li>
</ol>
<h1 id="给定先序和后序，求解中序遍历"><a href="#给定先序和后序，求解中序遍历" class="headerlink" title="给定先序和后序，求解中序遍历"></a><font size="5" color="red">给定先序和后序，求解中序遍历</font></h1><p>这个是无法求解的，因为已知先序和后序，出现了过多的信息冗余，导致有效信息不足，以上题来说，先序的第一个节点一定是A，那么后序的最后一个节点也一定是A，这就是无效信息，下图展示了一个极端的例子。<br><img src="/images/SKILL/tree_postorder.png" alt="0"><br>在这个图中，小伙伴们可以写一下它们的先序遍历和后序遍历，就会发现它们的先序遍历和后序遍历都是一样的，因为它们只有左子树或者只有右子树，可以将左子树和右子树看成一个整体，因此两个遍历的结果是相同的，所以不能够通过先序和后序得出树得全貌。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font size="5" color="red">小结</font></h1><p>  树的遍历是经典的笔试考题，掌握小伙伴的基本功力，因此小伙伴们一定要学习如何通过两种遍历得到另一种遍历的过程。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>数据结构部分</category>
      </categories>
  </entry>
  <entry>
    <title>Linux(操作系统)</title>
    <url>/2019/09/23/skill%20Linux/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Linux</font></strong></center><p></p>
<h1 id="Linux介绍"><a href="#Linux介绍" class="headerlink" title="Linux介绍"></a><font size="5" color="red">Linux介绍</font></h1><p>  <strong>Linux:</strong>在1991年10月被<strong>Linus Torvalds(林纳斯·托瓦兹)</strong>创建，并于<strong>1994年发布了Linux-v1.0</strong>。是一套<strong>免费使用</strong>和<strong>自由传播</strong>的<strong>类Unix</strong>操作系统，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。<br><a id="more"></a></p>
<p><img src="/images/SKILL/linux1.jpg" alt="1"></p>
<h1 id="Linux特点"><a href="#Linux特点" class="headerlink" title="Linux特点"></a><font size="5" color="red">Linux特点</font></h1><p>  <font size="3">Linux是一款完全免费的操作系统，用户可以通过各种渠道下载使用。</font><br>  <font size="3">Linux是一款完全开源的操作系统，用户可以任意修改其源代码。</font><br>  <font size="3">Linux支持多用户，多任务的使用方式，对不同的用户有着不同的权利。</font><br>  <font size="3">Linux具有良好的界面，同时具有字符界面和图形界面。</font><br>  <font size="3">Linux支持多平台，可以运行在多种硬件平台上。</font><br>  <font size="3">Linux内核高效稳定，可使用户方便地建立防火墙，服务器。</font></p>
<h1 id="Linux注意事项"><a href="#Linux注意事项" class="headerlink" title="Linux注意事项"></a><font size="5" color="red">Linux注意事项</font></h1><p>  <font size="3">Linux严格区分大小写，大小写不同，命令不同。</font><br>  <font size="3">Linux中所有内容以文件形式保存，包括硬件。</font><br>  <font size="3">Linux和Windows不同，不靠扩展名来区分文件类型。</font><br>  <font size="3">Linux所有的设备都需要先挂载之后才能使用。</font><br>  <font size="3">Windows下的程序不能直接在Linux中安装运行。</font></p>
<h1 id="Linux常用命令"><a href="#Linux常用命令" class="headerlink" title="Linux常用命令"></a><font size="5" color="red">Linux常用命令</font></h1><p>  <font size="3">此命令都是运行在Ubuntu系统中，不同的Linux系列，如Debian系列和Redhat命令大同小异。</font></p>
<h2 id="显示目录文件"><a href="#显示目录文件" class="headerlink" title="显示目录文件"></a><font size="4">显示目录文件</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ls -a</td>
<td>显示所有的文件，包括隐含文件(以.开头)</td>
</tr>
<tr>
<td>ls -l</td>
<td>显示文件的详细信息，不包括隐含文件</td>
</tr>
<tr>
<td>ls -h</td>
<td>以人性化形式显示文件，不包括隐含文件</td>
</tr>
<tr>
<td>ls -i</td>
<td>查看文件的i结点，不包括隐含文件</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux1.png" alt="1"></p>
<p>  <font size="4" color="red">文件信息字段</font><br>  <font size="3">第一项第一个字母：文件的类型，-代表二进制文件，d代表目录，l代表软连接文件</font><br>  <font size="3">第一项第二个字母到第四个字母：文件所有者可对文件的操作</font><br>  <font size="3">第一项第五个字母到第七个字母：组内成员可对文件的操作</font><br>  <font size="3">第一项第八个字母到第十个字母：其他用户可对文件的操作</font><br>  <font size="3">三个字母为一组，从左到右分别是读(r)，写(w)，执行(x)</font><br>  <font size="3">第二项：文件硬链接数</font><br>  <font size="3">第三项：文件的所有者</font><br>  <font size="3">第四项：文件的所属组</font><br>  <font size="3">第五项：文件所占用的字节空间</font><br>  <font size="3">第六项：文件最近的访问时间</font><br>  <font size="3">第七项：文件名</font></p>
<h2 id="目录处理命令"><a href="#目录处理命令" class="headerlink" title="目录处理命令"></a><font size="4">目录处理命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>mkdir -p dicname</td>
<td>递归创建名为dicname的文件夹</td>
</tr>
<tr>
<td>mkdir dicname</td>
<td>创建名为dicname的文件夹</td>
</tr>
<tr>
<td>cd dicname</td>
<td>切换目录</td>
</tr>
<tr>
<td>cd ..</td>
<td>返回上一级目录</td>
</tr>
<tr>
<td>pwd</td>
<td>显示当前目录</td>
</tr>
<tr>
<td>rmdir dicname</td>
<td>删除空目录</td>
</tr>
<tr>
<td>cp old new</td>
<td>复制文件</td>
</tr>
<tr>
<td>cp -r old new</td>
<td>复制目录</td>
</tr>
<tr>
<td>cp -p old new</td>
<td>保留属性复制</td>
</tr>
<tr>
<td>mv old new</td>
<td>剪切文件</td>
</tr>
<tr>
<td>rm filename</td>
<td>删除文件</td>
</tr>
<tr>
<td>rm -r dicname</td>
<td>删除目录</td>
</tr>
<tr>
<td>rm -f</td>
<td>强制执行</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux2.png" alt="2"></p>
<h2 id="文件处理命令"><a href="#文件处理命令" class="headerlink" title="文件处理命令"></a><font size="4">文件处理命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>touch filename</td>
<td>创建名为filename的空文件</td>
</tr>
<tr>
<td>cat filename</td>
<td>显示filename文件内容</td>
</tr>
<tr>
<td>cat -n filename</td>
<td>显示filename文件内容，并显示行号</td>
</tr>
<tr>
<td>tac</td>
<td>反向显示文件内容</td>
</tr>
<tr>
<td>less</td>
<td>分页显示文件内容(pageup和pagedown)</td>
</tr>
<tr>
<td>head -n m</td>
<td>显示文件前m行</td>
</tr>
<tr>
<td>tail -n m</td>
<td>显示文件后m行</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux4.png" alt="4"></p>
<h2 id="链接命令"><a href="#链接命令" class="headerlink" title="链接命令"></a><font size="4">链接命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ln filename hardlink</td>
<td>生成链接到filename的硬链接</td>
</tr>
<tr>
<td>ln -s filename softlink</td>
<td>生成链接到filename的软链接</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="4" color="red">硬链接</font><br>  <font size="3">硬链接除了文件名所在地，其余信息都相同。</font><br>  <font size="3">硬链接后，文件信息中的链接数会加1。</font><br>  <font size="3">硬链接文件的i节点和源文件相同。</font><br>  <font size="3">硬链接不能跨分区。</font><br>  <font size="3">硬链接不能针对目录。</font><br>  <font size="3">源文件丢失，仍然可以访问硬链接。</font></p>
<p>  <font size="4" color="red">软链接</font><br>  <font size="3">软链接类似于Windows中的快捷方式，有箭头指向。</font><br>  <font size="3">软链接后，文件信息中的链接数不变。</font><br>  <font size="3">软链接文件的i节点和源文件不同。</font><br>  <font size="3">软链接可以跨分区。</font><br>  <font size="3">软链接可以针对目录。</font><br>  <font size="3">源文件丢失，不能访问软链接。</font></p>
<p><img src="/images/SKILL/linux3.png" alt="3"></p>
<h2 id="权限管理命令"><a href="#权限管理命令" class="headerlink" title="权限管理命令"></a><font size="4">权限管理命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>chmod op filename</td>
<td>修改filename文件的权限</td>
</tr>
<tr>
<td>chmod -R op dicname</td>
<td>修改dicname目录下所有文件的权限</td>
</tr>
<tr>
<td>chown own filename_or_dicname</td>
<td>修改文件或目录的所有者</td>
</tr>
<tr>
<td>chgrp grp filename_or_dicname</td>
<td>修改文件或目录的所属组</td>
</tr>
<tr>
<td>umask</td>
<td>查看当前用户新建文件的缺省权限</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="4" color="red">文件权限</font><br>  <font size="3">r：读权限，可以查看文件内容，如cat, tac, less, head, tail等</font><br>  <font size="3">w：写权限，可以修改文件内容，如vi, vim等</font><br>  <font size="3">x：执行权限，可以执行文件，如script, command等</font></p>
<p>  <font size="4" color="red">目录权限</font><br>  <font size="3">r：读权限，可以列出目录内容，如ls等</font><br>  <font size="3">w：写权限，可以在目录中创建删除文件，如touch, mkdir, rmdir, rm等</font><br>  <font size="3">x：执行权限，可以进入目录，如cd等</font></p>
<p>  <font size="4" color="red">修改权限两种操作</font><br>  <font size="3">u/g/o/a +/-/= r/w/x对所有者/所属组/其他用户/所有人 加/减/赋值 读/写/执行权限</font><br>  <font size="3">如 chmod g+w, o-r filename 对filename的所属组添加写权限，对其他用户删除读权限</font></p>
<p>  <font size="3">直接利用数字进行赋值权限</font><br>  <font size="3">如 chmod 644 filename 对filename的所有者添加读写权限，对所属组和其他用户添加读权限</font><br><img src="/images/SKILL/linux6.png" alt="6"></p>
<h2 id="文件搜索命令"><a href="#文件搜索命令" class="headerlink" title="文件搜索命令"></a><font size="4">文件搜索命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>find range condition</td>
<td>查找range范围内符合条件的文件或目录</td>
</tr>
<tr>
<td>locate filename</td>
<td>从文件资料库中查找文件</td>
</tr>
<tr>
<td>which command</td>
<td>搜索命令所在目录及别名信息</td>
</tr>
<tr>
<td>whereis command</td>
<td>搜索命令所在目录及帮助文档路径</td>
</tr>
<tr>
<td>grep string file</td>
<td>在文件中搜索字符串匹配的行并输出</td>
</tr>
<tr>
<td>grep -i string file</td>
<td>不区分字符串大小写搜索匹配的行并输出</td>
</tr>
<tr>
<td>grep -v string file</td>
<td>在文件中排除与字符串匹配的行并输出</td>
</tr>
<tr>
<td>grep -n string file</td>
<td>在文件中搜索字符串匹配的行并输出，并显示行数</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="4" color="red">find搜索匹配条件</font><br>  <font size="3">*：匹配字符多个</font><br>  <font size="3">如*init指以init结尾的文件名，*init*指包含init的文件名</font><br>  <font size="3">?：匹配单个字符</font><br>  <font size="3">如???init指以init结尾长度为7的文件名</font><br><img src="/images/SKILL/linux5.png" alt="5"></p>
<h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a><font size="4">帮助命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>man command</td>
<td>获得命令的帮助信息</td>
</tr>
<tr>
<td>whatis command</td>
<td>查看命令的功能</td>
</tr>
<tr>
<td>apropos filename</td>
<td>查看配置文件的简要信息</td>
</tr>
<tr>
<td>command —help</td>
<td>查看命令的常见选项</td>
</tr>
<tr>
<td>help command</td>
<td>查看shell内置命令的帮助信息</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux7.png" alt="7"></p>
<h2 id="网络命令"><a href="#网络命令" class="headerlink" title="网络命令"></a><font size="4">网络命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>write username</td>
<td>给用户发信息</td>
</tr>
<tr>
<td>wall</td>
<td>发广播信息</td>
</tr>
<tr>
<td>ping ip</td>
<td>对ip地址发数据包检测网络连通性，一直在发送</td>
</tr>
<tr>
<td>ping -c n ip</td>
<td>对ip地址发数据包检测网络连通性，发送n次</td>
</tr>
<tr>
<td>ifconfig net_card ip</td>
<td>配置网卡的ip地址</td>
</tr>
<tr>
<td>mail username</td>
<td>查看发送的电子邮件</td>
</tr>
<tr>
<td>last</td>
<td>列出登录系统的用户信息</td>
</tr>
<tr>
<td>lastlog</td>
<td>查看所有用户最后一次登录的时间</td>
</tr>
<tr>
<td>lastlog -u userid</td>
<td>查看用户id为userid(不是用户名)的用户最后一次登录时间</td>
</tr>
<tr>
<td>traceroute url</td>
<td>查看数据包到主机间的路径</td>
</tr>
<tr>
<td>netstat -t</td>
<td>显示网络中的TCP协议</td>
</tr>
<tr>
<td>netstat -u</td>
<td>显示网络中的UDP协议</td>
</tr>
<tr>
<td>netstat -l</td>
<td>监听网络服务</td>
</tr>
<tr>
<td>netstat -r</td>
<td>查看路由表</td>
</tr>
<tr>
<td>netstat -n</td>
<td>显示ip地址和端口号</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux8.png" alt="8"></p>
<h2 id="关机重启命令"><a href="#关机重启命令" class="headerlink" title="关机重启命令"></a><font size="4">关机重启命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>shutdown -c</td>
<td>取消上一个关机命令</td>
</tr>
<tr>
<td>shutdown -h +n</td>
<td>n分钟后关机</td>
</tr>
<tr>
<td>shutdown -h time</td>
<td>到达时间time关机</td>
</tr>
<tr>
<td>shutdown -h now</td>
<td>现在关机</td>
</tr>
<tr>
<td>shutdown -r +n</td>
<td>n分钟后重启</td>
</tr>
<tr>
<td>shutdown -r time</td>
<td>到达时间time重启</td>
</tr>
<tr>
<td>shutdown -r now</td>
<td>现在重启</td>
</tr>
</tbody>
</table>
</div>
<h2 id="修改系统默认运行级别"><a href="#修改系统默认运行级别" class="headerlink" title="修改系统默认运行级别"></a><font size="4">修改系统默认运行级别</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>vim /etc/inittab</td>
<td>修改系统默认运行级别</td>
</tr>
<tr>
<td>runlevel</td>
<td>查看系统运行级别</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="4" color="red">系统运行级别</font><br>  <font size="3">0：关机</font><br>  <font size="3">1：单用户模式</font><br>  <font size="3">2：不完全多用户模式，不含 NFS服务</font><br>  <font size="3">3：完全多用户模式务</font><br>  <font size="3">4：未分配</font><br>  <font size="3">5：图形界面</font><br>  <font size="3">6：重启</font></p>
<h2 id="用户配置文件"><a href="#用户配置文件" class="headerlink" title="用户配置文件"></a><font size="4">用户配置文件</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>less /etc/passwd</td>
<td>查看用户信息文件</td>
</tr>
<tr>
<td>less /etc/shadow</td>
<td>查看用户影子文件</td>
</tr>
<tr>
<td>less /etc/group</td>
<td>查看组信息文件</td>
</tr>
<tr>
<td>less /etc/gshadow</td>
<td>查看组影子文件</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="4" color="red">用户信息文件字段</font><br>  <font size="3">第一个字段：用户名称</font><br>  <font size="3">第二个字段：密码标志</font><br>  <font size="3">第三个字段：用户ID(UID)</font><br>  <font size="3">第四个字段：用户初始组ID(GID)</font><br>  <font size="3">第五个字段：用户说明</font><br>  <font size="3">第六个字段：家用户</font><br>  <font size="3">第七个字段：登录后的shell</font></p>
<p>  <font size="4" color="red">用户影子文件字段</font><br>  <font size="3">第一个字段：用户名称</font><br>  <font size="3">第二个字段：加密密码</font><br>  <font size="3">第三个字段：密码最后一次修改时间</font><br>  <font size="3">第四个字段：两次密码修改间隔</font><br>  <font size="3">第五个字段：密码有效期</font><br>  <font size="3">第六个字段：密码到期前的警告天数</font><br>  <font size="3">第七个字段：密码过期后的宽限天数</font><br>  <font size="3">第八个字段：账号失效时间</font><br>  <font size="3">第九个字段：保留字段</font></p>
<p>  <font size="4" color="red">组信息文件字段</font><br>  <font size="3">第一个字段：组名称</font><br>  <font size="3">第二个字段：组密码标志</font><br>  <font size="3">第三个字段：组ID(GID)</font><br>  <font size="3">第四个字段：组中附加用户</font></p>
<p>  <font size="4" color="red">组影子文件字段</font><br>  <font size="3">第一个字段：组名称</font><br>  <font size="3">第二个字段：组密码</font><br>  <font size="3">第三个字段：组管理员用户名</font><br>  <font size="3">第四个字段：组中附加用户</font></p>
<h2 id="用户管理命令"><a href="#用户管理命令" class="headerlink" title="用户管理命令"></a><font size="4">用户管理命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>useradd username</td>
<td>添加新用户</td>
</tr>
<tr>
<td>useradd -u username</td>
<td>添加新用户，手动指定用户id</td>
</tr>
<tr>
<td>useradd -d username</td>
<td>添加新用户，手动指定家目录</td>
</tr>
<tr>
<td>useradd -c username</td>
<td>添加新用户，手动指定用户说明</td>
</tr>
<tr>
<td>useradd -G username</td>
<td>添加新用户，手动指定附加组</td>
</tr>
<tr>
<td>useradd -g username</td>
<td>添加新用户，手动指定初始组</td>
</tr>
<tr>
<td>useradd -s username</td>
<td>添加新用户，手动指定登录shell</td>
</tr>
<tr>
<td>passwd username</td>
<td>设置用户密码</td>
</tr>
<tr>
<td>passwd -s username</td>
<td>查询用户密码状态</td>
</tr>
<tr>
<td>passwd -l username</td>
<td>暂时锁定用户</td>
</tr>
<tr>
<td>passwd -u username</td>
<td>解锁用户</td>
</tr>
<tr>
<td>userdel username</td>
<td>删除用户</td>
</tr>
<tr>
<td>change -l username</td>
<td>列出用户的详细密码状态</td>
</tr>
<tr>
<td>change -d username</td>
<td>修改密码最后一次更改日期</td>
</tr>
<tr>
<td>change -m username</td>
<td>修改两次密码修改间隔</td>
</tr>
<tr>
<td>change -M username</td>
<td>修改密码有效期</td>
</tr>
<tr>
<td>change -W username</td>
<td>修改密码过期前警告天数</td>
</tr>
<tr>
<td>change -I username</td>
<td>修改密码过期后宽限天数</td>
</tr>
<tr>
<td>change -E username</td>
<td>修改账号失效时间</td>
</tr>
</tbody>
</table>
</div>
<h2 id="用户组管理命令"><a href="#用户组管理命令" class="headerlink" title="用户组管理命令"></a><font size="4">用户组管理命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>groupadd groupname</td>
<td>添加新用户组</td>
</tr>
<tr>
<td>groupadd -g groupname</td>
<td>添加新用户，手动指定组id</td>
</tr>
<tr>
<td>groupmod -g groupname</td>
<td>修改组id</td>
</tr>
<tr>
<td>groupmod -n groupname</td>
<td>修改组名</td>
</tr>
<tr>
<td>groupdel groupname</td>
<td>删除用户组</td>
</tr>
<tr>
<td>gpasswd -a groupname</td>
<td>将用户加入用户组</td>
</tr>
<tr>
<td>gpasswd -a groupname</td>
<td>将用户从用户组删除</td>
</tr>
</tbody>
</table>
</div>
<h2 id="文件系统管理命令"><a href="#文件系统管理命令" class="headerlink" title="文件系统管理命令"></a><font size="4">文件系统管理命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>df -a dirname</td>
<td>显示文件的系统信息</td>
</tr>
<tr>
<td>df -h dirname</td>
<td>以人性化方式显示文件的系统信息</td>
</tr>
<tr>
<td>df -a dirname</td>
<td>显示文件的系统类型</td>
</tr>
<tr>
<td>du -a dicname</td>
<td>显示每个子文件的磁盘占用量</td>
</tr>
<tr>
<td>du -h dicname</td>
<td>以人性化方式显示每个子文件的磁盘占用量</td>
</tr>
<tr>
<td>du -s dicname</td>
<td>统计总占用量</td>
</tr>
<tr>
<td>fdisk -l</td>
<td>查看u盘的设备文件名</td>
</tr>
<tr>
<td>mount -t vfat device dicname</td>
<td>将u盘文件名device挂载到dicname文件名中</td>
</tr>
<tr>
<td>umount device</td>
<td>卸载挂载device</td>
</tr>
</tbody>
</table>
</div>
<h2 id="终端常用命令"><a href="#终端常用命令" class="headerlink" title="终端常用命令"></a><font size="4">终端常用命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ctrl + Alt +t</td>
<td>打开终端</td>
</tr>
<tr>
<td>Ctrl + d</td>
<td>退出终端</td>
</tr>
<tr>
<td>Ctrl + c</td>
<td>终止正在运行的程序</td>
</tr>
<tr>
<td>Ctrl + l</td>
<td>清屏</td>
</tr>
<tr>
<td>Ctrl + s</td>
<td>锁住终端</td>
</tr>
<tr>
<td>Ctrl + q</td>
<td>解锁终端</td>
</tr>
<tr>
<td>Ctrl + r</td>
<td>查找历史命令</td>
</tr>
<tr>
<td>^up</td>
<td>查看上一个历史记录</td>
</tr>
<tr>
<td>^down</td>
<td>查看下一个历史记录</td>
</tr>
<tr>
<td>su</td>
<td>切换到root用户</td>
</tr>
<tr>
<td>su username</td>
<td>切换到username用户</td>
</tr>
<tr>
<td>sudo command</td>
<td>以root权限执行命令</td>
</tr>
<tr>
<td>TAB</td>
<td>命令与文件补全</td>
</tr>
<tr>
<td>alias</td>
<td>查看命令的别名</td>
</tr>
<tr>
<td>alias newname command</td>
<td>给原命令起一个别名</td>
</tr>
</tbody>
</table>
</div>
<h2 id="重定向命令"><a href="#重定向命令" class="headerlink" title="重定向命令"></a><font size="4">重定向命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>command &gt; filename</td>
<td>将正确命令的结果覆盖到filename文件中</td>
</tr>
<tr>
<td>command &gt;&gt; filename</td>
<td>将正确命令的结果追加到filename文件中</td>
</tr>
<tr>
<td>command 2&gt; filename</td>
<td>将错误命令的结果覆盖到filename文件中</td>
</tr>
<tr>
<td>command 2&gt;&gt; filename</td>
<td>将错误命令的结果追加到filename文件中</td>
</tr>
<tr>
<td>command &amp;&gt; filename</td>
<td>将命令的结果覆盖到filename文件中(无论正确与否)</td>
</tr>
<tr>
<td>command &amp;&gt;&gt; filename</td>
<td>将命令的结果追加到filename文件中(无论正确与否)</td>
</tr>
<tr>
<td>command &gt;&gt; filename1 &amp;&gt;&gt; filename2</td>
<td>将正确的命令结果追加到filename1，错误命令的结果追加到到filename2</td>
</tr>
</tbody>
</table>
</div>
<h2 id="多命令"><a href="#多命令" class="headerlink" title="多命令"></a><font size="4">多命令</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>command1 ; command2 ; …</td>
<td>多个命令顺序执行，命令1出错命令2也会执行</td>
</tr>
<tr>
<td>command1 &amp;&amp; command2 &amp;&amp; …</td>
<td>逻辑与，命令1正确执行，命令2才会执行</td>
</tr>
<tr>
<td>command1 ll command2 ll …</td>
<td>逻辑或，命令1不正确执行，命令2才会执行</td>
</tr>
<tr>
<td>command 2&gt;&gt; filename</td>
<td>将错误命令的结果追加到filename文件中</td>
</tr>
<tr>
<td>command &amp;&gt; filename</td>
<td>将命令的结果覆盖到filename文件中(无论正确与否)</td>
</tr>
<tr>
<td>command &amp;&gt;&gt; filename</td>
<td>将命令的结果追加到filename文件中(无论正确与否)</td>
</tr>
<tr>
<td>command &gt;&gt; filename1 &amp;&gt;&gt; filename2</td>
<td>将正确的命令结果追加到filename1，错误命令的结果追加到到filename2</td>
</tr>
<tr>
<td>command1 l command2</td>
<td>管道符，命令1的正确输出作为命令2的操作对象</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux9.png" alt="9"></p>
<h2 id="特殊符号"><a href="#特殊符号" class="headerlink" title="特殊符号"></a><font size="4">特殊符号</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>?</td>
<td>匹配一个任意字符</td>
</tr>
<tr>
<td>*</td>
<td>匹配任意多个字符</td>
</tr>
<tr>
<td>[]</td>
<td>匹配[]中任意一个字符</td>
</tr>
<tr>
<td>[-]</td>
<td>匹配[]中任意一个字符，-代表范围，如0-9</td>
</tr>
<tr>
<td>[^]</td>
<td>匹配不在[]中的任意一个字符</td>
</tr>
<tr>
<td>‘’</td>
<td>单引号将其作为一个整体，其中的所有特殊符号都是普通符号</td>
</tr>
<tr>
<td>“”</td>
<td>双引号中$调用变量的值，`引用命令，\转义字符</td>
</tr>
<tr>
<td>``</td>
<td>反引号中的内容为系统命令</td>
</tr>
<tr>
<td>$</td>
<td>美元符号调用变量的值</td>
</tr>
<tr>
<td>\</td>
<td>反斜杠指转义符</td>
</tr>
<tr>
<td>#</td>
<td>注释符</td>
</tr>
</tbody>
</table>
</div>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a><font size="4">正则表达式</font></h2><p>  <font size="3">在Linux中，正则表达式是用来在文件中匹配符合条件的字符串，正则是包含匹配，grep，awk，sed等命令支持正则表达式。</font><br>  <font size="3">在Linux中，通配符是用来匹配符合条件的文件名，通配符是完全匹配，ls，find，cp等命令不支持正则表达式，只能使用通配符进行匹配。</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>前一个字符匹配0次或任意多次</td>
</tr>
<tr>
<td>.</td>
<td>匹配除换行符外任意一个字符</td>
</tr>
<tr>
<td>^</td>
<td>匹配行首</td>
</tr>
<tr>
<td>$</td>
<td>匹配行尾</td>
</tr>
<tr>
<td>[]</td>
<td>匹配括号中指定的任意一个字符</td>
</tr>
<tr>
<td>[^]</td>
<td>匹配除了括号中指定的任意一个字符</td>
</tr>
<tr>
<td>\</td>
<td>转义字符</td>
</tr>
<tr>
<td>{n}</td>
<td>表示前面的字符出现n次</td>
</tr>
<tr>
<td>{n,}</td>
<td>表示前面的字符出现不小于n次</td>
</tr>
<tr>
<td>{n,m}</td>
<td>表示前面的字符至少出现n次，至多m次</td>
</tr>
</tbody>
</table>
</div>
<h2 id="字符处理命令"><a href="#字符处理命令" class="headerlink" title="字符处理命令"></a><font size="4">字符处理命令</font></h2><p>|  符号   | 说明  |<br>|  cut -f n filename  |  提取文件第n列  |<br>|  cut -d interval -f n filename   |  设定分隔符提取文件第n列  |<br>|  printf “type_and_format” content  |  格式化输出  |<br>|  awk “condition1 {action1} condition2 {action2} …” filename  |  对filename中符合condition的进行action操作  |<br>|  awk “BEGIN{action} condition1 {action1} condition2 {action2} …” filename  |  在对filename操作之前进行action操作  |<br>|  awk “BEGIN{FS=’c’} condition1 {action1} condition2 {action2} …” filename  |  以c为分隔符进行操作，默认分隔符为制表符  |<br>|  awk “END{action} condition1 {action1} condition2 {action2} …” filename  |  在对filename操作之后进行action操作  |<br>|  sed -n  |  把只经过sed处理的输出，原文件不变化  |<br>|  sed -e  |  允许对输入数据应用多条sed命令  |<br>|  sed -i  |  直接对文件进行修改，不显示输出  |<br>|  sed a  |  在当前行后添加一行或多行  |<br>|  sed c  |  对当前行替换  |<br>|  sed i  |  对当前行插入  |<br>|  sed d  |  删除指定的行  |<br>|  sed p |  打印指定的行  |<br>|  sed s  |  字符替换，格式为”行范围/s/old_str/new_str/g”  |<br>|  sort  |  以数值型排序  |<br>|  sort -f  |  忽略大小写排序  |<br>|  sort -n |  以数值型排序  |<br>|  sort -r  |  反向排序  |<br>|  sort -t |  指定分隔符，默认为制表符  |<br>|  sort -k n[,m]  |  按照指定的字段，从n开始到m结束  |<br>|  wc  |  输入字符串，Ctrl+d结束，统计行数，单词数和字符数  |<br>|  wc filename  |  统计filename文件中的行数，单词数和字符数  |<br>|  wc -c  |  输入字符串，Ctrl+d结束，统计字符数  |<br>|  wc -w  |  输入字符串，Ctrl+d结束，统计单词数  |<br>|  wc -l  |  输入字符串，Ctrl+d结束，统计行数  |<br><img src="/images/SKILL/linux11.png" alt="11"></p>
<h2 id="系统管理"><a href="#系统管理" class="headerlink" title="系统管理"></a><font size="4">系统管理</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ps aux</td>
<td>查看系统中的所有进程</td>
</tr>
<tr>
<td>top</td>
<td>查看系统的健康状态，默认每3秒更新一次</td>
</tr>
<tr>
<td>top -d</td>
<td>设置更新的秒数</td>
</tr>
<tr>
<td>top P</td>
<td>以CPU使用率排序</td>
</tr>
<tr>
<td>top M</td>
<td>以内存使用率排序</td>
</tr>
<tr>
<td>top N</td>
<td>以进程号(PID)排序</td>
</tr>
<tr>
<td>q</td>
<td>退出top</td>
</tr>
<tr>
<td>pstree</td>
<td>查看进程树</td>
</tr>
<tr>
<td>pstree -p</td>
<td>查看进程树，并显示进程号</td>
</tr>
<tr>
<td>pstree -u</td>
<td>查看进程树，并显示所属用户</td>
</tr>
<tr>
<td>kill -l</td>
<td>查看可用的进程信号</td>
</tr>
<tr>
<td>kill PID</td>
<td>正常关闭进程号为PID的进程</td>
</tr>
<tr>
<td>kill -n PID</td>
<td>对进程号为PID的进程进行n操作，n可以通过kill -l查询</td>
</tr>
<tr>
<td>killall p_name</td>
<td>杀死进程名为p_name的进程</td>
</tr>
<tr>
<td>killall p_name</td>
<td>杀死进程名为p_name的进程</td>
</tr>
<tr>
<td>killall p_name</td>
<td>杀死进程名为p_name的进程</td>
</tr>
<tr>
<td>command &amp;</td>
<td>将命令放在后台执行</td>
</tr>
<tr>
<td>command + Ctrl + z</td>
<td>将命令放在后台，且不执行</td>
</tr>
<tr>
<td>jobs</td>
<td>显示后台的进程</td>
</tr>
<tr>
<td>jobs -l</td>
<td>显示后台的进程，并显示PID</td>
</tr>
<tr>
<td>fg</td>
<td>恢复第一个后台暂停的进程到前台执行</td>
</tr>
<tr>
<td>fg %work_id</td>
<td>恢复工作号为work_id后台暂停的进程到前台执行，注意工作号和PID不同</td>
</tr>
<tr>
<td>bg</td>
<td>恢复第一个后台暂停的进程到后台执行</td>
</tr>
<tr>
<td>bg %work_id</td>
<td>恢复工作号为work_id后台暂停的进程到后台执行，注意工作号和PID不同</td>
</tr>
<tr>
<td>vmstat flu_time flu_num</td>
<td>查看系统资源，间隔为flu_time，次数为flu_num</td>
</tr>
<tr>
<td>free -b</td>
<td>以字节为单位查看内存使用状态</td>
</tr>
<tr>
<td>free -k</td>
<td>以KB为单位查看内存使用状态，默认以KB为单位</td>
</tr>
<tr>
<td>free -m</td>
<td>以MB为单位查看内存使用状态</td>
</tr>
<tr>
<td>free -g</td>
<td>以GB为单位查看内存使用状态</td>
</tr>
<tr>
<td>free -b</td>
<td>以字节为单位查看内存使用状态</td>
</tr>
<tr>
<td>cat /proc/cpuinfo</td>
<td>查看CPU的详细信息</td>
</tr>
<tr>
<td>uptime</td>
<td>显示系统的启动时间和平均负载</td>
</tr>
<tr>
<td>uptime -a</td>
<td>查看系统所有相关信息</td>
</tr>
<tr>
<td>uptime -r</td>
<td>查看内核版本</td>
</tr>
<tr>
<td>uptime -s</td>
<td>查看内核名称</td>
</tr>
<tr>
<td>file /bin/ls</td>
<td>查看操作系统的位数</td>
</tr>
<tr>
<td>lsb_release -a</td>
<td>查询Linux的发行版本</td>
</tr>
<tr>
<td>lsof -c string</td>
<td>列出以字符串开头的进程打开的文件</td>
</tr>
<tr>
<td>lsof -u username</td>
<td>列出某个用户的进程打开的文件</td>
</tr>
<tr>
<td>lsof -p pid</td>
<td>列出某个PID进程打开的文件</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux18.png" alt="18"></p>
<h2 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a><font size="4">定时任务</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>crontab -e</td>
<td>编辑定时任务</td>
</tr>
<tr>
<td>crontab -l</td>
<td>查询定时任务</td>
</tr>
<tr>
<td>crontab -r</td>
<td>删除所有定时任务</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="4" color="red">编辑定时任务格式</font><br>  <font size="3">* * * * * 执行的任务</font><br>  <font size="3">第一个*：一小时当中的第几分钟(0-59)</font><br>  <font size="3">第二个*：一天当中的第几小时(0-23)</font><br>  <font size="3">第三个*：一个月当中的第几天(1-31)</font><br>  <font size="3">第四个*：一年当中的第几月(1-12)</font><br>  <font size="3">第五个*：一周当中的星期几(0-7)</font></p>
<p>  <font size="4" color="red">编辑定时任务特殊符号</font><br>  <font size="3">*：代表任何时间</font><br>  <font size="3">,：代表不连续时间</font><br>  <font size="3">-：代表连续的时间范围</font><br>  <font size="3">*/n：代表每隔多久执行一次</font></p>
<p>  <font size="3">编辑定时任务例子</font><br>  <font size="3">45 22 * * * command：每天的22:45执行命令</font><br>  <font size="3">30 12 * * 1 command：每周一的12:30执行命令</font><br>  <font size="3">0 8,12,16 * * * command：每天的8:00，12:00和16:00都执行命令</font><br>  <font size="3">0 5 * * 1-6 command：每周一的5:00执行命令</font><br>  <font size="3">0/10 4 * * * command：每天的凌晨4点，每隔10分钟执行一次</font><br>  <font size="3">0 0 1,15 * 1 command：每周一的0:00和每个月的1号和15号都会执行命令，尽量不要这样写</font><br><img src="/images/SKILL/linux19.png" alt="19"></p>
<h2 id="备份与恢复"><a href="#备份与恢复" class="headerlink" title="备份与恢复"></a><font size="4">备份与恢复</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>dump -level</td>
<td>设定level备份级别，0为完全备份，1-9为增量备份，对分区可以增量备份，对于文件或目录只能完全备份</td>
</tr>
<tr>
<td>dump -f b_file o_file</td>
<td>将o_file备份到b_file中</td>
</tr>
<tr>
<td>dump -u</td>
<td>备份成功后，把备份时间记录在/etc/dumpdates文件</td>
</tr>
<tr>
<td>dump -v</td>
<td>显示备份过程中更多的输出信息</td>
</tr>
<tr>
<td>dump -j</td>
<td>调用bzlib库压缩备份文件，将备份文件压缩为.bz2格式</td>
</tr>
<tr>
<td>dump -W</td>
<td>显示允许被dump的分区的备份等级及备份时间</td>
</tr>
<tr>
<td>restore -C</td>
<td>比较备份数据和实际数据的变换</td>
</tr>
<tr>
<td>restore -i</td>
<td>进入交互模式，手工选择需要恢复的文件</td>
</tr>
<tr>
<td>restore -t</td>
<td>查看模式，用于查看备份文件中拥有哪些数据</td>
</tr>
<tr>
<td>restore -r</td>
<td>还原模式，用于数据还原</td>
</tr>
<tr>
<td>restore -f</td>
<td>指定备份文件的文件名</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Shell基础"><a href="#Shell基础" class="headerlink" title="Shell基础"></a><font size="4">Shell基础</font></h2><p>  <font size="3">Shell是一个命令行解释器，为用户提供一个向Linux内核发送请求以便运行程序的系统级程序，用户可以用Shell启动，挂起，停止甚至编写程序</font></p>
<p>  <font size="3">Shell是一个功能强大的解释性脚本语言，易编写，易调试，灵活性强，且在Shell中可以直接调用Linux系统命令。</font></p>
<p>  <font size="3">Bash是Linux的基本Shell，执行时使用/文件名或者bash 文件名</font></p>
<h3 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a><font size="3">定义变量</font></h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>var_name=’xxx’</td>
<td>定义变量，等于号前后不要加空格</td>
</tr>
<tr>
<td>$var_name</td>
<td>调用变量</td>
</tr>
<tr>
<td>unset var_name</td>
<td>删除变量</td>
</tr>
<tr>
<td>set</td>
<td>查看所有变量</td>
</tr>
<tr>
<td>echo</td>
<td>输出</td>
</tr>
<tr>
<td>read -t n var_name</td>
<td>给var_name读入一个值，等待n秒</td>
</tr>
<tr>
<td>read -p str var_name</td>
<td>显示str字符串，再给var_name读入一个值</td>
</tr>
</tbody>
</table>
</div>
<h3 id="位置参数变量"><a href="#位置参数变量" class="headerlink" title="位置参数变量"></a><font size="3">位置参数变量</font></h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>$n</td>
<td>0代表命令本身，1-9代表第一到第九个参数，10以上要用{}括起来</td>
</tr>
<tr>
<td>$*</td>
<td>所有参数，看作一个整体</td>
</tr>
<tr>
<td>$@</td>
<td>所有参数，每个参数分开对待</td>
</tr>
<tr>
<td>$#</td>
<td>所有参数的个数</td>
</tr>
</tbody>
</table>
</div>
<h3 id="预定义变量"><a href="#预定义变量" class="headerlink" title="预定义变量"></a><font size="3">预定义变量</font></h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>$?</td>
<td>判断最后一次执行命令的返回状态，为0则正确，否则错误</td>
</tr>
<tr>
<td>$$</td>
<td>当前进程的进程号(PID)</td>
</tr>
<tr>
<td>$!</td>
<td>后台运行的最后一个进程的进程号</td>
</tr>
</tbody>
</table>
</div>
<h3 id="声明变量类型"><a href="#声明变量类型" class="headerlink" title="声明变量类型"></a><font size="3">声明变量类型</font></h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>declare - var_name</td>
<td>给变量设定类型属性</td>
</tr>
<tr>
<td>declare + var_name</td>
<td>取消变量的类型属性</td>
</tr>
<tr>
<td>declare -i var_name</td>
<td>将变量声明为整型</td>
</tr>
<tr>
<td>declare -x var_name</td>
<td>将变量声明为环境变量</td>
</tr>
<tr>
<td>declare -p var_name</td>
<td>显示变量的类型</td>
</tr>
</tbody>
</table>
</div>
<p>  <font size="3">Linux中的变量都默认为字符串型，数值运算时要采用var_name=$((运算式))的格式。</font><br><img src="/images/SKILL/linux10.png" alt="10"></p>
<h3 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a><font size="3">条件判断</font></h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>[ -d filename ]</td>
<td>注意中括号前后都有空格，判断文件是否存在，并且是否为目录文件，是目录文件为真</td>
</tr>
<tr>
<td>[ -e filename ]</td>
<td>判断文件是否存在，存在为真</td>
</tr>
<tr>
<td>[ -f filename ]</td>
<td>判断文件是否存在，并且是否为普通文件，是普通文件为真</td>
</tr>
<tr>
<td>[ -r filename ]</td>
<td>判断文件是否存在，并且是否具有读权限(无论是拥有者还是所属组还是其他用户，只要有就为真)</td>
</tr>
<tr>
<td>[ -w filename ]</td>
<td>判断文件是否存在，并且是否具有写权限</td>
</tr>
<tr>
<td>[ -x filename ]</td>
<td>判断文件是否存在，并且是否具有执行权限</td>
</tr>
<tr>
<td>[ filename1 -nt filename2 ]</td>
<td>判断文件1是否比文件2新(修改时间)</td>
</tr>
<tr>
<td>[ filename1 -ot filename2 ]</td>
<td>判断文件1是否比文件2旧</td>
</tr>
<tr>
<td>[ filename1 -ef filename2 ]</td>
<td>判断文件1和文件2的i节点是否一致，可以判断硬链接</td>
</tr>
<tr>
<td>[ int1 -eq int2 ]</td>
<td>判断整数1是否等于整数2</td>
</tr>
<tr>
<td>[ int1 -ne int2 ]</td>
<td>判断整数1是否不等于整数2</td>
</tr>
<tr>
<td>[ int1 -gt int2 ]</td>
<td>判断整数1是否大于整数2</td>
</tr>
<tr>
<td>[ int1 -lt int2 ]</td>
<td>判断整数1是否小于整数2</td>
</tr>
<tr>
<td>[ int1 -ge int2 ]</td>
<td>判断整数1是否大于等于整数2</td>
</tr>
<tr>
<td>[ int1 -le int2 ]</td>
<td>判断整数1是否小于等于整数2</td>
</tr>
<tr>
<td>[ -z str ]</td>
<td>判断字符串是否为空</td>
</tr>
<tr>
<td>[ -n str ]</td>
<td>判断字符串是否非空</td>
</tr>
<tr>
<td>[ str1==str2 ]</td>
<td>判断字符串1是否等于字符串2</td>
</tr>
<tr>
<td>[ str1!=str2 ]</td>
<td>判断字符串1是否不等于字符串2</td>
</tr>
<tr>
<td>[ judge1 -a judge2 ]</td>
<td>逻辑与，判断1和判断2都为真则为真</td>
</tr>
<tr>
<td>[ judge1 -o judge2 ]</td>
<td>逻辑或，判断1和判断2都为假则为假</td>
</tr>
<tr>
<td>[ !judge ]</td>
<td>逻辑非，判断取反</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/images/SKILL/linux12.png" alt="12"></p>
<h3 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a><font size="3">流程控制</font></h3><p>  <font size="3">Linux中Shell脚本的第一句为#!bin/bash，说明下面的内容都是Shell脚本。</font></p>
<p>  <font size="3">执行脚本时，先将文件的权限变为可执行文件，然后./filename或者直接使用bash filename</font></p>
<h3 id="if条件流程控制"><a href="#if条件流程控制" class="headerlink" title="if条件流程控制"></a><font size="3">if条件流程控制</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 单分支if条件语句格式</span><br><span class="line"># if [ condition ]</span><br><span class="line">#     then</span><br><span class="line">#         程序</span><br><span class="line"># fi</span><br><span class="line"># 如果condition成立则执行程序，否则不执行</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 双分支if条件语句格式</span><br><span class="line"># if [ condition ]</span><br><span class="line">#     then</span><br><span class="line">#         程序1</span><br><span class="line">#     else</span><br><span class="line">#         程序2</span><br><span class="line"># fi</span><br><span class="line"># 如果condition成立则执行程序1，否则执行程序2</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/linux13.png" alt="13"></p>
<h3 id="case条件流程控制"><a href="#case条件流程控制" class="headerlink" title="case条件流程控制"></a><font size="3">case条件流程控制</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 多分支case条件语句</span><br><span class="line"># case $变量名 in</span><br><span class="line">#     "value1")</span><br><span class="line">#         程序1</span><br><span class="line">#         ;;</span><br><span class="line">#     "value2")</span><br><span class="line">#         程序2</span><br><span class="line">#         ;;</span><br><span class="line">#     *)</span><br><span class="line">#         程序n</span><br><span class="line">#         ;;</span><br><span class="line"># esac</span><br><span class="line"># 如果变量的值为value1执行程序1，变量值为value2执行程序2，...，如果都不等于则执行程序n</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/linux15.png" alt="15"></p>
<h3 id="for循环流程控制"><a href="#for循环流程控制" class="headerlink" title="for循环流程控制"></a><font size="3">for循环流程控制</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># for 变量 in value1 value2 ...</span><br><span class="line">#     do</span><br><span class="line">#         程序</span><br><span class="line">#     done</span><br><span class="line"># 和Python语言的for循环类似，将value1，value2，...，依次带入程序，不同value之间用空格分开</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># for ((初始值;循环控制条件;变量变换))</span><br><span class="line">#     do</span><br><span class="line">#         程序</span><br><span class="line">#     done</span><br><span class="line"># 和C语言的for循环类似，将变量带入程序，每次循环结束时更改变量的值，并且判断循环条件是否满足</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/linux14.png" alt="14"></p>
<h3 id="while循环流程控制"><a href="#while循环流程控制" class="headerlink" title="while循环流程控制"></a><font size="3">while循环流程控制</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># while [ condition ]</span><br><span class="line">#     do</span><br><span class="line">#         程序</span><br><span class="line">#     done</span><br><span class="line"># 如果满足条件则进入循环，每次循环结束要重新判断是否满足条件</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/linux16.png" alt="16"></p>
<h3 id="until循环流程控制"><a href="#until循环流程控制" class="headerlink" title="until循环流程控制"></a><font size="3">until循环流程控制</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># until [ condition ]</span><br><span class="line">#     do</span><br><span class="line">#         程序</span><br><span class="line">#     done</span><br><span class="line"># 如果不满足条件则进入循环，每次循环结束要重新判断是否满足条件</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/linux17.png" alt="17"></p>
<h1 id="Linux小结"><a href="#Linux小结" class="headerlink" title="Linux小结"></a><font size="5" color="red">Linux小结</font></h1><p>  因为Linux的安全性和开源特性，使得Linux受到广泛的青睐，尤其是在公司层面。在个人机上，多数人为了使用方便，采用Windows系统。但是为了公司服务器运维稳定，可靠，方便，Linux是使用最广泛的操作系统。因此学会Linux是程序员的必修课之一。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Vim(文本编辑器)</title>
    <url>/2019/09/22/skill%20Vim/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Vim</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>  <strong>Vim</strong>是一个类似于Vi的著名的功能强大、高度可定制的<strong>文本编辑器</strong>。代码补全、编译及错误跳转等方便编程的<strong>功能特别丰富</strong>，在程序员中被广泛使用，是<strong>类Unix</strong>系统用户最喜欢的文本编辑器。<br><a id="more"></a></p>
<h1 id="Vim特点"><a href="#Vim特点" class="headerlink" title="Vim特点"></a><font size="5" color="red">Vim特点</font></h1><p>  <font size="3">解放程序员的双手，这一点非常重要，使得程序员在编辑文档时可以不再依赖于鼠标</font><br>  <font size="3">Vim具有高效率的移动，在行内，文件内可以随意的移动，可以节约大量时间。</font><br>  <font size="3">Vim具有高效率的输入，可以有很多的插入方式，复制，粘贴，剪切都非常方便。</font></p>
<h1 id="Vim关系图"><a href="#Vim关系图" class="headerlink" title="Vim关系图"></a><font size="5" color="red">Vim关系图</font></h1><p><img src="/images/SKILL/Vim2.png" alt="2"></p>
<h1 id="Vim应用"><a href="#Vim应用" class="headerlink" title="Vim应用"></a><font size="5" color="red">Vim应用</font></h1><p><img src="/images/SKILL/Vim1.png" alt="1"></p>
<h2 id="进入Vim"><a href="#进入Vim" class="headerlink" title="进入Vim"></a><font size="4">进入Vim</font></h2><p>  <font size="3">在终端中输入vim filename 进入Vim，如果存在该文件则编辑该文件，如果不存在该文件则创建一个新文件并编辑该文件</font></p>
<h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a><font size="4">插入</font></h2><p>  <font size="3">一般是由命令模式进入插入模式</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td>在光标所在字符后插入</td>
</tr>
<tr>
<td>A</td>
<td>在光标所在行尾插入</td>
</tr>
<tr>
<td>i</td>
<td>在光标所在字符前插入</td>
</tr>
<tr>
<td>I</td>
<td>在光标所在行首插入</td>
</tr>
<tr>
<td>o</td>
<td>在光标下插入新行</td>
</tr>
<tr>
<td>O</td>
<td>在光标上插入新行</td>
</tr>
</tbody>
</table>
</div>
<h2 id="光标移动"><a href="#光标移动" class="headerlink" title="光标移动"></a><font size="4">光标移动</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>k</td>
<td>光标向上移动一行</td>
</tr>
<tr>
<td>nk</td>
<td>光标向上移动n行</td>
</tr>
<tr>
<td>j</td>
<td>光标向下移动一行</td>
</tr>
<tr>
<td>nj</td>
<td>光标向下移动n行</td>
</tr>
<tr>
<td>h</td>
<td>光标向左移动一行</td>
</tr>
<tr>
<td>nh</td>
<td>光标向左移动n行</td>
</tr>
<tr>
<td>l</td>
<td>光标向右移动一行</td>
</tr>
<tr>
<td>nl</td>
<td>光标向右移动n行</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>b</td>
<td>光标移动到前一个单词的首字母上</td>
</tr>
<tr>
<td>nb</td>
<td>光标移动到前n个单词的首字母上</td>
</tr>
<tr>
<td>w</td>
<td>光标移动到后一个单词的首字母上</td>
</tr>
<tr>
<td>nw</td>
<td>光标移动到后n个单词的首字母上</td>
</tr>
<tr>
<td>ge</td>
<td>光标移动到前一个单词的尾字母上</td>
</tr>
<tr>
<td>nge</td>
<td>光标移动到前n个单词的尾字母上</td>
</tr>
<tr>
<td>e</td>
<td>光标移动到后一个单词的尾字母上</td>
</tr>
<tr>
<td>ne</td>
<td>光标移动到后n个单词的尾字母上</td>
</tr>
<tr>
<td>n<space></space></td>
<td>光标移动到后n个字符上</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>gg</td>
<td>光标移动到第一行首</td>
</tr>
<tr>
<td>G</td>
<td>光标移动到最后一行首</td>
</tr>
<tr>
<td>ngg或nG或:n</td>
<td>光标移动到第n行首</td>
</tr>
<tr>
<td>-</td>
<td>光标移动到上一行行首</td>
</tr>
<tr>
<td>n-</td>
<td>光标移动到上n行行首</td>
</tr>
<tr>
<td>+</td>
<td>光标移动到下一行行首</td>
</tr>
<tr>
<td>n+</td>
<td>光标移动到下n行行首</td>
</tr>
<tr>
<td>0</td>
<td>光标移动到该行行首</td>
</tr>
<tr>
<td>$</td>
<td>光标移动到该行行尾</td>
</tr>
<tr>
<td>n$</td>
<td>光标移动到下n行行尾</td>
</tr>
<tr>
<td>^</td>
<td>光标移动到该行首字母</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Home</td>
<td>光标移动到该行行首(可以在插入模式下使用)</td>
</tr>
<tr>
<td>End</td>
<td>光标移动到该行行尾(可以在插入模式下使用)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="删除-剪切-字符"><a href="#删除-剪切-字符" class="headerlink" title="删除(剪切)字符"></a><font size="4">删除(剪切)字符</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>删除光标所在字符</td>
</tr>
<tr>
<td>nx</td>
<td>删除光标处及后n-1个字符</td>
</tr>
<tr>
<td>X</td>
<td>删除光标前一个字符</td>
</tr>
<tr>
<td>nX</td>
<td>删除光标前n个字符</td>
</tr>
<tr>
<td>dd</td>
<td>删除光标所在行</td>
</tr>
<tr>
<td>ndd</td>
<td>删除光标所在行及后n-1行</td>
</tr>
<tr>
<td>dw</td>
<td>删除光标所在处的单词</td>
</tr>
<tr>
<td>dnw</td>
<td>删除光标所在处及后n-1个单词</td>
</tr>
<tr>
<td>dG</td>
<td>删除光标所在行到文件末尾的所有行</td>
</tr>
<tr>
<td>dgg</td>
<td>删除光标所在行到文件开始的所有行</td>
</tr>
<tr>
<td>d/word</td>
<td>删除从光标所在处到单词word的所有文本</td>
</tr>
<tr>
<td>D</td>
<td>删除光标所在处到该行尾的所有内容</td>
</tr>
<tr>
<td>:nd</td>
<td>删除第n行</td>
</tr>
<tr>
<td>:n1,n2d</td>
<td>删除n1行到n2行</td>
</tr>
</tbody>
</table>
</div>
<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a><font size="4">复制</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>yy</td>
<td>复制光标所在行</td>
</tr>
<tr>
<td>nyy</td>
<td>复制光标所在行及后n-1行</td>
</tr>
<tr>
<td>yw</td>
<td>复制光标所在处的单词</td>
</tr>
<tr>
<td>ynw</td>
<td>复制光标所在处及后n-1个单词</td>
</tr>
<tr>
<td>yG</td>
<td>复制光标所在行到文件末尾的所有行</td>
</tr>
<tr>
<td>ygg</td>
<td>复制光标所在行到文件开始的所有行</td>
</tr>
<tr>
<td>y/word</td>
<td>复制从光标所在处到单词word的所有文本</td>
</tr>
<tr>
<td>Y</td>
<td>复制光标所在处到该行尾的所有内容</td>
</tr>
<tr>
<td>:ny</td>
<td>复制第n行</td>
</tr>
<tr>
<td>:n1,n2y</td>
<td>复制n1行到n2行</td>
</tr>
</tbody>
</table>
</div>
<h2 id="粘贴"><a href="#粘贴" class="headerlink" title="粘贴"></a><font size="4">粘贴</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>p</td>
<td>粘贴在当前光标下</td>
</tr>
<tr>
<td>P</td>
<td>粘贴在当前光标上</td>
</tr>
</tbody>
</table>
</div>
<h2 id="可视"><a href="#可视" class="headerlink" title="可视"></a><font size="4">可视</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>v</td>
<td>进入可视(选择)模式</td>
</tr>
<tr>
<td>d</td>
<td>删除光标内容</td>
</tr>
<tr>
<td>y</td>
<td>复制光标内容</td>
</tr>
</tbody>
</table>
</div>
<h2 id="可视-1"><a href="#可视-1" class="headerlink" title="可视"></a><font size="4">可视</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>v</td>
<td>进入可视(选择)模式</td>
</tr>
<tr>
<td>y</td>
<td>复制光标内容</td>
</tr>
<tr>
<td>d</td>
<td>剪切光标内容</td>
</tr>
</tbody>
</table>
</div>
<h2 id="撤回和恢复"><a href="#撤回和恢复" class="headerlink" title="撤回和恢复"></a><font size="4">撤回和恢复</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>u</td>
<td>复原前一次操作</td>
</tr>
<tr>
<td>Ctrl + r</td>
<td>重做上个动作</td>
</tr>
</tbody>
</table>
</div>
<h2 id="翻页操作"><a href="#翻页操作" class="headerlink" title="翻页操作"></a><font size="4">翻页操作</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ctrl + f</td>
<td>屏幕向下移动一页</td>
</tr>
<tr>
<td>Ctrl + b</td>
<td>屏幕向上移动一页</td>
</tr>
<tr>
<td>Ctrl + d</td>
<td>屏幕向下移动半页</td>
</tr>
<tr>
<td>Ctrl + u</td>
<td>屏幕向下移动半页</td>
</tr>
</tbody>
</table>
</div>
<h2 id="设置行号"><a href="#设置行号" class="headerlink" title="设置行号"></a><font size="4">设置行号</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>:set nu</td>
<td>显示所有的行号</td>
</tr>
<tr>
<td>:set nonu</td>
<td>取消显示行号</td>
</tr>
</tbody>
</table>
</div>
<h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a><font size="4">搜索</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>/word</td>
<td>向光标之下寻找/word的字符串</td>
</tr>
<tr>
<td>?word</td>
<td>向光标之上寻找/word的字符串</td>
</tr>
<tr>
<td>n</td>
<td>继续向下查找下一个匹配的字符串</td>
</tr>
<tr>
<td>N</td>
<td>继续向上查找下一个匹配的字符串</td>
</tr>
<tr>
<td>:noh</td>
<td>取消高亮显示</td>
</tr>
<tr>
<td>:set ic</td>
<td>查找忽略大小写</td>
</tr>
<tr>
<td>:set noic</td>
<td>查找不忽略大小写</td>
</tr>
</tbody>
</table>
</div>
<h2 id="替换"><a href="#替换" class="headerlink" title="替换"></a><font size="4">替换</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>r</td>
<td>取代光标处的字符串</td>
</tr>
<tr>
<td>R</td>
<td>从光标处开始替换字符，Esc结束替换</td>
</tr>
<tr>
<td>:n1,n2s/word1/word2/g</td>
<td>在n1到n2行之间将word1换成word2</td>
</tr>
<tr>
<td>:%s/word1/word2/g</td>
<td>将文档中所有的word1换成word2</td>
</tr>
<tr>
<td>:%s/word1/word2/g</td>
<td>将文档中所有的word1换成word2，取代前询问</td>
</tr>
</tbody>
</table>
</div>
<h2 id="替换-1"><a href="#替换-1" class="headerlink" title="替换"></a><font size="4">替换</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>r</td>
<td>取代光标处的字符串</td>
</tr>
<tr>
<td>R</td>
<td>从光标处开始替换字符，Esc结束替换</td>
</tr>
<tr>
<td>:n1,n2s/word1/word2/g</td>
<td>在n1到n2行之间将word1换成word2</td>
</tr>
<tr>
<td>:%s/word1/word2/g</td>
<td>将文档中所有的word1换成word2</td>
</tr>
<tr>
<td>:%s/word1/word2/g</td>
<td>将文档中所有的word1换成word2，取代前询问</td>
</tr>
<tr>
<td>:ab word1 word2</td>
<td>文档中以后出现的word1字符自动转换为word2</td>
</tr>
</tbody>
</table>
</div>
<h2 id="定义快捷键"><a href="#定义快捷键" class="headerlink" title="定义快捷键"></a><font size="4">定义快捷键</font></h2><p>  <font size="3">在命令模式下</font><br>  <font size="3">:map ctrl+v+字符 命令 可以用来定义快捷键</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>:map ctrl+v+p I#<esc></esc></td>
<td>按ctrl+v+p则会在行首加#注释</td>
</tr>
<tr>
<td>:map ctrl+v+H iHello World !<esc></esc></td>
<td>按ctrl+v+H会插入Hello World !</td>
</tr>
</tbody>
</table>
</div>
<h2 id="连续行注释"><a href="#连续行注释" class="headerlink" title="连续行注释"></a><font size="4">连续行注释</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>:n1,n2s/^/xxx/g</td>
<td>在n1到n2行的行首加xxx</td>
</tr>
<tr>
<td>:n1,n2s/^xxx//g</td>
<td>将n1到n2行行首的xxx删去</td>
</tr>
<tr>
<td>:n1,n2s/^/\/\//g</td>
<td>在n1到n2行的行首加//，\/代表/</td>
</tr>
</tbody>
</table>
</div>
<h2 id="保存和退出"><a href="#保存和退出" class="headerlink" title="保存和退出"></a><font size="4">保存和退出</font></h2><p>  <font size="3">在命令模式下</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>:w</td>
<td>保存修改</td>
</tr>
<tr>
<td>:w filename</td>
<td>另存为filename文件</td>
</tr>
<tr>
<td>:Wq或:wq!或ZZ</td>
<td>保存修改并退出</td>
</tr>
<tr>
<td>:q!</td>
<td>不保存修改并退出</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Vim小结"><a href="#Vim小结" class="headerlink" title="Vim小结"></a><font size="5" color="red">Vim小结</font></h1><p>  Vim作为一款古老的文本编辑器，但是它具有许多有用的功能，使其可以与现代文本编辑器竞争，也是作为Linux系统自带的文本编辑器Vi的升级版，可以完全解放双手，对于程序员来说，Vim是必不可少的技能之一。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Vim</category>
      </categories>
  </entry>
  <entry>
    <title>Markdown</title>
    <url>/2019/09/21/skill%20Markdown/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Markdown</font></strong></center><p></p>
<h1 id="Markdown介绍"><a href="#Markdown介绍" class="headerlink" title="Markdown介绍"></a><font size="5" color="red">Markdown介绍</font></h1><p>  <strong>Markdown</strong>:是一种可以使用<strong>普通文本编辑器</strong>编写的<strong>标记语言</strong>，通过简单的<strong>标记语法</strong>，它可以使普通文本内容<strong>具有一定的格式</strong>。<br><a id="more"></a></p>
<h1 id="Markdown语法"><a href="#Markdown语法" class="headerlink" title="Markdown语法"></a><font size="5" color="red">Markdown语法</font></h1><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a><font size="4">标题</font></h2><p>  <font size="3">用#表示标题，几级标题对应几个#，最多6个，注意#和标题直接有空格</font><br>  <font size="3"># 一级标题</font><br>  <font size="3">## 二级标题</font><br>  <font size="3">### 三级标题</font><br>  <font size="3">#### 四级标题</font><br>  <font size="3">##### 五级标题</font><br>  <font size="3">###### 六级标题</font><br><img src="/images/SKILL/markdown1.png" alt="1"></p>
<h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a><font size="4">字体</font></h2><div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>效果</th>
</tr>
</thead>
<tbody>
<tr>
<td>*斜体文本*</td>
<td><em>斜体文本</em></td>
</tr>
<tr>
<td>_斜体文本_</td>
<td><em>斜体文本</em></td>
</tr>
<tr>
<td>**粗体文本**</td>
<td><strong>粗体文本</strong></td>
</tr>
<tr>
<td>__粗体文本__</td>
<td><strong>粗体文本</strong></td>
</tr>
<tr>
<td>***粗斜体文本***</td>
<td><strong><em>粗斜体文本</em></strong></td>
</tr>
<tr>
<td>___粗斜体文本___</td>
<td><strong><em>粗斜体文本</em></strong></td>
</tr>
</tbody>
</table>
</div>
<h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a><font size="4">分割线</font></h2><p>  <font size="3">***</font></p>
<hr>
<p>  <font size="3">星号中间可以有空格也可以没有空格</font></p>
<p>  <font size="3">- - -</font></p>
<hr>
<p>  <font size="3">减号中间必须有空格</font></p>
<h2 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a><font size="4">删除线</font></h2><p>  <font size="3">&lt;u&gt;这是一条删除线&lt;\u&gt;</font><br>  <u>这是一条删除线</u></p>
<h2 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a><font size="4">脚注</font></h2><p>  <font size="3">用中括号创建[脚注]。</font><br>  <font size="3">[脚注]: 脚注中的内容</font></p>
<p>  用中括号创建<a href="脚注中的内容">脚注</a>。</p>
<h2 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a><font size="4">无序列表</font></h2><p>  <font size="3">无序列表使用*或+或-作为列表标记</font><br>  <font size="3">符号和内容之间要用空格分开</font></p>
<p>  - 第一项<br>  * 第二项<br>  + 第三项 </p>
<ul>
<li>第一项</li>
</ul>
<ul>
<li>第二项</li>
</ul>
<ul>
<li>第三项 </li>
</ul>
<h2 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a><font size="4">有序列表</font></h2><p>  <font size="3">无序列表使用数字加上.作为列表标记</font><br>  <font size="3">符号和内容之间要用空格分开</font></p>
<ol>
<li>第一项</li>
<li>第二项</li>
<li>第三项 </li>
</ol>
<h2 id="列表嵌套"><a href="#列表嵌套" class="headerlink" title="列表嵌套"></a><font size="4">列表嵌套</font></h2><p>  <font size="3">列表嵌套只要在子列表中添加四个空格即为下一层列表</font></p>
<p>  1. 第一层：<br>      - 第一层的第一个内容<br>      - 第一层的第二个内容<br>  2. 第二层：<br>      - 第二层的第一个内容<br>      - 第二层的第二个内容</p>
<ol>
<li>第一层：<ul>
<li>第一层的第一个内容</li>
<li>第一层的第二个内容</li>
</ul>
</li>
<li>第二层：<ul>
<li>第二层的第一个内容</li>
<li>第二层的第二个内容</li>
</ul>
</li>
</ol>
<h2 id="区块"><a href="#区块" class="headerlink" title="区块"></a><font size="4">区块</font></h2><p>  <font size="3">区块使用大于号&gt;作为标记</font><br>  <font size="3">符号和内容之间要用空格分开</font></p>
<p>  &gt; 这是一个区块<br>  &gt; &gt; 这是一个子区块</p>
<blockquote>
<p>这是一个区块</p>
<blockquote>
<p>这是一个子区块</p>
</blockquote>
</blockquote>
<h2 id="代码引用"><a href="#代码引用" class="headerlink" title="代码引用"></a><font size="4">代码引用</font></h2><p>  <font size="3">代码引用使用反引号`作为标记</font><br>  <font size="3">还可以使用反引号```大段代码```</font></p>
<p>  `print(‘Hello Markdown’)`<br>  <code>print('Hello Markdown')</code></p>
<p>  ```<br>  def my_print():<br>      print(‘Hello’)<br>      print(‘Markdown’)<br>  ```<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def my_print():</span><br><span class="line">    print('Hello')</span><br><span class="line">    print('Markdown')</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a><font size="4">链接</font></h2><p>  <font size="3">引用链接的格式为：[链接名称](链接地址)</font></p>
<p>  这是一个搜索引擎[百度](www.baidu.com)</p>
<p>  这是一个搜索引擎<a href="www.baidu.com">百度</a></p>
<h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a><font size="4">图片</font></h2><p>  <font size="3">放置图片的格式为：![图片文字](图片地址)</font></p>
<p>  ![本地图片](/images/SKILL/markdown1.jpg)<br><img src="/images/SKILL/markdown.jpg" alt="本地图片"></p>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a><font size="4">表格</font></h2><p>  <font size="3">表格的格式为：</font><br>  <font size="3">| 表头1 | 表头2 |</font><br>  <font size="3">| --- | --- |</font><br>  <font size="3">| 单元格1 | 单元格2 |</font><br>  <font size="3">| 单元格3 | 单元格4 |</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>表头1</th>
<th>表头2</th>
</tr>
</thead>
<tbody>
<tr>
<td>单元格1</td>
<td>单元格2</td>
</tr>
<tr>
<td>单元格3</td>
<td>单元格4</td>
</tr>
</tbody>
</table>
</div>
<h2 id="HTML元素"><a href="#HTML元素" class="headerlink" title="HTML元素"></a><font size="4">HTML元素</font></h2><p>  <font size="3">Markdown支持很多HTML元素，不逐一介绍，感兴趣可以查阅HTML元素</font></p>
<p>  5&lt;sup&gt;2&lt;/sup&gt; + x&lt;sub&gt;n&lt;/sub&gt;</p>
<p>  5<sup>2</sup> + x<sub>n</sub></p>
<h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a><font size="4">公式</font></h2><p>  <font size="3">Markdown使用TeX或LaTeX格式的数学公式来实现，会根据需要加载 Mathjax 对数学公式进行渲染。</font></p>
<p>  <font size="3">Markdown在公式两端加上$输入文中公式</font></p>
<p>  平方和公式：$(a + b)^2 = a^2 + 2ab + b^2$</p>
<p>  <font size="3">Markdown在公式两端加上$$另起一行输入公式</font></p>
<p>  平方差公式：</p>
<script type="math/tex; mode=display">(a - b)^2 = a^2 - 2ab + b^2</script><h2 id="转义字符"><a href="#转义字符" class="headerlink" title="转义字符"></a><font size="4">转义字符</font></h2><p>  <font size="3">绝大多数字符都可以用\转义，但是下表字符要用指定的编号转义</font></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>符号</th>
<th>效果</th>
</tr>
</thead>
<tbody>
<tr>
<td>空格</td>
<td>&amp;nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>小于号</td>
<td>&amp;lt;</td>
<td>&lt;</td>
</tr>
<tr>
<td>大于号</td>
<td>&amp;gt;</td>
<td>&gt;</td>
</tr>
<tr>
<td>与符号</td>
<td>&amp;amp;</td>
<td>&amp;</td>
</tr>
<tr>
<td>单引号</td>
<td>&amp;apos;</td>
<td>'</td>
</tr>
<tr>
<td>双引号</td>
<td>&amp;quot;</td>
<td>"</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Markdown小结"><a href="#Markdown小结" class="headerlink" title="Markdown小结"></a><font size="5" color="red">Markdown小结</font></h1><p>  Markdown的语法简洁明了，学习容易，而且功能强大，因此很多人用它写博客，我的所有博客都是采用Markdown来写的，也是为了查询的方便，故写下了这篇文字。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Markdown</category>
      </categories>
  </entry>
  <entry>
    <title>LaTeX</title>
    <url>/2019/09/20/skill%20Latex/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">LaTeX</font></strong></center><p></p>
<h1 id="LaTeX介绍"><a href="#LaTeX介绍" class="headerlink" title="LaTeX介绍"></a><font size="5" color="red">LaTeX介绍</font></h1><p>  <strong>LaTeX</strong>:是一种基于<strong>TEX的排版系统</strong>，由美国计算机学家莱斯利·兰伯特(Leslie Lamport)在20世纪80年代初期开发，利用这种格式，对于<strong>生成复杂表格和数学公式</strong>，表现得尤为突出。<br><a id="more"></a></p>
<h1 id="LaTeX数学公式"><a href="#LaTeX数学公式" class="headerlink" title="LaTeX数学公式"></a><font size="5" color="red">LaTeX数学公式</font></h1><h2 id="格式说明"><a href="#格式说明" class="headerlink" title="格式说明"></a><font size="4">格式说明</font></h2><p><img src="/images/SKILL/latex1.png" alt="LaTeX"></p>
<h2 id="常见希腊字母"><a href="#常见希腊字母" class="headerlink" title="常见希腊字母"></a><font size="4">常见希腊字母</font></h2><p><img src="/images/SKILL/latex2.png" alt="LaTeX"></p>
<h2 id="顶部符号"><a href="#顶部符号" class="headerlink" title="顶部符号"></a><font size="4">顶部符号</font></h2><p><img src="/images/SKILL/latex3.png" alt="LaTeX"></p>
<h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a><font size="4">常用函数</font></h2><p><img src="/images/SKILL/latex4.png" alt="LaTeX"></p>
<h2 id="算术运算"><a href="#算术运算" class="headerlink" title="算术运算"></a><font size="4">算术运算</font></h2><p><img src="/images/SKILL/latex5.png" alt="LaTeX"></p>
<h2 id="微分运算"><a href="#微分运算" class="headerlink" title="微分运算"></a><font size="4">微分运算</font></h2><p><img src="/images/SKILL/latex6.png" alt="LaTeX"></p>
<h2 id="关系运算"><a href="#关系运算" class="headerlink" title="关系运算"></a><font size="4">关系运算</font></h2><p><img src="/images/SKILL/latex7.png" alt="LaTeX"></p>
<h2 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a><font size="4">逻辑运算</font></h2><p><img src="/images/SKILL/latex8.png" alt="LaTeX"></p>
<h2 id="集合运算"><a href="#集合运算" class="headerlink" title="集合运算"></a><font size="4">集合运算</font></h2><p><img src="/images/SKILL/latex9.png" alt="LaTeX"></p>
<h2 id="特殊符号"><a href="#特殊符号" class="headerlink" title="特殊符号"></a><font size="4">特殊符号</font></h2><p><img src="/images/SKILL/latex10.png" alt="LaTeX"></p>
<h2 id="空格"><a href="#空格" class="headerlink" title="空格"></a><font size="4">空格</font></h2><p><img src="/images/SKILL/latex11.png" alt="LaTeX"></p>
<h2 id="字体颜色"><a href="#字体颜色" class="headerlink" title="字体颜色"></a><font size="4">字体颜色</font></h2><p><img src="/images/SKILL/latex12.png" alt="LaTeX"></p>
<h2 id="常用数学符号"><a href="#常用数学符号" class="headerlink" title="常用数学符号"></a><font size="4">常用数学符号</font></h2><p><img src="/images/SKILL/latex13.png" alt="LaTeX"></p>
<p><img src="/images/SKILL/latex14.png" alt="LaTeX"></p>
<h2 id="多行符号"><a href="#多行符号" class="headerlink" title="多行符号"></a><font size="4">多行符号</font></h2><p><img src="/images/SKILL/latex15.png" alt="LaTeX"></p>
<h1 id="LaTeX小结"><a href="#LaTeX小结" class="headerlink" title="LaTeX小结"></a><font size="5" color="red">LaTeX小结</font></h1><p>  LaTeX作为当下流行的排版系统，许多文档都是以LaTeX排版的，对于公式较多的学术文档，LaTeX是必不可少的。此网页上的所有公式都是使用LaTeX编辑的，也是为了查询的方便，故写下了这篇文字。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>LaTeX</category>
      </categories>
  </entry>
  <entry>
    <title>Object-Oriented(面向对象)</title>
    <url>/2019/09/18/python_class/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python14.jpg" alt="14"></p>
<h1 id="Object-Oriented介绍"><a href="#Object-Oriented介绍" class="headerlink" title="Object-Oriented介绍"></a><font size="5" color="red">Object-Oriented介绍</font></h1><p>  面向对象是一种非常重要的编程思想，把数据和操作放在一起，作为一个整体，称为对象。Python的面向对象和C++类似，也具有面向对象的三大特点，封装，继承和多态。<br><a id="more"></a></p>
<h1 id="面向过程与面向对象"><a href="#面向过程与面向对象" class="headerlink" title="面向过程与面向对象"></a><font size="5" color="red">面向过程与面向对象</font></h1><h2 id="面向过程的编程思想"><a href="#面向过程的编程思想" class="headerlink" title="面向过程的编程思想"></a><font size="4">面向过程的编程思想</font></h2><p>  <font size="3">自上而下顺序执行，逐步求精。</font><br>  <font size="3">程序结构按照功能分为若干模块，各部分相对独立。</font><br>  <font size="3">每一模块内部均是由顺序，选择，循环三种基本结构。</font><br>  <font size="3">程序流程在写程序时就已经确定。</font></p>
<h2 id="面向对象的编程思想"><a href="#面向对象的编程思想" class="headerlink" title="面向对象的编程思想"></a><font size="4">面向对象的编程思想</font></h2><p>  <font size="3">把数据和操作放在一起，作为一个整体，称为对象。</font><br>  <font size="3">对同类对象抽象出其共性，形成类。</font><br>  <font size="3">类通过一个外部接口与外界操作。</font><br>  <font size="3">程序流程在用户使用时决定。</font></p>
<h1 id="Python面向对象应用"><a href="#Python面向对象应用" class="headerlink" title="Python面向对象应用"></a><font size="5" color="red">Python面向对象应用</font></h1><h2 id="Python创建类"><a href="#Python创建类" class="headerlink" title="Python创建类"></a><font size="4">Python创建类</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 类就是一种物体的总称，具有属性(成员变量)和行为(成员方法)两个特征。其本身并不占用内存空间，其实例化的对象占内存空间。</span><br><span class="line"># class 类名(父类): </span><br><span class="line">#     属性</span><br><span class="line">#     行为</span><br><span class="line"></span><br><span class="line"># 类名一般首字母大写，object是所有类的父类，一般没有合适的父类就写object。</span><br><span class="line">class Person(object):</span><br><span class="line"># 定义属性</span><br><span class="line">    name = ''</span><br><span class="line">    age = 0</span><br><span class="line">    height = 0</span><br><span class="line">    weight = 0</span><br><span class="line"></span><br><span class="line"># 定义行为，注意成员方法的参数一般以self当作第一个参数(可以为其他的单词，但是几乎都使用self)，其中self就代表类的实例，哪个对象调用方法哪个对象就是self，类似于C/C++中的this指针。</span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python88.png" alt="88"></p>
<h2 id="Python实例化对象"><a href="#Python实例化对象" class="headerlink" title="Python实例化对象"></a><font size="4">Python实例化对象</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    name = ''</span><br><span class="line">    age = 0</span><br><span class="line">    height = 0</span><br><span class="line">    weight = 0</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br><span class="line"></span><br><span class="line"># 类似于女娲造人一样，有了人型模具，女娲可以按照模具创建人类对象</span><br><span class="line"># 对象名 = 类名(参数列表) 用类名实例化对象，注意如果没有参数，也不能省略括号。</span><br><span class="line">per = Person()</span><br><span class="line">print(per)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python89.png" alt="89"></p>
<h2 id="Python访问对象属性"><a href="#Python访问对象属性" class="headerlink" title="Python访问对象属性"></a><font size="4">Python访问对象属性</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    name = ''</span><br><span class="line">    age = 0</span><br><span class="line">    height = 0</span><br><span class="line">    weight = 0</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat ' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br><span class="line"></span><br><span class="line"># 对象名.属性名 访问该对象的某一个属性，也可以通过这种方法对该对象的某一属性赋值</span><br><span class="line">per = Person()</span><br><span class="line">print(per.name + '的年龄为：' + str(per.age))</span><br><span class="line">per.name, per.age = '张三', 18</span><br><span class="line">print(per.name + '的年龄为：' + str(per.age))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python90.png" alt="90"></p>
<h2 id="Python访问对象方法"><a href="#Python访问对象方法" class="headerlink" title="Python访问对象方法"></a><font size="4">Python访问对象方法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    name = ''</span><br><span class="line">    age = 0</span><br><span class="line">    height = 0</span><br><span class="line">    weight = 0</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat ' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br><span class="line"></span><br><span class="line"># 对象名.方法名(参数列表) 访问该对象的某一个方法，注意self参数不需要传值</span><br><span class="line">per = Person()</span><br><span class="line">per.eat('apple')</span><br><span class="line">per.sleep()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python91.png" alt="91"></p>
<h2 id="Python类的构造函数"><a href="#Python类的构造函数" class="headerlink" title="Python类的构造函数"></a><font size="4">Python类的构造函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># def __init__(self, 参数列表): 构造函数在使用类创建对象的时候自动调用，如果不显示的写出构造函数，默认自动添加一个空的构造函数</span><br><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age, height, weight):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat ' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br><span class="line"></span><br><span class="line"># 类名实例化对象时给对象的属性赋值</span><br><span class="line">per = Person('李四', 20, 180, 140)</span><br><span class="line">print(per.name + '的年龄为：' + str(per.age))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python92.png" alt="92"></p>
<h2 id="Python类的析构函数"><a href="#Python类的析构函数" class="headerlink" title="Python类的析构函数"></a><font size="4">Python类的析构函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># def __del__(self): 析构函数在释放对象的时候自动调用，如果不显示的写出析构函数，默认自动添加一个空的析构函数</span><br><span class="line">class Person(object):</span><br><span class="line">    def __del__(self):</span><br><span class="line">        print('Destroy the object')</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat ' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br><span class="line"></span><br><span class="line"># 类名实例化对象时给对象的属性赋值</span><br><span class="line">per = Person()</span><br><span class="line">del per</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python93.png" alt="93"></p>
<h2 id="Python中类属性和对象属性"><a href="#Python中类属性和对象属性" class="headerlink" title="Python中类属性和对象属性"></a><font size="4">Python中类属性和对象属性</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    talent = None</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, age):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line"></span><br><span class="line"># 类属性是写在类内部的属性，而对象属性是用self定义或者在外部动态定义的。</span><br><span class="line"># 对象属性的优先级高于类属性，如果一个对象没有对象属性，则使用其类属性，如果添加了对象属性，则使用其对象属性。</span><br><span class="line"># 在此代码中talent属于类属性，可以通过类名.属性调用，name和age属于对象属性，通过对象名.属性调用。</span><br><span class="line"># 注意：尽量不要将对象属性与类属性同名，因为对象属性会屏蔽类属性，当删除对象属性后，又能使用类属性了。</span><br><span class="line">per = Person('张三', 18)</span><br><span class="line">print(Person.talent)</span><br><span class="line">print(per.talent)</span><br><span class="line">per.talent = 'Python'</span><br><span class="line">print(Person.talent)</span><br><span class="line">print(per.talent)</span><br><span class="line"></span><br><span class="line"># 类方法和对象方法类似，类方法是在类内部的方法，而对象方式是在外部动态定义的方法，一般不常用，作为了解即可。</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python100.png" alt="100"></p>
<h2 id="Python类打印函数"><a href="#Python类打印函数" class="headerlink" title="Python类打印函数"></a><font size="4">Python类打印函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># def __str__(self): 在调用print打印对象时自动调用，是一个给用户使用的描述对象的方法，如果不显示的写出，默认返回类的名称和所处的内存地址</span><br><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age, height, weight):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">        self.weight = weight</span><br><span class="line"> </span><br><span class="line">    def __str__(self):</span><br><span class="line">        return "姓名：%s  年龄：%d，身高：%.1f，体重：%.1f" %(self.name, self.age, self.height, self.weight)</span><br><span class="line"></span><br><span class="line">per = Person('王五', 21, 178, 160)</span><br><span class="line">print(per)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python94.png" alt="94"></p>
<h2 id="Python动态语言"><a href="#Python动态语言" class="headerlink" title="Python动态语言"></a><font size="4">Python动态语言</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age, height, weight):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line">per = Person('赵六', 22, 186, 170)</span><br><span class="line">print(per.name + '的存款为：' + str(per.money))</span><br><span class="line"></span><br><span class="line"># per本来没有money属性，可以动态添加money属性</span><br><span class="line">per.money = 10000</span><br><span class="line">print(per.name + '的存款为：' + str(per.money))</span><br><span class="line"></span><br><span class="line"># 还可以动态添加方法，需要从types中导入Method类</span><br><span class="line">from types import MethodType </span><br><span class="line"></span><br><span class="line">def say(self):</span><br><span class="line">    print('my name is ' + self.name)</span><br><span class="line"></span><br><span class="line">per.say()</span><br><span class="line"></span><br><span class="line"># 对象名.方法名 = MethodType(添加的函数名, 对象名)</span><br><span class="line">per.say = MethodType(say, per)</span><br><span class="line">per.say()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python95.png" alt="95"></p>
<h2 id="Python中动态添加限制"><a href="#Python中动态添加限制" class="headerlink" title="Python中动态添加限制"></a><font size="4">Python中动态添加限制</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from types import MethodType </span><br><span class="line"></span><br><span class="line"># 通过定义__slots__ = (成员属性或者成员方法名) 使对象中的成员必须存在于元组之中，可以限制对象随意动态添加成员</span><br><span class="line">class Person(object):</span><br><span class="line">    __slots__ = ('name', 'age', 'money')</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, age):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line"></span><br><span class="line">per = Person('赵六', 22)</span><br><span class="line">per.money = 10000</span><br><span class="line">print(per.name + '的存款为：' + str(per.money))</span><br><span class="line">per.weight = 160</span><br><span class="line"></span><br><span class="line">def say(self):</span><br><span class="line">    print('my name is ' + self.name)</span><br><span class="line"></span><br><span class="line">per.say = MethodType(say, per)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python101.png" alt="101"></p>
<h2 id="Python类中的共有和私有"><a href="#Python类中的共有和私有" class="headerlink" title="Python类中的共有和私有"></a><font size="4">Python类中的共有和私有</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># __属性名/函数名 如果想让内部成员不被外部直接访问，在成员属性或方法前加__(两个下划线)，但是在内部是可以使用的</span><br><span class="line"># 如果想修改其值只能通过自定义一个函数，实现对某些成员变量进行修改操作，这样也达到了一种保护作用</span><br><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age, height, weight):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">    def set_weight(self, weight):</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">    def enquire(self):</span><br><span class="line">        print('体重为：' + str(self.__weight))</span><br><span class="line"></span><br><span class="line">per = Person('王五', 21, 178, 160)</span><br><span class="line">per.enquire()</span><br><span class="line">print(per.__weight)</span><br><span class="line">per.set_weight(150)</span><br><span class="line">per.enquire()</span><br><span class="line"></span><br><span class="line"># 原因是Python解释器将__成员变成了_(一个下划线)类名__(两个下划线)成员名(即在此将__weight改成了_Person__weight)，因此不是绝对私有的</span><br><span class="line">print(per._Person__weight)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python96.png" alt="96"></p>
<h2 id="Python类中的-property装饰器"><a href="#Python类中的-property装饰器" class="headerlink" title="Python类中的@property装饰器"></a><font size="4">Python类中的@property装饰器</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 对私有成员想要便捷的访问和修改可以使用@property装饰器，相当于调用了get和set方法，可以让受限制的成员也能够直接使用.语法</span><br><span class="line"># @property </span><br><span class="line"># def 变量名(self):</span><br><span class="line">#     return self.__变量名</span><br><span class="line"># @变量名.setter</span><br><span class="line"># def 变量名(self, 变量名):</span><br><span class="line">#    xxx</span><br><span class="line"># 以上变量名都是未加下划线的变量名，@property下面的内容相当于get方法，@变量名.setter下面的内容相当于set方法。</span><br><span class="line"></span><br><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age, height, weight):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">    def set_weight(self, weight):</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">    @property</span><br><span class="line">    def weight(self):</span><br><span class="line">        return self.__weight</span><br><span class="line">    @weight.setter</span><br><span class="line">    def weight(self, weight):</span><br><span class="line">        self.__weight = weight</span><br><span class="line"></span><br><span class="line">per = Person('王五', 21, 178, 160)</span><br><span class="line"></span><br><span class="line"># 调用时也是直接调用对象名.原名即可，不需要加双下划线__</span><br><span class="line">print(per.weight)</span><br><span class="line">per.weight = 150</span><br><span class="line">print(per.weight)</span><br><span class="line"></span><br><span class="line"># 原因是Python解释器将__成员变成了_(一个下划线)类名__(两个下划线)成员名(即在此将__weight改成了_Person__weight)，因此不是绝对私有的</span><br><span class="line">print(per._Person__weight)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python96.png" alt="96"></p>
<h2 id="Python类的单继承"><a href="#Python类的单继承" class="headerlink" title="Python类的单继承"></a><font size="4">Python类的单继承</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age, height, weight):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print('eat ' + food)</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('I need sleep')</span><br><span class="line"></span><br><span class="line"># 对于世间万物，大多数都有这一般和特殊的关系，如人和程序员之间的关系，程序员继承了人的所有特点，但是又有一些特殊的特点。将人这个类别称为子类(基类)，将程序员这个类别称为父类(超类)。</span><br><span class="line"># 所有的类都是继承于object类，继承可以大大简化代码，提高代码的健壮性和安全性。</span><br><span class="line"># class 类名(父类): 子类继承父类，需要在类名后面的括号中写入父类名，继承时调用父类的__init__只需要写super(子类名, self).__init__(参数列表)即可，参数列表中不需要写self</span><br><span class="line"># 注意父类的私有成员子类可以继承过来，但是无法直接使用，只能通过父类的自定义函数访问。</span><br><span class="line"># 子类特有的成员和之前定义普通类时相同</span><br><span class="line">class Programmer(Person):</span><br><span class="line">    def __init__(self, name, age, height, weight, language):</span><br><span class="line">        super(Programmer, self).__init__(name, age, height, weight)</span><br><span class="line">        self.language = language</span><br><span class="line"></span><br><span class="line">pro = Programmer('钱七', 23, 181, 135, 'Python')</span><br><span class="line">pro.eat('watermelon')</span><br><span class="line">print(pro.language)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python97.png" alt="97"></p>
<h2 id="Python类的多继承"><a href="#Python类的多继承" class="headerlink" title="Python类的多继承"></a><font size="4">Python类的多继承</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Father(object):</span><br><span class="line">    def __init__(self, name, age, talent):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.talent = talent</span><br><span class="line"></span><br><span class="line">    def play(self):</span><br><span class="line">        print('play computer games')</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('Father need sleep')</span><br><span class="line"></span><br><span class="line">class Mother(object):</span><br><span class="line">    def __init__(self, name, age, beauty):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.beauty = beauty</span><br><span class="line"></span><br><span class="line">    def shopping(self):</span><br><span class="line">        print('go shopping')</span><br><span class="line"></span><br><span class="line">    def sleep(self):</span><br><span class="line">        print('Mother need sleep')</span><br><span class="line"></span><br><span class="line"># 除了单继承外也有多继承的情况，比如遗传就是一种典型的多继承，孩子要继承父亲和母亲的特点</span><br><span class="line"># class 类名(父类): 子类继承父类，如果需要多继承，则在类名后面的括号中写入多个父类名</span><br><span class="line"># 继承时构造函数中调用父类的__init__，只需要写父类名.__init__(self, 参数列表)即可使用，注意要写self</span><br><span class="line"># 注意父类中方法名相同，默认调用的是在括号中排在前面的父类中的方法</span><br><span class="line">class Child(Father, Mother):</span><br><span class="line">    def __init__(self, name, age, talent, beauty):</span><br><span class="line">        Father.__init__(self, name, age, talent)</span><br><span class="line">        Mother.__init__(self, name, age, beauty)</span><br><span class="line"></span><br><span class="line">chi = Child('辛巴', 22, 'Python', 99)</span><br><span class="line">print(chi.name + '的年龄为：' + str(chi.age))</span><br><span class="line">print('我的才能是：' + chi.talent)</span><br><span class="line">print('我的颜值是：' + str(chi.beauty))</span><br><span class="line">chi.play()</span><br><span class="line">chi.shopping()</span><br><span class="line">chi.sleep()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python98.png" alt="98"></p>
<h2 id="Python类的多态"><a href="#Python类的多态" class="headerlink" title="Python类的多态"></a><font size="4">Python类的多态</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Animal(object):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    def eat(self, food):</span><br><span class="line">        print(self.name + ' eat ' + food)</span><br><span class="line"></span><br><span class="line">class Cat(Animal):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(Cat, self).__init__(name)</span><br><span class="line"></span><br><span class="line">class Mouse(Animal):</span><br><span class="line">    def __init__(self, name):</span><br><span class="line">        super(Mouse, self).__init__(name)</span><br><span class="line"></span><br><span class="line">class Person(object):</span><br><span class="line">    def feed(self, animal, food):</span><br><span class="line">        animal.eat(food)</span><br><span class="line"></span><br><span class="line"># 对于继承自同一类的多个类具有多态的性质，即子类有多种表现形态</span><br><span class="line"># 此代码中动物类就是父类，猫类和老鼠类都继承自动物类，所以猫类和鼠类都有父类的方法</span><br><span class="line"># 因此传入不同的子类对象具有不同的表现形态</span><br><span class="line"></span><br><span class="line">per = Person()</span><br><span class="line">tom = Cat('Tom')</span><br><span class="line">jerry = Mouse('Jerry')</span><br><span class="line">per.feed(tom, 'fish')</span><br><span class="line">per.feed(jerry, 'rice')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python99.png" alt="99"></p>
<h2 id="Python运算符重载"><a href="#Python运算符重载" class="headerlink" title="Python运算符重载"></a><font size="4">Python运算符重载</font></h2><p><img src="/images/LANGUAGE/python109.png" alt="109"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 为了使运算方便，有时需要进行运算符重载，典型的就是字符串的相加，1 + 2 = 3，但是字符串相加就是字符串的连接。</span><br><span class="line"># 说明对字符串的加法进行了重新定义，使其可以完成相加操作。同理，对自己写的类也可以进行运算符重载，使两个类可以做运算。</span><br><span class="line"># 要重载什么操作就查操作对应的特殊函数，然后将其重载即可。</span><br><span class="line"></span><br><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, money):</span><br><span class="line">        self.money = money</span><br><span class="line"></span><br><span class="line">    def __add__(self, other):</span><br><span class="line">        return Person(self.money + other.money)</span><br><span class="line"></span><br><span class="line">    def __str__(self):</span><br><span class="line">        return 'money：' + str(self.money)</span><br><span class="line"></span><br><span class="line"># 此代码重载了加法运算符和打印操作</span><br><span class="line">per1 = Person(100)</span><br><span class="line">print(per1)</span><br><span class="line">per2 = Person(200)</span><br><span class="line">print(per2)</span><br><span class="line">per3 = per1 + per2</span><br><span class="line">print(per3)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/python103.png" alt="103"></p>
<h1 id="Object-Oriented小结"><a href="#Object-Oriented小结" class="headerlink" title="Object-Oriented小结"></a><font size="5" color="red">Object-Oriented小结</font></h1><p>  Object-Oriented面向对象是计算机语言中一种重要的思想，它的出现将程序员从一个执行者变成了一个管理者，程序员在使用时只需要知道能做什么，而不需要知道具体如何实现，而且每次创建对象时只需要一行代码，调用某一函数时也不需要关心内部的结构，大大减少了阅读代码的时间和内存的占用情况。因此面向过程是程序员的必经之路，需要熟练的掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Import(导入模块)</title>
    <url>/2019/09/17/python_import/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python13.jpg" alt="13"></p>
<h1 id="Import介绍"><a href="#Import介绍" class="headerlink" title="Import介绍"></a><font size="5" color="red">Import介绍</font></h1><p>  Python中使用Import导入模块，类似于C/C++中的include，但是使用起来更加灵活和方便，可以导入整个模块或者导入模块的某一部分。<br><a id="more"></a></p>
<h1 id="Import应用"><a href="#Import应用" class="headerlink" title="Import应用"></a><font size="5" color="red">Import应用</font></h1><h2 id="导入路径"><a href="#导入路径" class="headerlink" title="导入路径"></a><font size="4">导入路径</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line"># sys.path 查询导包时的路径顺序，当有相同名字的包出现时，则按照顺序查询是否在此路径，路径中如果含有两个文件夹即两个包，都含有相同名字的.py文件，当导入该.py文件时，需要写清楚包名.文件名</span><br><span class="line">print(sys.path)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python78.png" alt="78"></p>
<h2 id="安装第三方模块"><a href="#安装第三方模块" class="headerlink" title="安装第三方模块"></a><font size="4">安装第三方模块</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 在虚拟环境中输入pip install xxx  安装xxx模块</span><br></pre></td></tr></tbody></table></figure>
<h2 id="import语句"><a href="#import语句" class="headerlink" title="import语句"></a><font size="4">import语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># import module1, module2, ... 一次性引入多个模块，使用模块时格式为：模块名.函数名/变量名</span><br><span class="line">import sys, time</span><br><span class="line"></span><br><span class="line">start = time.clock()</span><br><span class="line">end = time.clock()</span><br><span class="line">res = end - start</span><br><span class="line"></span><br><span class="line"># import module as module_name 一个模块名如果较长，书写不方便，可以将其改名为module_name</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([1, 2, 3])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python79.png" alt="79"></p>
<h2 id="from-…-import语句"><a href="#from-…-import语句" class="headerlink" title="from … import语句"></a><font size="4">from … import语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># from module import name1, name2, ... 从module模块中引入一个指定的部分到当前命名空间，使用时不需要加模块名</span><br><span class="line">from numpy import array, arange</span><br><span class="line"></span><br><span class="line">a = array([1, 2, 3])</span><br><span class="line">b = arange(5) </span><br><span class="line"></span><br><span class="line"># from module import name as new_name 一个函数名或变量名如果较长，书写不方便，可以将其改名为new_name</span><br><span class="line">from numpy import linspace as lsp</span><br><span class="line"></span><br><span class="line">c = lsp(0, 10, 6)</span><br><span class="line"></span><br><span class="line"># from module import * 把module模块中所有的内容全部导入当前模块</span><br><span class="line">from numpy import *</span><br><span class="line"></span><br><span class="line">d = zeros((3, 3))</span><br><span class="line"></span><br><span class="line"># from .... import语句存在着危险性，如果下面定义了同名的函数，则会覆盖引入的函数</span><br><span class="line">from numpy import *</span><br><span class="line"></span><br><span class="line">def zeros(* par):</span><br><span class="line">    return 0</span><br><span class="line"></span><br><span class="line">e = zeros((3, 3))</span><br><span class="line"></span><br><span class="line"># 如果有一个.py文件需要被导入，也需要单独的运行此文件。但是如果直接导入该文件，会自动执行该文件，如果希望运行时不执行该文件需要在.py文件中写入</span><br><span class="line"># if __name__ == "__main__": 然后主程序程序写在下面，这样单独运行该文件时会执行主程序，被导入时不会执行主程序。</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python80.png" alt="80"></p>
<h1 id="Import小结"><a href="#Import小结" class="headerlink" title="Import小结"></a><font size="5" color="red">Import小结</font></h1><p>  Python之所以被称为胶水语言，主要归功于Import的强大功能。随着Python的火热，各个领域都为Python提供功能强大的接口，如计算机视觉领域有opencv库，机器学习领域有sklearn库，深度学习领域有TensorFlow, Torch库，数据分析领域有Numpy, Matplotlib库等等，这为Python的使用者提供非常大的便捷。而且在大型的工程应用中，往往需要写很多的子文件，也需要Import的帮助，因此要熟练掌握这些导入模块的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Function(函数)</title>
    <url>/2019/09/16/python_function/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python10.jpg" alt="10"></p>
<h1 id="Function介绍"><a href="#Function介绍" class="headerlink" title="Function介绍"></a><font size="5" color="red">Function介绍</font></h1><p>  Python中的Function一种重要的调用方式，和C/C++类似，通过参数的传递和数据的返回完成所预期的目的。<br><a id="more"></a></p>
<h1 id="Python内建Function"><a href="#Python内建Function" class="headerlink" title="Python内建Function"></a><font size="5" color="red">Python内建Function</font></h1><h2 id="Python进制转换函数"><a href="#Python进制转换函数" class="headerlink" title="Python进制转换函数"></a><font size="4">Python进制转换函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 100</span><br><span class="line"></span><br><span class="line"># bin(x) 对x用二进制字符串表示</span><br><span class="line">bin_a = bin(a)</span><br><span class="line"></span><br><span class="line"># oct(x) 对x用八进制字符串表示</span><br><span class="line">oct_a = oct(a)</span><br><span class="line"></span><br><span class="line"># hex(x) 对x用十六进制字符串表示</span><br><span class="line">hex_a = hex(a)</span><br><span class="line"></span><br><span class="line"># int(x, mode) 2 &lt;= mode &lt;= 36，将x转换为mode进制</span><br><span class="line">int(bin_a, 2)</span><br><span class="line">int(oct_a, 8)</span><br><span class="line">int(hex_a, 16)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python112.png" alt="112"></p>
<h2 id="Python求和函数，最大值最小值函数"><a href="#Python求和函数，最大值最小值函数" class="headerlink" title="Python求和函数，最大值最小值函数"></a><font size="4">Python求和函数，最大值最小值函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># sum(iterable) 对于列表，元组， 集合来说sum是指所有元素之和，前提是元素可以求和，对于字典来说sum是指关键字Key求和</span><br><span class="line">sum({1, 2, 3, 4})</span><br><span class="line">sum({1:11, 2:22, 3:33, 4:44})</span><br><span class="line"></span><br><span class="line"># max(iterable) 用法同sum，求元素的最大值</span><br><span class="line">max({1, 2, 3, 4})</span><br><span class="line">max({1:11, 2:22, 3:33, 4:44})</span><br><span class="line"></span><br><span class="line"># min(iterable) 用法同sum，求元素的最小值</span><br><span class="line">min({1, 2, 3, 4})</span><br><span class="line">min({1:11, 2:22, 3:33, 4:44})</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python60.png" alt="60"></p>
<h2 id="Python长度函数"><a href="#Python长度函数" class="headerlink" title="Python长度函数"></a><font size="4">Python长度函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># len(iterable) 求可迭代对象的长度，即其中包含的元素个数</span><br><span class="line">len([1, 2, 3, 4])</span><br><span class="line">len((1, 2, (3, [4, 5]), 6))</span><br><span class="line">len({1:11, 2:22, 3:33, 4:44})</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python61.png" alt="61"></p>
<h2 id="Python排序函数"><a href="#Python排序函数" class="headerlink" title="Python排序函数"></a><font size="4">Python排序函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1,5,3,2,4]</span><br><span class="line">b = {1:11, 5:55, 3:33, 2:22, 4:44}</span><br><span class="line">c = [(1, 5), (4, 8), (3, 7), (2, 9)]</span><br><span class="line"></span><br><span class="line"># sorted(iterable, key, reverse=False) 对可迭代对象按照key进行排序，如果对字典进行排序则对其关键字进行排序，reverse为True指从大到小排序，默认为从小到大排序</span><br><span class="line">sorted(a)</span><br><span class="line">sorted(b)</span><br><span class="line">sorted(c)</span><br><span class="line">sorted(c, key=lambda x:(x[1], x[0]))</span><br><span class="line">sorted(c, key=lambda x:(x[1], x[0]), reverse=True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python62.png" alt="62"></p>
<h2 id="Python翻转函数"><a href="#Python翻转函数" class="headerlink" title="Python翻转函数"></a><font size="4">Python翻转函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1,5,3,2,4]</span><br><span class="line">b = [(1, 5), (4, 8), (3, 7), (2, 9)]</span><br><span class="line"></span><br><span class="line"># reversed(iterable) 返回翻转后的迭代器对象，可以用list，tuple等进行转换，字典无法进行翻转操作</span><br><span class="line">reversed(a)</span><br><span class="line">list(reversed(a))</span><br><span class="line">tuple(reversed(b))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python63.png" alt="63"></p>
<h2 id="Python枚举函数"><a href="#Python枚举函数" class="headerlink" title="Python枚举函数"></a><font size="4">Python枚举函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1,5,3,2,4]</span><br><span class="line">b = {1:11, 5:55, 3:33, 2:22, 4:44}</span><br><span class="line">c = [(1, 5), (4, 8), (3, 7), (2, 9)]</span><br><span class="line"></span><br><span class="line"># enumerate(iterable) 返回从0开始枚举的迭代器对象，可以用list，tuple等进行转换，对字典枚举则对其关键字进行枚举</span><br><span class="line">reversed(a)</span><br><span class="line">enumerate(a)</span><br><span class="line">list(enumerate(a))</span><br><span class="line">list(enumerate(b))</span><br><span class="line">tuple(enumerate(c))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python64.png" alt="64"></p>
<h2 id="Python打包函数"><a href="#Python打包函数" class="headerlink" title="Python打包函数"></a><font size="4">Python打包函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1,5,3,2,4]</span><br><span class="line">b = {1:11, 5:55, 3:33, 2:22, 4:44}</span><br><span class="line">c = [(1, 5), (4, 8), (3, 7), (2, 9)]</span><br><span class="line"></span><br><span class="line"># zip(iterable1, iterable2) 将两个迭代器对象打包，合并成一个迭代器对象，打包元素按照元素数量少的进行打包，对字典打包则对其关键字进行打包</span><br><span class="line">zip(a, b)</span><br><span class="line">list(zip(a, b))</span><br><span class="line">tuple(zip(a, c))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python65.png" alt="65"></p>
<h2 id="Python删除函数"><a href="#Python删除函数" class="headerlink" title="Python删除函数"></a><font size="4">Python删除函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = True</span><br><span class="line">b = [1,5,3,2,4]</span><br><span class="line"></span><br><span class="line"># del obj 将obj删除，不存在该对象</span><br><span class="line">del a</span><br><span class="line">del b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python66.png" alt="66"></p>
<h2 id="Python中input函数"><a href="#Python中input函数" class="headerlink" title="Python中input函数"></a><font size="4">Python中input函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># input() 从标准输入中读取一行文本，返回该内容的字符串</span><br><span class="line">str = input('请输入:')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python87.png" alt="87"></p>
<h2 id="Python中print函数"><a href="#Python中print函数" class="headerlink" title="Python中print函数"></a><font size="4">Python中print函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># print(obj1, obj2, ..., end='\n') 将obj1, obj2, ...按顺序输出，以空格分开，end是输出后的结尾字符，默认为换行符</span><br><span class="line">print([1, 2, 3], (4, 5, 6))</span><br><span class="line">print('hello world' + '\n' + 'hello python ', end='end')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python84.png" alt="84"></p>
<h2 id="Python推导式"><a href="#Python推导式" class="headerlink" title="Python推导式"></a><font size="4">Python推导式</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1, 2, 3, 4, 5]</span><br><span class="line"></span><br><span class="line"># [x for x in iterable] 从iterable中逐一获取元素，并生成列表</span><br><span class="line">[2 ** x for x in a]</span><br><span class="line">[[i + j * 3 for i in range(3)] for j in range(3)]</span><br><span class="line"></span><br><span class="line"># {x for x in iterable} 从iterable中逐一获取元素，并生成集合</span><br><span class="line">{2 ** x for x in a}</span><br><span class="line"></span><br><span class="line"># {x: y for x in iterable} 从iterable中逐一获取元素，并生成字典</span><br><span class="line">{x: 2 ** x for x in a}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python67.png" alt="67"></p>
<h2 id="Python中lambda表达式"><a href="#Python中lambda表达式" class="headerlink" title="Python中lambda表达式"></a><font size="4">Python中lambda表达式</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># lambda arg1, arg2: function 一行表达式简单实现函数，参数为arg1, arg2, ...，函数体为function</span><br><span class="line">f = lambda x, y: x * y</span><br><span class="line">f(3, 4)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python68.png" alt="68"></p>
<h2 id="Python中filter函数"><a href="#Python中filter函数" class="headerlink" title="Python中filter函数"></a><font size="4">Python中filter函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># filter(function or None, iterable) 若第一个参数为None则返回iterable中为真的元素，并生成迭代器对象，若第一个参数为function，则将iterable中的每个元素带入函数，将为真的元素生成迭代器对象</span><br><span class="line">filter(None, [x % 3 for x in range(10)])</span><br><span class="line">list(filter(None, [x % 3 for x in range(10)]))</span><br><span class="line"></span><br><span class="line">filter(lambda x: x % 3, range(10))</span><br><span class="line">list(filter(lambda x: x % 3, range(10)))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python69.png" alt="69"></p>
<h2 id="Python中map函数"><a href="#Python中map函数" class="headerlink" title="Python中map函数"></a><font size="4">Python中map函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = '12345'</span><br><span class="line">f = lambda x: 2 ** x</span><br><span class="line"></span><br><span class="line"># map(function, iterable) 将iterable中的元素带入函数，返回函数生成的迭代器对象</span><br><span class="line">map(int, a)</span><br><span class="line">list(map(int, a))</span><br><span class="line"></span><br><span class="line">map(f, range(5))</span><br><span class="line">tuple(map(f, range(5)))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python70.png" alt="70"></p>
<h1 id="Python自定义Function"><a href="#Python自定义Function" class="headerlink" title="Python自定义Function"></a><font size="5" color="red">Python自定义Function</font></h1><h2 id="Python中def定义函数"><a href="#Python中def定义函数" class="headerlink" title="Python中def定义函数"></a><font size="4">Python中def定义函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 定义名为function_name的函数，形式参数为arg1, arg2, ...，函数体为function，返回值为value(可以无返回值)，与C/C++不同，可以有多个返回值</span><br><span class="line"># def function_name(arg1, arg2, ...): </span><br><span class="line">#     function</span><br><span class="line">#     return value</span><br><span class="line"></span><br><span class="line">def my_pow(a, b):</span><br><span class="line">    return a ** b, b ** a</span><br><span class="line"></span><br><span class="line"># function_name(x1, x2, ...) 调用名为function_name的函数，实际参数为x1, x2, ...，调用时将实参本身传递到形参，可以按顺序传入参数或者手动指定参数</span><br><span class="line">c, d = my_pow(3, 4)</span><br><span class="line">e, f = my_pow(b=4, a=3)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python71.png" alt="71"></p>
<h2 id="Python函数的默认参数"><a href="#Python函数的默认参数" class="headerlink" title="Python函数的默认参数"></a><font size="4">Python函数的默认参数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># def function_name(arg1, arg2=x) 设置函数的默认参数为arg2，其值为x，调用时如果没有赋值则赋值为x，注意默认参数只能放在非默认参数之后</span><br><span class="line">def my_pow(a, b=2):</span><br><span class="line">    return b ** a</span><br><span class="line"></span><br><span class="line">a = my_pow(5)</span><br><span class="line">b = my_pow(3, 3)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python81.png" alt="81"></p>
<h2 id="Python函数的收集参数"><a href="#Python函数的收集参数" class="headerlink" title="Python函数的收集参数"></a><font size="4">Python函数的收集参数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># def function_name(*args) 将所有的参数都打包起来，调用时传入多少个都可以，都生成一个元组，如果没有传入参数则是一个空元组。</span><br><span class="line"></span><br><span class="line">def my_func(*par):</span><br><span class="line">    print(par)</span><br><span class="line">    print('参数的个数为:', len(par))</span><br><span class="line"></span><br><span class="line">my_func(1, 2, [3, 4], '56', {7, 8, 9})</span><br><span class="line"></span><br><span class="line"># def function_name(**kwargs) 将所有的参数都打包起来，调用时传入多少个都可以，都生成一个字典，传入参数时必须使用键值对的形式，如果没有传入参数则是一个空字典。</span><br><span class="line"></span><br><span class="line">def my_func(**par):</span><br><span class="line">    print(par)</span><br><span class="line">    print('参数的个数为:', len(par))</span><br><span class="line"></span><br><span class="line">my_func(a=1, b=2, c=[1, 2])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python82.png" alt="82"></p>
<h2 id="Python星号的用法"><a href="#Python星号的用法" class="headerlink" title="Python星号的用法"></a><font size="4">Python星号的用法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 用作运算符，一个星号代表乘法，两个星号代表乘方</span><br><span class="line">a, b = 2, 3</span><br><span class="line">a * b</span><br><span class="line">a ** b</span><br><span class="line"></span><br><span class="line"># 定义函数时表示收集，*args表示将位置参数都装入元组args中，**kwargs表示将位置参数都装入字典kwargs中</span><br><span class="line">def test(*args, **kwargs):</span><br><span class="line">  print(args[0])</span><br><span class="line">  print(kwargs['a'])</span><br><span class="line"></span><br><span class="line">test(1, 2, 3, a='aa', b='bb')</span><br><span class="line"></span><br><span class="line"># 调用函数时表示分散，*L表示将可迭代对象中的每个元素作为位置参数传入，**D表示将字典的键值对作为位置参数传入</span><br><span class="line">def test(a, b, c):</span><br><span class="line">  print(a)</span><br><span class="line"></span><br><span class="line">L = [1, 2]</span><br><span class="line">D = {'c': 3}</span><br><span class="line">test(*L, **D)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python110.png" alt="110"></p>
<h2 id="Python函数的全局变量"><a href="#Python函数的全局变量" class="headerlink" title="Python函数的全局变量"></a><font size="4">Python函数的全局变量</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 在函数中使用和外部名称相同的变量时，会建立一个同名的局部变量，即使修改了其值，也只是修改了局部变量额值，函数调用完毕后，外部的变量仍然没有被修改</span><br><span class="line">a = 10</span><br><span class="line"></span><br><span class="line">def my_func():</span><br><span class="line">    a = 5</span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line">my_func()</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line"># 如果想在函数中修改外部变量的值，则需要将其声明为全局变量，和C/C++不同，C/C++是在定义时将变量声明为全局，而Python中是在外部先定义，然后在函数内部使用关键字global将其声明为全局</span><br><span class="line">a = 10</span><br><span class="line"></span><br><span class="line">def my_func():</span><br><span class="line">    global a</span><br><span class="line">    a = 5</span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line">my_func()</span><br><span class="line">print(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python83.png" alt="83"></p>
<h2 id="Python函数的非局部变量"><a href="#Python函数的非局部变量" class="headerlink" title="Python函数的非局部变量"></a><font size="4">Python函数的非局部变量</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># nonlocal关键字修饰变量后标识变量是上一层函数中的局部变量，对变量进行修改就是修改上一层函数中的局部变量，如果上一层函数中不存在同名的局部变量，则会报错，经常用于闭包和装饰器中，有关闭包和装饰器的相关知识可以参考我的另一篇博客Closure &amp; Decorators(闭包和装饰器)。</span><br><span class="line">def decorators(func):</span><br><span class="line">  a = 1</span><br><span class="line">  print("正在装饰")</span><br><span class="line">  print("外层局部变量a的值为: ", a)</span><br><span class="line">  def wrapper():</span><br><span class="line">    func()</span><br><span class="line">    nonlocal a</span><br><span class="line">    a += 1</span><br><span class="line">    print("内层局部变量a的值为: ", a)</span><br><span class="line">  return wrapper</span><br><span class="line"></span><br><span class="line">@decorators</span><br><span class="line">def say():</span><br><span class="line">  print("hello world!")</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python111.png" alt="111"></p>
<h2 id="Python内嵌函数"><a href="#Python内嵌函数" class="headerlink" title="Python内嵌函数"></a><font size="4">Python内嵌函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 在函数内部可以定义另一个函数，这样外部函数无法调用该函数，仅仅能在定义该函数的函数中使用，这样可以使主程序更加清晰。内嵌函数的使用频率较低，了解即可。</span><br><span class="line">def test1():</span><br><span class="line">    print('This is test1')</span><br><span class="line">    def test2():</span><br><span class="line">        print('This is test2')</span><br><span class="line">    test2()</span><br><span class="line"></span><br><span class="line">test1()</span><br><span class="line">test2()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python104.png" alt="104"></p>
<h2 id="Python偏函数"><a href="#Python偏函数" class="headerlink" title="Python偏函数"></a><font size="4">Python偏函数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 偏函数是指对函数参数中默认值的控制</span><br><span class="line"># functools模块中有一个partial方法，可以完成对默认值的控制</span><br><span class="line"># new_func = functools.partial(old_func, para=x) 将原函数old_func中的para参数固定为x</span><br><span class="line">import functools</span><br><span class="line"></span><br><span class="line">a = int('1010', base=2)</span><br><span class="line"></span><br><span class="line">int2 = functools.partial(int, base=2)</span><br><span class="line">b = int2('1010')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python107.png" alt="107"></p>
<h1 id="Function小结"><a href="#Function小结" class="headerlink" title="Function小结"></a><font size="5" color="red">Function小结</font></h1><p>  Function函数是计算机语言中一种重要的调用方式，无论是在何种语言中，函数的使用都是至关重要的，有了函数可以使代码更加整洁和清晰，模块与模块之间达到高内聚低耦合，大大提高代码的可读性。可以节省大因此使用的频率非常高，所以要灵活掌握Function的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Exception(异常)</title>
    <url>/2019/09/16/python_exception/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python11.jpg" alt="11"></p>
<h1 id="Exception-异常"><a href="#Exception-异常" class="headerlink" title="Exception(异常)"></a><font size="5" color="red">Exception(异常)</font></h1><p>  在学习Python时，如果使用IDEA，我们经常会看到一些红色的报错信息，导致程序终止，没有得到我们想要的输出，这是怎么回事呢？在这个博客中我会专门介绍Python的一些异常。<br><a id="more"></a></p>
<h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a><font size="5" color="red">异常处理</font></h1><h2 id="异常类型"><a href="#异常类型" class="headerlink" title="异常类型"></a><font size="4">异常类型</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># throw语句在代码块中可以抛出异常， </span><br><span class="line"># 除数不能为0，会触发除0异常</span><br><span class="line">a = 1 / 0</span><br><span class="line"></span><br><span class="line">b = [1, 2, 3]</span><br><span class="line"># 索引不能超过数组长度，会触发索引越界异常</span><br><span class="line">print(b[3])</span><br><span class="line"></span><br><span class="line"># str类型和数字不能直接相加，会触发类型异常</span><br><span class="line">c = "123" + 456</span><br><span class="line"></span><br><span class="line"># assert断言：当表达式为False时会触发断言异常</span><br><span class="line">assert 6 &gt; 10</span><br></pre></td></tr></tbody></table></figure>
<p>我们在命令行中进行测试，因此没有红色的提示信息，如果在PyCharm或者其他的IDEA中运行，则会看到红色的提示信息。<br><img src="/images/LANGUAGE/python114.png" alt="114"></p>
<h2 id="try…except异常捕获"><a href="#try…except异常捕获" class="headerlink" title="try…except异常捕获"></a><font size="4">try…except异常捕获</font></h2><p><img src="/images/LANGUAGE/python115.png" alt="115"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># try: 语句1 except: 语句2 执行语句1如果发生异常则直接跳到except中执行语句2，如果没有异常则不执行语句2</span><br><span class="line"># try:</span><br><span class="line">#     语句1(可能出错的步骤)</span><br><span class="line"># except ErrorName(默认为所有异常都抛弃):</span><br><span class="line">#     语句2(出现错误的处理过程)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    print('除以0之前')</span><br><span class="line">    a = 5 / 0</span><br><span class="line">    print('除以0之后')</span><br><span class="line">except ZeroDivisionError:</span><br><span class="line">    a = 5</span><br><span class="line">    print('except')</span><br><span class="line">print(a)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/python116.png" alt="116"></p>
<h2 id="try…except…else异常捕获"><a href="#try…except…else异常捕获" class="headerlink" title="try…except…else异常捕获"></a><font size="4">try…except…else异常捕获</font></h2><p><img src="/images/LANGUAGE/python117.png" alt="117"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># try: 语句1 except: 语句2 else: 语句3 执行语句1如果发生异常则直接跳到except中执行语句2，如果没有异常则执行语句3</span><br><span class="line"># try:</span><br><span class="line">#     语句1(可能出错的步骤)</span><br><span class="line"># except ErrorName(默认为所有异常都抛弃):</span><br><span class="line">#     语句2(出现错误的处理过程)</span><br><span class="line"># else:</span><br><span class="line">#     语句3(没有出错执行的代码)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    print('除以0之前')</span><br><span class="line">    a = 5 / 0</span><br><span class="line">    print('除以0之后')</span><br><span class="line">except ZeroDivisionError:</span><br><span class="line">    a = 5</span><br><span class="line">    print('except')</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    print('除以2之前')</span><br><span class="line">    a = 5 / 2</span><br><span class="line">    print('除以2之后')</span><br><span class="line">except ZeroDivisionError:</span><br><span class="line">    a = 5</span><br><span class="line">    print('except')</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br><span class="line">print(a)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/python118.png" alt="118"></p>
<h2 id="try…except…else…finally"><a href="#try…except…else…finally" class="headerlink" title="try…except…else…finally"></a><font size="4">try…except…else…finally</font></h2><p><img src="/images/LANGUAGE/python119.png" alt="119"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># try: 语句1 except: 语句2 else: 语句3 finally: 语句4 执行语句1如果发生异常则直接跳到except中执行语句2，如果没有异常则执行语句3，最终都要执行finally中的语句4</span><br><span class="line"># try:</span><br><span class="line">#     语句1(可能出错的步骤)</span><br><span class="line"># except ErrorName(默认为所有异常都抛弃):</span><br><span class="line">#     语句2(出现错误的处理过程)</span><br><span class="line"># else:</span><br><span class="line">#     语句3(没有出错执行的代码)</span><br><span class="line"># finally:</span><br><span class="line">#     语句4(最终都要执行的代码)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    print('除以0之前')</span><br><span class="line">    a = 5 / 0</span><br><span class="line">    print('除以0之后')</span><br><span class="line">except ZeroDivisionError:</span><br><span class="line">    a = 5</span><br><span class="line">    print('except')</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br><span class="line">finally:</span><br><span class="line">    print('finally')</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    print('除以2之前')</span><br><span class="line">    a = 5 / 2</span><br><span class="line">    print('除以2之后')</span><br><span class="line">except ZeroDivisionError:</span><br><span class="line">    a = 5</span><br><span class="line">    print('except')</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br><span class="line">finally:</span><br><span class="line">    print('finally')</span><br><span class="line">print(a)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/LANGUAGE/python120.png" alt="120"></p>
<h2 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a><font size="4">自定义异常</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">// 用户可以创建一个新的异常类来使用自定义异常。异常类需要继承自Exception类。</span><br><span class="line">class MyException(Exception):</span><br><span class="line">    def __init__(self, value):</span><br><span class="line">        super(MyException, self).__init__(value)</span><br><span class="line"></span><br><span class="line">// raise抛出一个指定异常对象，可以抛出任何类型，但是处理时必须用相应的异常类型去捕获</span><br><span class="line">raise MyException("月份值不能超过12！")</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python121.png" alt="121"></p>
<h1 id="Special-Structure小结"><a href="#Special-Structure小结" class="headerlink" title="Special Structure小结"></a><font size="5" color="red">Special Structure小结</font></h1><p>  红色的异常语句是每一个程序员都遇到过的，在这里我们对异常进行了揭秘，可能在平时的做题或者工程中很难用到，我们还是要了解它的机制，当我们需要的时候可以及时回忆起来。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>else &amp; with(Python特殊结构)</title>
    <url>/2019/09/15/python_special/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python113.png" alt="11"></p>
<h1 id="else-amp-with-Python特殊结构"><a href="#else-amp-with-Python特殊结构" class="headerlink" title="else &amp; with(Python特殊结构)"></a><font size="5" color="red">else &amp; with(Python特殊结构)</font></h1><p>  Python中的特殊结构指除了条件，循环之外的结构，如else语句，with语句,在一些特定的条件下可以发挥出较好的效果。<br><a id="more"></a></p>
<h1 id="Python特殊结构"><a href="#Python特殊结构" class="headerlink" title="Python特殊结构"></a><font size="5" color="red">Python特殊结构</font></h1><h2 id="else语句"><a href="#else语句" class="headerlink" title="else语句"></a><font size="4">else语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># else语句有4种组合方式，可以和if组合成if condition: 语句1 else: 语句2，可以和while组合成while condition: 循环语句 else 语句，可以和for组合成for target in iterable: 循环语句 else: 语句，可以和try组合成try: 语句1 except: 语句2 else: 语句3</span><br><span class="line"></span><br><span class="line"># if condition: 语句1 else: 语句2，如果condition正确则执行语句1，否则执行语句2</span><br><span class="line"># if condition:</span><br><span class="line">#     语句1</span><br><span class="line"># else:</span><br><span class="line">#     语句2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># while condition: 循环语句 else 语句，如果循环执行完毕则执行else中的语句，如果中间跳出循环则不执行else中的语句</span><br><span class="line"># while condition:</span><br><span class="line">#     循环语句</span><br><span class="line"># else:</span><br><span class="line">#     语句</span><br><span class="line">a = 3</span><br><span class="line">while a &gt; 0:</span><br><span class="line">    a -= 1</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br><span class="line"></span><br><span class="line"># for target in iterable: 循环语句 else: 语句，如果循环执行完毕则执行else中的语句，如果中间跳出循环则不执行else中的语句</span><br><span class="line"># for target in iterable: </span><br><span class="line">#     循环语句</span><br><span class="line"># else:</span><br><span class="line">#     语句</span><br><span class="line">a = 3</span><br><span class="line">for i in range(3):</span><br><span class="line">    a -= 1</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br><span class="line"></span><br><span class="line"># try: 语句1 except: 语句2 else: 语句3，如果发生异常则不执行else后面的语句3，没有异常则执行else后面的语句3</span><br><span class="line"># try:</span><br><span class="line">#     语句1</span><br><span class="line"># except:</span><br><span class="line">#     语句2</span><br><span class="line"># else: </span><br><span class="line">#     语句3</span><br><span class="line">try:</span><br><span class="line">    a = 4 / 0</span><br><span class="line">except:</span><br><span class="line">    a = 4 / 1</span><br><span class="line">else:</span><br><span class="line">    print('else')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python73.png" alt="73"></p>
<h2 id="with语句"><a href="#with语句" class="headerlink" title="with语句"></a><font size="4">with语句</font></h2><pre><code># with 语句1: 语句2 用于文件操作或者进程线程互斥时，语句2执行完之后会自动释放语句1所产生的资源，不需要再手动完成后续处理
# with 语句1:
#     语句2
with open('dm01.txt') as f:
    print(f.read())
print(f.closed)
</code></pre><p><img src="/images/LANGUAGE/python74.png" alt="74"></p>
<h1 id="Python特殊结构小结"><a href="#Python特殊结构小结" class="headerlink" title="Python特殊结构小结"></a><font size="5" color="red">Python特殊结构小结</font></h1><p>  特殊结构使用频率相对较低，当小伙伴们遇到能够认识它们即可，如果忘记了具体的用法，直接去网上搜索，仅仅作为了解即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>File(文件)</title>
    <url>/2019/09/15/python_file/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python12.jpg" alt="12"></p>
<h1 id="File介绍"><a href="#File介绍" class="headerlink" title="File介绍"></a><font size="5" color="red">File介绍</font></h1><p>  学习一门语言，最终目的是解决实际的生活问题，尤其是Python语言，出色的应用在人工智能领域。但是面对大数据的浪潮，数据的读取是一个关键的问题，因此文件操作是我们必须要掌握的内容。<br><a id="more"></a></p>
<h1 id="File应用"><a href="#File应用" class="headerlink" title="File应用"></a><font size="5" color="red">File应用</font></h1><h2 id="File打开"><a href="#File打开" class="headerlink" title="File打开"></a><font size="4">File打开</font></h2><script type="math/tex; mode=display">\begin{array}{|c|c|} 模式 & 描述 \\ x & 写模式，新建一个文件，如果该文件已存在则会报错。 \\ b & 二进制模式。 \\ + & 打开一个文件进行更新(可读可写)。 \\ r & 以只读方式打开文件。文件的指针将会放在文件的开头。 \\ w & 以写入方式打开文件。如果该文件已存在则从开头开始编辑。否则创建新文件。 \\ a & 以追加方式打开文件，如果该文件不存在则创建新文件写入。 \\ \end{array}</script><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None) 最重要的</span><br><span class="line">f = open('dm01.txt', mode='a+') 以读写的方式打开文件dm01.txt，用于在文件后追加内容</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python76.png" alt="76"></p>
<h2 id="File操作"><a href="#File操作" class="headerlink" title="File操作"></a><font size="4">File操作</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># file.flush() 刷新内部缓存，将缓存区的数据写入文件</span><br><span class="line"></span><br><span class="line"># file.read(size) 从文件读取size大小的字节，默认读取所有字节 </span><br><span class="line"></span><br><span class="line"># file.readline() 读取整行，包括换行符</span><br><span class="line"></span><br><span class="line"># file.readlines() 读取所有行，并以列表形式返回</span><br><span class="line"></span><br><span class="line"># file.seek(n) 设置文件指针当前位置指向n</span><br><span class="line"></span><br><span class="line"># file.tell() 返回文件指针当前位置 </span><br><span class="line"></span><br><span class="line"># file.write() 将字符串写入文件，返回写入的字符长度</span><br><span class="line"></span><br><span class="line"># file.writelines() 向文件写入一个序列的字符串列表，如果需要换行则加入每行的换行符</span><br><span class="line"></span><br><span class="line"># flie.close() 关闭文件，关闭后无法进行读写操作</span><br><span class="line">f = open('dm01.txt', mode='r+', encoding='utf-8')</span><br><span class="line">f</span><br><span class="line">f.tell()</span><br><span class="line">f.seek(0)</span><br><span class="line">f.readlines()</span><br><span class="line">f.writelines(['\nfile append1\nfile append2'])</span><br><span class="line">f.seek(0)</span><br><span class="line">f.readlines()</span><br><span class="line">f.close()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python77.png" alt="77"></p>
<h1 id="File小结"><a href="#File小结" class="headerlink" title="File小结"></a><font size="5" color="red">File小结</font></h1><p>  对文件的操作经常使用于文本的批量化修改，大数据的读取或者网页爬虫的应用。这些都属于较高级别的应用领域，因此初学者很少使用到File文件操作，但是为了以后应用的方便，学好文件操作是必不可少的！</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Set(集合)</title>
    <url>/2019/09/14/python_set/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python9.jpg" alt="9"></p>
<h1 id="Set介绍"><a href="#Set介绍" class="headerlink" title="Set介绍"></a><font size="5" color="red">Set介绍</font></h1><p>  Python中的Set是集合的概念，其和列表，元组最大的区别是集合中不存在相同的元素。<br><a id="more"></a></p>
<h1 id="Set操作"><a href="#Set操作" class="headerlink" title="Set操作"></a><font size="5" color="red">Set操作</font></h1><h2 id="Python创建集合"><a href="#Python创建集合" class="headerlink" title="Python创建集合"></a><font size="4">Python创建集合</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># set(iterable) 将可迭代对象转换为set类型</span><br><span class="line">a = set(range(5))</span><br><span class="line"></span><br><span class="line"># {a, b, c, ...} 创建元素为a, b, c, ...的集合，注意空集合不能写{}，要用set()定义，{}默认为字典类型</span><br><span class="line">b = {1, 2, 3, 4, 5}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python56.png" alt="56"></p>
<h2 id="Python集合运算"><a href="#Python集合运算" class="headerlink" title="Python集合运算"></a><font size="4">Python集合运算</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1, 2, 3, 4, 5}</span><br><span class="line">b = {3, 4, 5, 6, 7}</span><br><span class="line"></span><br><span class="line"># |(求并集)，&amp;(求交集)，-(求差集)，^(求对称差集)，==(比较是否相等)，!=(比较是否不等)，&lt;(比较是否为真子集)，&lt;=(比较是否为子集)，&gt;(比较是否为真超集)，&gt;=(比较是否为超集)</span><br><span class="line">a | b</span><br><span class="line">a &amp; b</span><br><span class="line">a - b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python57.png" alt="57"></p>
<h2 id="Python向集合中增加，删除，修改元素"><a href="#Python向集合中增加，删除，修改元素" class="headerlink" title="Python向集合中增加，删除，修改元素"></a><font size="4">Python向集合中增加，删除，修改元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1, 2, 3, 4, 5}</span><br><span class="line"></span><br><span class="line"># obj.add(ele) 向集合中添加元素，不能添加集合，列表，字典类型，可以添加数字，字符串，元组类型，如果已经存在于集合中，则不做任何操作</span><br><span class="line">a.add(6)</span><br><span class="line">a.add(3)</span><br><span class="line"></span><br><span class="line"># obj.remove(ele) 从集合中删除元素ele，如果没有该元素会报错</span><br><span class="line">a.remove(1)</span><br><span class="line"></span><br><span class="line"># obj.discard(ele) 从集合中删除元素ele，如果没有该元素不会报错</span><br><span class="line">a.discard(2)</span><br><span class="line"></span><br><span class="line"># obj.pop() 从集合中删除第一个元素并返回该元素</span><br><span class="line">a.pop()</span><br><span class="line"></span><br><span class="line"># obj.clear() 删除所有元素</span><br><span class="line">a.clear()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python59.png" alt="59"></p>
<h1 id="Set小结"><a href="#Set小结" class="headerlink" title="Set小结"></a><font size="5" color="red">Set小结</font></h1><p>  Set集合是使用频率相对较低，但是如果使用则会大大提高效率，在统计类别时，很多物品属于同一类，此时不需要关心该物品，建立集合时，可以节省大量的内存空间和用户查询时间，因此在某些特定情况下能发挥独特的优势，所以也要熟练掌握Set的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Dict(字典)</title>
    <url>/2019/09/14/python_dict/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python8.jpg" alt="8"></p>
<h1 id="Dict介绍"><a href="#Dict介绍" class="headerlink" title="Dict介绍"></a><font size="5" color="red">Dict介绍</font></h1><p>  Python中的Dict是一种哈希表的数据结构，是由键值对构成的，一个Key对应一个Value，方便数据的查找。<br><a id="more"></a></p>
<h1 id="Dict操作"><a href="#Dict操作" class="headerlink" title="Dict操作"></a><font size="5" color="red">Dict操作</font></h1><h2 id="Python创建字典"><a href="#Python创建字典" class="headerlink" title="Python创建字典"></a><font size="4">Python创建字典</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># dict.fromkeys(key, value) 生成以key为关键字，value为值的字典，初始时所有的key对应的值都相同，默认为None</span><br><span class="line">a = dict.fromkeys([1, 2, 3])</span><br><span class="line"></span><br><span class="line"># {a:aa, b:bb, ...}创建Key为a, b, ...，Value为aa, bb, ...的字典</span><br><span class="line">b = {1:None, 2:None, 3:None}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python50.png" alt="50"></p>
<h2 id="Python索引字典元素"><a href="#Python索引字典元素" class="headerlink" title="Python索引字典元素"></a><font size="4">Python索引字典元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1:'one', 2:2, 3:True}</span><br><span class="line"></span><br><span class="line"># 和列表，元组，字符串不同，字典的索引是无序的，只能根据Key来索引</span><br><span class="line">a[1]</span><br><span class="line"></span><br><span class="line"># obj.get(key, value) 若key在关键字中，则返回其值，否则返回value，默认为None</span><br><span class="line">a.get(1)</span><br><span class="line"></span><br><span class="line"># obj.setdefault(key, value) 若key在关键字中，则返回其值，否则给字典添加(key, value)value默认为None</span><br><span class="line">a.setdefault(4, 'four')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python51.png" alt="51"></p>
<h2 id="Python获得所有的键，值信息"><a href="#Python获得所有的键，值信息" class="headerlink" title="Python获得所有的键，值信息"></a><font size="4">Python获得所有的键，值信息</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1:'one', 2:2, 3:True}</span><br><span class="line"></span><br><span class="line"># obj.keys() 获取字典的所有键</span><br><span class="line">a.keys()</span><br><span class="line"></span><br><span class="line"># obj.values() 获取字典的所有值</span><br><span class="line">a.values()</span><br><span class="line"></span><br><span class="line"># obj.items() 获取字典的所有键值对</span><br><span class="line">a.items()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python52.png" alt="52"></p>
<h2 id="Python增加，删除，修改字典元素"><a href="#Python增加，删除，修改字典元素" class="headerlink" title="Python增加，删除，修改字典元素"></a><font size="4">Python增加，删除，修改字典元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1:'one', 2:2, 3:True}</span><br><span class="line"></span><br><span class="line"># obj[key] = value 将字典的key对应的值改为value，如果不存在则增加一个键值对(key, value)</span><br><span class="line">a[3] = False</span><br><span class="line">a[4] = 'FOUR'</span><br><span class="line"></span><br><span class="line"># del obj[key] 将字典中的key对应的键值对删除</span><br><span class="line">del a[4]</span><br><span class="line"></span><br><span class="line"># obj.pop(key) 弹出关键字位key的元素，并返回其Value</span><br><span class="line">a.pop(1)</span><br><span class="line"></span><br><span class="line"># obj.popitem() 弹出最后一个元素，并返回其键值对</span><br><span class="line">a.popitem()</span><br><span class="line"></span><br><span class="line"># obj.clear() 删除所有元素</span><br><span class="line">a.clear()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python53.png" alt="53"></p>
<h2 id="Python字典合并"><a href="#Python字典合并" class="headerlink" title="Python字典合并"></a><font size="4">Python字典合并</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1:'one', 2:2, 3:True}</span><br><span class="line">b = {1:'ONE', 4:4, 5:False}</span><br><span class="line"></span><br><span class="line"># obj.update(obj1) 给字典obj添加另一个字典obj1，两个字典取并集，如果具有相同的Key则值为obj1中key对应的值</span><br><span class="line">a.update(b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python54.png" alt="54"></p>
<h2 id="Python判断关键字是否在字典中"><a href="#Python判断关键字是否在字典中" class="headerlink" title="Python判断关键字是否在字典中"></a><font size="4">Python判断关键字是否在字典中</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = {1:'one', 2:2, 3:True}</span><br><span class="line"></span><br><span class="line"># key in obj，判断key是否在obj的关键字中，key not in obj，判断key是否不在obj的关键字中</span><br><span class="line">b = 2 in a</span><br><span class="line">c = 4 not in a</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python55.png" alt="55"></p>
<h1 id="Dict小结"><a href="#Dict小结" class="headerlink" title="Dict小结"></a><font size="5" color="red">Dict小结</font></h1><p>  Dict字典是Python中一种重要的数据结构，在大数据的存储或者统计各分数段人数时，有时为了便于查询，需要建立字典，索引时只需要关键字Key，可以节省大量的内存空间和用户查询时间，因此使用的频率非常高，所以要灵活掌握Dict的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Str(字符串)</title>
    <url>/2019/09/13/python_str/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python7.jpg" alt="7"></p>
<h1 id="Str介绍"><a href="#Str介绍" class="headerlink" title="Str介绍"></a><font size="5" color="red">Str介绍</font></h1><p>  Python中的Str是可迭代对象，类似于C/C++中的字符串，但是更加灵活，具有很多内置的API。<br><a id="more"></a></p>
<h1 id="Str操作"><a href="#Str操作" class="headerlink" title="Str操作"></a><font size="5" color="red">Str操作</font></h1><h2 id="Python创建字符串"><a href="#Python创建字符串" class="headerlink" title="Python创建字符串"></a><font size="4">Python创建字符串</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># str(obj) 将obj转换为字符串，一般用来将数字转换为字符串</span><br><span class="line">a = str(123)</span><br><span class="line"></span><br><span class="line"># 'abc...'或者"abc..." 创建值为abc...的字符串，如果字符串本身具有单引号则创建时要用双引号，如果字符串本身具有双引号，则创建时要用单引号</span><br><span class="line">b = 'Hello Python'</span><br><span class="line">c = "Hello World"</span><br><span class="line">d = 'I love "Python"'</span><br><span class="line">e = "I love 'coding'"</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python30.png" alt="30"></p>
<h2 id="Python索引字符串元素"><a href="#Python索引字符串元素" class="headerlink" title="Python索引字符串元素"></a><font size="4">Python索引字符串元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 和C/C++相同，通过中括号[]索引字符串元素，可以通过:运算符获取连续的索引，负数索引为从后向前索引，-1代表最后一个元素，-2代表倒数第二个元素</span><br><span class="line">a = 'Hello Python'</span><br><span class="line">b = a[:2]</span><br><span class="line">c = a[4]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python31.png" alt="31"></p>
<h2 id="Python向字符串中增加，删除，修改元素"><a href="#Python向字符串中增加，删除，修改元素" class="headerlink" title="Python向字符串中增加，删除，修改元素"></a><font size="4">Python向字符串中增加，删除，修改元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># Python中字符串没有append，pop等API，如果想修改元素必须采用算术运算修改元素</span><br><span class="line">a = 'Hello pythan'</span><br><span class="line">a = a[:-2] + 'o' + a[-1]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python32.png" alt="32"></p>
<h2 id="Python字符串大小写转换"><a href="#Python字符串大小写转换" class="headerlink" title="Python字符串大小写转换"></a><font size="4">Python字符串大小写转换</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'heLLo pythOn'</span><br><span class="line"></span><br><span class="line"># obj.capitalize() 第一个字符改为大写，其他字符改为小写并返回</span><br><span class="line">b = a.capitalize()</span><br><span class="line"></span><br><span class="line"># obj.title() 将每个单词的第一个字符改为大写，其他字符改为小写并返回</span><br><span class="line">c = a.title()</span><br><span class="line"></span><br><span class="line"># obj.lower() 将大写转换为小写</span><br><span class="line">d =a.lower()</span><br><span class="line"></span><br><span class="line"># obj.upper() 将小写转换为大写</span><br><span class="line">e = a.upper()</span><br><span class="line"></span><br><span class="line"># obj.swapcase() 将大小写字符翻转，大写变小写，小写变大写</span><br><span class="line">f = a.swapcase()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python33.png" alt="33"></p>
<h2 id="Python字符串大小比较"><a href="#Python字符串大小比较" class="headerlink" title="Python字符串大小比较"></a><font size="4">Python字符串大小比较</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj1 op obj2 将两个字符串进行大小比较，从第一个元素开始比较，如果相同继续比较</span><br><span class="line">a = 'hello world'</span><br><span class="line">b = 'hello python'</span><br><span class="line">a &gt; b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python34.png" alt="34"></p>
<h2 id="Python字符串乘法"><a href="#Python字符串乘法" class="headerlink" title="Python字符串乘法"></a><font size="4">Python字符串乘法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj * n，n为正整数，将obj复制n次</span><br><span class="line">a = 'hello world '</span><br><span class="line">b = a * 3</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python35.png" alt="35"></p>
<h2 id="Python判断元素是否在字符串中"><a href="#Python判断元素是否在字符串中" class="headerlink" title="Python判断元素是否在字符串中"></a><font size="4">Python判断元素是否在字符串中</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># data in obj，判断data是否在obj中，data not in obj，判断data是否不在obj中</span><br><span class="line">a = 'hello world'</span><br><span class="line">b = 'he' in a</span><br><span class="line">c = 'she' not in a</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python36.png" alt="36"></p>
<h2 id="Python求某个元素出现的次数"><a href="#Python求某个元素出现的次数" class="headerlink" title="Python求某个元素出现的次数"></a><font size="4">Python求某个元素出现的次数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.count(data) 求data在字符串中出现的次数</span><br><span class="line">a = 'hello world'</span><br><span class="line">a.count('l')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python37.png" alt="37"></p>
<h2 id="Python求某个元素的索引"><a href="#Python求某个元素的索引" class="headerlink" title="Python求某个元素的索引"></a><font size="4">Python求某个元素的索引</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.index(data, begin, end) 从begin到end-1中索引第一次出现data的位置，默认从第一个元素到最后一个元素</span><br><span class="line">a = 'hello world'</span><br><span class="line">a.index('l')</span><br><span class="line">a.index('l', 4)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python38.png" alt="38"></p>
<h2 id="Python字符串与列表或元组的转换"><a href="#Python字符串与列表或元组的转换" class="headerlink" title="Python字符串与列表或元组的转换"></a><font size="4">Python字符串与列表或元组的转换</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'string'</span><br><span class="line">b = ['L', 'i', 's', 't']</span><br><span class="line">c = ('T', 'u', 'p', 'l', 'e')</span><br><span class="line"></span><br><span class="line"># list(obj)或者tuple(obj) 字符串转换成列表或者元组，转换后列表或者元组的每一个元素为一个字符</span><br><span class="line">d = list(a)</span><br><span class="line">e = tuple(a)</span><br><span class="line"></span><br><span class="line"># ''.join(obj) 将obj转换为字符串</span><br><span class="line">f = ''.join(b)</span><br><span class="line">g = ''.join(c)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python39.png" alt="39"></p>
<h2 id="Python将字符串翻转"><a href="#Python将字符串翻转" class="headerlink" title="Python将字符串翻转"></a><font size="4">Python将字符串翻转</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'hello python'</span><br><span class="line"></span><br><span class="line"># 通过索引翻转[::-1]</span><br><span class="line">a[::-1]</span><br><span class="line"></span><br><span class="line"># Python不允许字符串进行翻转，但是可以借助列表进行翻转，然后再转换为字符串即可</span><br><span class="line">a = list(a)</span><br><span class="line">a.reverse()</span><br><span class="line">a = ''.join(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python40.png" alt="40"></p>
<h2 id="Python将字符串排序"><a href="#Python将字符串排序" class="headerlink" title="Python将字符串排序"></a><font size="4">Python将字符串排序</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabbc'</span><br><span class="line"></span><br><span class="line"># Python不允许字符串进行排序，但是可以借助列表进行排序，然后再转换为字符串即可</span><br><span class="line">a = list(a)</span><br><span class="line">a.sort()</span><br><span class="line">a = ''.join(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python41.png" alt="41"></p>
<h2 id="Python判断字符串类型"><a href="#Python判断字符串类型" class="headerlink" title="Python判断字符串类型"></a><font size="4">Python判断字符串类型</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = '1a2b3c'</span><br><span class="line">b = 'abcdef'</span><br><span class="line">c = '123456'</span><br><span class="line"></span><br><span class="line"># obj.isalnum() 判断字符串是否全是字母或数字</span><br><span class="line">a.isalnum()</span><br><span class="line"></span><br><span class="line"># obj.isalpha() 判断字符串是否全是字符</span><br><span class="line">b.isalpha()</span><br><span class="line"></span><br><span class="line"># obj.isdigit() 判断字符串是否全是数字</span><br><span class="line">c.isdigit()</span><br><span class="line"></span><br><span class="line"># obj.islower() 判断字符串是否全是小写字母</span><br><span class="line">b.islower()</span><br><span class="line"></span><br><span class="line"># obj.isupper() 判断字符串是否全是大写字母</span><br><span class="line">b.isupper()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python42.png" alt="42"></p>
<h2 id="Python字符串居中"><a href="#Python字符串居中" class="headerlink" title="Python字符串居中"></a><font size="4">Python字符串居中</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = '----------'</span><br><span class="line"></span><br><span class="line"># obj.center(width, fillchar) 字符串居中，总长度为width，两边填充的字符为fillchar，默认为空格</span><br><span class="line">a.center(20)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python43.png" alt="43"></p>
<h2 id="Python查找子串出现的次数"><a href="#Python查找子串出现的次数" class="headerlink" title="Python查找子串出现的次数"></a><font size="4">Python查找子串出现的次数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabbc'</span><br><span class="line"></span><br><span class="line"># obj.count(str, begin, end) 查找子串str从begin到end-1出现的次数，默认从第一个到最后一个</span><br><span class="line">a.count('ab')</span><br><span class="line">a.count('ab', 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python44.png" alt="44"></p>
<h2 id="Python查询字符串开头或者结尾是否为某一子串"><a href="#Python查询字符串开头或者结尾是否为某一子串" class="headerlink" title="Python查询字符串开头或者结尾是否为某一子串"></a><font size="4">Python查询字符串开头或者结尾是否为某一子串</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabbc'</span><br><span class="line"></span><br><span class="line"># obj.startswith(str, begin, end) 判断obj从begin到end-1是否以str开头</span><br><span class="line">a.startswith('abc')</span><br><span class="line"></span><br><span class="line"># obj.endswith(str, begin, end) 判断obj从begin到end-1是否以str结尾</span><br><span class="line">a.endswith('bc')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python45.png" alt="45"></p>
<h2 id="Python求字符串中子串的索引"><a href="#Python求字符串中子串的索引" class="headerlink" title="Python求字符串中子串的索引"></a><font size="4">Python求字符串中子串的索引</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabbc'</span><br><span class="line"></span><br><span class="line"># obj.find(str, begin, end) 从左边查找子串str从begin到end-1出现的索引，默认从第一个到最后一个</span><br><span class="line">a.find('abb')</span><br><span class="line">a.find('abbds')</span><br><span class="line"></span><br><span class="line"># obj.rfind(str, begin, end) 从右边查找子串str从begin到end-1出现的索引，默认从第一个到最后一个</span><br><span class="line">a.rfind('abb')</span><br><span class="line">a.rfind('abbds')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python46.png" alt="46"></p>
<h2 id="Python将字符串左边或右边的字符删去"><a href="#Python将字符串左边或右边的字符删去" class="headerlink" title="Python将字符串左边或右边的字符删去"></a><font size="4">Python将字符串左边或右边的字符删去</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabba'</span><br><span class="line"></span><br><span class="line"># obj.lstrip(str) 将左边的str字符删去，如果str为字符串则代表字符串中的所有字符都删去</span><br><span class="line">a.lstrip('a')</span><br><span class="line"></span><br><span class="line"># obj.rstrip(str) 将右边的str字符删去，如果str为字符串则代表字符串中的所有字符都删去</span><br><span class="line">a.rstrip('a')</span><br><span class="line"></span><br><span class="line"># obj.strip(str) 将左边和右边的str字符删去，如果str为字符串则代表字符串中的所有字符都删去</span><br><span class="line">a.strip('a')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python47.png" alt="47"></p>
<h2 id="Python替换字符串"><a href="#Python替换字符串" class="headerlink" title="Python替换字符串"></a><font size="4">Python替换字符串</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabbc'</span><br><span class="line"></span><br><span class="line"># obj.replace(old, new) 将old子串用new替代</span><br><span class="line">a.replace('abb', 'cdd')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python48.png" alt="48"></p>
<h2 id="Python拆分字符串"><a href="#Python拆分字符串" class="headerlink" title="Python拆分字符串"></a><font size="4">Python拆分字符串</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = 'abcabbc'</span><br><span class="line"></span><br><span class="line"># obj.partition(str) 将字符串拆分为3部分，str之前的部分，str，str之后的部分</span><br><span class="line"></span><br><span class="line"># obj.split(str) 将obj按照str拆分，默认为空格拆分</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python49.png" alt="49"></p>
<h2 id="Python字符串格式化"><a href="#Python字符串格式化" class="headerlink" title="Python字符串格式化"></a><font size="4">Python字符串格式化</font></h2><script type="math/tex; mode=display">\begin{array}{|c|c|} 格式 & 描述 \\  \%c & 以ASCII码格式化字符 \\ \%s & 格式化字符串 \\ \%d & 格式化整数 \\ \%m.nf & 格式化浮点数，m指总长度，n指小数点后面的精度，不够在左侧补空格 \\ \%-m.nf & 格式化浮点数，m指总长度，n指小数点后面的精度，不够在右侧补空格 \\ \end{array}</script><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># '{}...{}...'.format('xxx', 'yyy', ...) 将xxx，yyy填入字符串的花括号中</span><br><span class="line">s1 = '{}的网址是"{}"'.format('阿里巴巴', 'www.alibabagroup.com')</span><br><span class="line">s2 = '{0}的网址是"{1}"'.format('腾讯', 'www.tencent.com')</span><br><span class="line">s3 = '{name}的网址是"{site}"'.format(name='百度', site='www.baidu.com')</span><br><span class="line"></span><br><span class="line"># '{0:x}...{1:y}...'.format('xxx', 'yyy', ...) 将xxx，yyy填入字符串的花括号中，x和y指输入的格式，可以达到美化效果</span><br><span class="line">s4 = '{name:10s}==&gt;{id:10d}'.format(name='张三', id=1)</span><br><span class="line"></span><br><span class="line"># '格式1, 格式2, 格式3' %(数据1, 数据2, 数据3) 将数据1以格式1的方式，数据2以格式2的方式，数据3以格式3的方式放入字符串中，注意格式与数据直接没有逗号连接</span><br><span class="line">s5 = '%s：%d/%d/%d' %('今天的日期为', 2019, 9, 18)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python86.png" alt="86"></p>
<h1 id="Str小结"><a href="#Str小结" class="headerlink" title="Str小结"></a><font size="5" color="red">Str小结</font></h1><p>  Str字符串是Python中一种常见的结构，在实际的应用中，经常有许多数据无法用数字表示，如姓名，地址等信息，因此使用的频率也是非常高的，所以要灵活掌握Str的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Tuple(元组)</title>
    <url>/2019/09/12/python_tuple/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python6.jpg" alt="5"></p>
<h1 id="Tuple介绍"><a href="#Tuple介绍" class="headerlink" title="Tuple介绍"></a><font size="5" color="red">Tuple介绍</font></h1><p>  Python中的Tuple类似于一种带上枷锁的列表，功能和List类似，但是不能够修改其中的元素和顺序。<br><a id="more"></a></p>
<h1 id="Tuple操作"><a href="#Tuple操作" class="headerlink" title="Tuple操作"></a><font size="5" color="red">Tuple操作</font></h1><h2 id="Python创建元组"><a href="#Python创建元组" class="headerlink" title="Python创建元组"></a><font size="4">Python创建元组</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># tuple(iterable) 将可迭代对象转换为tuple类型</span><br><span class="line">a = tuple(range(5))</span><br><span class="line"></span><br><span class="line"># (a, b, c, ...) 或者 a, b, c, ...创建元素为a, b, c, ...的元组，创建单元素元组时，需要加逗号,</span><br><span class="line">b = (1, 3.14, 'hello world', True, [1, 2, 3])</span><br><span class="line">c = 1, 2, 3</span><br><span class="line">d = (2,)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python20.png" alt="20"></p>
<h2 id="Python索引元组元素"><a href="#Python索引元组元素" class="headerlink" title="Python索引元组元素"></a><font size="4">Python索引元组元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 通过中括号[]索引元组元素，和List相同</span><br><span class="line">a = (1, 3.14, 'hello world', True, (1, 2, 3)) </span><br><span class="line">b = a[1:3]</span><br><span class="line">c = a[4]</span><br><span class="line">d = a[4][1]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python21.png" alt="21"></p>
<h2 id="Python向元组中增加，删除，修改元素"><a href="#Python向元组中增加，删除，修改元素" class="headerlink" title="Python向元组中增加，删除，修改元素"></a><font size="4">Python向元组中增加，删除，修改元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = (1, 3, 6, 7, 9)</span><br><span class="line"></span><br><span class="line"># Python中不允许在原来的元组上修改任何元素，List中的append，pop，都无法使用，如果想修改元素必须采用算术运算修改元素</span><br><span class="line">b = a[:2] + (5,) + a[3:]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python22.png" alt="22"></p>
<h2 id="Python元组大小比较"><a href="#Python元组大小比较" class="headerlink" title="Python元组大小比较"></a><font size="4">Python元组大小比较</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj1 op obj2 将两个元组进行大小比较，从第一个元素开始比较，如果相同继续比较</span><br><span class="line">a = (1, 3.14, 'hello world', True, [1, 2, 3])</span><br><span class="line">b = (1, 2.71, 'hello world', True, [1, 2, 3]) </span><br><span class="line">a &gt; b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python23.png" alt="23"></p>
<h2 id="Python元组乘法"><a href="#Python元组乘法" class="headerlink" title="Python元组乘法"></a><font size="4">Python元组乘法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj * n，n为正整数，将obj复制n次</span><br><span class="line">a = (1, 3.14, True, [1, 2, 3])</span><br><span class="line">b = a * 3</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python24.png" alt="24"></p>
<h2 id="Python判断元素是否在元组中"><a href="#Python判断元素是否在元组中" class="headerlink" title="Python判断元素是否在元组中"></a><font size="4">Python判断元素是否在元组中</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># data in obj，判断data是否在obj中，data not in obj，判断data是否不在obj中</span><br><span class="line">a = (1, 3.14, True, [1, 2, 3])</span><br><span class="line">b = 3.14 in a</span><br><span class="line">c = True not in a</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python25.png" alt="25"></p>
<h2 id="Python求某个元素出现的次数"><a href="#Python求某个元素出现的次数" class="headerlink" title="Python求某个元素出现的次数"></a><font size="4">Python求某个元素出现的次数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.count(data) 求data在元组中出现的次数</span><br><span class="line">a = (1, 3, 1, 2, 5)</span><br><span class="line">a.count(1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python26.png" alt="26"></p>
<h2 id="Python求某个元素的索引"><a href="#Python求某个元素的索引" class="headerlink" title="Python求某个元素的索引"></a><font size="4">Python求某个元素的索引</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.index(data, begin, end) 从begin到end-1中索引第一次出现data的位置，默认从第一个元素到最后一个元素</span><br><span class="line">a = (1, 3, 1, 2, 5)</span><br><span class="line">a.index(1)</span><br><span class="line">a.index(1, 1, 3)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python27.png" alt="27"></p>
<h2 id="Python将元组翻转"><a href="#Python将元组翻转" class="headerlink" title="Python将元组翻转"></a><font size="4">Python将元组翻转</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = (1, 3, 1, 2, 5)</span><br><span class="line"></span><br><span class="line"># 通过索引翻转[::-1]</span><br><span class="line">a[::-1]</span><br><span class="line"></span><br><span class="line"># Python不允许元组进行翻转，但是元组和列表都是可迭代对象，可以互相转换，于是可以先转换为列表进行翻转，然后再转换为元组即可</span><br><span class="line">a = list(a)</span><br><span class="line">a.reverse()</span><br><span class="line">a = tuple(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python28.png" alt="28"></p>
<h2 id="Python将列表排序"><a href="#Python将列表排序" class="headerlink" title="Python将列表排序"></a><font size="4">Python将列表排序</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># Python不允许元组进行排序，但是元组和列表都是可迭代对象，可以互相转换，于是可以先转换为列表进行排序，然后再转换为元组即可</span><br><span class="line">a = (1, 3, 1, 2, 5)</span><br><span class="line">a = list(a)</span><br><span class="line">a.sort()</span><br><span class="line">a = tuple(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python29.png" alt="29"></p>
<h1 id="Tuple小结"><a href="#Tuple小结" class="headerlink" title="Tuple小结"></a><font size="5" color="red">Tuple小结</font></h1><p>  Tuple元组是Python中一种常见的结构，由于元组的元素操作存在限制，因此可以用来存储固定不变的数据，防止出现误操作使数据修改，如存放个人出生年月，身份证号等信息，因此使用的频率也是非常高的，所以要灵活掌握Tuple的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>List(列表)</title>
    <url>/2019/09/11/python_list/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python5.jpg" alt="5"></p>
<h1 id="List介绍"><a href="#List介绍" class="headerlink" title="List介绍"></a><font size="5" color="red">List介绍</font></h1><p>  Python中的List是可迭代对象，类似于C/C++中的数组，但是比数组更加灵活，可以动态的随意增加和删除元素，还可以存储不同的数据类型。<br><a id="more"></a></p>
<h1 id="List操作"><a href="#List操作" class="headerlink" title="List操作"></a><font size="5" color="red">List操作</font></h1><h2 id="Python创建列表"><a href="#Python创建列表" class="headerlink" title="Python创建列表"></a><font size="4">Python创建列表</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># list(iterable) 将可迭代对象转换为list类型</span><br><span class="line">a = list(range(5))</span><br><span class="line"></span><br><span class="line"># [a, b, c, ...] 创建元素为a, b, c, ...的列表</span><br><span class="line">b = [1, 3.14, 'hello world', True, [1, 2, 3]]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python9.png" alt="9"></p>
<h2 id="Python索引列表元素"><a href="#Python索引列表元素" class="headerlink" title="Python索引列表元素"></a><font size="4">Python索引列表元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 和C/C++相同，通过中括号[]索引列表元素，可以通过:运算符获取连续的索引，负数索引为从后向前索引，-1代表最后一个元素，-2代表倒数第二个元素</span><br><span class="line">a = [1, 3.14, 'hello world', True, [1, 2, 3]] </span><br><span class="line">b = a[1:3]</span><br><span class="line">c = a[4]</span><br><span class="line">d = a[4][1]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python10.png" alt="10"></p>
<h2 id="Python向列表中增加元素"><a href="#Python向列表中增加元素" class="headerlink" title="Python向列表中增加元素"></a><font size="4">Python向列表中增加元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.append(obj1) 在obj末尾追加obj1，可以追加一个数据，也可以追加一个列表</span><br><span class="line">a = [1, 3.14, 'hello world', True, [1, 2, 3]] </span><br><span class="line">a.append(-1)</span><br><span class="line">a.append([1, 2, 3])</span><br><span class="line"></span><br><span class="line"># obj1 + obj2 将两个列表相加，obj2会追加在obj1的后面</span><br><span class="line">b = a + [[1, 2, 3]] # 得到的值等价于a.append([1, 2, 3])，但是a.append()只能在a后面追加，如果想赋值给b而不想改变a就要通过加法运算</span><br><span class="line">c = a + [1] # 得到的值等价于a.append(1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python11.png" alt="11"></p>
<h2 id="Python从列表中删除元素"><a href="#Python从列表中删除元素" class="headerlink" title="Python从列表中删除元素"></a><font size="4">Python从列表中删除元素</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1, 3.14, 'hello world', True, [1, 2, 3]] </span><br><span class="line"></span><br><span class="line"># obj.remove(data) 从obj中删除首次出现值为data的元素</span><br><span class="line">a.remove(3.14)</span><br><span class="line"></span><br><span class="line"># del obj 删除obj数据，是用来删除不用的变量，也可以删除列表中的某个元素</span><br><span class="line">del a[1]</span><br><span class="line"></span><br><span class="line"># obj.pop(n) 弹出第n个元素并返回该元素</span><br><span class="line">b = a.pop(-1)</span><br><span class="line"></span><br><span class="line"># obj.clear() 删除所有元素</span><br><span class="line">a.clear()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python12.png" alt="12"></p>
<h2 id="Python列表大小比较"><a href="#Python列表大小比较" class="headerlink" title="Python列表大小比较"></a><font size="4">Python列表大小比较</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj1 op obj2 将两个列表进行大小比较，从第一个元素开始比较，如果相同继续比较</span><br><span class="line">a = [1, 3.14, 'hello world', True, [1, 2, 3]] </span><br><span class="line">b = [1, 2.71, 'hello world', True, [1, 2, 3]] </span><br><span class="line">a &gt; b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python13.png" alt="13"></p>
<h2 id="Python列表乘法"><a href="#Python列表乘法" class="headerlink" title="Python列表乘法"></a><font size="4">Python列表乘法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj * n，n为正整数，将obj复制n次</span><br><span class="line">a = [1, 3.14, True, [1, 2, 3]] </span><br><span class="line">b = a * 3</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python14.png" alt="14"></p>
<h2 id="Python判断元素是否在列表中"><a href="#Python判断元素是否在列表中" class="headerlink" title="Python判断元素是否在列表中"></a><font size="4">Python判断元素是否在列表中</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># data in obj，判断data是否在obj中，data not in obj，判断data是否不在obj中</span><br><span class="line">a = [1, 3.14, True, [1, 2, 3]]</span><br><span class="line">b = 3.14 in a</span><br><span class="line">c = True not in a</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python15.png" alt="15"></p>
<h2 id="Python求某个元素出现的次数"><a href="#Python求某个元素出现的次数" class="headerlink" title="Python求某个元素出现的次数"></a><font size="4">Python求某个元素出现的次数</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.count(data) 求data在列表中出现的次数</span><br><span class="line">a = [1, 3, 1, 2, 5]</span><br><span class="line">a.count(1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python16.png" alt="16"></p>
<h2 id="Python求某个元素的索引"><a href="#Python求某个元素的索引" class="headerlink" title="Python求某个元素的索引"></a><font size="4">Python求某个元素的索引</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.index(data, begin, end) 从begin到end-1中索引第一次出现data的位置，默认从第一个元素到最后一个元素</span><br><span class="line">a = [1, 3, 1, 2, 5]</span><br><span class="line">a.index(1)</span><br><span class="line">a.index(1, 1, 3)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python17.png" alt="17"></p>
<h2 id="Python将列表翻转"><a href="#Python将列表翻转" class="headerlink" title="Python将列表翻转"></a><font size="4">Python将列表翻转</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1, 3, 1, 2, 5]</span><br><span class="line"></span><br><span class="line"># 通过索引翻转[::-1]</span><br><span class="line">a[::-1]</span><br><span class="line"></span><br><span class="line"># obj.reverse() 将列表反转</span><br><span class="line">a.reverse()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python18.png" alt="18"></p>
<h2 id="Python将列表排序"><a href="#Python将列表排序" class="headerlink" title="Python将列表排序"></a><font size="4">Python将列表排序</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># obj.sort(key, reverse=False) 将obj按照关键字key进行排序，reverse=False默认为从小到大排序，reverse=True为从大到小排序</span><br><span class="line">a = [1, 3, 1, 2, 5]</span><br><span class="line">a.sort()</span><br><span class="line">a.sort(reverse=True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python19.png" alt="19"></p>
<h1 id="List小结"><a href="#List小结" class="headerlink" title="List小结"></a><font size="5" color="red">List小结</font></h1><p>  List列表是Python中最灵活的一种结构，没有任何的限制，可以代替栈和队列的各种操作，因此使用的频率也是非常高的，所以要灵活掌握List的应用。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Python基础</title>
    <url>/2019/09/10/python_foundation/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python.jpg" alt="2"></p>
<h1 id="Python介绍"><a href="#Python介绍" class="headerlink" title="Python介绍"></a><font size="5" color="red">Python介绍</font></h1><p>  在前面已经介绍了Python的由来，这里主要介绍Python的基础知识，包括Python运算和Python结构。<br><a id="more"></a></p>
<h1 id="Python运算"><a href="#Python运算" class="headerlink" title="Python运算"></a><font size="5" color="red">Python运算</font></h1><p><img src="/images/LANGUAGE/python3.jpg" alt="3"></p>
<h2 id="Python创建变量"><a href="#Python创建变量" class="headerlink" title="Python创建变量"></a><font size="4">Python创建变量</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># Python中的常用数据类型可以直接赋值即定义，和C，Java等语言不同，且可以同时赋值多个变量</span><br><span class="line">a = 10</span><br><span class="line">b = 3.14</span><br><span class="line">c, d = 'Hello Python', True</span><br><span class="line"></span><br><span class="line"># 可以用type(obj) 查看创建的变量类型，isinstance(obj, type)查看变量obj和type是否为相同类型</span><br><span class="line">type(a)</span><br><span class="line">type(b)</span><br><span class="line">isinstance(c, str)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python1.png" alt="1"></p>
<h2 id="Python算术运算"><a href="#Python算术运算" class="headerlink" title="Python算术运算"></a><font size="4">Python算术运算</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># +(加)，-(减)，*(乘)，/(除)，//(地板除)，**(乘方)，%(求余)，整数除法/可以得到小数，和C，Java等语言不同</span><br><span class="line">a, b = 9, 4</span><br><span class="line">a / b</span><br><span class="line">a // b</span><br><span class="line">a ** b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python2.png" alt="2"></p>
<h2 id="Python关系运算"><a href="#Python关系运算" class="headerlink" title="Python关系运算"></a><font size="4">Python关系运算</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># &gt;(大于)，&lt;(小于)，&gt;=(大于等于)，&lt;=(小于等于)，==(等于)，!=(不等于)，和C，Java等语言不同，字符串也可以直接比较大小，字符串之间根据ASCII码值越大则字符串越大，先比较第一个，如果相同继续向下比较</span><br><span class="line">a, b = 3.14, 1.414</span><br><span class="line">c, d = 'Hello', 'Python'</span><br><span class="line">a &gt; b</span><br><span class="line">c &gt; d</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python108.png" alt="108"></p>
<h2 id="Python逻辑运算"><a href="#Python逻辑运算" class="headerlink" title="Python逻辑运算"></a><font size="4">Python逻辑运算</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># and(与)，or(或)，not(非)，和C，Java等语言不同，用&amp;&amp;，||，!表示与或非</span><br><span class="line">a, b = True, False</span><br><span class="line">a and b</span><br><span class="line">a or b</span><br><span class="line">not a</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python3.png" alt="3"></p>
<h2 id="Python条件表达式"><a href="#Python条件表达式" class="headerlink" title="Python条件表达式"></a><font size="4">Python条件表达式</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># x if condition else y 判断condition，为真则x，为假则y，和C，Java等语言不同(b?x:y)</span><br><span class="line">a, b, c, d = 1, 2, 3, 4</span><br><span class="line">x = a if c &gt; d else b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python4.png" alt="4"></p>
<h1 id="Python结构"><a href="#Python结构" class="headerlink" title="Python结构"></a><font size="5" color="red">Python结构</font></h1><p><img src="/images/LANGUAGE/python4.jpg" alt="4"></p>
<h2 id="Python条件结构"><a href="#Python条件结构" class="headerlink" title="Python条件结构"></a><font size="4">Python条件结构</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># Python条件结构if condition1: 语句1 elif condition2: 语句2 else 语句3 先判断if后面的condition1是否成立，如果成立则执行语句1并结束判断，否则判断elif后面的condition2是否成立，如果成立则执行语句2并结束判断，否则执行语句3，和C，Java等语言不同(if ... else if ... else ...)</span><br><span class="line"># if condition1:</span><br><span class="line">#     语句1</span><br><span class="line"># elif condition2:</span><br><span class="line">#     语句2</span><br><span class="line"># else:</span><br><span class="line">#     语句3</span><br><span class="line">if 3 &gt; 5:</span><br><span class="line">    a = 1</span><br><span class="line">elif 3 &lt; 5:</span><br><span class="line">    a = 2</span><br><span class="line">else:</span><br><span class="line">    a = 3</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python5.png" alt="5"></p>
<h2 id="Python循环结构-while"><a href="#Python循环结构-while" class="headerlink" title="Python循环结构(while)"></a><font size="4">Python循环结构(while)</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># while condition: 循环语句 while循环，先判断condition是否满足，如果满足则进入循环执行循环语句，否则循环结束，和C，Java等语言不同(还有do ... while)</span><br><span class="line"># while condition:</span><br><span class="line">#     循环语句</span><br><span class="line">res, i = 0, 1</span><br><span class="line">while i &lt; 10:</span><br><span class="line">    res, i = res + i, i + 1</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python6.png" alt="6"></p>
<h2 id="Python循环结构-for"><a href="#Python循环结构-for" class="headerlink" title="Python循环结构(for)"></a><font size="4">Python循环结构(for)</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># range(start=0, end, step=1) 从start开始到end-1，start默认为0，step默认为1，返回步长为step的所有数字组成的迭代器</span><br><span class="line"></span><br><span class="line"># for target in iterable: 循环语句 for循环，target从可迭代对象iterable中逐次取出然后执行循环语句，和C，Java等语言不同(for(初始条件;终止条件;自变量变化操作))</span><br><span class="line"># for target in iterable:</span><br><span class="line">#     循环语句</span><br><span class="line">res = 0</span><br><span class="line">for i in range(1, 10):</span><br><span class="line">    res += i</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python7.png" alt="7"></p>
<h2 id="break，continue语句"><a href="#break，continue语句" class="headerlink" title="break，continue语句"></a><font size="4">break，continue语句</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 对于循环结构来说，break和continue语句非常重要，用法和C，Java等语言相同</span><br><span class="line"># break：终止并跳出循环</span><br><span class="line"># continue：终止本次循环，进入下一次循环</span><br><span class="line"></span><br><span class="line">res_break, res_continue = 0, 0</span><br><span class="line"></span><br><span class="line"># 1 + 2 + 3 + 4 = 10</span><br><span class="line">for i in range(1, 10):</span><br><span class="line">    if i == 5:</span><br><span class="line">        break </span><br><span class="line">    res_break += i</span><br><span class="line"></span><br><span class="line"># 1 + 2 + 3 + 4 + 6 + 7 + 8 + 9 = 40</span><br><span class="line">for i in range(1, 10):</span><br><span class="line">    if i == 5:</span><br><span class="line">        continue</span><br><span class="line">    res_continue += i</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LANGUAGE/python8.png" alt="8"></p>
<h1 id="Python小结"><a href="#Python小结" class="headerlink" title="Python小结"></a><font size="5" color="red">Python小结</font></h1><p>  基础部分每种语言都大同小异，因为基础部分是所有语言的基础，学习每一种语言都离不开运算操作和算法结构，虽然难度较小，但是非常重要，无论以后从事什么样的研究，基础能力都是必不可少的，因此需要熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Git(分布式版本控制系统)</title>
    <url>/2019/09/10/skill%20Git/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Git</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>  <strong>Git:是一个开源的分布式版本控制系统</strong>，可以有效、高速地处理<strong>从很小到非常大的项目</strong>版本管理。特别适合于<strong>企业级项目</strong>的使用，因此也成为了<strong>程序员必备技能</strong>之一。Git中的大多数语句是Linux语句，因为最初它就是由Linux之父Linus Torvalds帮助管理 Linux 内核开发而开发的。<br><a id="more"></a></p>
<h1 id="Git特点"><a href="#Git特点" class="headerlink" title="Git特点"></a><font size="5" color="red">Git特点</font></h1><p>  <font size="3">直接记录快照，而非差异比较，速度非常快。</font><br>  <font size="3">几乎所有操作都是本地执行，方便管理。</font><br>  <font size="3">时刻保存数据完整性，保证信息的不丢失。</font><br>  <font size="3">适合于分布式开发，服务器压力小。</font><br>  <font size="3">开发者之间可以容易的解决冲突。</font></p>
<h1 id="Git关系图"><a href="#Git关系图" class="headerlink" title="Git关系图"></a><font size="5" color="red">Git关系图</font></h1><p>  <font size="3">Git的逻辑较为复杂，一定要理解逻辑图，并记住状态之间的相互转换。</font><br><img src="/images/SKILL/git.png" alt="0"></p>
<h1 id="Git应用"><a href="#Git应用" class="headerlink" title="Git应用"></a><font size="5" color="red">Git应用</font></h1><h2 id="创建管理员身份"><a href="#创建管理员身份" class="headerlink" title="创建管理员身份"></a><font size="4">创建管理员身份</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git config --global user.name XXX 创建管理员用户名XXX</span><br><span class="line"></span><br><span class="line"># git config --global user.email YYY 创建管理员邮箱YYY</span><br></pre></td></tr></tbody></table></figure>
<h2 id="将文件夹变成管理库文件夹"><a href="#将文件夹变成管理库文件夹" class="headerlink" title="将文件夹变成管理库文件夹"></a><font size="4">将文件夹变成管理库文件夹</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git init 创建管理库文件夹</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git1.png" alt="1"></p>
<h2 id="在文件夹中添加文件"><a href="#在文件夹中添加文件" class="headerlink" title="在文件夹中添加文件"></a><font size="4">在文件夹中添加文件</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># touch xxx 添加文件xxx</span><br><span class="line">touch dm01.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git2.png" alt="2"></p>
<h2 id="查看文件的状态"><a href="#查看文件的状态" class="headerlink" title="查看文件的状态"></a><font size="4">查看文件的状态</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git status 查看文件状态(详细叙述)</span><br><span class="line"></span><br><span class="line"># git status -s 查看文件状态(简写)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git3.png" alt="3"></p>
<h2 id="将文件加入文件管理库"><a href="#将文件加入文件管理库" class="headerlink" title="将文件加入文件管理库"></a><font size="4">将文件加入文件管理库</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git add xxx 将xxx文件加入文件管理库</span><br><span class="line">git add dm01.py</span><br><span class="line"></span><br><span class="line"># git add . 将所有文件加入文件管理库</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git4.png" alt="4"></p>
<h2 id="提交文件"><a href="#提交文件" class="headerlink" title="提交文件"></a><font size="4">提交文件</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git commit -m xxx yyy 提交yyy文件到xxx版本中，如果只有xxx，则提交当前所有可提交文件至xxx版本</span><br><span class="line">git commit -m dm01.py</span><br><span class="line"></span><br><span class="line"># git commit --amend --no-edit xxx 将xxx文件添加到最新的版本</span><br><span class="line"></span><br><span class="line"># git commit --amend -m xxx 为最后的版本添加xxx说明</span><br><span class="line"></span><br><span class="line"># git commit --amend 编辑文本说明</span><br><span class="line"></span><br><span class="line"># git commit -am xxx 将所有文件先添加为Staged状态，再进行提交，等价于git add . + git commit -m xxx</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git5.png" alt="5"></p>
<h2 id="编辑文件"><a href="#编辑文件" class="headerlink" title="编辑文件"></a><font size="4">编辑文件</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># vim xxx 用vim编辑xxx文件，文件状态由Unmodified变为Modified，再次提交时需要先add变成Staged状态</span><br><span class="line">vim dm01.py</span><br><span class="line"></span><br><span class="line">print('First addition!')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git6.png" alt="6"></p>
<h2 id="查看之前已提交的更改"><a href="#查看之前已提交的更改" class="headerlink" title="查看之前已提交的更改"></a><font size="4">查看之前已提交的更改</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git log 查看文件的具体信息</span><br><span class="line"></span><br><span class="line"># git log --oneline 查看文件的简要信息</span><br><span class="line"></span><br><span class="line"># git log --graph 以图的形式查看文件的具体信息</span><br><span class="line"></span><br><span class="line"># git log --graph --oneline 以图的形式查看文件的简要信息</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git7.png" alt="7"></p>
<h2 id="查看之前更改的内容"><a href="#查看之前更改的内容" class="headerlink" title="查看之前更改的内容"></a><font size="4">查看之前更改的内容</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git diff 查看Modified与之前提交的区别</span><br><span class="line"></span><br><span class="line"># git diff --cached 查看Stage与之前提交的区别</span><br><span class="line"></span><br><span class="line"># git diff HEAD 同时有Modified和Stage状态，查看总区别</span><br><span class="line"></span><br><span class="line"># git diff ID1, ID2 查看两个历史快照的区别，ID1为之前的，ID2是后面的，其中输入git log --oneline中显示在最前面的编号即为ID</span><br><span class="line">git diff 84cefee 521a873</span><br><span class="line"></span><br><span class="line"># git diff ID 比较ID与当前目录内容</span><br><span class="line">git diff 84cefee</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git8.png" alt="8"></p>
<h2 id="将文件从Staged状态返回至Modified状态"><a href="#将文件从Staged状态返回至Modified状态" class="headerlink" title="将文件从Staged状态返回至Modified状态"></a><font size="4">将文件从Staged状态返回至Modified状态</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">vim dm01.py # 将dm01状态变为红色的M，即为Modified状态</span><br><span class="line"></span><br><span class="line">git add dm01.py #将dm01从红色的M变成绿色的M，即为Staged状态</span><br><span class="line"></span><br><span class="line"># git reset xxx 将xxx从Staged状态返回至Modified状态</span><br><span class="line">git reset dm01.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git9.png" alt="9"></p>
<h2 id="查看每一步的变化"><a href="#查看每一步的变化" class="headerlink" title="查看每一步的变化"></a><font size="4">查看每一步的变化</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git reflog 查看对文件夹进行的所有操作，并且可以得到ID号和对应的指针</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git10.png" alt="10"></p>
<h2 id="回到过去"><a href="#回到过去" class="headerlink" title="回到过去"></a><font size="4">回到过去</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git reset --method HEAD~n 回到前n个版本，method=soft为回滚快照，移动HEAD指向(仓库区域)，method=mixed(默认)为将快照回滚到临时区域，method=hard将快照还原到工作区，可以通过打开文件看到</span><br><span class="line"></span><br><span class="line"># git reset --method ID/point 回到指定的文件号/指针，method同上</span><br><span class="line"></span><br><span class="line"># git checkout ID -- xxx 对xxx文件回到ID状态，内容也会改变</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git11.png" alt="11"></p>
<h2 id="创建分支"><a href="#创建分支" class="headerlink" title="创建分支"></a><font size="4">创建分支</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git branch 查看所有分支和当前所处分支</span><br><span class="line"></span><br><span class="line"># git branch xxx 创建xxx分支</span><br><span class="line">git branch br01</span><br><span class="line"></span><br><span class="line"># git checkout -b xxx 创建xxx分支</span><br><span class="line">git checkout -b br02</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git12.png" alt="12"></p>
<h2 id="切换分支"><a href="#切换分支" class="headerlink" title="切换分支"></a><font size="4">切换分支</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git checkout xxx 切换到xxx分支</span><br><span class="line">git checkout br01</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git13.png" alt="13"></p>
<h2 id="删除分支"><a href="#删除分支" class="headerlink" title="删除分支"></a><font size="4">删除分支</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git branch -d xxx 删除xxx分支，删除时不能位于该分支，该方法不能删除未合并的分支</span><br><span class="line">git branch -d br02</span><br><span class="line"></span><br><span class="line"># git branch -D xxx 删除未合并的xxx分支</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git14.png" alt="14"></p>
<h2 id="合并分支"><a href="#合并分支" class="headerlink" title="合并分支"></a><font size="4">合并分支</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git merge xxx 在当前分支下，合并xxx分支</span><br><span class="line">git merge br01</span><br><span class="line"></span><br><span class="line"># 如果在新分支里面修改提交的文件，在原分支也经过了修改提交，则会出现报错，需要手动修改文件内容，然后再添加提交即可</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git15.png" alt="15"></p>
<h2 id="查看已合并的分支和未合并的分支"><a href="#查看已合并的分支和未合并的分支" class="headerlink" title="查看已合并的分支和未合并的分支"></a><font size="4">查看已合并的分支和未合并的分支</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git branch --merged 查看已合并的分支</span><br><span class="line"></span><br><span class="line">#git branch --no-merged 查看未合并的分支</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git16.png" alt="16"></p>
<h2 id="换基操作"><a href="#换基操作" class="headerlink" title="换基操作"></a><font size="4">换基操作</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git rebase xxx 当一个分支添加功能时，此时如果主分支发生修改，开发人员想基于修改过的主分支接着添加功能，可以使用换基操作，紧接着xxx之后进行修改</span><br></pre></td></tr></tbody></table></figure>
<h2 id="暂存区"><a href="#暂存区" class="headerlink" title="暂存区"></a><font size="4">暂存区</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git stash 将现在的文件放到暂存区中(分支中存在未提交的文件，无法切换分支。此时可以将现在的文件放到暂存区中，然后切换分支)。</span><br><span class="line"></span><br><span class="line"># git stash list 查看暂存区的文件</span><br><span class="line"></span><br><span class="line"># git stash apply stash@{n} 从暂存区中恢复编号为n的文件(默认为最近一个)，暂存区文件不变</span><br><span class="line"></span><br><span class="line"># git stash drop stash@{n} 从暂存区中删除编号为n的文件(默认为最近一个)</span><br><span class="line"></span><br><span class="line"># git stash pop 从暂存区中取出最近的一个文件，暂存区中少一个文件，类似于栈的pop，等价于git stash apply + git stash drop</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git17.png" alt="17"></p>
<h2 id="链接到GitHub"><a href="#链接到GitHub" class="headerlink" title="链接到GitHub"></a><font size="4">链接到GitHub</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 打开GitHub，并新建一个仓库</span><br><span class="line"></span><br><span class="line"># git remote add origin xxx 链接到远程xxx地址，即为GitHub仓库地址</span><br><span class="line"></span><br><span class="line"># git push -u origin yyy 将yyy分支推上去，一般是master分支</span><br></pre></td></tr></tbody></table></figure>
<h2 id="Git三个区域"><a href="#Git三个区域" class="headerlink" title="Git三个区域"></a><font size="4">Git三个区域</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 工作区域：存放项目的地方，可以观察到的文件夹即为工作区域，修改的内容可以通过打开文件看到</span><br><span class="line"></span><br><span class="line"># 临时区域：stage区域，用于临时存放改动，即将提交的区域</span><br><span class="line"></span><br><span class="line"># 仓库区域：最终存放的版本数据，HEAD指向最终提交的内容</span><br></pre></td></tr></tbody></table></figure>
<h2 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a><font size="4">删除文件</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git rm 删除工作区域和临时区域中的文件，但是仓库区域依然可以看到</span><br><span class="line"></span><br><span class="line"># git rm -f 强行删除工作区域和临时区域中的文件</span><br><span class="line">git rm -f dm01.py</span><br><span class="line"></span><br><span class="line"># git rm --cached 删除临时区的文件</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git18.png" alt="18"></p>
<h2 id="修改文件名"><a href="#修改文件名" class="headerlink" title="修改文件名"></a><font size="4">修改文件名</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># git mv old_name new_name 将原文件名old_name换为new_name</span><br><span class="line">git mv dm02.py dm03.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/SKILL/git19.png" alt="19"></p>
<h1 id="Git小结"><a href="#Git小结" class="headerlink" title="Git小结"></a><font size="5" color="red">Git小结</font></h1><p>  Git作为当下最红的分布式版本控制系统，使得程序员之间的协作更为方便，因此各大公司都使用Git作为一项必备技能。因为Git的命令大多为Linux语言，所以习惯于Windows平台的用户需要多多练习。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title>Python介绍</title>
    <url>/2019/09/10/python_introduction/</url>
    <content><![CDATA[<p><img src="/images/LANGUAGE/python.png" alt="0"></p>
<h1 id="python由来"><a href="#python由来" class="headerlink" title="python由来"></a><font size="5" color="red">python由来</font></h1><p>  Python的创始人为荷兰人吉多·范罗苏姆(Guido van Rossum)。1989年圣诞节期间，在阿姆斯特丹，Guido为了打发圣诞节的无趣，决心开发一个新的脚本解释程序。选中Python作为该编程语言的名字，是取自英国20世纪70年代首播的电视喜剧(Monty Python’s Flying Circus)<br><a id="more"></a></p>
<h1 id="语言的比较"><a href="#语言的比较" class="headerlink" title="语言的比较"></a><font size="5" color="red">语言的比较</font></h1><p>  <font size="3">将其他语言翻译成机器语言的工具称为编译器，编译的方式有两种，一种是编译，一种是解释</font><br>  <font size="3">编译型语言：C/C++，Pascal等语言都属于编译型语言，先由编译器生成可执行文件，运行时不需要重新编译，直接使用编译的结果即可，因此程序执行效率高，跨平台能力差。</font><br>  <font size="3">解释型语言：Java，Python等语言都属于解释型语言，运行时由解释器逐行解释每一句源代码，每次运行都需要解释一次，因此程序执行效率低，跨平台能力强。</font><br><img src="/images/LANGUAGE/python1.jpg" alt="1"></p>
<h1 id="Python与C-C-的具体区别"><a href="#Python与C-C-的具体区别" class="headerlink" title="Python与C/C++的具体区别"></a><font size="5" color="red">Python与C/C++的具体区别</font></h1><p>  <font size="3">（1）代码格式，Python中的代码块以缩进标志，具有相同缩进的处于同一代码块，而C/C++以花括号对{}标志。</font><br>  <font size="3">（2）注释形式，Python中的注释以#开始或者以’’’xxx’’’完成大段注释，而C/C++以双斜杠//标志或者/<em>xxx</em>/完成大段注释。</font><br>  <font size="3">（3）定义变量，Python可以直接赋值a=5，而C/C++必须写int a=5。</font><br>  <font size="3">（4）赋值操作，Python可以同时赋值多个a, b=5, 6，而C/C++只能单独赋值。</font><br>  <font size="3">（5）除法操作，Python中对两个整数进行除法时，结果可以为小数，3 / 5 =0.6，而C/C++结果为0。</font><br>  <font size="3">（6）乘方操作，Python中**表示乘方，而C/C++没有乘方操作。</font><br>  <font size="3">（7）逻辑操作，Python中and，or，not表示与或非，而C/C++用&amp;&amp;，||，!表示。</font><br>  <font size="3">（8）条件表达式，Python中x if condition else y 判断condition为条件表达式，而C/C++用condition?x:y表示。</font><br>  <font size="3">（9）条件语句，Python中if … elif… else …，而C/C++用if … else if … else …。</font><br>  <font size="3">（10）自加自减，Python中没有i++或者++i，而C/C++有。</font><br>  <font size="3">（11）do … while语句，Python中没有do … while语句，而C/C++有。</font><br>  <font size="3">（12）大数字运算，Python中支持大整数的运算，而C/C++有数据类型的限制，一旦超过范围会出现问题。</font><br>  <font size="3">（13）：运算，Python中支持冒号运算获取连续索引，而C/C++冒号和问号一起作为三目运算符。</font><br>  <font size="3">（14）索引操作，Python中支持负数索引，-1代表最好一个元素，而C/C++不支持。</font><br>  <font size="3">（15）内置数据结构，Python中具有很多非常好用的内置数据结构，如列表，元组，字典等，而C/C++没有。</font><br>  <font size="3">（16）内置函数，Python中具有很多非常好用的内置函数，如len(), sorted()等，而C/C++没有。</font><br>  <font size="3">（17）内置语法结构，Python中具有很多非常好用的内置语法结构，如with语法，lambda表达式等，而C/C++没有。</font><br>  <font size="3">（18）函数返回值，Python中函数返回值可以同时返回多个值，而C/C++只能返回一个。</font><br>  <font size="3">（19）函数定义，Python中用def加函数名定义，且输入参数没有类型名，而C/C++必须先写返回值的类型名加函数名，且输入参数也必须有类型名。</font><br>  <font size="3">（20）宏定义，Python中没有宏定义，而C/C++可以使用define。</font><br>  <font size="3">（21）指针，Python中没有指针的概念，而C/C++指针是最重要也是最复杂的内容。</font><br>  <font size="3">（22）else，Python中else可以和if, while, for, try结合，而C/C++else一般和if结合在一起。</font><br>  <font size="3">（23）pass，Python中pass代表后面没有内容，也可以用三个小数点(…)表示，而C/C++没有pass，后面没有代码代表没有内容。</font><br>  <font size="3">（24）导入模块，Python中使用import导入模块，而C/C++使用include导入模块。</font><br>  <font size="3">（25）全局变量，Python中使用global在使用处声明，而且在外部也要先定义该变量，而C/C++用extern或者在函数外部直接定义。</font><br>  <font size="3">（26）对象指针，Python中类对象的指针为函数列表中的第一个参数，一般为self，而C/C++用this指针表示。</font><br>  <font size="3">（27）私有变量，Python中在属性前加(__)两个下划线，而C/C++用private定义。</font><br>  <font size="3">（28）动态语言，Python中可以动态给一个对象添加属性或方法，而C/C++必须提前定义，无法动态添加。</font><br>  <font size="3">（29）垃圾回收，Python中利用引用计数为主，隔代回收为辅对垃圾进行回收，而C/C++必须手动回收，也是最重要的环节，保证程序稳定性。</font><br>  <font size="3">（30）for循环，Python中for i in range(a)，并且在for中修改a的值，for循环仍然执行a次，这可能产生问题。</font></p>
<h1 id="Python特点"><a href="#Python特点" class="headerlink" title="Python特点"></a><font size="5" color="red">Python特点</font></h1><p>  <font size="3">简单性：Python语法非常简单，相比于大学通用课程的C省去了最晦涩的指针。</font><br>  <font size="3">简洁性：Python代码量约为Java的五分之一，故有”人生苦短，我用Python”。</font><br>  <font size="3">标准库：Python拥有强大的标准库，能解决大多数使用者的需求。</font><br>  <font size="3">社区强：Python社区非常强大，能够提供大量的第三方模块。</font><br>  <font size="3">可移植：Python由于其开源本质，已经被移植在很多平台。</font></p>
<h1 id="Python小结"><a href="#Python小结" class="headerlink" title="Python小结"></a><font size="5" color="red">Python小结</font></h1><p>  Python被称为胶水语言，主要归功于python库的强大，使得在机器学习，数据挖掘等方向火热的今天受到了广泛的关注，在各个软件排行榜中，Python都以最快的速度上升，由于其简单易学，许多高校也将传统的入门语言从C转向了Python，因此在AI盛行的时代，拥抱Python吧！</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>PyTorch</title>
    <url>/2019/09/08/frame%20pytorch/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">PyTorch</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>PyTorch:</strong>是Facebook公司于2017年1月发布的<strong>神经网络，深度学习开发平台</strong>。但是PyTorch的历史可以追溯到2002年，当时Torch使用了一种小众语言Lua作为借口，使用人数较少，在2017年推出了Python接口的Torch，故称为PyTorch，现在也称为了当下最流行的深度学习框架之一。<br><a id="more"></a></p>
<p><img src="/images/LIBRARY/pytorch.jpg" alt="pytorch"></p>
<h1 id="PyTorch特点"><a href="#PyTorch特点" class="headerlink" title="PyTorch特点"></a><font size="5" color="red">PyTorch特点</font></h1><p>  <font size="3">PyTorch具有高度的简洁性：和TensorFlow1.x版本有较大差距，便于用户使用和理解。</font><br>  <font size="3">PyTorch具有较快的速度：PyTorch的速度表现胜过TensorFlow和Keras等框架。</font><br>  <font size="3">PyTorch使用方便：PyTorch写代码非常的优雅，所思即所写，不用考虑太多关于框架本身的束缚。</font><br>  <font size="3">PyTorch具有活跃的社区，目前由作者亲自维护，供广大用户的学习和交流。</font><br>  <font size="3">PyTorch具有功能强大的可视化组建Visdom，可以在训练时监控训练过程。</font></p>
<h1 id="PyTorch应用"><a href="#PyTorch应用" class="headerlink" title="PyTorch应用"></a><font size="5" color="red">PyTorch应用</font></h1><h2 id="PyTorch创建tensor"><a href="#PyTorch创建tensor" class="headerlink" title="PyTorch创建tensor"></a><font size="4">PyTorch创建tensor</font></h2><h3 id="tensor，arange方法"><a href="#tensor，arange方法" class="headerlink" title="tensor，arange方法"></a><font size="3">tensor，arange方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.tensor(data, dtype) 将data转换为tensor，类型为dtype</span><br><span class="line">a = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"># torch.arange(start, end, steps, dtype) 产生连续的tensor，从start开始到end结束，步长为step</span><br><span class="line">b = torch.arange(1, 10, 2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch1.png" alt="1"></p>
<h3 id="zeros，zeros-like，ones，ones-like，eye方法"><a href="#zeros，zeros-like，ones，ones-like，eye方法" class="headerlink" title="zeros，zeros_like，ones，ones_like，eye方法"></a><font size="3">zeros，zeros_like，ones，ones_like，eye方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.zeros(size, dtype=None) 生成形状为shape值全为0的tensor</span><br><span class="line">a = torch.zeros((2,3))</span><br><span class="line"></span><br><span class="line"># torch.ones(size, dtype=None) 生成形状为shape值全为1的tensor</span><br><span class="line">b = torch.ones((2,3))</span><br><span class="line"></span><br><span class="line"># torch.zeros_like(obj, dtype) 生成形状与array相同，值全为0的tensor</span><br><span class="line">c = torch.zeros_like(b)</span><br><span class="line"></span><br><span class="line"># torch.ones_like(obj, dtype) 生成形状与array相同，值全为1的tensor</span><br><span class="line">d = torch.ones_like(a)</span><br><span class="line"></span><br><span class="line"># torch.eye(n, m) 生成n行m列的单位矩阵，m默认等于n</span><br><span class="line">e = torch.eye(3, 4)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch2.png" alt="2"></p>
<h3 id="rand，randn，randperm，randint方法"><a href="#rand，randn，randperm，randint方法" class="headerlink" title="rand，randn，randperm，randint方法"></a><font size="3">rand，randn，randperm，randint方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.rand(size) 生成形状为size的(0-1)均匀分布随机数</span><br><span class="line">a = torch.rand((2,3))</span><br><span class="line"></span><br><span class="line"># torch.randn(size) 生成形状为size的标准高斯分布随机数</span><br><span class="line">b = torch.randn((2,3))</span><br><span class="line"></span><br><span class="line"># torch.randperm(n) 生成0到n-1整数的随机排列</span><br><span class="line">c = torch.randperm(10)</span><br><span class="line"></span><br><span class="line"># torch.randint(low, high, size) 生成形状为size，最小值为low，最大值为high-1的随机整数</span><br><span class="line">d = torch.randint(1, 10, (3, 3))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch3.png" alt="3"></p>
<h3 id="linspace，logspace方法"><a href="#linspace，logspace方法" class="headerlink" title="linspace，logspace方法"></a><font size="3">linspace，logspace方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.linspace(start, end, steps=100, dtype=None) 将start到stop等分成steps个点(默认为100个点)，包括end点</span><br><span class="line">a = torch.linspace(10, 20, 6)</span><br><span class="line"></span><br><span class="line"># torch.logspace(start, stop, steps=100, base=10.0, dtype=None) 将start到stop等分成steps个点(默认为100个点)，每一个点i的值为base的i次幂</span><br><span class="line">b = torch.logspace(1, 2, 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch4.png" alt="4"></p>
<h3 id="is-tensor，numel，from-numpy，numpy方法"><a href="#is-tensor，numel，from-numpy，numpy方法" class="headerlink" title="is_tensor，numel，from_numpy，numpy方法"></a><font size="3">is_tensor，numel，from_numpy，numpy方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = torch.arange(10, 20, 2)</span><br><span class="line">b = np.arange(10, 20, 2)</span><br><span class="line"></span><br><span class="line"># torch.is_tensor(obj) 判断obj是否为tensor</span><br><span class="line">torch.is_tensor(a)</span><br><span class="line"></span><br><span class="line"># torch.numel(obj) 计算obj中的元素个数</span><br><span class="line">torch.numel(a)</span><br><span class="line"></span><br><span class="line"># torch.from_numpy(ndarray) 将ndarray数组类型转换为tensor</span><br><span class="line">c = torch.from_numpy(b)</span><br><span class="line"></span><br><span class="line"># obj.numpy() 返回obj的ndarray数组类型</span><br><span class="line">d = c.numpy()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch5.png" alt="5"></p>
<h3 id="shape，dtype方法"><a href="#shape，dtype方法" class="headerlink" title="shape，dtype方法"></a><font size="3">shape，dtype方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randint(1, 9, (3, 3))</span><br><span class="line"></span><br><span class="line"># obj.shape 查看obj的形状</span><br><span class="line">a.shape</span><br><span class="line"></span><br><span class="line"># obj.dtype 查看obj的元素类型</span><br><span class="line">a.dtype</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch8.png" alt="8"></p>
<h2 id="PyTorch切片与索引"><a href="#PyTorch切片与索引" class="headerlink" title="PyTorch切片与索引"></a><font size="4">PyTorch切片与索引</font></h2><h3 id="索引"><a href="#索引" class="headerlink" title="[]索引"></a><font size="3">[]索引</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(27).reshape((3, 3, 3))</span><br><span class="line"></span><br><span class="line"># obj[index0][index1]...等价于obj[index0, index1, ...] 索引</span><br><span class="line">a[1][1][1]</span><br><span class="line">a[1, 1, 1]</span><br><span class="line"></span><br><span class="line"># obj[start, end, step] 切片索引</span><br><span class="line">a[0:2, 0:2, 0:2]</span><br><span class="line"></span><br><span class="line"># obj[...] ...可以代替连续的:</span><br><span class="line">a[..., 0]</span><br><span class="line">a[0, ...]</span><br><span class="line">a[0, ..., 0]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch6.png" alt="6"></p>
<h3 id="gather方法"><a href="#gather方法" class="headerlink" title="gather方法"></a><font size="3">gather方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.gather(tensor, dim, index) 按照dim和index对tensor进行索引</span><br><span class="line">b = torch.gather(a, dim=0, index=torch.tensor([[0, 1, 2], [1, 2, 0], [2, 0, 1]])) 按照第一个维度行开始索引，[0, 1, 2]代表第一行的三个元素来自于a中的第一行，第二行，第三行，列按顺序第一列，第二列，第三列，即第一行的元素为a[0][0]，a[1][1]，a[2][2]</span><br><span class="line">c = torch.gather(a, dim=1, index=torch.tensor([[0, 1, 2], [1, 2, 0], [2, 0, 1]])) 按照第二个维度列开始索引，[0, 1, 2]代表第一行的三个元素来自于a中的第一列，第二列，第三列，都属于第一行，即第一行的元素为a[0][0]，a[0][1]，a[0][2]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch2.png" alt="2"></p>
<h2 id="PyTorch维度变换"><a href="#PyTorch维度变换" class="headerlink" title="PyTorch维度变换"></a><font size="4">PyTorch维度变换</font></h2><h3 id="reshape，squeeze，unsqueeze，transpose方法"><a href="#reshape，squeeze，unsqueeze，transpose方法" class="headerlink" title="reshape，squeeze，unsqueeze，transpose方法"></a><font size="3">reshape，squeeze，unsqueeze，transpose方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(12)</span><br><span class="line"></span><br><span class="line"># obj.reshape(shape) 将obj的形状变为shape</span><br><span class="line">b = a.reshape((3, 4))</span><br><span class="line"></span><br><span class="line"># obj.unsqueeze(dim) 在dim上插入一个大小为1的轴</span><br><span class="line">c = b.unsqueeze(1)</span><br><span class="line"></span><br><span class="line"># obj.squeeze(dim) 将大小为1的轴dim删去，默认为所有大小为1的轴，如果大小不为1则不删去</span><br><span class="line">d = c.squeeze()</span><br><span class="line"></span><br><span class="line"># obj.transpose(dim0, dim1) 将obj的轴0和轴1调换，obj.t()将二维obj转置</span><br><span class="line">e = b.transpose(0, 1)</span><br><span class="line">f = b.t()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch9.png" alt="9"></p>
<h3 id="torch-broadcast-tensors方法"><a href="#torch-broadcast-tensors方法" class="headerlink" title="torch.broadcast_tensors方法"></a><font size="3">torch.broadcast_tensors方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(3)</span><br><span class="line">b = torch.ones((3, 3, 3))</span><br><span class="line"></span><br><span class="line"># torch.broadcast_tensors(a, b) 将a广播为b的大小，返回a广播后的tensor和b</span><br><span class="line">c, d = torch.broadcast_tensors(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch10.png" alt="10"></p>
<h2 id="PyTorch合并与分割"><a href="#PyTorch合并与分割" class="headerlink" title="PyTorch合并与分割"></a><font size="4">PyTorch合并与分割</font></h2><h3 id="cat，stack，chunk，split方法"><a href="#cat，stack，chunk，split方法" class="headerlink" title="cat，stack，chunk，split方法"></a><font size="3">cat，stack，chunk，split方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.arange(6).reshape((2, 3))</span><br><span class="line">b = torch.arange(7,13).reshape((2, 3))</span><br><span class="line"></span><br><span class="line"># torch.cat(tensors, dim) 将多个tensors按照dim进行合并</span><br><span class="line">c = torch.cat([a, b], dim=1)</span><br><span class="line"></span><br><span class="line"># tf.stack(tensors, dim) 增加一个新维度，并合并到该维度</span><br><span class="line">d = torch.stack([a, b], dim=0)</span><br><span class="line"></span><br><span class="line"># torch.chunk(tensor, chunks, dim) 对tensor按照dim轴进行拆分成chunks份</span><br><span class="line">e, f = torch.chunk(d, 2, dim=0)</span><br><span class="line"></span><br><span class="line"># torch.split(tensor, split_size_or_sections, dim) 对tensor按照dim轴进行拆分，如果希望均匀拆分则num_or_size_splits为常数，代表每部分的个数(不同于TensorFlow，代表分成多少个部分)，否则输入一个列表，代表每一部分的数量</span><br><span class="line">h = torch.split(d, 1, dim=2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch11.png" alt="11"></p>
<h2 id="PyTorch数据统计"><a href="#PyTorch数据统计" class="headerlink" title="PyTorch数据统计"></a><font size="4">PyTorch数据统计</font></h2><h3 id="max，min方法"><a href="#max，min方法" class="headerlink" title="max，min方法"></a><font size="3">max，min方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randperm(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.max(obj, dim) 求在指定轴dim的最大值及其索引，默认为求全局最大值</span><br><span class="line">b = torch.max(a, dim=0)</span><br><span class="line"></span><br><span class="line"># torch.min(obj, dim) 求在指定轴dim的最小值及其索引，默认为求全局最小值</span><br><span class="line">c = torch.min(a, dim=0)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch12.png" alt="12"></p>
<h3 id="dist，mean，median，mode方法"><a href="#dist，mean，median，mode方法" class="headerlink" title="dist，mean，median，mode方法"></a><font size="3">dist，mean，median，mode方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randint(3, 7, (3, 3), dtype=torch.float32).reshape((3, 3))</span><br><span class="line">b = torch.randint(3, 7, (3, 3), dtype=torch.float32).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.dist(tensor1, tensor2, p) 计算tensor1-tensor2的p范数，要先转换成float32格式进行计算</span><br><span class="line">c = torch.dist(a, b, 2)</span><br><span class="line"></span><br><span class="line"># torch.mean(tensor, dim) 计算tensor的平均值</span><br><span class="line">d = torch.mean(a, dim=0)</span><br><span class="line"></span><br><span class="line"># torch.median(tensor, dim) 计算tensor的中位数及其索引</span><br><span class="line">e = torch.median(a, dim=0)</span><br><span class="line"></span><br><span class="line"># torch.mode(tensor, dim) 计算tensor的众数及其索引</span><br><span class="line">f = torch.mode(a, dim=0)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch13.png" alt="13"></p>
<h3 id="sort，topk方法"><a href="#sort，topk方法" class="headerlink" title="sort，topk方法"></a><font size="3">sort，topk方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randperm(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.sort(tensor, dim=None, descending=False) 将tensor按照dim维度进行排序(默认为最后一个维度)，descending=False默认递增排序，descending=True为递减排序</span><br><span class="line">b = torch.sort(a)</span><br><span class="line"></span><br><span class="line"># torch.topk(tensor, k, dim=None, largest=True, sorted=True) 求tensor最大或最小的k个值，dim默认为最后一个维度，largest=True表示最大k个值，largest=False表示最小k个值，sorted=True表示默认排序，sorted=False表示不排序</span><br><span class="line">c = torch.topk(a, 2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch14.png" alt="14"></p>
<h2 id="PyTorch张量限幅"><a href="#PyTorch张量限幅" class="headerlink" title="PyTorch张量限幅"></a><font size="4">PyTorch张量限幅</font></h2><h3 id="clamp方法"><a href="#clamp方法" class="headerlink" title="clamp方法"></a><font size="3">clamp方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randperm(9, dtype=torch.float32).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.clamp(tensor, min, max) 将tensor中，小于min的值赋值为min，大于max的值赋值为max</span><br><span class="line">b = torch.clamp(a, 3, 6)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch16.png" alt="16"></p>
<h2 id="PyTorch数学运算"><a href="#PyTorch数学运算" class="headerlink" title="PyTorch数学运算"></a><font size="4">PyTorch数学运算</font></h2><h3 id="常规运算方法"><a href="#常规运算方法" class="headerlink" title="常规运算方法"></a><font size="3">常规运算方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randint(-4, 5, (3, 3), dtype=torch.float32)</span><br><span class="line">b = torch.randperm(9, dtype=torch.float32).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># tensor1 op tensor2 将tensor1与tensor2进行常规的数学运算，如果维度大小不同，则进行广播，如果不能广播则报错</span><br><span class="line">a + b</span><br><span class="line">a * b</span><br><span class="line"></span><br><span class="line"># torch.abs(tensor) 求tensor的绝对值</span><br><span class="line">torch.abs(a)</span><br><span class="line"></span><br><span class="line"># torch.sqrt(tensor) 求tensor的平方根</span><br><span class="line">torch.sqrt(b)</span><br><span class="line"></span><br><span class="line"># torch.sin(tensor) 求tensor的正弦值</span><br><span class="line">torch.sin(a)</span><br><span class="line"></span><br><span class="line"># torch.exp(tensor) 求e的tensor次幂</span><br><span class="line">torch.exp(a)</span><br><span class="line"></span><br><span class="line"># torch.log(tensor) 求tensor以自然对数为底的值</span><br><span class="line">torch.log(b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch15.png" alt="15"></p>
<h3 id="ceil，floor，round，frac，trunc方法"><a href="#ceil，floor，round，frac，trunc方法" class="headerlink" title="ceil，floor，round，frac，trunc方法"></a><font size="3">ceil，floor，round，frac，trunc方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.rand((3, 3)) * 10</span><br><span class="line"></span><br><span class="line"># torch.ceil(tensor) 将tensor的小数部分上取整</span><br><span class="line">b = torch.ceil(a)</span><br><span class="line"></span><br><span class="line"># torch.floor(tensor) 将tensor的小数部分下取整</span><br><span class="line">c = torch.floor(a)</span><br><span class="line"></span><br><span class="line"># torch.round(tensor) 将tensor的小数部分四舍五入</span><br><span class="line">d = torch.round(a)</span><br><span class="line"></span><br><span class="line"># torch.frac(tensor) 保留tensor的小数部分</span><br><span class="line">e = torch.frac(a)</span><br><span class="line"></span><br><span class="line"># torch.trunc(tensor) 保留tensor的整数部分</span><br><span class="line">f = torch.trunc(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch17.png" alt="17"></p>
<h3 id="sign，sigmoid，kthvalue方法"><a href="#sign，sigmoid，kthvalue方法" class="headerlink" title="sign，sigmoid，kthvalue方法"></a><font size="3">sign，sigmoid，kthvalue方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randn((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.sign(tensor) 求tensor作用在符号函数上的值</span><br><span class="line">b = torch.sign(a)</span><br><span class="line"></span><br><span class="line"># torch.sigmoid(tensor) 求tensor作用在sigmoid函数上的值</span><br><span class="line">c = torch.sigmoid(a)</span><br><span class="line"></span><br><span class="line"># torch.kthvalue(tensor, k, dim=None) 求tensor第k小的值，dim默认为最后一个维度</span><br><span class="line">d = torch.kthvalue(a, 2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch18.png" alt="18"></p>
<h3 id="eq，equal方法"><a href="#eq，equal方法" class="headerlink" title="eq，equal方法"></a><font size="3">eq，equal方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randint(1, 5, (3, 3))</span><br><span class="line">b = torch.randint(1, 5, (3, 3))</span><br><span class="line"></span><br><span class="line"># torch.eq(tensor1, tensor2) 等价于tensor1 == tensor2，比较tensor1和tensor2是否相等，在如果相等则对应位置为True，否则为False</span><br><span class="line">torch.eq(a, b)</span><br><span class="line"></span><br><span class="line"># torch.equal(tensor1, tensor2) 比较tensor1和tensor2是否相等，如果相等则返回True，否则为False</span><br><span class="line">torch.equal(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch19.png" alt="19"></p>
<h2 id="PyTorch线性代数"><a href="#PyTorch线性代数" class="headerlink" title="PyTorch线性代数"></a><font size="4">PyTorch线性代数</font></h2><h3 id="diag，trace，tril，triu方法"><a href="#diag，trace，tril，triu方法" class="headerlink" title="diag，trace，tril，triu方法"></a><font size="3">diag，trace，tril，triu方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randperm(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.diag(tensor, diagonal=0) 如果tensor为一维张量，返回二维张量，如果tensor为二维张量，返回对角线张量，diagonal代表对角线的偏移量</span><br><span class="line">b = torch.diag(a)</span><br><span class="line"></span><br><span class="line"># torch.trace(tensor) 求tensor的迹</span><br><span class="line">c = torch.trace(a)</span><br><span class="line"></span><br><span class="line"># torch.tril(tensor, k=0) 返回tensor的下三角张量，偏移为k</span><br><span class="line">d = torch.tril(a)</span><br><span class="line"></span><br><span class="line"># torch.triu(tensor, k=0) 返回tensor的上三角张量，偏移为k</span><br><span class="line">e = torch.triu(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch20.png" alt="20"></p>
<h3 id="inverse，eig，svd方法"><a href="#inverse，eig，svd方法" class="headerlink" title="inverse，eig，svd方法"></a><font size="3">inverse，eig，svd方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randperm(9, dtype=torch.float32).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># torch.inverse(tensor) 求tensor的逆矩阵</span><br><span class="line">b = torch.inverse(a)</span><br><span class="line"></span><br><span class="line"># torch.eig(tensor, eigenvectors=False) 求tensor的特征值，eigenvectors=False默认不计算特征向量，eigenvectors=True计算特征向量</span><br><span class="line">c = torch.eig(a, True)</span><br><span class="line"></span><br><span class="line"># torch.svd(tensor) 求tensor的奇异值分解</span><br><span class="line">U, S, V = torch.svd(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch21.png" alt="21"></p>
<h3 id="dot，mm，mv方法"><a href="#dot，mm，mv方法" class="headerlink" title="dot，mm，mv方法"></a><font size="3">dot，mm，mv方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">a = torch.randperm(9).reshape((3, 3))</span><br><span class="line">b = torch.tensor([1, 2, 3])</span><br><span class="line"></span><br><span class="line"># torch.dot(tensor1, tensor2) 两个一维向量点乘</span><br><span class="line">c = torch.dot(b, b)</span><br><span class="line"></span><br><span class="line"># torch.mm(tensor1, tensor2) 矩阵乘法</span><br><span class="line">d = torch.mm(a, a)</span><br><span class="line"></span><br><span class="line"># torch.mv(tensor1, tensor2) 矩阵tensor1乘向量tensor2</span><br><span class="line">e = torch.mv(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pytorch22.png" alt="22"></p>
<h2 id="PyTorch深度学习"><a href="#PyTorch深度学习" class="headerlink" title="PyTorch深度学习"></a><font size="4">PyTorch深度学习</font></h2><h3 id="functional-函数-模块"><a href="#functional-函数-模块" class="headerlink" title="functional(函数)模块"></a><font size="3">functional(函数)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from torch.nn import functional as f</span><br><span class="line"></span><br><span class="line"># f.relu(input) ReLu激活函数</span><br><span class="line"></span><br><span class="line"># f.sigmoid(input) Sigmoid激活函数</span><br><span class="line"></span><br><span class="line"># f.tanh(input) tanh激活函数</span><br><span class="line"></span><br><span class="line"># f.softmax(input) softmax层</span><br><span class="line"></span><br><span class="line"># f.mse_loss(input, target) 计算input和target的均方差</span><br><span class="line"></span><br><span class="line"># f.binary_cross_entropy(input, target) 计算input和target二分类交叉熵</span><br><span class="line"></span><br><span class="line"># f.cross_entropy(input, target)计算input和target的交叉熵，里面内置了softmax层，因此不需要先经过softmax</span><br></pre></td></tr></tbody></table></figure>
<h3 id="autograd-自动求导-模块"><a href="#autograd-自动求导-模块" class="headerlink" title="autograd(自动求导)模块"></a><font size="3">autograd(自动求导)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.tensor(data ,requires_grad=True) 创建时使其具有可导属性</span><br><span class="line"></span><br><span class="line"># obj.requires_grad_() 使已经创建的obj具有可导属性</span><br><span class="line"></span><br><span class="line"># torch.autograd.grad(outputs, inputs) outputs对inputs进行自动求导，前提是保证inputs具有可导属性</span><br><span class="line">torch.autograd.grad(res, w)</span><br><span class="line"></span><br><span class="line"># obj.backward() 对obj进行从后向前自动求导，然后调用变量的grad成员变量即可得到其导数</span><br><span class="line">res.backward()</span><br><span class="line">w.grad</span><br></pre></td></tr></tbody></table></figure>
<h3 id="optim-优化器-模块"><a href="#optim-优化器-模块" class="headerlink" title="optim(优化器)模块"></a><font size="3">optim(优化器)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.optim.SGD(lr=0.01, momentum=0.0, dampending=0, weight_decay=0.0, nesterov=False) 随机梯度下降优化器，学习率lr默认为0.01，动量momentum默认为0，动量抑制因子为0，学习率衰减decay默认为0，默认不使用nesterov动量</span><br><span class="line"></span><br><span class="line"># torch.optim.RMSprop(lr=0.001, alpha=0.9, eps=None, weight_decay=0.0, momentum=0.0) RMSProp优化器，学习率lr默认为0.001，参数alpha默认为0.99，模糊因子epsilon默认为None，学习率衰减weight_decay默认为0，动量momentum默认为0</span><br><span class="line"></span><br><span class="line"># torch.optim.Adam(lr=0.001, betas=(0.9, 0.999), eps=None, weight_decay=0.0) Adam优化器，学习率lr默认为0.001，参数beta_1默认为0.9, 参数beta_2默认为0.999，模糊因子epsilon默认为None，学习率衰减weight_decay默认为0</span><br></pre></td></tr></tbody></table></figure>
<h3 id="CPU与GPU模块"><a href="#CPU与GPU模块" class="headerlink" title="CPU与GPU模块"></a><font size="3">CPU与GPU模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.device(device) 返回设备对象</span><br><span class="line">device = torch.device('cuda:0')</span><br><span class="line"></span><br><span class="line"># obj.to(device) 返回一个device设备上的对象</span><br><span class="line">a = a.to(device)</span><br><span class="line"></span><br><span class="line"># obj.cpu() 返回一个CPU对象</span><br><span class="line"></span><br><span class="line"># obj.cuda() 返回一个GPU对象</span><br></pre></td></tr></tbody></table></figure>
<h3 id="datasets-数据集-模块"><a href="#datasets-数据集-模块" class="headerlink" title="datasets(数据集)模块"></a><font size="3">datasets(数据集)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torchvision.datasets as dsets</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line"># dsets.XXX(root, train=True, transform, download=False) 从root为打开本地目录下载XXX数据集，train=True默认为训练集，train=False为测试集，download=False默认为不从网上下载，download=True为从网站上下载，数据预处理的部分为transform</span><br><span class="line">train = dsets.MNIST(root='mnist', train=True, transform=torchvision.transforms.ToTensor(), download=False)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="data-数据-模块"><a href="#data-数据-模块" class="headerlink" title="data(数据)模块"></a><font size="3">data(数据)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch.utils.data as Data</span><br><span class="line"></span><br><span class="line"># Data.DataLoader(datasets, batch_size, shuffle=False) 读取已经加载的数据集datasets，并且分成batch，每个batch的大小为batch_size，shuffle=False默认不打乱顺序，shuffle=True为打乱batch的顺序</span><br><span class="line"></span><br><span class="line"># Data.random.split(data, [train_size, test_size]) 将data分成训练集和测试集，每部分大小为[train_size, test_size]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="nn-神经网络-模块"><a href="#nn-神经网络-模块" class="headerlink" title="nn(神经网络)模块"></a><font size="3">nn(神经网络)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"># nn.Sequential() 时序容器，可以传入多个网络，和TensorFlow不同，只能一个一个传入，并用逗号分隔</span><br><span class="line"></span><br><span class="line"># nn.Linear(in_features, out_features) 创建线性层，输入维度为in_features，输出维度为out_features</span><br><span class="line"></span><br><span class="line"># nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0) 创建一个卷积层，输入信号通道为in_channels，输出信号通道为out_channels，卷积核大小为kernel_size，核移动的步长为stride，padding为补0的层数</span><br><span class="line"></span><br><span class="line"># nn.MaxPool2d(kernel_size, stride=None, padding=0) 创建一个最大值池化层(平均值池化为AvgPool2d)，核大小为kernel_size，核移动的步长默认为核的大小，padding为补0的层数</span><br><span class="line"></span><br><span class="line"># nn.BatchNorm1d(num_features, eps=1e-5, momentum=0.1, affine=True) 创建标准化层(二维为BatchNorm2d)，num_features为要训练的数据量，</span><br><span class="line"></span><br><span class="line"># nn.RNN(input_size, hidden_size, num_layers, nonlinearity='tanh') 创建RNN层，输入特征数量input_size，隐层结点数hidden_size，RNN层数num_layers，非线性激活函数nonlinearity默认为tanh </span><br><span class="line"></span><br><span class="line"># nn.LSTM(input_size, hidden_size, num_layers, nonlinearity='tanh') 创建长短期记忆网络层，输入特征数量input_size，隐层结点数hidden_size，RNN层数num_layers，非线性激活函数nonlinearity默认为tanh </span><br><span class="line"></span><br><span class="line"># nn.Dropout(p=0.5) 创建dropout层(二维为Dropout2d)，随机丢弃结点的概率为p，默认为0.5</span><br><span class="line"></span><br><span class="line"># nn.Module 自定义网络层的基类</span><br><span class="line">class MyLayer(nn.Module):</span><br><span class="line">    def __init__(self, input_dim, output_dim):</span><br><span class="line">        super(MyLayer, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.kernel = nn.Parameter(torch.randn(input_dim, output_dim))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(output_dim))</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        out = inputs @ self.kernel + self.bias</span><br><span class="line">        return out</span><br></pre></td></tr></tbody></table></figure>
<h3 id="transforms-数据变换-模块"><a href="#transforms-数据变换-模块" class="headerlink" title="transforms(数据变换)模块"></a><font size="3">transforms(数据变换)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torchvision.transforms as transforms</span><br><span class="line"></span><br><span class="line"># transforms.Normalize(mean, std) 标准化操作(类方法)</span><br><span class="line"></span><br><span class="line"># transforms.RandomRotation(n) 将图片旋转-n到n度</span><br><span class="line"></span><br><span class="line"># transforms.ToTensor() 将numpy图片转换为tensor</span><br><span class="line"></span><br><span class="line"># transforms.ToPILImage() 将tensor转换为numpy图片形式</span><br></pre></td></tr></tbody></table></figure>
<h3 id="models-模型-模块"><a href="#models-模型-模块" class="headerlink" title="models(模型)模块"></a><font size="3">models(模型)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torchvision.models as models</span><br><span class="line"></span><br><span class="line"># models.resnet18(pretrained=False) 获得resnet18网络结构，默认是没有经过训练的，pretrained=True是获得经过训练的参数，便于在少样本时进行迁移学习</span><br><span class="line"></span><br><span class="line"># models.AlexNet(pretrained=False) 获得AlexNet网络结构，默认是没有经过训练的，pretrained=True是获得经过训练的参数，便于在少样本时进行迁移学习</span><br><span class="line"></span><br><span class="line"># models.VGG16(pretrained=False) 获得VGG16网络结构，默认是没有经过训练的，pretrained=True是获得经过训练的参数，便于在少样本时进行迁移学习</span><br></pre></td></tr></tbody></table></figure>
<h3 id="save-保持-模块"><a href="#save-保持-模块" class="headerlink" title="save(保持)模块"></a><font size="3">save(保持)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># torch.save(obj, filename) 将obj保存在以.pkl结尾的filename文件中</span><br><span class="line"></span><br><span class="line"># torch.load(filename) 读取filename文件中的数据信息</span><br></pre></td></tr></tbody></table></figure>
<h1 id="PyTorch小结"><a href="#PyTorch小结" class="headerlink" title="PyTorch小结"></a><font size="5" color="red">PyTorch小结</font></h1><p>  由于PyTorch的简洁性和优雅性，使得PyTorch对于入门学习的人来说非常的友好，现在PyTorch也是最热门的深度学习框架之一，具有较大的潜力。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>深度学习框架</category>
      </categories>
  </entry>
  <entry>
    <title>TensorFlow</title>
    <url>/2019/09/06/frame%20TensorFlow/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">TensorFlow</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  <strong>TensorFlow:</strong>是谷歌公司于2015年11月9日推出的一个划时代的<strong>神经网络，深度学习开发平台</strong>。TensorFlow是一个庞大的系统，结构复杂，功能强大，利用<strong>数据流图(Data Flow Graphs)</strong>进行数值计算的开源软件库，数据流图中的<strong>结点(Node)</strong>代表数学运算操作，<strong>边(Edge)</strong>代表节点之间流通的数据，即张量(Tensor)。<br><a id="more"></a></p>
<p><img src="/images/FRAME/tensorflow.jpg" alt="tensorflow"></p>
<h1 id="TensorFlow特点"><a href="#TensorFlow特点" class="headerlink" title="TensorFlow特点"></a><font size="5" color="red">TensorFlow特点</font></h1><p>  <font size="3">TensorFlow具有高度的灵活性：只要能够将计算表示为一个数据流，就可以使用TensorFlow进行运算。</font><br>  <font size="3">TensorFlow具有强的可移植性：TensorFlow支持CPU和GPU运算，并且可以运行在个人电脑，服务器，移动设备等。</font><br>  <font size="3">TensorFlow运算简单：内部实现了自动求导方式，像搭积木一样，只要建好运算图，不需要关心求导的复杂程度。</font><br>  <font size="3">TensorFlow具有功能强大的可视化组建TensorBoard，可以在训练时监控训练过程。</font></p>
<h1 id="TensorFlow应用"><a href="#TensorFlow应用" class="headerlink" title="TensorFlow应用"></a><font size="5" color="red">TensorFlow应用</font></h1><h2 id="TensorFlow创建tensor"><a href="#TensorFlow创建tensor" class="headerlink" title="TensorFlow创建tensor"></a><font size="4">TensorFlow创建tensor</font></h2><h3 id="constant方法"><a href="#constant方法" class="headerlink" title="constant方法"></a><font size="3">constant方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># tf.constant(value, dtype=None, shape=None) 创建一个形状为shape，类型为dtype，值为value的张量</span><br><span class="line">a = tf.constant([[1, 2, 3], [4, 5, 6]])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow1.png" alt="1"></p>
<h3 id="CPU，GPU方法"><a href="#CPU，GPU方法" class="headerlink" title="CPU，GPU方法"></a><font size="3">CPU，GPU方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([[1, 2, 3], [4, 5, 6]])</span><br><span class="line"></span><br><span class="line"># obj.device() 查看tensor的环境是CPU还是GPU</span><br><span class="line">a.device</span><br><span class="line"></span><br><span class="line"># obj.gpu() 返回一个新tensor位于GPU </span><br><span class="line">b = a.gpu()</span><br><span class="line"></span><br><span class="line"># obj.cpu() 返回一个新tensor位于CPU</span><br><span class="line">c = b.cpu()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow2.png" alt="3"></p>
<h3 id="numpy，shape，ndim，dtype方法"><a href="#numpy，shape，ndim，dtype方法" class="headerlink" title="numpy，shape，ndim，dtype方法"></a><font size="3">numpy，shape，ndim，dtype方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([[1, 2, 3], [4, 5, 6]])</span><br><span class="line"></span><br><span class="line"># obj.numpy() 返回一个新的ndarray，即将tensor变成numpy数组</span><br><span class="line">b = a.numpy</span><br><span class="line"></span><br><span class="line"># obj.shape 查看tensor的维度信息</span><br><span class="line">a.shape</span><br><span class="line"></span><br><span class="line"># obj.ndim 查看tensor的维度数</span><br><span class="line">a.ndim</span><br><span class="line"></span><br><span class="line"># obj.dtype 查看tensor的类型</span><br><span class="line">a.dtype</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow3.png" alt="3"></p>
<h3 id="convert-to-tensor，cast方法"><a href="#convert-to-tensor，cast方法" class="headerlink" title="convert_to_tensor，cast方法"></a><font size="3">convert_to_tensor，cast方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2, 3], [4, 5, 6]])</span><br><span class="line"></span><br><span class="line"># tf.convert_to_tensor(value, dtype=None) 将value转换为tensor形式，常用来将numpy格式转换为tensor格式</span><br><span class="line">b = tf.convert_to_tensor(a)</span><br><span class="line"></span><br><span class="line"># tf.cast(value, dtype) 返回一个值为value，类型为dtype的tensor，常用来修改tensor的类型</span><br><span class="line">c = tf.cast(b, dtype=tf.float32)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow4.png" alt="4"></p>
<h3 id="zeros，ones，fill，random方法"><a href="#zeros，ones，fill，random方法" class="headerlink" title="zeros，ones，fill，random方法"></a><font size="3">zeros，ones，fill，random方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># tf.zeros(shape) 产生形状为shape的值全为0的tensor</span><br><span class="line">a = tf.zeros((3, 3))</span><br><span class="line"></span><br><span class="line"># tf.ones(shape) 产生形状为shape的值全为1的tensor</span><br><span class="line">b = tf.ones((3, 3))</span><br><span class="line"></span><br><span class="line"># tf.fill(shape, value) 产生形状为shape的值全为value的tensor</span><br><span class="line">c = tf.fill((3, 3), -1) </span><br><span class="line"></span><br><span class="line"># tf.random.normal(shape, mean=0, stddev=1) 产生形状为shape的高斯分布，均值默认为0，标准差默认为1</span><br><span class="line">d = tf.random.normal((3, 3)) </span><br><span class="line"></span><br><span class="line"># tf.random.uniform(shape, mean=0, stddev=1) 产生形状为shape的均匀分布，默认为(0-1)均匀分布</span><br><span class="line">e = tf.random.uniform((3, 3)) </span><br><span class="line"></span><br><span class="line"># tf.random.shuffle(value, seed) 将value按照种子seed打散</span><br><span class="line">f = tf.random.shuffle(d)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow5.png" alt="5"></p>
<h3 id="zeros-like，ones-like，one-hot，range方法"><a href="#zeros-like，ones-like，one-hot，range方法" class="headerlink" title="zeros_like，ones_like，one_hot，range方法"></a><font size="3">zeros_like，ones_like，one_hot，range方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.random.normal((3, 3))</span><br><span class="line"></span><br><span class="line"># tf.zeros_like(input, dtype) 产生一个大小和input相同值为全0的tensor</span><br><span class="line">b = tf.zeros_like(a)</span><br><span class="line"></span><br><span class="line"># tf.ones_like(input, dtype) 产生一个大小和input相同值为全1的tensor</span><br><span class="line">c = tf.ones_like(a)</span><br><span class="line"></span><br><span class="line"># tf.range(start, end, interval, dtype) 产生从start到end，步长为interval的连续张量，用法同numpy中的arange</span><br><span class="line">d = tf.range(10)</span><br><span class="line"></span><br><span class="line"># tf.one_hot(indices, depth) 将indices转换为独热编码，深度为depth</span><br><span class="line">e = tf.one_hot(d, depth=10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow6.png" alt="6"></p>
<h2 id="TensorFlow切片与索引"><a href="#TensorFlow切片与索引" class="headerlink" title="TensorFlow切片与索引"></a><font size="4">TensorFlow切片与索引</font></h2><h3 id="索引"><a href="#索引" class="headerlink" title="[]索引"></a><font size="3">[]索引</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(27).reshape((3, 3, 3))</span><br><span class="line">b = tf.convert_to_tensor(a)</span><br><span class="line"></span><br><span class="line"># obj[index0][index1]...等价于obj[index0, index1, ...] 索引</span><br><span class="line">b[1][1][1]</span><br><span class="line">b[1, 1, 1]</span><br><span class="line"></span><br><span class="line"># obj[start, end, step] 切片索引</span><br><span class="line">b[0:2, 0:2, 0:2]</span><br><span class="line"></span><br><span class="line"># obj[...] ...可以代替连续的:</span><br><span class="line">b[..., 0]</span><br><span class="line">b[0, ...]</span><br><span class="line">b[0, ..., 0]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow7.png" alt="7"></p>
<h3 id="gather，gather-nd，boolean-mask方法"><a href="#gather，gather-nd，boolean-mask方法" class="headerlink" title="gather，gather_nd，boolean_mask方法"></a><font size="3">gather，gather_nd，boolean_mask方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(27).reshape((3, 3, 3))</span><br><span class="line">b = tf.convert_to_tensor(a)</span><br><span class="line"></span><br><span class="line"># tf.gather(obj, axis, indices) 在维度axis上索引indices，并且连接成一个新的tensor</span><br><span class="line">c = tf.gather(b, axis=0, indices=[1, 0]) # 在第一个维度上选择前两个，并且将顺序调换</span><br><span class="line">d = tf.gather(b, axis=1, indices=[1, 0]) # 在第二个维度上选择前两个，并且将顺序调换</span><br><span class="line"></span><br><span class="line"># tf.gather_nd(obj, indices) 在多维度上索引indices，并且连接成一个新的tensor</span><br><span class="line">e = tf.gather_nd(b, indices=[[0, 0], [1, 1]]) # 索引第1个维度的第一个和第2个维度的第二个数据</span><br><span class="line">f = tf.gather_nd(b, indices=[[0, 0, 0], [0, 0, 1], [0, 0, 2]]) # 索引第1个维度的第1行的第1列，第1个维度的第1行的第2列，第1个维度的第1行的第3列</span><br><span class="line"></span><br><span class="line"># tf.boolean_mask(obj, mask, axis) 在axis轴上掩模索引</span><br><span class="line">g = tf.boolean_mask(b, [[True,True,False],[True,False,False],[False,False,False]], axis=0) # 在第一维度上选择前两行，在第二维度上选择第一行，一共三行</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow8.png" alt="8"></p>
<h2 id="TensorFlow维度变化"><a href="#TensorFlow维度变化" class="headerlink" title="TensorFlow维度变化"></a><font size="4">TensorFlow维度变化</font></h2><h3 id="reshape，transpose，expand-dims，squeeze方法"><a href="#reshape，transpose，expand-dims，squeeze方法" class="headerlink" title="reshape，transpose，expand_dims，squeeze方法"></a><font size="3">reshape，transpose，expand_dims，squeeze方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(4).reshape((2, 1, 2))</span><br><span class="line">b = tf.constant(a)</span><br><span class="line"></span><br><span class="line"># tf.reshape(tensor, shape) 返回形状为shape的tensor</span><br><span class="line">c = tf.reshape(a, (2, 2))</span><br><span class="line"></span><br><span class="line"># tf.transpose(tensor, perm=None) 将轴进行调换，默认翻转轴</span><br><span class="line">d = tf.transpose(b, (1, 2, 0))</span><br><span class="line"></span><br><span class="line"># tf.expand_dims(tensor, axis) 在axis上增加一个维度</span><br><span class="line">e = tf.expand_dims(b, axis=3)</span><br><span class="line"></span><br><span class="line"># tf.squeeze(tensor, axis=None) 将axis上为1的维度删去，默认删除所有为1的维度</span><br><span class="line">f = tf.squeeze(e)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow9.png" alt="9"></p>
<h3 id="broadcast-to，tile方法"><a href="#broadcast-to，tile方法" class="headerlink" title="broadcast_to，tile方法"></a><font size="3">broadcast_to，tile方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.range(3)</span><br><span class="line">b = tf.reshape(a, (1, 3))</span><br><span class="line"></span><br><span class="line"># tf.broadcast_to(input, shape) 返回一个广播后的tensor</span><br><span class="line">c = tf.broadcast_to(a, (3, 3))</span><br><span class="line"></span><br><span class="line"># tf.tile(input, multiples) 返回一个经过复制的tensor</span><br><span class="line">d = tf.tile(b, [2, 2])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow10.png" alt="10"></p>
<h2 id="TensorFlow合并与分割"><a href="#TensorFlow合并与分割" class="headerlink" title="TensorFlow合并与分割"></a><font size="4">TensorFlow合并与分割</font></h2><h3 id="concat，stack，unstack，split方法"><a href="#concat，stack，unstack，split方法" class="headerlink" title="concat，stack，unstack，split方法"></a><font size="3">concat，stack，unstack，split方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(6).reshape((2, 3))</span><br><span class="line">b = np.arange(3, 9).reshape((2, 3))</span><br><span class="line">c = tf.constant(a)</span><br><span class="line">d = tf.constant(b)</span><br><span class="line"></span><br><span class="line"># tf.concat(values, axis) 将多个values按照axis轴进行合并</span><br><span class="line">e = tf.concat([c, d], axis=1)</span><br><span class="line"></span><br><span class="line"># tf.stack(values, axis) 增加一个新维度，并合并到该维度</span><br><span class="line">f = tf.stack([c, d], axis=1)</span><br><span class="line"></span><br><span class="line"># tf.unstack(value, axis) 对value按照axis轴进行拆分</span><br><span class="line">g = tf.unstack(f, axis=1)</span><br><span class="line"></span><br><span class="line"># tf.split(value, num_or_size_splits, axis) 对value按照axis轴进行拆分，如果希望均匀拆分则num_or_size_splits为常数，否则输入一个列表，代表每一部分的数量</span><br><span class="line">h = tf.split(e, 3, axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow11.png" alt="11"></p>
<h2 id="tensorflow数据统计"><a href="#tensorflow数据统计" class="headerlink" title="tensorflow数据统计"></a><font size="4">tensorflow数据统计</font></h2><h3 id="reduce-min，reduce-max，reduce-mean方法"><a href="#reduce-min，reduce-max，reduce-mean方法" class="headerlink" title="reduce_min，reduce_max，reduce_mean方法"></a><font size="3">reduce_min，reduce_max，reduce_mean方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 13)), (3, 4))</span><br><span class="line"></span><br><span class="line"># tf.reduce_min(input_tensor, axis=None) 求input_tensor在axis上的最小值，默认为全局最小值</span><br><span class="line">b = tf.reduce_min(a)</span><br><span class="line"></span><br><span class="line"># tf.reduce_max(input_tensor, axis=None) 求input_tensor在axis上的最大值，默认为全局最大值</span><br><span class="line">c = tf.reduce_max(a, axis=0)</span><br><span class="line"></span><br><span class="line"># tf.reduce_mean(input_tensor, axis=None) 求input_tensor在axis上的平均值，默认为全局平均值</span><br><span class="line">d = tf.reduce_mean(a, axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow12.png" alt="12"></p>
<h3 id="argmax，argmin方法"><a href="#argmax，argmin方法" class="headerlink" title="argmax，argmin方法"></a><font size="3">argmax，argmin方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 13)), (3, 4))</span><br><span class="line"></span><br><span class="line"># tf.argmax(input, axis=0) 求input在axis轴的最大值索引，默认在第一个轴</span><br><span class="line">b = tf.argmax(a, axis=0)</span><br><span class="line"></span><br><span class="line"># tf.argmin(input, axis=0) 求input在axis轴的最小值索引，默认在第一个轴</span><br><span class="line">c = tf.argmin(a, axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow13.png" alt="13"></p>
<h3 id="equal，unique方法"><a href="#equal，unique方法" class="headerlink" title="equal，unique方法"></a><font size="3">equal，unique方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([[1, 1], [0, 0]])</span><br><span class="line">b = tf.constant([[1, 0], [1, 0]])</span><br><span class="line">c = tf.constant([1,2,3,2,1])</span><br><span class="line"></span><br><span class="line"># tf.equal(x, y) 比较x和y是否相等，在如果相等则对应位置为True，否则为False</span><br><span class="line">d = tf.equal(a, b)</span><br><span class="line"></span><br><span class="line"># tf.unique(x) 找出x中有多少不同的元素，并返回其索引</span><br><span class="line">e = tf.unique(c)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow14.png" alt="14"></p>
<h3 id="norm，top-k方法"><a href="#norm，top-k方法" class="headerlink" title="norm，top_k方法"></a><font size="3">norm，top_k方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 13, dtype=tf.float32)), (3, 4))</span><br><span class="line"></span><br><span class="line"># tf.norm(tensor, str, axis=-1) 求tensor的p范数，默认为全局p范数</span><br><span class="line">b = tf.norm(a, 2, axis=0)</span><br><span class="line"></span><br><span class="line"># tf.math.top_k(input, k, bool=True) 在最后一个维度求input中前k个最大值或最小值及其索引，bool=True为最大值，bool=False为最小值。</span><br><span class="line">c = tf.math.top_k(a, 2, True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow15.png" alt="15"></p>
<h2 id="tensorflow排序"><a href="#tensorflow排序" class="headerlink" title="tensorflow排序"></a><font size="4">tensorflow排序</font></h2><h3 id="sort，argsort方法"><a href="#sort，argsort方法" class="headerlink" title="sort，argsort方法"></a><font size="3">sort，argsort方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 13)), (3, 4))</span><br><span class="line"></span><br><span class="line"># tf.sort(values, direction='ASCENDING', axis=-1) 按axis轴对values进行排序，返回排序后的结果，direction='ASCENDING'代表递增排序，'DESCENDING'代表递减排序</span><br><span class="line">b = tf.sort(a, axis=0)</span><br><span class="line"></span><br><span class="line"># tf.argsort(values, direction='ASCENDING', axis=-1) 按axis轴对values进行排序，返回排序后的索引，direction='ASCENDING'代表递增排序，'DESCENDING'代表递减排序</span><br><span class="line">c = tf.argsort(a, axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow16.png" alt="16"></p>
<h2 id="tensorflow张量限幅"><a href="#tensorflow张量限幅" class="headerlink" title="tensorflow张量限幅"></a><font size="4">tensorflow张量限幅</font></h2><h3 id="maximun，minimum方法"><a href="#maximun，minimum方法" class="headerlink" title="maximun，minimum方法"></a><font size="3">maximun，minimum方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 13)), (3, 4))</span><br><span class="line">b = tf.reshape(tf.random.shuffle(tf.range(1, 13)), (3, 4))</span><br><span class="line"></span><br><span class="line"># tf.maximun(x, y) 取x，y中的大数并返回</span><br><span class="line">c = tf.maximum(a, b)</span><br><span class="line"></span><br><span class="line"># tf.minimun(x, y) 取x，y中的小数并返回</span><br><span class="line">d = tf.minimum(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow17.png" alt="17"></p>
<h3 id="clip-by-value方法"><a href="#clip-by-value方法" class="headerlink" title="clip_by_value方法"></a><font size="3">clip_by_value方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 13)), (3, 4))</span><br><span class="line"></span><br><span class="line"># tf.clip_by_value(t, clip_value_min, clip_value_max) 将t中小于clip_value_min的值赋值为clip_value_min，大于clip_value_max的值赋值为clip_value_max</span><br><span class="line">b = tf.clip_by_value(a, 3, 7)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow18.png" alt="18"></p>
<h2 id="tensorflow数学运算"><a href="#tensorflow数学运算" class="headerlink" title="tensorflow数学运算"></a><font size="4">tensorflow数学运算</font></h2><h3 id="常规运算方法"><a href="#常规运算方法" class="headerlink" title="常规运算方法"></a><font size="3">常规运算方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 5, dtype=tf.float32)), (2, 2))</span><br><span class="line">b = tf.reshape(tf.random.shuffle(tf.range(1, 5, dtype=tf.float32)), (2, 2))</span><br><span class="line"></span><br><span class="line"># tensor1 op tensor2 将tensor1与tensor2进行常规的数学运算，如果维度大小不同，则进行广播，如果不能广播则报错</span><br><span class="line">c = a + b</span><br><span class="line">d = a ** b</span><br><span class="line"></span><br><span class="line"># tf.sqrt(x) 将x进行开方运算</span><br><span class="line">e = tf.sqrt(a)</span><br><span class="line"></span><br><span class="line"># tf.exp(x) 求e的x次幂</span><br><span class="line">f = tf.exp(a)</span><br><span class="line"></span><br><span class="line"># tf.math.log(x) 求x以e为底的对数</span><br><span class="line">g = tf.math.log(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow19.png" alt="19"></p>
<h3 id="matmul方法"><a href="#matmul方法" class="headerlink" title="matmul方法"></a><font size="3">matmul方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.reshape(tf.random.shuffle(tf.range(1, 5, dtype=tf.float32)), (2, 2))</span><br><span class="line">b = tf.reshape(tf.random.shuffle(tf.range(1, 5, dtype=tf.float32)), (2, 2))</span><br><span class="line"></span><br><span class="line"># tf.matmul(a, b) a和b的矩阵乘法，等价于a @ b</span><br><span class="line">c = tf.matmul(a, b)</span><br><span class="line">d = a @ b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow20.png" alt="20"></p>
<h3 id="where方法"><a href="#where方法" class="headerlink" title="where方法"></a><font size="3">where方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([[False, True], [True, False]])</span><br><span class="line">b = tf.constant([[1, 2], [3, 4]])</span><br><span class="line">c = tf.constant([[-1, -2], [-3, -4]])</span><br><span class="line"></span><br><span class="line"># tf.where(obj) 返回obj中True的位置的索引</span><br><span class="line">d = tf.where(a)</span><br><span class="line"></span><br><span class="line"># tf.where(tensor1, tensor2, tensor3) 如果tensor1对应位置为True则从tensor2中取得相应元素，否则从tensor3中取得相应元素</span><br><span class="line">e = tf.where(a, b, c)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow21.png" alt="21"></p>
<h2 id="tensorflow深度学习"><a href="#tensorflow深度学习" class="headerlink" title="tensorflow深度学习"></a><font size="4">tensorflow深度学习</font></h2><h3 id="datasets-数据集-模块"><a href="#datasets-数据集-模块" class="headerlink" title="datasets(数据集)模块"></a><font size="3">datasets(数据集)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.keras import datasets</span><br><span class="line"></span><br><span class="line"># datasets.XXX.load_data() # 下载XXX数据集，常用的有mnist，cifar10，cifar100等等，此时数据为numpy格式，并不是tensor</span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data() # 下载mnist手写数字数据集</span><br><span class="line"></span><br><span class="line">x_train.shape</span><br><span class="line">y_train.shape</span><br><span class="line"></span><br><span class="line">x_test.shape</span><br><span class="line">y_test.shape</span><br><span class="line"></span><br><span class="line">y_train[:6]</span><br><span class="line">y_train_onehot = tf.one_hot(y_train[:6], depth=10)</span><br><span class="line">y_train_onehot</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow22.png" alt="22"></p>
<h3 id="data-数据操作-模块"><a href="#data-数据操作-模块" class="headerlink" title="data(数据操作)模块"></a><font size="3">data(数据操作)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># tf.data.Dataset.from_tensor_slices(tensor) 将tensor数据转换成一个可迭代的对象</span><br><span class="line">db = tf.data.Dataset.from_tensor_slices(x_train)</span><br><span class="line"></span><br><span class="line"># next(iter(db)) 返回下一个迭代器的内容</span><br><span class="line"></span><br><span class="line"># db.shuffle(n) 将0-n的迭代器内容打散，使其训练更加合理</span><br><span class="line"></span><br><span class="line"># db.map(function) 将迭代器中的数据全部经过function处理，常用于图片的预处理等功能</span><br><span class="line"></span><br><span class="line">#db.batch(n) 将迭代器中的内容分成很多个batch，每一个batch中有n个数据</span><br><span class="line"></span><br><span class="line"># db.repeat(n) 将db对象迭代n次，默认为无限迭代</span><br></pre></td></tr></tbody></table></figure>
<h3 id="nn-神经网络-模块"><a href="#nn-神经网络-模块" class="headerlink" title="nn(神经网络)模块"></a><font size="3">nn(神经网络)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># tf.nn.relu(features) ReLu激活函数</span><br><span class="line"></span><br><span class="line"># tf.nn.sigmoid(features) Sigmoid激活函数</span><br><span class="line"></span><br><span class="line"># tf.nn.tanh(features) tanh激活函数</span><br><span class="line"></span><br><span class="line"># tf.nn.softmax(logits) softmax层</span><br></pre></td></tr></tbody></table></figure>
<h3 id="optimizers-优化器-模块"><a href="#optimizers-优化器-模块" class="headerlink" title="optimizers(优化器)模块"></a><font size="3">optimizers(优化器)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from tensorflow.keras import optimizers</span><br><span class="line"></span><br><span class="line"># optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False) 随机梯度下降优化器，学习率lr默认为0.01，动量momentum默认为0，学习率衰减decay默认为0，默认不使用nesterov动量</span><br><span class="line"></span><br><span class="line"># optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0) RMSprop优化器，学习率lr默认为0.001，参数rho默认为0.9，模糊因子epsilon默认为None，学习率衰减decay默认为0.0</span><br><span class="line"></span><br><span class="line"># optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0) Adam优化器，学习率lr默认为0.001，参数beta_1默认为0.9, 参数beta_2默认为0.999，模糊因子epsilon默认为None，学习率衰减decay默认为0</span><br></pre></td></tr></tbody></table></figure>
<h3 id="layers-网络层-模块"><a href="#layers-网络层-模块" class="headerlink" title="layers(网络层)模块"></a><font size="3">layers(网络层)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.keras import layers</span><br><span class="line"></span><br><span class="line"># layers.Dense(out_dim) 建立一个全连接层，结点数为out_dim个</span><br><span class="line"></span><br><span class="line"># layers.Layer 自定义网络层的基类</span><br><span class="line">class MyDense(layers.Layer):</span><br><span class="line">    def __init__(self, input_dim, output_dim):</span><br><span class="line">        super(MyDense, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.kernel = self.add_variable('w', [input_dim, output_dim])</span><br><span class="line">        self.bias = self.add_variable('b', [output_dim])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None):</span><br><span class="line">        out = inputs @ self.kernel + self.bias</span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line"># layers.Dropout(rate) 建立一个Dropout层，失活的比率为rate，保持连接的比率为1-rate，和PyTorch相同</span><br><span class="line"></span><br><span class="line"># layers.Flatten() 建立一个Flatten层，将数据展平成一维</span><br><span class="line"></span><br><span class="line"># layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid') 建立一个卷积层，卷积核的个数为filters，核的大小为kernel_size，strides为模板移动的步长，padding为是否在周围补0，valid为不补0，same为补0保证大小不变</span><br><span class="line"></span><br><span class="line"># layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='valid') 建立一个最大值池化层(平均值池化为AveragePooling2D)，池化层模板为pool_size，strides为模板移动的步长，padding为是否在周围补0，valid为不补0，same为补0保证大小不变</span><br><span class="line"></span><br><span class="line"># layers.SimpleRNNCell(units, activation='tanh', dropout=0.0, return_sequences=False, unroll=False) 建立一个循环神经网络层，单元数为units，dropout丢弃百分百为0.0，return_sequences=False返回序列最后一个输出，return_sequences=True返回全部序列，unroll=True，则网络将展开，否则将使用符号循环。</span><br><span class="line"></span><br><span class="line"># layers.LSTM(units, activation='tanh', dropout=0.0, return_sequences=False, unroll=False) 建立一个长短期记忆网络，单元数为units，dropout丢弃百分百为0.0，return_sequences=False返回序列最后一个输出，return_sequences=True返回全部序列，unroll=True，则网络将展开，否则将使用符号循环。</span><br></pre></td></tr></tbody></table></figure>
<h3 id="losses-误差计算-模块"><a href="#losses-误差计算-模块" class="headerlink" title="losses(误差计算)模块"></a><font size="3">losses(误差计算)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># tf.losses.MSE(y, logits) 计算真实值y与预测值logits的均方差</span><br><span class="line"></span><br><span class="line"># tf.losses.categorical_crossentropy(y, logits) 计算真实值y与预测值logits的交叉熵</span><br><span class="line"></span><br><span class="line"># tf.losses.binary_crossentropy(label, prob) 根据标签和概率计算二分类问题的交叉熵</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Gradient-梯度下降-模块"><a href="#Gradient-梯度下降-模块" class="headerlink" title="Gradient(梯度下降)模块"></a><font size="3">Gradient(梯度下降)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># tf.Variable(tensor) 将tensor赋有可求导属性</span><br><span class="line"></span><br><span class="line"># 将前向运算过程放在tf.GradientTape()中，即可实现自动求导，前提是变量具有可导属性</span><br><span class="line">with tf.GradientTape() as tape：</span><br><span class="line">    XXX</span><br></pre></td></tr></tbody></table></figure>
<h3 id="TensorBoard模块"><a href="#TensorBoard模块" class="headerlink" title="TensorBoard模块"></a><font size="3">TensorBoard模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 首先要安装TensorBoard，pip install tensorboard</span><br><span class="line"># 新建一个文件夹，命名为logs，在该文件路径下并输入tensorboard --logdir logs  会显示TensorBoard 1.14.0 at http://DESKTOP-1NSILG1:6006/ (Press CTRL+C to quit)</span><br><span class="line"># 建立日志文件tf.summary.create_file_writer(filename)</span><br><span class="line"># 给日志写数据</span><br><span class="line">with summary_writer.as_default():</span><br><span class="line">    tf.summary.scalar(label, data, step) # 给label添加数据data，以step作为x轴</span><br><span class="line">    tf.summary.image(label, img, step) # 给label添加图片img</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow24.png" alt="24"></p>
<h3 id="visdom模块"><a href="#visdom模块" class="headerlink" title="visdom模块"></a><font size="3">visdom模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 首先要安装visdom，pip install visdom</span><br><span class="line"># 在该文件路径下并输入python -m visdom.server，会出现下面的提示</span><br><span class="line">Checking for scripts.</span><br><span class="line">It's Alive!</span><br><span class="line">INFO:root:Application Started</span><br><span class="line">You can navigate to http://localhost:8097</span><br><span class="line"># 在python文件中写入</span><br><span class="line">from visdom import Visdom</span><br><span class="line"></span><br><span class="line">vis = Visdom()</span><br><span class="line"></span><br><span class="line"># vis.line(Y, X, win, updata) 在win窗口下创建横坐标为X，纵坐标为Y的折线，updata为折线的更新方式</span><br><span class="line"></span><br><span class="line"># vis.images(tensor, win) 在win窗口下显示图片tensor</span><br><span class="line"></span><br><span class="line"># vis.text(text, win) 在win窗口下显示text文本文字</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow24.png" alt="24"></p>
<h3 id="metrics-衡量指标-模块"><a href="#metrics-衡量指标-模块" class="headerlink" title="metrics(衡量指标)模块"></a><font size="3">metrics(衡量指标)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from tensorflow.keras import metrics</span><br><span class="line"></span><br><span class="line"># metrics.Accuracy() 返回准确度衡量指标对象</span><br><span class="line">acc_metrics = metrics.Accuracy()</span><br><span class="line"></span><br><span class="line"># metrics.Mean() 返回平均值衡量指标对象</span><br><span class="line">mean_metrics = metrics.Mean()</span><br><span class="line"></span><br><span class="line"># obj.updata_state() 向metrics对象中添加数据</span><br><span class="line">acc_metrics.updata_state(loss)</span><br><span class="line">mean_metrics.updata_state(y, pred)</span><br><span class="line"></span><br><span class="line"># obj.result() 将metrics中的数据取出</span><br><span class="line">acc_metrics.result()</span><br><span class="line">mean_metrics.result()</span><br><span class="line"></span><br><span class="line"># obj.reset_states() 清除metrics中的数据</span><br><span class="line">acc_metrics.reset_states()</span><br><span class="line">mean_metrics.reset_states()</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Model-模型-模块"><a href="#Model-模型-模块" class="headerlink" title="Model(模型)模块"></a><font size="3">Model(模型)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.keras import Sequential, layers</span><br><span class="line">from tensorflow import keras</span><br><span class="line"></span><br><span class="line"># model = Sequential([layer1, layer2, ...]) 创建一个网络结构，第一层为layer1，第二层为layer2，……</span><br><span class="line">model = Sequential([layers.Dense(512), layers.Dense(128), layers.Dense(10)])</span><br><span class="line"></span><br><span class="line"># keras.Model 自定义网络结构的基类</span><br><span class="line">class MyModel(keras.Model):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(MyModel, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.fc1 = MyDense(28 * 28, 256)</span><br><span class="line">        self.fc2 = MyDense(256, 64)</span><br><span class="line">        self.fc3 = MyDense(64, 10)</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None):</span><br><span class="line">        x = self.fc1(inputs)</span><br><span class="line">        x = tf.nn.relu(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = tf.nn.relu(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># model.build(input_shape) 定义网络输入的形状</span><br><span class="line">model.build(input_shape=(None, 784))</span><br><span class="line"></span><br><span class="line"># model.summary() 查看网络结构</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"># model.trainable_variables 查看网络所有可训练参数</span><br><span class="line">model.trainable_variables</span><br><span class="line"></span><br><span class="line"># model.compile(optimizer, loss, metrics) 配置训练模型，设置优化器为optimizer，损失函数为loss，衡量指标为metrics</span><br><span class="line"></span><br><span class="line"># model.fit(db, epoch, validation_data, validation_freq) 训练模型，训练集为db，训练epoch次，validation_freq次对validation_data进行一次测试，防止过拟合</span><br><span class="line"></span><br><span class="line"># model.evaluate(db_test) 对测试集进行测试</span><br><span class="line"></span><br><span class="line"># model.predict(x) 对未知的数据进行预测</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/FRAME/tensorflow23.png" alt="23"></p>
<h3 id="save-保存-模块"><a href="#save-保存-模块" class="headerlink" title="save(保存)模块"></a><font size="3">save(保存)模块</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># model.save_weights(filename) 将网络的训练参数保存在filename中，仅仅保存权值</span><br><span class="line"># model.load_weights(filename) 读取filename中的训练参数，前提是要创建一个相同结构的网络</span><br><span class="line"></span><br><span class="line"># model.save(filename) 保存网络的所有结构和参数</span><br><span class="line"># tf.keras.models.load_model(filename) 读取模型，不需要创建网络，会生成一个相同的网络</span><br><span class="line"></span><br><span class="line"># tf.saved_model.save(model, filename) 保存网络的所有结构和参数，便于给其他语言提供调用</span><br></pre></td></tr></tbody></table></figure>
<h1 id="TensorFlow小结"><a href="#TensorFlow小结" class="headerlink" title="TensorFlow小结"></a><font size="5" color="red">TensorFlow小结</font></h1><p>  由于TensorFlow背靠谷歌，具有最全的文档和资源，而且很多模型都有TensorFlow的源码实现，所以拥有较大的用户基数，这样使用户出现问题时能较容易地找到解决方案，这使TensorFlow目前作为最流行的深度学习框架。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>深度学习</category>
        <category>深度学习框架</category>
      </categories>
  </entry>
  <entry>
    <title>网络流(Network Flows)</title>
    <url>/2019/09/02/algorithm%20network_flows/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">网络流</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Network Flows:网络流</strong>，是运筹学中的最优化问题，也是图论中的一种理论方法。类比水流的解决问题，与线性规划密切相关，常常用来解决实际的生活问题。<br><a id="more"></a></p>
<p><img src="/images/ALGORITHM/union1.jpg" alt="1"></p>
<h1 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a><font size="5" color="red">算法基础</font></h1><h2 id="图的基本术语"><a href="#图的基本术语" class="headerlink" title="图的基本术语"></a><font size="4">图的基本术语</font></h2><p>  <font size="3">(1)无向图：G中的每条边都是没有方向的，顶点v1和v2之间的边记为(v1,v2)或(v2,v1)。</font><br><img src="/images/ALGORITHM/network1.jpg" alt="2"><br>  <font size="3">(2)有向图：G中的每条边都是有方向的，顶点v1和v2之间的边记为<v1,v2>，不能写成<v2,v1>。</v2,v1></v1,v2></font><br><img src="/images/ALGORITHM/network2.jpg" alt="3"><br>  <font size="3">(3)网：在边上标注距离，时间，花费等等数值，称为边的权值，带有权值的图称为网。</font><br><img src="/images/ALGORITHM/network3.jpg" alt="4"><br>  <font size="3">(4)二分图：如果顶点集V可分割为两个互不相交的子集V1,V2，并且图中的每条边所对应的两个顶点分别属于这两个不同的顶点集，称G为二分图。</font><br><img src="/images/ALGORITHM/network4.jpg" alt="5"></p>
<h2 id="网络的基本术语"><a href="#网络的基本术语" class="headerlink" title="网络的基本术语"></a><font size="4">网络的基本术语</font></h2><p>  <font size="3">(1)网络：在有向网中，有两个特殊的点，源点s和汇点t，图中各边的方向表示允许的流向，边上的权值表示可允许的最大流量，且两个结点之间最多只有一条边，称这样的图为网络。</font><br><img src="/images/ALGORITHM/network1.png" alt="6"><br>  <font size="3">(2)网络流：网络上的流，即定义在边集E上的非负函数flow称为网络流。</font><br>  <font size="3">(3)可行流：满足容量约束（每个边的实际流量不大于最大容量）和流量守恒（除了源点s和汇点t外，所有内部结点流入量等于流出量）两个性质的网络流称为可行流。</font><br>  <font size="3">(4)最大流：在满足可行流的条件下，在网络中找到一个净输出最大的网络流称为最大流。</font></p>
<h1 id="经典例题-最大网络流，最短增广路算法"><a href="#经典例题-最大网络流，最短增广路算法" class="headerlink" title="经典例题(最大网络流，最短增广路算法)"></a><font size="5" color="red">经典例题(最大网络流，最短增广路算法)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  一家公司要把一批货物从工厂运到北京，中间经过若干个城市，已知城市数，连接数和城市之间的最大运输量，求如何运输使运输量最大。<br>  第一行输入结点个数和边数，然后每行输入连通的两个城市以及最大运输量，使用空格分隔。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">6 9 # 结点个数n和边数m</span><br><span class="line">1 2 12 # 说明1号城市和2号城市之间的最大运输量为12</span><br><span class="line">1 3 10</span><br><span class="line">2 4 8</span><br><span class="line">3 2 2</span><br><span class="line">3 5 13</span><br><span class="line">4 3 5</span><br><span class="line">4 6 18</span><br><span class="line">5 4 6</span><br><span class="line">5 6 4</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  如果一条边的容量为n，已经流出了m则该点最多可以正向流出(n-m)或者反向流入m，因此引入一个残余网络，正向代表可增量，即还可以流出的容量，反向代表流量，即已经流出的容量，等于可以流入的流量。<br><img src="/images/ALGORITHM/network2.png" alt="12"><br>  利用深度优先或者广度优先从源点s对该图进行遍历，如果从i点到达j点的值大于0，说明可以流通，则继续。当搜索到t点时，说明该路径是一条可行流，找到该路径上边的最小值，最大流加上该值，然后修改网络，将路径上的边正向减去该值，反向加上该值。重新搜索，直到无法到达t点算法结束。</p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def sap(connect_map, n):</span><br><span class="line">    real_map = [[0 for i in range(n + 1)] for j in range(n + 1)]</span><br><span class="line">    residue_map = [[x for x in row] for row in connect_map]</span><br><span class="line">    max_flow, find_flag = 0, True</span><br><span class="line">    while find_flag:</span><br><span class="line">        queue, find_flag = [[1, [1]]], False</span><br><span class="line">        while queue:</span><br><span class="line">            i, route = queue.pop(0)</span><br><span class="line">            for j in range(1, n + 1):</span><br><span class="line">                if residue_map[i][j] &gt; 0 and j not in route:</span><br><span class="line">                    if j == n:</span><br><span class="line">                        flow, route, queue, find_flag = [], route + [j], [], True</span><br><span class="line">                        for k in range(len(route) - 1):</span><br><span class="line">                            flow.append(residue_map[route[k]][route[k + 1]])</span><br><span class="line">                        min_flow = min(flow)</span><br><span class="line">                        max_flow += min_flow</span><br><span class="line">                        for p in range(len(route) - 1):</span><br><span class="line">                            real_map[route[p]][route[p + 1]] += min_flow</span><br><span class="line">                            residue_map[route[p]][route[p + 1]] -= min_flow</span><br><span class="line">                            residue_map[route[p + 1]][route[p]] += min_flow</span><br><span class="line">                        break</span><br><span class="line">                    else:</span><br><span class="line">                        queue.append([j, route + [j]])</span><br><span class="line">    return real_map, max_flow</span><br><span class="line"></span><br><span class="line">print('请输入结点个数n和边数m:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n, m = [int(x) for x in line.strip().split()]</span><br><span class="line">    connect_map, label, direction = [[0 for i in range(n + 1)] for j in range(n + 1)], ['v' + str(i) for i in range(1, n + 1)], []</span><br><span class="line">    print('请输入结点个数u,v及边u-v的容量w:')</span><br><span class="line">    for i in range(m):</span><br><span class="line">        u, v, w = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        connect_map[u][v] = w</span><br><span class="line">        direction.append([u, v])</span><br><span class="line">    real_map, max_flow = sap(connect_map, n)</span><br><span class="line">    for k in direction:</span><br><span class="line">        real_map[k[0]][k[1]] -= real_map[k[1]][k[0]]</span><br><span class="line">        real_map[k[1]][k[0]] = 0</span><br><span class="line">    net_work = pd.DataFrame([[x for x in row[1:]] for row in real_map[1:]], index=label, columns=label)</span><br><span class="line">    print('网络的最大流值为:', max_flow, '\n---------实流网络如下:---------\n', net_work)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/network4.png" alt="14"></p>
<h1 id="经典例题-最大网络流，重贴标签算法"><a href="#经典例题-最大网络流，重贴标签算法" class="headerlink" title="经典例题(最大网络流，重贴标签算法)"></a><font size="5" color="red">经典例题(最大网络流，重贴标签算法)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  一家公司要把一批货物从工厂运到北京，中间经过若干个城市，已知城市数，连接数和城市之间的最大运输量，求如何运输使运输量最大。<br>  第一行输入结点个数和边数，然后每行输入连通的两个城市以及最大运输量，使用空格分隔。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">6 9 # 结点个数n和边数m</span><br><span class="line">1 2 12 # 说明1号城市和2号城市之间的最大运输量为12</span><br><span class="line">1 3 10</span><br><span class="line">2 4 8</span><br><span class="line">3 2 2</span><br><span class="line">3 5 13</span><br><span class="line">4 3 5</span><br><span class="line">4 6 18</span><br><span class="line">5 4 6</span><br><span class="line">5 6 4</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  在上例算法中，浪费了许多时间，因为要从源点重复进行深度优先遍历或者广度优先遍历，因此有重复的大量计算。<br>  引入混合网络，将残余网络进行优化，同向边为一个元组(cap, flow)记录容量和当前流量，反向边也是一个元组(0, -flow)记录容量个当前流量，可以通过该网络直接看出方向和流量。<br><img src="/images/ALGORITHM/network3.png" alt="13"><br>  (1)从汇点开始，利用广度优先算法对结点添加标签，从0开始，第一次直接访问到的点标记为1，第二次间接访问到的点标记为2，依次贴标签。<br>  (2)如果源点高度大于等于结点数，说明已经找到了最大流，算法结束，否则从源点开始，搜索源点高度-1的点，观察是否可以前进，如果可以，当结点为汇点时，进行增流减流操作(同向边增流，反向边减流)，如果不可以则需要重贴标签。<br>  (3)重贴标签：如果拥有当前结点高度的结点只有一个，则算法结束，否则寻找是否有可行邻接边(容量大于流量)，如果有则令当前结点高度等于邻接点高度的最小值+1，否则令当前结点的高度等于结点数。重新回到(2)</p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def isap(mix_net, height_table, n):</span><br><span class="line">    max_flow, real_map = 0, [[0 for i in range(n + 1)] for j in range(n + 1)]</span><br><span class="line">    while height_table[1] &lt; n:</span><br><span class="line">        current_node, stack = 1, []</span><br><span class="line">        while current_node != n:</span><br><span class="line">            next_height, flag, index = height_table[current_node] - 1, False, 0</span><br><span class="line">            for i in range(1, n + 1):</span><br><span class="line">                if height_table[i] == next_height and mix_net[current_node][i][0] &gt; mix_net[current_node][i][1]:</span><br><span class="line">                    flag, index = True, i</span><br><span class="line">                    break</span><br><span class="line">            if flag:</span><br><span class="line">                stack.append(current_node)</span><br><span class="line">                current_node = index</span><br><span class="line">                if current_node == n:</span><br><span class="line">                    stack.append(current_node)</span><br><span class="line">                    flow = []</span><br><span class="line">                    for k in range(len(stack) - 1):</span><br><span class="line">                        flow.append(mix_net[stack[k]][stack[k + 1]][0] - mix_net[stack[k]][stack[k + 1]][1])</span><br><span class="line">                    min_flow = min(flow)</span><br><span class="line">                    max_flow += min_flow</span><br><span class="line">                    for p in range(len(stack) - 1):</span><br><span class="line">                        real_map[stack[p]][stack[p + 1]] += min_flow</span><br><span class="line">                        mix_net[stack[p]][stack[p + 1]][1] += min_flow</span><br><span class="line">                        mix_net[stack[p + 1]][stack[p]][1] -= min_flow</span><br><span class="line">            else:</span><br><span class="line">                if height_table.count(height_table[current_node]) == 1:</span><br><span class="line">                    return real_map, max_flow</span><br><span class="line">                min_neibor, no_neibor = n, True</span><br><span class="line">                for i in range(1, n + 1):</span><br><span class="line">                    if mix_net[current_node][i][0] &gt; mix_net[current_node][i][1]:</span><br><span class="line">                        no_neibor, min_neibor = False, min(min_neibor, height_table[i])</span><br><span class="line">                height_table[current_node] = n if no_neibor else min_neibor + 1</span><br><span class="line">                if stack:</span><br><span class="line">                    current_node = stack[-1]</span><br><span class="line">                    stack.pop()</span><br><span class="line">                else:</span><br><span class="line">                    current_node = 1</span><br><span class="line">    return real_map, max_flow</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_height(queue):</span><br><span class="line">    global height_table</span><br><span class="line">    while queue:</span><br><span class="line">        j, height = queue.pop(0)</span><br><span class="line">        for i in range(1, n + 1):</span><br><span class="line">            if mix_net[i][j][0] &gt; 0 and height_table[i] == -1:</span><br><span class="line">                height_table[i] = height + 1</span><br><span class="line">                queue.append([i, height + 1])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print('请输入结点个数n和边数m:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n, m = [int(x) for x in line.strip().split()]</span><br><span class="line">    mix_net, label, height_table, direction = [[[0, 0] for i in range(n + 1)] for j in range(n + 1)], ['v' + str(i) for i in range(1, n + 1)], [-1] * n + [0], []</span><br><span class="line">    print('请输入结点个数u,v及边u-v的容量w:')</span><br><span class="line">    for i in range(m):</span><br><span class="line">        u, v, w = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        mix_net[u][v], mix_net[v][u] = [w, 0], [0, 0]</span><br><span class="line">        direction.append([u, v])</span><br><span class="line">    init_height([[n, 0]])</span><br><span class="line">    real_map, max_flow = isap(mix_net, height_table, n)</span><br><span class="line">    for k in direction:</span><br><span class="line">        real_map[k[0]][k[1]] -= real_map[k[1]][k[0]]</span><br><span class="line">        real_map[k[1]][k[0]] = 0</span><br><span class="line">    net_work = pd.DataFrame([[x for x in row[1:]] for row in real_map[1:]], index=label, columns=label)</span><br><span class="line">    print('网络的最大流值为:', max_flow, '\n---------实流网络如下:---------\n', net_work)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/network5.png" alt="15"></p>
<h1 id="经典例题-最小费用最大流"><a href="#经典例题-最小费用最大流" class="headerlink" title="经典例题(最小费用最大流)"></a><font size="5" color="red">经典例题(最小费用最大流)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  一家公司要把一批货物从工厂运到北京，中间经过若干个城市，已知城市数，连接数和城市之间的最大运输量，以及单位货物的运送费用，如何找到一种流量最大费用尽可能小的方法。<br>  第一行输入结点个数和边数，然后每行输入连通的两个城市以及最大运输量，和单位货物运输费用，使用空格分隔。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">6 10 # 结点个数n和边数m</span><br><span class="line">1 2 3 1 # 说明1号城市和2号城市之间的最大运输量为3，单位运输量费用为1</span><br><span class="line">1 3 4 7</span><br><span class="line">2 3 1 1</span><br><span class="line">2 4 6 4</span><br><span class="line">2 5 4 5</span><br><span class="line">3 4 5 3</span><br><span class="line">3 5 3 6</span><br><span class="line">4 6 7 6</span><br><span class="line">5 4 3 3</span><br><span class="line">5 6 3 2</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  (1)最短增广路算法类似，先建立混合网络。<br>  (2)从源点开始搜索，找到一条最短费用路，如果无法搜索到汇点，则算法结束，已经找到最小费用最大流，否则总花费加上该路径边上的最小值乘路径上的所有花费之和作为目前的总花费。<br>  (3)然后更新混合网络，正向增流，反向减流。回到步骤(2)</p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def spfa(mix_net, n):</span><br><span class="line">    real_map = [[0 for i in range(n + 1)] for j in range(n + 1)]</span><br><span class="line">    max_flow, total_cost, find_flag, min_cost, min_route = 0, 0, True, 65535, [1]</span><br><span class="line">    while min_route:</span><br><span class="line">        queue, find_flag, min_cost, min_route = [[1, [1], 0]], False, 65535, []</span><br><span class="line">        while queue:</span><br><span class="line">            i, route, cost = queue.pop(0)</span><br><span class="line">            if i == n and min_cost &gt; cost:</span><br><span class="line">                min_cost, min_route = cost, route</span><br><span class="line">            for j in range(1, n + 1):</span><br><span class="line">                if mix_net[i][j][0] &gt; mix_net[i][j][1] and j not in route:</span><br><span class="line">                    queue.append([j, route + [j], cost + mix_net[i][j][2]])</span><br><span class="line">        if min_route:</span><br><span class="line">            flow = []</span><br><span class="line">            for k in range(len(min_route) - 1):</span><br><span class="line">                flow.append(mix_net[min_route[k]][min_route[k + 1]][0] - mix_net[min_route[k]][min_route[k + 1]][1])</span><br><span class="line">            min_flow = min(flow)</span><br><span class="line">            max_flow += min_flow</span><br><span class="line">            total_cost += min_cost * min_flow</span><br><span class="line">            for p in range(len(min_route) - 1):</span><br><span class="line">                real_map[min_route[p]][min_route[p + 1]] += min_flow</span><br><span class="line">                mix_net[min_route[p]][min_route[p + 1]][1] += min_flow</span><br><span class="line">                mix_net[min_route[p + 1]][min_route[p]][1] -= min_flow</span><br><span class="line">    return real_map, max_flow, total_cost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print('请输入结点个数n和边数m:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    n, m = [int(x) for x in line.strip().split()]</span><br><span class="line">    mix_net, label, direction = [[[0, 0, 0] for i in range(n + 1)] for j in range(n + 1)], ['v' + str(i) for i in range(1, n + 1)], []</span><br><span class="line">    print('请输入结点个数u，v及边u-v的容量w，单位容量费用c:')</span><br><span class="line">    for i in range(m):</span><br><span class="line">        u, v, w, c = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        mix_net[u][v], mix_net[v][u] = [w, 0, c], [0, 0, -c]</span><br><span class="line">        direction.append([u, v])</span><br><span class="line">    real_map, max_flow, total_cost = spfa(mix_net, n)</span><br><span class="line">    for k in direction:</span><br><span class="line">        real_map[k[0]][k[1]] -= real_map[k[1]][k[0]]</span><br><span class="line">        real_map[k[1]][k[0]] = 0</span><br><span class="line">    net_work = pd.DataFrame([[x for x in row[1:]] for row in real_map[1:]], index=label, columns=label)</span><br><span class="line">    print('网络的最大流值为:', max_flow, '\n网络的最小费用为:', total_cost, '\n---------实流网络如下:---------\n', net_work)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/network6.png" alt="16"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  网络流是一种较为复杂的算法，通常用来解决实际的问题，其模板固定，难点在于如何将问题转化为一个网络流表示的形式，因此需要多加练习，做到熟练掌握。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>OpenCV</title>
    <url>/2019/08/20/library%20opencv/</url>
    <content><![CDATA[<p><img src="/images/LIBRARY/cv.jpg" alt="0"></p>
<h1 id="OpenCV介绍"><a href="#OpenCV介绍" class="headerlink" title="OpenCV介绍"></a><font size="5" color="red">OpenCV介绍</font></h1><p>  OpenCV是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效，由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。<br><a id="more"></a></p>
<h1 id="OpenCV特点"><a href="#OpenCV特点" class="headerlink" title="OpenCV特点"></a><font size="5" color="red">OpenCV特点</font></h1><p>  <font size="3">OpenCV是开源的计算机视觉库，采用C / C++编写，处理速度很快。</font><br>  <font size="3">OpenCV可以提供主流语言的接口，方便开发者调用。</font><br>  <font size="3">OpenCV具有通用的图像/视频载，保存和获取模块，具有底层和高层的应用开发包。</font></p>
<h1 id="OpenCV应用"><a href="#OpenCV应用" class="headerlink" title="OpenCV应用"></a><font size="5" color="red">OpenCV应用</font></h1><h2 id="OpenCV读取，显示与保存"><a href="#OpenCV读取，显示与保存" class="headerlink" title="OpenCV读取，显示与保存"></a><font size="4">OpenCV读取，显示与保存</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line"># cv.imread(filename, code) 以code格式读取一张图片，code可以为cv.IMREAD_GRAYSCALE读取一张灰度图像</span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line"></span><br><span class="line"># cv.namedWindow(windowname) 创建一个名为windowname的窗口</span><br><span class="line">cv.namedWindow('lena')</span><br><span class="line"></span><br><span class="line"># cv.imshow(window_name, img) 将img图片显示在窗口处</span><br><span class="line">cv.imshow('lena', img)</span><br><span class="line"></span><br><span class="line"># cv.waitkey(n) 等待用户按键n毫秒，0代表永远等待</span><br><span class="line">cv.waitkey(0)</span><br><span class="line"></span><br><span class="line"># cv.destroyAllWindows() 关闭所有窗口</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"># cv.VideoCapture(n) 获取第n个摄像头，从0开始编号</span><br><span class="line">cv.VideoCapture(0)</span><br><span class="line"></span><br><span class="line"># cv.imwrite(filename, img) 将img图片保存在filename文件中</span><br><span class="line">cv.imwrite('lena1.png', img)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv1.png" alt="1"></p>
<h2 id="OpenCV图像格式转换"><a href="#OpenCV图像格式转换" class="headerlink" title="OpenCV图像格式转换"></a><font size="4">OpenCV图像格式转换</font></h2><h3 id="cvtColor方法"><a href="#cvtColor方法" class="headerlink" title="cvtColor方法"></a><font size="3">cvtColor方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line"></span><br><span class="line"># cv.cvtColor(img, code) 将img转换为code格式，code可以为cv.COLOR_BGR2GRAY将RGB三通道彩色图像转换为灰度图像，cv.COLOR_BGR2HSV将RGB颜色通道转换为HSV颜色通道</span><br><span class="line">img_gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('gray')</span><br><span class="line">cv.imshow('gray', img_gray)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv2.png" alt="2"></p>
<h2 id="OpenCV图像形态学变换"><a href="#OpenCV图像形态学变换" class="headerlink" title="OpenCV图像形态学变换"></a><font size="4">OpenCV图像形态学变换</font></h2><h3 id="morphologyEx方法"><a href="#morphologyEx方法" class="headerlink" title="morphologyEx方法"></a><font size="3">morphologyEx方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">kernel = np.ones((3, 3), np.uint8)</span><br><span class="line">img = cv.imread('lena.jpg', cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"># cv.morphologyEx(img, op, kernel) 将img进行模板为kernel的op操作，其中op可以为cv.MORPH_DILATE膨胀操作，cv.MORPH_ERODE腐蚀操作，cv.MORPH_OPEN开操作，cv.MORPH_CLOSE闭操作，cv.MORPH_GRADIENT梯度操作(膨胀+腐蚀)找出边缘</span><br><span class="line">img_gradient = cv.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('gradient')</span><br><span class="line">cv.imshow('gradient', img_gradient)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv3.png" alt="3"></p>
<h2 id="OpenCV图像形状变换"><a href="#OpenCV图像形状变换" class="headerlink" title="OpenCV图像形状变换"></a><font size="4">OpenCV图像形状变换</font></h2><h3 id="resize方法"><a href="#resize方法" class="headerlink" title="resize方法"></a><font size="3">resize方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.resize(img, shape) 将img的大小调整为shape</span><br><span class="line">img_resize = cv.resize(img, (500, 500))</span><br><span class="line">cv.namedWindow('resize')</span><br><span class="line">cv.imshow('resize',img_resize)</span><br><span class="line"></span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv7.png" alt="7"></p>
<h3 id="flip方法"><a href="#flip方法" class="headerlink" title="flip方法"></a><font size="3">flip方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.flip(img, n) 将img翻转，n&gt;0沿y轴对称翻转，n=0沿x轴对称翻转，n&lt;0沿x轴y轴同时对称翻转</span><br><span class="line">img_flip_x = cv.flip(img, 0)</span><br><span class="line">cv.namedWindow('flip_x')</span><br><span class="line">cv.imshow('flip_x',img_flip_x)</span><br><span class="line"></span><br><span class="line">img_flip_y = cv.flip(img, 1)</span><br><span class="line">cv.namedWindow('flip_y')</span><br><span class="line">cv.imshow('flip_y',img_flip_y)</span><br><span class="line"></span><br><span class="line">img_flip_xy = cv.flip(img, -1)</span><br><span class="line">cv.namedWindow('flip_xy')</span><br><span class="line">cv.imshow('flip_xy',img_flip_xy)</span><br><span class="line"></span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv4.png" alt="4"></p>
<h3 id="warpAffine方法"><a href="#warpAffine方法" class="headerlink" title="warpAffine方法"></a><font size="3">warpAffine方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv </span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(5)</span><br><span class="line"></span><br><span class="line">m = np.random.rand(2,3)</span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.warpAffine(img, m, dsize) 将img进行仿射变换，变换矩阵为m，变换后的大小为dsize</span><br><span class="line">img_affine = cv.warpAffine(img, m, (img.shape[0], img.shape[1]))</span><br><span class="line">cv.namedWindow('affine')</span><br><span class="line">cv.imshow('affine',img_affine)</span><br><span class="line"></span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv5.png" alt="5"></p>
<h2 id="OpenCV图像操作"><a href="#OpenCV图像操作" class="headerlink" title="OpenCV图像操作"></a><font size="4">OpenCV图像操作</font></h2><h3 id="bitwise方法"><a href="#bitwise方法" class="headerlink" title="bitwise方法"></a><font size="3">bitwise方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">img_random = np.random.randint(0, 256, img.shape, dtype=np.uint8)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># cv.bitwise_not(img) 按位取反，等价于~img</span><br><span class="line">img_not = cv.bitwise_not(img)</span><br><span class="line">cv.namedWindow('not')</span><br><span class="line">cv.imshow('not', img_not)</span><br><span class="line"></span><br><span class="line"># cv.bitwise_and(img1, img2) 按位与，等价于img1 &amp; img2</span><br><span class="line">img_and = cv.bitwise_and(img, img_random)</span><br><span class="line">cv.namedWindow('and')</span><br><span class="line">cv.imshow('and', img_and)</span><br><span class="line"></span><br><span class="line"># cv.bitwise_or(img1, img2) 按位或，等价于img1 | img2</span><br><span class="line">img_or = cv.bitwise_or(img, img_random)</span><br><span class="line">cv.namedWindow('or')</span><br><span class="line">cv.imshow('or', img_or)</span><br><span class="line"></span><br><span class="line"># cv.bitwise_xor(img1, img2) 按位异或，等价于img1 ^ img2</span><br><span class="line">img_xor = cv.bitwise_xor(img, img_random)</span><br><span class="line">cv.namedWindow('xor')</span><br><span class="line">cv.imshow('xor', img_xor)</span><br><span class="line"></span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv6.png" alt="6"></p>
<h3 id="add，subtract，multiply，divide，addweight方法"><a href="#add，subtract，multiply，divide，addweight方法" class="headerlink" title="add，subtract，multiply，divide，addweight方法"></a><font size="3">add，subtract，multiply，divide，addweight方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">img_random = np.random.randint(0, 256, img.shape, dtype=np.uint8)</span><br><span class="line"></span><br><span class="line"># cv.add(img1, img2) 将两张图片相加，如果加和大于上限则赋值为上限(200+200=255)，和img1+img2不同，img1+img2如果大于上限则从下限开始计算(200+200=400-256=144)</span><br><span class="line">img_add = cv.add(img, img_random)</span><br><span class="line">cv.namedWindow('add')</span><br><span class="line">cv.imshow('add', img_add)</span><br><span class="line"></span><br><span class="line">img_plus = img + img_random</span><br><span class="line">cv.namedWindow('plus')</span><br><span class="line">cv.imshow('plus', img_plus)</span><br><span class="line"></span><br><span class="line"># cv.subtract(img1, img2) 将两张图片相减，用法同add</span><br><span class="line"></span><br><span class="line"># cv.multiply(img1, img2) 将两张图片相乘，用法同add</span><br><span class="line"></span><br><span class="line"># cv.divide(img1, img2) 将两张图片相除，用法同add</span><br><span class="line"></span><br><span class="line"># cv.addweight(img1, x, img2, y, z) 将两张图片相加，结果为img1 * x + img2 * y + z</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv8.png" alt="8"></p>
<h3 id="blur，medianBlur，GaussianBlur，filter2D方法"><a href="#blur，medianBlur，GaussianBlur，filter2D方法" class="headerlink" title="blur，medianBlur，GaussianBlur，filter2D方法"></a><font size="3">blur，medianBlur，GaussianBlur，filter2D方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line"></span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.blur(img, ksize) 将img做均值模糊操作，核大小为ksize</span><br><span class="line">img_blur = cv.blur(img, (5, 5))</span><br><span class="line"></span><br><span class="line">cv.namedWindow('blur')</span><br><span class="line">cv.imshow('blur', img_blur)</span><br><span class="line"></span><br><span class="line"># cv.medianBlur(img, ksize) 将img做中值模糊操作，核大小为ksize</span><br><span class="line">img_median_blur = cv.medianBlur(img, 5)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('median_blur')</span><br><span class="line">cv.imshow('median_blur', img_median_blur)</span><br><span class="line"></span><br><span class="line"># cv.GaussianBlur(img, ksize, sigmaX) 将img做高斯模糊操作，核大小为ksize，σ为sigmaX</span><br><span class="line">img_gauss_blur = cv.GaussianBlur(img, (5, 5), sigmaX=1)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('gauss_blur')</span><br><span class="line">cv.imshow('gauss_blur', img_gauss_blur)</span><br><span class="line"></span><br><span class="line"># cv.filter2D(img, ddepth, kernel) 将img做二位卷积操作，卷积核为kernel，如果要保持大小则ddepth为-1</span><br><span class="line">img_edge = cv.filter2D(img, -1, np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]]))</span><br><span class="line"></span><br><span class="line">cv.namedWindow('edge')</span><br><span class="line">cv.imshow('edge', img_edge)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv9.png" alt="9"></p>
<h2 id="OpenCV统计"><a href="#OpenCV统计" class="headerlink" title="OpenCV统计"></a><font size="4">OpenCV统计</font></h2><h3 id="getTickCount，getTickFrequency方法"><a href="#getTickCount，getTickFrequency方法" class="headerlink" title="getTickCount，getTickFrequency方法"></a><font size="3">getTickCount，getTickFrequency方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line"># cv.getTickCount() 计算从开机到当前时间的时钟周期数</span><br><span class="line">t1 = cv.getTickCount()</span><br><span class="line">t2 = cv.getTickCount()</span><br><span class="line"></span><br><span class="line"># cv.getTickFrequency() 获得一秒的时钟周期数，常常用时钟周期数除以该数获得所用时间</span><br><span class="line">f = cv.getTickFrequency()</span><br><span class="line"></span><br><span class="line">print('所用时间为:', (t2-t1) / f)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv10.png" alt="10"></p>
<h3 id="mean，meanStdDev方法"><a href="#mean，meanStdDev方法" class="headerlink" title="mean，meanStdDev方法"></a><font size="3">mean，meanStdDev方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line"></span><br><span class="line"># cv.mean(img) 计算img每个通道的均值</span><br><span class="line">mean = cv.mean(img)</span><br><span class="line"></span><br><span class="line"># cv.meanStdDev(img) 计算img每个通道的均值和方差</span><br><span class="line">mean1, std1 = cv.meanStdDev(img)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv11.png" alt="11"></p>
<h3 id="calcHist方法"><a href="#calcHist方法" class="headerlink" title="calcHist方法"></a><font size="3">calcHist方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">color=['blue','green','red']</span><br><span class="line"></span><br><span class="line"># cv.calcHist(img, channels, mask, histSize, ranges) 绘制img中channels通道的直方图，histSize为直方图大小，ranges为直方图的范围</span><br><span class="line">for i,color_i in enumerate(color):</span><br><span class="line">    hist = cv.calcHist([img],[i],None,[256],[0,255])</span><br><span class="line">    plt.plot(hist,color_i)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv12.png" alt="12"></p>
<h2 id="OpenCV常用图像操作"><a href="#OpenCV常用图像操作" class="headerlink" title="OpenCV常用图像操作"></a><font size="4">OpenCV常用图像操作</font></h2><h3 id="inRange方法"><a href="#inRange方法" class="headerlink" title="inRange方法"></a><font size="3">inRange方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line">img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)</span><br><span class="line"></span><br><span class="line"># cv.inRange(img, lowerb, upperb) 将HSV色彩空间中的颜色过滤，img颜色通道先转换为HSV，然后再进行颜色过滤</span><br><span class="line">res = cv.inRange(img_hsv, np.array([125, 43, 46]), np.array([155, 255, 255]))</span><br><span class="line"></span><br><span class="line">cv.namedWindow('purple')</span><br><span class="line">cv.imshow('purple', res)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<font size="3">HSV空间颜色分布表：</font>

<script type="math/tex; mode=display">\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|} 颜色 & 黑 & 灰 & 白 & 红 & 橙 & 黄 & 绿 & 青 & 蓝 & 紫 \\\\ \\hline h_{min} & 0 & 0 & 0 & 0 & 11 & 26 & 35 & 78 & 100 & 125\\\\ h_{max} & 180 & 180 & 180 & 10 & 25 & 34 & 77 & 99 & 124 & 155\\\\ s_{min} & 0 & 0 & 0 & 43 & 43 & 43 & 43 & 43 & 43 & 43\\\\ s_{max} & 255 & 43 & 30 & 255 & 255 & 255 & 255 & 255 & 255 & 255\\\\ v_{min} & 0 & 46 & 221 & 46 & 46 & 46 & 46 & 46 & 46 & 46\\\\ v_{max} & 46 & 220 & 255 & 255 & 255 & 255 & 255 & 255 & 255 & 255\\\\ \end{array}</script><p><img src="/images/LIBRARY/cv13.png" alt="13"></p>
<h3 id="equalizeHist方法"><a href="#equalizeHist方法" class="headerlink" title="equalizeHist方法"></a><font size="4">equalizeHist方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.equalizeHist(img) 对img图像进行直方图均衡化</span><br><span class="line">img_equal = cv.equalizeHist(img)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('euqal')</span><br><span class="line">cv.imshow('equal', img_equal)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destoryAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv14.png" alt="14"></p>
<h3 id="compareHist，calcBackProject，matchTemplate方法"><a href="#compareHist，calcBackProject，matchTemplate方法" class="headerlink" title="compareHist，calcBackProject，matchTemplate方法"></a><font size="3">compareHist，calcBackProject，matchTemplate方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># cv.compareHist(hist1, hist2, method) 对两个直方图进行比较，method可以为cv.HISTCMP_BHATTACHARYYA，cv.HISTCMP_CORREL等等</span><br><span class="line"></span><br><span class="line"># cv.calcBackProject(target, channel, hsv_hist, range) 从target中寻找处与模板相似的区域，其中模板为HSV图像的直方图，channel为通道数，range为直方图的长和宽</span><br><span class="line"></span><br><span class="line"># cv.matchTemplate(target, mask, method) 计算图片之间的匹配程度，method可以为cv.TM_SQDIFF_NORMED，cv.TM_CCOERR_NORMED，cv.TM_CCOEFF_NORMED等等</span><br></pre></td></tr></tbody></table></figure>
<h3 id="line，rectangle，circle方法"><a href="#line，rectangle，circle方法" class="headerlink" title="line，rectangle，circle方法"></a><font size="3">line，rectangle，circle方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># cv.line(img, pt1, pt2, color, thickness) 在img图像上画一条直线，起点坐标为pt1，终点坐标为pt2，颜色为color，线宽为thickness</span><br><span class="line"></span><br><span class="line"># cv.rectangle(img, pt1, pt2, color, thickness) 在img图像上画一个矩形，左上点坐标为pt1，右下点坐标为pt2，颜色为color，线宽为thickness</span><br><span class="line"></span><br><span class="line"># cv.circle(img, center, radius, color, thickness) 在img图像上画一个圆，圆心坐标为center，半径为radius，颜色为color，线宽为thickness</span><br></pre></td></tr></tbody></table></figure>
<h3 id="threshold方法"><a href="#threshold方法" class="headerlink" title="threshold方法"></a><font size="3">threshold方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.threshold(img, thresh, maxval, type) 对灰度图像img进行阈值分割，thresh为指定按照阈值大小分割，最大的灰度值为maxval，分割方法为type，可以为cv.THRESH_OTSU等等，如果指定type则thresh失效</span><br><span class="line">thresh, img_thresh = cv.threshold(img, 0, 255, cv.THRESH_OTSU)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('thresh')</span><br><span class="line">cv.imshow('thresh', img_thresh)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destoryAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv15.png" alt="15"></p>
<h3 id="pyrDown，pyrUp方法"><a href="#pyrDown，pyrUp方法" class="headerlink" title="pyrDown，pyrUp方法"></a><font size="3">pyrDown，pyrUp方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.pyrDown(img) 对img进行下采样</span><br><span class="line">img_down = cv.pyrDown(img)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('down')</span><br><span class="line">cv.imshow('down', img_down)</span><br><span class="line"></span><br><span class="line"># cv.pyrUp(img) 对img进行上采样</span><br><span class="line">img_up = cv.pyrUp(img)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('up')</span><br><span class="line">cv.imshow('up', img_up)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destoryAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv16.png" alt="16"></p>
<h2 id="OpenCV算子"><a href="#OpenCV算子" class="headerlink" title="OpenCV算子"></a><font size="4">OpenCV算子</font></h2><h3 id="Sobel，Laplacian，Canny方法"><a href="#Sobel，Laplacian，Canny方法" class="headerlink" title="Sobel，Laplacian，Canny方法"></a><font size="3">Sobel，Laplacian，Canny方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line"></span><br><span class="line">img = cv.imread('lena.jpg')</span><br><span class="line">img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('origin')</span><br><span class="line">cv.imshow('origin', img)</span><br><span class="line"></span><br><span class="line"># cv.Sobel(img, ddepth, dx, dy) 对img进行Sobel算子滤波，dx=1,dy=0代表水平方向，dx=0,dy=1代表垂直方向</span><br><span class="line">img_sobel = cv.Sobel(img, -1, dx=0, dy=1)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('sobel')</span><br><span class="line">cv.imshow('sobel', img_sobel)</span><br><span class="line"></span><br><span class="line"># cv.Laplacian(img, ddepth) 将img进行Laplacian算子滤波</span><br><span class="line">img_laplacian = cv.Laplacian(img, -1)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('laplacian')</span><br><span class="line">cv.imshow('laplacian', img_laplacian)</span><br><span class="line"></span><br><span class="line"># cv.Canny(img, threshold1, threshold2) 将img进行Canny算子滤波，低阈值为threshold1，高阈值为threshold2</span><br><span class="line">img_canny = cv.Canny(img, 50, 150)</span><br><span class="line"></span><br><span class="line">cv.namedWindow('canny')</span><br><span class="line">cv.imshow('canny', img_canny)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/cv17.png" alt="17"></p>
<h2 id="OpenCV霍夫变换"><a href="#OpenCV霍夫变换" class="headerlink" title="OpenCV霍夫变换"></a><font size="4">OpenCV霍夫变换</font></h2><h3 id="HoughLines，HoughCircles方法"><a href="#HoughLines，HoughCircles方法" class="headerlink" title="HoughLines，HoughCircles方法"></a><font size="3">HoughLines，HoughCircles方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># cv.HoughLines(img, rho, theta, threshold) 霍夫直线检测，边缘提取后的图像为img，步长为rho，角度步长为theta，阈值为threshold，返回所有直线信息</span><br><span class="line"></span><br><span class="line"># cv.HoughCircles(img, method, dp, minDist, param1, param2, minRadius, maxRadius) 霍夫圆检测，检测方法method，可以为cv.HOUGH_GRADIENT等等，dp为累加器分辨率与图像分辨率的反比，dp越大，累加器数组越小，minDist为检测到原中心的最小距离，如果太靠近则检测不出，param1用于边缘检测的阈值，param2为累加器阈值，越高则越精确，但是圆越少，minRadius为圆的最小半径，maxRadius为圆的最大半径</span><br></pre></td></tr></tbody></table></figure>
<h2 id="OpenCV轮廓处理"><a href="#OpenCV轮廓处理" class="headerlink" title="OpenCV轮廓处理"></a><font size="4">OpenCV轮廓处理</font></h2><h3 id="findContour，drawContour，contourArea方法"><a href="#findContour，drawContour，contourArea方法" class="headerlink" title="findContour，drawContour，contourArea方法"></a><font size="3">findContour，drawContour，contourArea方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># cv.findContour(img, mode, method) 寻找轮廓，mode表示轮廓的检索模式，可以为cv2.RETR_EXTERNAL，cv2.RETR_TREE等等，method表示轮廓的近似办法，可以为cv2.CHAIN_APPROX_NONE，cv2.CHAIN_APPROX_SIMPLE等等</span><br><span class="line"></span><br><span class="line"># cv.drawContour(img, contours, contourIdx, color, thickness) 根据寻找到的轮廓，画出第contourIdx个轮廓，颜色为color，线宽为thickness</span><br><span class="line"></span><br><span class="line"># cv.contourArea(contour) 计算轮廓的面积</span><br></pre></td></tr></tbody></table></figure>
<h1 id="OpenCV小结"><a href="#OpenCV小结" class="headerlink" title="OpenCV小结"></a><font size="5" color="red">OpenCV小结</font></h1><p>  通过OpenCV，使用者可以仅需要几行代码，便可以完成一系列图像处理任务，在这里介绍的只是小部分常见的功能，因此在图像处理的研究应用中，OpenCV是必不可少的帮手。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python常用库</category>
      </categories>
  </entry>
  <entry>
    <title>Scipy</title>
    <url>/2019/08/16/library%20scipy/</url>
    <content><![CDATA[<p><img src="/images/LIBRARY/scipy.jpg" alt="0"></p>
<h1 id="Scipy介绍"><a href="#Scipy介绍" class="headerlink" title="Scipy介绍"></a><font size="5" color="red">Scipy介绍</font></h1><p>  Scipy是一个用于数学、科学、工程领域的常用软件包，可以处理插值、积分、优化、常微分方程数值解的求解、图像处理、信号处理等问题。它用于有效计算Numpy矩阵，使Numpy和Scipy协同工作，高效解决问题。<br><a id="more"></a></p>
<h1 id="Scipy特点"><a href="#Scipy特点" class="headerlink" title="Scipy特点"></a><font size="5" color="red">Scipy特点</font></h1><p>  <font size="3">Scipy支持大多数工程数学运算。</font><br>  <font size="3">Scipy每一个子模块都可以完成一类功能。</font><br>  <font size="3">Scipy中的函数类似于MATLAB中的函数，使用方便。</font></p>
<h1 id="Scipy应用"><a href="#Scipy应用" class="headerlink" title="Scipy应用"></a><font size="5" color="red">Scipy应用</font></h1><h2 id="Scipy常数模块"><a href="#Scipy常数模块" class="headerlink" title="Scipy常数模块"></a><font size="4">Scipy常数模块</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import constants as C</span><br><span class="line"></span><br><span class="line"># C.c 光速常数</span><br><span class="line">C.c</span><br><span class="line"></span><br><span class="line"># C.h 普朗克常数</span><br><span class="line">C.h</span><br><span class="line"></span><br><span class="line"># C.mile 英里</span><br><span class="line">C.mile</span><br><span class="line"></span><br><span class="line"># C.pi 圆周率π</span><br><span class="line">C.pi</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy1.png" alt="1"></p>
<h2 id="Scipy特殊函数模块"><a href="#Scipy特殊函数模块" class="headerlink" title="Scipy特殊函数模块"></a><font size="4">Scipy特殊函数模块</font></h2><h3 id="gamma，gammaln方法"><a href="#gamma，gammaln方法" class="headerlink" title="gamma，gammaln方法"></a><font size="3">gamma，gammaln方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import special as S</span><br><span class="line"></span><br><span class="line"># S.gamma(n) 计算Γ(n)的值</span><br><span class="line">S.gamma(4)</span><br><span class="line"></span><br><span class="line"># S.gammaln(n) 计算ln|Γ(n)|的值，避免Γ(n)过大</span><br><span class="line">S.gammaln(4)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy2.png" alt="2"></p>
<h3 id="log1p方法"><a href="#log1p方法" class="headerlink" title="log1p方法"></a><font size="3">log1p方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import special as S</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># S.log1p(n) 计算ln(n+1)的值，使其可以计算很小的数</span><br><span class="line">S.log1p(np.e - 1)</span><br><span class="line">S.log1p(1e-10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy3.png" alt="3"></p>
<h2 id="Scipy拟合优化模块"><a href="#Scipy拟合优化模块" class="headerlink" title="Scipy拟合优化模块"></a><font size="4">Scipy拟合优化模块</font></h2><h3 id="fsolve方法"><a href="#fsolve方法" class="headerlink" title="fsolve方法"></a><font size="3">fsolve方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import optimize as O</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">def f(x):</span><br><span class="line">    x0, x1, x2 = x.tolist()</span><br><span class="line">    return [5 * x1 + 3, 4 * x0 ** 2 - 2 * math.sin(x1 * x2), x1 * x2 - 1.5]</span><br><span class="line"></span><br><span class="line"># O.fsolve(f, init) 求非线性方程组的解，f为方程函数，init为初始迭代值</span><br><span class="line">result = O.fsolve(f, [1, 1, 1])</span><br></pre></td></tr></tbody></table></figure>
<script type="math/tex; mode=display">\left \{\begin{aligned} 5x_1 + 3 & = 0 \\ 4{x_0}^2 -2\sin{x_1 \cdot x_2} & = 0 \\ x_1 \cdot x_2 -1.5 &= 0 \end{aligned} \right.</script><p><img src="/images/LIBRARY/scipy4.png" alt="4"></p>
<h3 id="leastsq方法"><a href="#leastsq方法" class="headerlink" title="leastsq方法"></a><font size="3">leastsq方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import optimize as O</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x = np.array([8.19,2.72,6.39,8.71,4.7,2.66,3.78])</span><br><span class="line">y = np.array([7.01,2.78,6.47,6.71,4.1,4.23,4.05])</span><br><span class="line"></span><br><span class="line">def residuals(p):</span><br><span class="line">    k, b = p</span><br><span class="line">    return y - (k * x + b)</span><br><span class="line"></span><br><span class="line">r = O.leastsq(residuals, [1,0])</span><br><span class="line"></span><br><span class="line">k, b = r[0]</span><br><span class="line">y_new = x * k + b</span><br><span class="line">print('k=', k, 'b=', b)</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(x, y_new)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy5.png" alt="5"></p>
<h2 id="Scipy线性代数模块"><a href="#Scipy线性代数模块" class="headerlink" title="Scipy线性代数模块"></a><font size="4">Scipy线性代数模块</font></h2><h3 id="solve方法"><a href="#solve方法" class="headerlink" title="solve方法"></a><font size="3">solve方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import linalg as L</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[2, 2, -1], [1, -2, 4], [5, 8, -1]])</span><br><span class="line">b = np.array([[6], [3], [27]])</span><br><span class="line"></span><br><span class="line"># L.solve(A, b) 求线性方程组Ax = b的解</span><br><span class="line">x = L.solve(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy6.png" alt="6"></p>
<h3 id="eig，svd方法"><a href="#eig，svd方法" class="headerlink" title="eig，svd方法"></a><font size="3">eig，svd方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import linalg as L</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[-2, 1, 1], [0, 2, 0], [-4, 1, 3]])</span><br><span class="line"></span><br><span class="line"># L.eig(array) 求array的特征值和特征向量</span><br><span class="line">m, x = L.eig(a)</span><br><span class="line"></span><br><span class="line"># L.svd(array) 求array的奇异值分解</span><br><span class="line">u, sigma, v = L.svd(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy7.png" alt="7"></p>
<h2 id="Scipy统计模块"><a href="#Scipy统计模块" class="headerlink" title="Scipy统计模块"></a><font size="4">Scipy统计模块</font></h2><h3 id="norm类，stats，rvs方法"><a href="#norm类，stats，rvs方法" class="headerlink" title="norm类，stats，rvs方法"></a><font size="3">norm类，stats，rvs方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import stats as ST</span><br><span class="line"></span><br><span class="line"># ST.norm(loc=0, scale=1) 获取偏移为loc(默认为0)，标准差为scale(默认为1)的正态分布(还可以定义其他的分布)</span><br><span class="line">norm_ = ST.norm(loc=1, scale=2)</span><br><span class="line"></span><br><span class="line"># obj.stats() 获取obj分布的期望和方差</span><br><span class="line">mean_norm, var_norm = norm_.stats()</span><br><span class="line"></span><br><span class="line"># obj.rvs(size=shape) 获取大小为shape的obj分布的随机抽样</span><br><span class="line">x = norm_.rvs(size=(100, 100))</span><br><span class="line">mean_x = np.mean(x)</span><br><span class="line">std_x = np.std(x)</span><br><span class="line"></span><br><span class="line"># obj.pdf(x) 获取x处的概率密度函数</span><br><span class="line">pdf_1 = norm_.pdf(1)</span><br><span class="line"></span><br><span class="line"># obj.cdf(x) 获取x处的分布函数</span><br><span class="line">cdf_1 = norm_.cdf(1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy8.png" alt="8"></p>
<h3 id="rv-discrete类，stats，rvs方法"><a href="#rv-discrete类，stats，rvs方法" class="headerlink" title="rv_discrete类，stats，rvs方法"></a><font size="3">rv_discrete类，stats，rvs方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import stats as ST</span><br><span class="line"></span><br><span class="line"># ST.rv_discrete(values=(x, p)) 自定义离散概率分布，x为可能的取值，p为对应的概率</span><br><span class="line">discrete_ = ST.rv_discrete(values=([1, 2, 3, 4, 5, 6], [0.75, 0.05, 0.05, 0.05, 0.05, 0.05]))</span><br><span class="line"></span><br><span class="line">discrete_.stats()</span><br><span class="line"></span><br><span class="line">x = discrete_.rvs(size=(100, 100))</span><br><span class="line">mean_x = np.mean(x)</span><br><span class="line">var_x = np.var(x)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.annotate(formulation, xy, xytext, fontsize, arrowprops) 在xy附近添加注解formulation，xytext为注解的位置，fontsize为注解的大小，arrowprops为箭头类型</span><br><span class="line">plt.annotate(r'$x^2-0.5$', (0, -0.5), xytext=(+0.25, 0), arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3, rad=0.2'))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy9.png" alt="9"></p>
<h3 id="binom-pmf方法"><a href="#binom-pmf方法" class="headerlink" title="binom.pmf方法"></a><font size="3">binom.pmf方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import stats as ST</span><br><span class="line"></span><br><span class="line"># ST.binom.pmf(list, n, p) 进行n次二项分布实验，出现的概率为p，计算出现list中对应值的概率</span><br><span class="line">x = ST.binom.pmf([0,1,2,3,4], 3, 0.8)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy10.png" alt="10"></p>
<h2 id="Scipy积分模块"><a href="#Scipy积分模块" class="headerlink" title="Scipy积分模块"></a><font size="4">Scipy积分模块</font></h2><h3 id="quad方法"><a href="#quad方法" class="headerlink" title="quad方法"></a><font size="3">quad方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import integrate as I</span><br><span class="line"></span><br><span class="line">I.quad(f, min_lim, max_lim) 计算函数f的积分(f可以是自定义函数也可以为lambda表达式)，并返回计算产生的误差，积分下限为min_lim，积分上限为max_lim</span><br><span class="line"></span><br><span class="line">pi_half, err = I.quad(lambda x:(1 - x ** 2) ** 0.5, -1, 1)</span><br><span class="line">print('pi:', pi_half * 2, 'err:', err)</span><br></pre></td></tr></tbody></table></figure>
<script type="math/tex; mode=display">\int_{-1}^{1} \sqrt{1-x^2}\, dx = \frac{\pi}{2}</script><p><img src="/images/LIBRARY/scipy11.png" alt="11"></p>
<h3 id="dblquad，tplquad方法"><a href="#dblquad，tplquad方法" class="headerlink" title="dblquad，tplquad方法"></a><font size="3">dblquad，tplquad方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import integrate as I</span><br><span class="line"></span><br><span class="line">f = lambda x, y : (1 - x ** 2 - y ** 2) ** 0.5</span><br><span class="line">f_y = lambda x : (1 - x ** 2) ** 0.5</span><br><span class="line"></span><br><span class="line"># I.dblquad(f, x_min_lim, x_max_lim, y_min_lim, y_max_lim) 计算函数f的二重积分，并返回计算产生的误差，x积分下限为x_min_lim，积分上限为x_max_lim，y积分下限为y_min_lim，积分上限为y_max_lim</span><br><span class="line">res, err = I.dblquad(lambda x, y : (1 - x ** 2 - y ** 2) ** 0.5, -1, 1, lambda x : -1 * f_y(x), f_y)</span><br><span class="line">print('res:', res * 1.5, 'err:', err)</span><br><span class="line"></span><br><span class="line"># I.tplquad(f, x_min_lim, x_max_lim, y_min_lim, y_max_lim, z_min_lim, z_max_lim) 计算函数f的三重积分，并返回计算产生的误差，x积分下限为x_min_lim，积分上限为x_max_lim，y积分下限为y_min_lim，积分上限为y_max_lim，z积分下限为z_min_lim，积分上限为z_max_lim</span><br></pre></td></tr></tbody></table></figure>
<script type="math/tex; mode=display">\int_{-1}^{1} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} \sqrt{1-x^2-y^2}\, dydx = \frac{2}{3}\pi</script><p><img src="/images/LIBRARY/scipy12.png" alt="12"></p>
<h2 id="Scipy插值模块"><a href="#Scipy插值模块" class="headerlink" title="Scipy插值模块"></a><font size="4">Scipy插值模块</font></h2><h3 id="interp1d，interp2d方法"><a href="#interp1d，interp2d方法" class="headerlink" title="interp1d，interp2d方法"></a><font size="3">interp1d，interp2d方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import interpolate as IP</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(0, 2 * np.pi, 11)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">x_new = np.linspace(0, 2 * np.pi, 51)</span><br><span class="line"></span><br><span class="line"># IP.interp1d(x, y, kind) 对x，y进行一维插值，kind为插值函数类型，可以为'nearest'最近邻插值，'cubic'立方插值等等</span><br><span class="line">f = IP.interp1d(x, y, kind='cubic')</span><br><span class="line">y_new = f(x_new)</span><br><span class="line"></span><br><span class="line">plt.subplot(121)</span><br><span class="line">plt.plot(x, y, label='origin')</span><br><span class="line">plt.subplot(122)</span><br><span class="line">plt.plot(x_new, y_new, label='new')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"># IP.interp2d(x, y, z, kind) 对x，y，z进行二维插值，kind同interp2d</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy13.png" alt="13"></p>
<h3 id="UnivariateSpline方法"><a href="#UnivariateSpline方法" class="headerlink" title="UnivariateSpline方法"></a><font size="4">UnivariateSpline方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import interpolate as IP</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(0, 2 * np.pi, 11)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">x_new = np.linspace(-0.5 * np.pi, 2.5 * np.pi, 51)</span><br><span class="line"></span><br><span class="line"># IP.interp1d(x, y, w, k=3, s=None) 对x，y进行一维插值，w为每个数据的权值，k为插值的阶数(默认为3)，s为曲线的平滑系数(默认为None)，和interp1d不同的是，该方法支持外推操作，即可以插值边缘点之外的部分。</span><br><span class="line">y_new=ip.UnivariateSpline(x, y)(x_new)</span><br><span class="line">plt.subplot(121)</span><br><span class="line">plt.plot(x,y,label='origin')</span><br><span class="line">plt.subplot(122)</span><br><span class="line">plt.plot(x_new,y_new,label='new')</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy14.png" alt="14"></p>
<h2 id="Scipy信号处理模块"><a href="#Scipy信号处理模块" class="headerlink" title="Scipy信号处理模块"></a><font size="4">Scipy信号处理模块</font></h2><h3 id="medfilt方法"><a href="#medfilt方法" class="headerlink" title="medfilt方法"></a><font size="3">medfilt方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import signal as SP</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">x =np.random.randint(0, 9, (5, 5))</span><br><span class="line"></span><br><span class="line"># SP.medfilt(array, kernel_size) 对array进行中值滤波，掩模的大小为kernel_size</span><br><span class="line">y = SP.medfilt(x, 3)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy15.png" alt="15"></p>
<h3 id="order-filter方法"><a href="#order-filter方法" class="headerlink" title="order_filter方法"></a><font size="3">order_filter方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import signal as SP</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">x =np.random.randint(0, 9, (5, 5))</span><br><span class="line"></span><br><span class="line"># SP.order_filter(array, domain, rank) 对array进行模板为domain的排序滤波，rank为第几小的值，rank=0代表最小值滤波，rank=domain.size-1代表最大值滤波</span><br><span class="line">y_min = SP.order_filter(x, np.ones((5, 5)), 0)</span><br><span class="line">y_mid = SP.order_filter(x, np.ones((5, 5)), 12)</span><br><span class="line">y_max = SP.order_filter(x, np.ones((5, 5)), 24)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy16.png" alt="16"></p>
<h3 id="iirdesign，lfilter方法"><a href="#iirdesign，lfilter方法" class="headerlink" title="iirdesign，lfilter方法"></a><font size="3">iirdesign，lfilter方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from scipy import signal as SP</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">fs = 100</span><br><span class="line">t = np.arange(0, 2, 1 / fs)</span><br><span class="line">y = np.sin(2 * np.pi * 2 * t) + np.sin(2 * np.pi * 4 * t) + np.sin(2 * np.pi * 6 * t)</span><br><span class="line"></span><br><span class="line"># SP.iirdesign([pass_low, pass_high], [stop_loss, stop_high], gp, gs) 设计IIR滤波器，通带频率为[pass_low × f0, pass_high × f0]，阻带频率为[0, stop_loss × f0] ∪ [stop_high × f0, ∞]，其中f0为采样频率的一半，gp为通带的最大增益衰减，gs为阻带的最小增益衰减，返回值为滤波器分子和分母的系数</span><br><span class="line">b_1, a_1 = SP.iirdesign([0.05, 0.2], [0.01, 0.5], 2, 40)</span><br><span class="line">b_2, a_2 = SP.iirdesign([0.1, 0.2], [0.01, 0.5], 2, 40)</span><br><span class="line"></span><br><span class="line"># SP.lfilter(b, a, x) 计算x经过b，a滤波器的结果</span><br><span class="line">out_1 = SP.lfilter(b_1, a_1, y)</span><br><span class="line">out_2 = SP.lfilter(b_2, a_2, y)</span><br><span class="line"></span><br><span class="line">plt.subplot(321)</span><br><span class="line">plt.plot(t, y, label='origin')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(322)</span><br><span class="line">plt.plot(np.abs(np.fft.fft(y)), label='origin fft')</span><br><span class="line">plt.xlim((0, fs / 2))</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(323)</span><br><span class="line">plt.plot(t, out_1, label='out_1')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(324)</span><br><span class="line">plt.plot(np.abs(np.fft.fft(out_1)), label='out_1 fft')</span><br><span class="line">plt.xlim((0, fs / 2))</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(325)</span><br><span class="line">plt.plot(t, out_2, label='out_2')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(326)</span><br><span class="line">plt.plot(np.abs(np.fft.fft(out_2)), label='out_2 fft')</span><br><span class="line">plt.xlim((0, fs / 2))</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/scipy17.png" alt="17"></p>
<h2 id="Scipy图像处理模块"><a href="#Scipy图像处理模块" class="headerlink" title="Scipy图像处理模块"></a><font size="4">Scipy图像处理模块</font></h2><p>  <font size="4">Scipy.ndimage 是一个处理多维图像的函数库，其中又包括以下模块。</font><br>  <font size="3">filters 图像滤波器函数库</font><br>  <font size="3">fourier 傅里叶变换函数库</font><br>  <font size="3">interpolation 图像变换函数库</font><br>  <font size="3">morphology 形态学操作函数库</font></p>
<p>  <font size="4">图像处理有许多更强大的库，如opencv，scikit-image库，在此不做过多介绍，可以参考opencv。</font></p>
<h1 id="Scipy小结"><a href="#Scipy小结" class="headerlink" title="Scipy小结"></a><font size="5" color="red">Scipy小结</font></h1><p>  通过Scipy，使用者可以仅需要几行代码，便可以完成一系列工程应用。在数据分析，实际项目中，常常需要对数据进行插值、拟合、优化，需要借助Scipy科学计算库的帮助，因此Scipy是工程研究中必不可少的帮手。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python常用库</category>
      </categories>
  </entry>
  <entry>
    <title>Matplotlib</title>
    <url>/2019/08/15/library%20matplotlib/</url>
    <content><![CDATA[<p><img src="/images/LIBRARY/matplotlib.jpg" alt="0"></p>
<h1 id="Matplotlib介绍"><a href="#Matplotlib介绍" class="headerlink" title="Matplotlib介绍"></a><font size="5" color="red">Matplotlib介绍</font></h1><p>  Matplotlib是python绘图领域使用最广泛的库。它能让使用者很轻松地将数据图形化，并且提供多样化的输出格式。<br><a id="more"></a></p>
<h1 id="Matplotlib特点"><a href="#Matplotlib特点" class="headerlink" title="Matplotlib特点"></a><font size="5" color="red">Matplotlib特点</font></h1><p>  <font size="3">Matplotlib支持LaTeX 的公式插入。</font><br>  <font size="3">Matplotlib支持交互式和非交互式绘图。</font><br>  <font size="3">Matplotlib可将图像保存成PNG等多种形式。</font><br>  <font size="3">Matplotlib支持曲线(折线)图、条形图、柱状图、饼图。</font><br>  <font size="3">Matplotlib类似于MATLAB的绘图函数，上手较为简单。</font></p>
<h1 id="Matplotlib应用"><a href="#Matplotlib应用" class="headerlink" title="Matplotlib应用"></a><font size="5" color="red">Matplotlib应用</font></h1><h2 id="Matplotlib绘制二维直线"><a href="#Matplotlib绘制二维直线" class="headerlink" title="Matplotlib绘制二维直线"></a><font size="4">Matplotlib绘制二维直线</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line"># plt.plot(x, y, color, linewidth, linestyle, label, alpha, marker=None) 画出x-y二维图形，color指颜色，linewidth指线宽，linestyle指线的形式，label指图形的标签，alpha指透明度，marker指该点的形状</span><br><span class="line">plt.plot(x, y, color='red', linewidth=0.5, alpha=0.8)</span><br><span class="line"></span><br><span class="line"># plt.show() 显示所画的图形</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib1.png" alt="1"></p>
<h2 id="matplotlib修饰图形"><a href="#matplotlib修饰图形" class="headerlink" title="matplotlib修饰图形"></a><font size="4">matplotlib修饰图形</font></h2><h3 id="style-use方法"><a href="#style-use方法" class="headerlink" title="style.use方法"></a><font size="3">style.use方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># plt.style.use(option) 设置窗口风格，option可选'dark_background'，'bmh'，'grayscale'，'ggplot'，'fivethirtyeight'</span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib24.png" alt="24"></p>
<h3 id="grid方法"><a href="#grid方法" class="headerlink" title="grid方法"></a><font size="3">grid方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.grid(b=True, color, linewidth, linestyle) 设置坐标系网格，b=True表示显示网格(默认为True)，False表示关闭网格，color指网格的颜色，linewidth指网格的宽度，linestyle指网格的类型</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib20.png" alt="20"></p>
<h3 id="grid方法-1"><a href="#grid方法-1" class="headerlink" title="grid方法"></a><font size="3">grid方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.grid(b=True, color, linewidth, linestyle) 设置坐标系网格，b=True表示显示网格(默认为True)，False表示关闭网格，color指网格的颜色，linewidth指网格的宽度，linestyle指网格的类型</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib20.png" alt="20"></p>
<h3 id="axis方法"><a href="#axis方法" class="headerlink" title="axis方法"></a><font size="3">axis方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-3, 3, 31)</span><br><span class="line">y = x ** 2</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.axis(b) 设置坐标系网格，b='on'表示显示坐标轴(默认为'on')，'off'表示关闭坐标轴，'equal'指坐标轴比例相同，'auto'自动调整坐标轴比例</span><br><span class="line">plt.axis('equal')</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib21.png" alt="21"></p>
<h3 id="subplot方法"><a href="#subplot方法" class="headerlink" title="subplot方法"></a><font size="3">subplot方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-3, 3, 31)</span><br><span class="line">y_1 = x</span><br><span class="line">y_2 = x ** 2</span><br><span class="line">y_3 = np.exp(x)</span><br><span class="line">y_4 = np.log(x)</span><br><span class="line"></span><br><span class="line"># plt.subplot(r, c, n) 将一个窗口分成r行c列，当前子窗口处于第n个</span><br><span class="line">plt.subplot(2,2,1)</span><br><span class="line">plt.plot(x, y_1, label='$x$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,2)</span><br><span class="line">plt.plot(x, y_2, label='$x^2$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,3)</span><br><span class="line">plt.plot(x, y_3, label='$e^x$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(2,2,4)</span><br><span class="line">plt.plot(x, y_4, label='$log(x)$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib22.png" alt="22"></p>
<h3 id="subplot2grid方法"><a href="#subplot2grid方法" class="headerlink" title="subplot2grid方法"></a><font size="3">subplot2grid方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-3, 3, 31)</span><br><span class="line">y_1 = x</span><br><span class="line">y_2 = x ** 2</span><br><span class="line">y_3 = np.exp(x)</span><br><span class="line">y_4 = np.log(x)</span><br><span class="line"></span><br><span class="line"># plt.subplot2grid((r, c), (begin, end), colspan=1, rowspan=1) 将一个窗口分成r行c列，当前窗口的位置在(begin, end)，横跨m个单位(默认为1个单位)，纵跨n个单位(默认为1个单位)</span><br><span class="line">plt.subplot2grid((3, 2),(0, 0), colspan=2, rowspan=1)</span><br><span class="line">plt.plot(x, y_1, label='$x$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3, 2), (1, 0))</span><br><span class="line">plt.plot(x, y_2, label='$x^2$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3, 2), (1, 1))</span><br><span class="line">plt.plot(x, y_3, label='$e^x$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3, 2), (2, 0), colspan=2, rowspan=1)</span><br><span class="line">plt.plot(x, y_4, label='$log(x)$')</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib23.png" alt="23"></p>
<h3 id="xlim，ylim方法"><a href="#xlim，ylim方法" class="headerlink" title="xlim，ylim方法"></a><font size="3">xlim，ylim方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.xlim((x_min, x_max))，plt.ylim((y_min, y_max)) 限制x，y坐标轴的范围</span><br><span class="line">plt.xlim((-1.5, 1.5))</span><br><span class="line">plt.ylim((-1, 1))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib3.png" alt="3"></p>
<h3 id="xlabel，ylabel方法"><a href="#xlabel，ylabel方法" class="headerlink" title="xlabel，ylabel方法"></a><font size="3">xlabel，ylabel方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.xlabel(x_describe)，plt.ylabel(y_describe) 设置x，y的坐标轴标签</span><br><span class="line">plt.xlabel('x')</span><br><span class="line">plt.ylabel('x^2-0.5')</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib4.png" alt="4"></p>
<h3 id="xticks，yticks方法"><a href="#xticks，yticks方法" class="headerlink" title="xticks，yticks方法"></a><font size="3">xticks，yticks方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(2)</span><br><span class="line"></span><br><span class="line">x = np.arange(1,13)</span><br><span class="line">y = np.random.randint(50, 100, 12)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.xticks(list_x)，plt.yticks(list_y) 设置x，y的角标，支持latex格式。</span><br><span class="line">plt.xticks(x)</span><br><span class="line">plt.yticks([60, 80, 90, 100], [r'$bad$', r'$good$', r'$nice$', r'$excellent$'])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib5.png" alt="5"></p>
<h3 id="gca方法"><a href="#gca方法" class="headerlink" title="gca方法"></a><font size="3">gca方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.gca 获取坐标脊</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line"># 将上方和右侧的坐标轴删除</span><br><span class="line">ax.spines['right'].set_color('none')</span><br><span class="line">ax.spines['top'].set_color('none')</span><br><span class="line"></span><br><span class="line"># 设置x，y轴为下方和左侧的脊</span><br><span class="line">ax.xaxis.set_ticks_position('bottom')</span><br><span class="line">ax.yaxis.set_ticks_position('left')</span><br><span class="line"></span><br><span class="line"># 设置坐标轴原点为(-0.1, -0.2)</span><br><span class="line">ax.spines['bottom'].set_position(('data', -0.2))</span><br><span class="line">ax.spines['left'].set_position(('data', -0.1))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib6.png" alt="6"></p>
<h3 id="legend方法"><a href="#legend方法" class="headerlink" title="legend方法"></a><font size="3">legend方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) + 1</span><br><span class="line">z = np.exp(x)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.plot(x, z)</span><br><span class="line"></span><br><span class="line"># plt.legend(handles, labels, loc='best') 设置图例，可以在handles和labels中写入多个，handle省略则按照图形的产生顺序设置图例，loc='best'指默认放在空白最好的位置</span><br><span class="line">plt.legend(labels=[r'$x^2+1$', r'$e^x$'])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib7.png" alt="7"></p>
<h3 id="annotate方法"><a href="#annotate方法" class="headerlink" title="annotate方法"></a><font size="3">annotate方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.annotate(formulation, xy, xytext, fontsize, arrowprops) 在xy附近添加注解formulation，xytext为注解的位置，fontsize为注解的大小，arrowprops为箭头类型</span><br><span class="line">plt.annotate(r'$x^2-0.5$', (0, -0.5), xytext=(+0.25, 0), arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3, rad=0.2'))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib8.png" alt="8"></p>
<h3 id="text方法"><a href="#text方法" class="headerlink" title="text方法"></a><font size="3">text方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># plt.text(x, y, text, fontdict) 在(x，y)处添加文本文字text，文字的大小颜色在fontdict定义</span><br><span class="line">plt.text(0, -0.2, r'$x^2-0.5$', fontdict={'size':20, 'color':'red'})</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib9.png" alt="9"></p>
<h2 id="matplotlib绘制散点图"><a href="#matplotlib绘制散点图" class="headerlink" title="matplotlib绘制散点图"></a><font size="4">matplotlib绘制散点图</font></h2><h3 id="scatter方法"><a href="#scatter方法" class="headerlink" title="scatter方法"></a><font size="3">scatter方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x = np.linspace(-1, 1, 21)</span><br><span class="line">y = np.power(x, 2) - 0.5</span><br><span class="line"></span><br><span class="line"># plt.scatter(x, y, color, s, label) 绘制x-y散点图，颜色为color，大小为s，标签为label</span><br><span class="line">plt.scatter(x, y, color='blue', s=3.0)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib10.png" alt="10"></p>
<h2 id="matplotlib绘制条形图"><a href="#matplotlib绘制条形图" class="headerlink" title="matplotlib绘制条形图"></a><font size="4">matplotlib绘制条形图</font></h2><h3 id="bar方法"><a href="#bar方法" class="headerlink" title="bar方法"></a><font size="3">bar方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">x = np.arange(10)</span><br><span class="line">y = np.random.rand(10)</span><br><span class="line"></span><br><span class="line"># plt.bar(x, y, facecolor, edgecolor) 绘制x-y条形图，facecolor为内部颜色，edgecolor为边缘颜色</span><br><span class="line">plt.bar(x, y)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib11.png" alt="11"></p>
<h2 id="matplotlib绘制等高线图"><a href="#matplotlib绘制等高线图" class="headerlink" title="matplotlib绘制等高线图"></a><font size="4">matplotlib绘制等高线图</font></h2><h3 id="contourf，contour，clabel方法"><a href="#contourf，contour，clabel方法" class="headerlink" title="contourf，contour，clabel方法"></a><font size="3">contourf，contour，clabel方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x=np.linspace(-1,1,100)</span><br><span class="line">y=np.linspace(-1,1,100)</span><br><span class="line">x, y=np.meshgrid(x, y)</span><br><span class="line">z = np.power(x, 2) + np.power(y, 2)</span><br><span class="line"></span><br><span class="line"># plt.contourf(x, y, z, n, alpha, cmap) 绘制(x, y, z)二维等高线图，n指等高线的条数，alpha为透明度，cmap=plt.hot()绘制热图，cmap=plt.cool()绘制冷图</span><br><span class="line">plt.contourf(x, y, z, 8, alpha=0.5, cmap=plt.hot())</span><br><span class="line"></span><br><span class="line"># plt.contour(x, y, z, n, colors) 绘制(x, y, z)二维等高线</span><br><span class="line">contour=plt.contour(x, y, z, 8, colors='black')</span><br><span class="line"></span><br><span class="line"># plt.clabel(contour, inline=True, fontsize) #在等高线contour中添加数字</span><br><span class="line">plt.clabel(contour)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib12.png" alt="12"></p>
<h2 id="matplotlib绘制直方图"><a href="#matplotlib绘制直方图" class="headerlink" title="matplotlib绘制直方图"></a><font size="4">matplotlib绘制直方图</font></h2><h3 id="hist方法"><a href="#hist方法" class="headerlink" title="hist方法"></a><font size="3">hist方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">x = np.random.randn(10000)</span><br><span class="line"></span><br><span class="line"># plt.hist(x, bins, color, normed=False) 将x绘制直方图，bins为直方图分组的个数，color为直方图的颜色，normed为是否标准化</span><br><span class="line">plt.hist(x, 100)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib13.png" alt="13"></p>
<h2 id="matplotlib绘制饼状图"><a href="#matplotlib绘制饼状图" class="headerlink" title="matplotlib绘制饼状图"></a><font size="4">matplotlib绘制饼状图</font></h2><h3 id="pie方法"><a href="#pie方法" class="headerlink" title="pie方法"></a><font size="4">pie方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x = [0.2236, 0.2664, 0.3218, 0.1882]</span><br><span class="line">label = ['first quarter', 'second quarter', 'third quarter', 'fourth quarter']</span><br><span class="line"></span><br><span class="line"># plt.pie(x, labels, autopct, explode, shadow=False) 将x绘制饼状图，labels为每个部分的标签，autopct为百分数的格式，explode指是否突出显示，shadow为是否添加阴影</span><br><span class="line">plt.pie(x, labels=label, autopct='%.2f%%', explode=[0, 0, 0.1, 0], shadow=True)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib14.png" alt="14"></p>
<h2 id="matplotlib填充图形"><a href="#matplotlib填充图形" class="headerlink" title="matplotlib填充图形"></a><font size="4">matplotlib填充图形</font></h2><h3 id="fill，fill-between方法"><a href="#fill，fill-between方法" class="headerlink" title="fill，fill_between方法"></a><font size="3">fill，fill_between方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">x=np.linspace(0,4*np.pi,100)</span><br><span class="line">y_1 =np.sin(x)</span><br><span class="line">y_2 =np.sin(2 * x)</span><br><span class="line"></span><br><span class="line"># plt.fill(x, y, color, alpha, interpolate=False) 对x，y图形与x轴进行填充，颜色为color，透明度为alpha，interpolate为是否精确填充</span><br><span class="line">plt.figure(1)</span><br><span class="line">plt.fill(x, y_1, color='r', alpha=0.5)</span><br><span class="line"></span><br><span class="line"># plt.fill_between(x, y_1, y_2, where, facecolor, interpolate=False) 对x，y_1图形与x，y_2图形进行填充，填充方式为where，颜色为color，透明度为alpha，interpolate为是否精确填充</span><br><span class="line">plt.figure(2)</span><br><span class="line">plt.plot(x, y_1)</span><br><span class="line">plt.plot(x, y_2)</span><br><span class="line">plt.fill_between(x, y_1, y_2, where=y_1 &gt; y_2, facecolor='red', interpolate=True)</span><br><span class="line">plt.fill_between(x, y_1, y_2, where=y_1 &lt; y_2, facecolor='blue', interpolate=True)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib15.png" alt="15"></p>
<h2 id="matplotlib绘制几何图形"><a href="#matplotlib绘制几何图形" class="headerlink" title="matplotlib绘制几何图形"></a><font size="4">matplotlib绘制几何图形</font></h2><h3 id="Cicle，Rectangle，Polygon，Ellipse方法"><a href="#Cicle，Rectangle，Polygon，Ellipse方法" class="headerlink" title="Cicle，Rectangle，Polygon，Ellipse方法"></a><font size="3">Cicle，Rectangle，Polygon，Ellipse方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib.patches as mpatches</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">fig, ax=plt.subplots()</span><br><span class="line"></span><br><span class="line">clc=[.2,.2]</span><br><span class="line">rec=[.2,.8]</span><br><span class="line">pol=np.array([0.7,0.1,0.8,0.3,0.9,0.3,0.6,0.5]).reshape(4,2)</span><br><span class="line">eli=[.8,.8]</span><br><span class="line"></span><br><span class="line"># mpatches.Circle(c, r, color) 产生c为圆心，r为半径，颜色为color的圆形</span><br><span class="line">cicle=mpatches.Circle(clc,0.1,color='blue')</span><br><span class="line">ax.add_patch(cicle)</span><br><span class="line"></span><br><span class="line"># mpatches.Rectangle(c, length, width, color) 产生左下角坐标为c，长为length，宽为width，颜色为color的矩形</span><br><span class="line">rectangle=mpatches.Rectangle(rec,0.2,0.1,color='red')</span><br><span class="line">ax.add_patch(rectangle)</span><br><span class="line"></span><br><span class="line"># mpatches.Polygon(pol, color) 产生各个定点为pol的多边形</span><br><span class="line">polygon=mpatches.Polygon(pol,color='green')</span><br><span class="line">ax.add_patch(polygon)</span><br><span class="line"></span><br><span class="line"># mpatches.Ellipse(c, a, b,color) 产生圆心为c，长轴为a，短轴为b的椭圆</span><br><span class="line">ellipse=mpatches.Ellipse(eli,0.4,0.2,color='yellow')</span><br><span class="line">ax.add_patch(ellipse)</span><br><span class="line"></span><br><span class="line">plt.axis('equal')</span><br><span class="line">plt.grid(True)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib16.png" alt="16"></p>
<h2 id="matplotlib绘制二维数据"><a href="#matplotlib绘制二维数据" class="headerlink" title="matplotlib绘制二维数据"></a><font size="4">matplotlib绘制二维数据</font></h2><h3 id="imshow，colorbar方法"><a href="#imshow，colorbar方法" class="headerlink" title="imshow，colorbar方法"></a><font size="3">imshow，colorbar方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">x = np.random.uniform(0, 255, (5,5))</span><br><span class="line">x</span><br><span class="line"># plt.imshow(array, interpolation='nearest', cmap='hot', origin='upper') 显示二维数据，interpolation为插值方式，默认为最近邻，cmap为颜色显示方式(默认为hot)，可以为'hot'，'cool'，'rainbow'，'bone'，origin为图形绘制的方向，upper从上到下，lower自下而上。</span><br><span class="line">plt.imshow(x, cmap='bone')</span><br><span class="line"></span><br><span class="line"># plt.colorbar() 添加颜色棒</span><br><span class="line">plt.colorbar()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib17.png" alt="17"></p>
<h2 id="matplotlib绘制3D图形"><a href="#matplotlib绘制3D图形" class="headerlink" title="matplotlib绘制3D图形"></a><font size="4">matplotlib绘制3D图形</font></h2><h3 id="Axes3D，plot-surface方法"><a href="#Axes3D，plot-surface方法" class="headerlink" title="Axes3D，plot_surface方法"></a><font size="3">Axes3D，plot_surface方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import mpl_toolkits.mplot3d as mp</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">x = np.arange(-4, 4, 0.25)</span><br><span class="line">y = np.arange(-4, 4, 0.25)</span><br><span class="line">x, y = np.meshgrid(x, y)</span><br><span class="line">z = np.sqrt(x**2 + y**2)</span><br><span class="line">z = np.sin(z)</span><br><span class="line"></span><br><span class="line"># mp.Axes3D(fig) 生成3D窗口</span><br><span class="line">ax = mp.Axes3D(fig)</span><br><span class="line"></span><br><span class="line"># obj.plot_surface(x, y, z, rstride=1, cstride=1, cmap=None) 画出3D表面图形，rstride为行跨度，cstride为列跨度，cmap为颜色显示方式同plt.imshow</span><br><span class="line">ax.plot_surface(x, y, z, cmap='rainbow')</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib18.png" alt="18"></p>
<h2 id="matplotlib极坐标系"><a href="#matplotlib极坐标系" class="headerlink" title="matplotlib极坐标系"></a><font size="4">matplotlib极坐标系</font></h2><h3 id="subplot方法-1"><a href="#subplot方法-1" class="headerlink" title="subplot方法"></a><font size="3">subplot方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">theta = np.linspace(-np.pi, np.pi, 100)</span><br><span class="line">r = 0.5 * (1 + np.cos(theta))</span><br><span class="line"></span><br><span class="line"># plt.subplot(111, projection='polar') 绘制极坐标</span><br><span class="line">fig = plt.subplot(111, projection='polar')</span><br><span class="line"></span><br><span class="line">fig.plot(theta, r)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/matplotlib19.png" alt="19"></p>
<h1 id="Matplotlib小结"><a href="#Matplotlib小结" class="headerlink" title="Matplotlib小结"></a><font size="5" color="red">Matplotlib小结</font></h1><p>  通过Matplotlib，开发者可以仅需要几行代码，便可以生成绘图。在数据分析，机器学习，深度学习中，要对当前的数据进行实时的显示或者对准确率有直观的展示，需要借助Matplotlib的帮助，因此Matplotlib也作为机器学习三剑客之一。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python常用库</category>
      </categories>
  </entry>
  <entry>
    <title>Pandas</title>
    <url>/2019/08/13/library%20Pandas/</url>
    <content><![CDATA[<p><img src="/images/LIBRARY/pandas.jpg" alt="0"></p>
<h1 id="Pandas介绍"><a href="#Pandas介绍" class="headerlink" title="Pandas介绍"></a><font size="5" color="red">Pandas介绍</font></h1><p>  pandas是基于Numpy的一种工具，该工具纳入了大量库和一些标准的数据模型，提供了大量能使我们快速便捷地处理数据的函数和方法。<br><a id="more"></a></p>
<h1 id="Pandas特点"><a href="#Pandas特点" class="headerlink" title="Pandas特点"></a><font size="5" color="red">Pandas特点</font></h1><p>  <font size="3">Pandas解决了Numpy不利于处理数据结构的问题</font><br>  <font size="3">Pandas能够合并处理常见数据库中的关系型运算</font><br>  <font size="3">Pandas更贴近于日常的生活使用，即表格化的数据形式</font><br>  <font size="3">Pandas具备数据对齐功能，且集成时间序列，既能处理时间序列数据，也能处理非时间序列数据</font></p>
<h1 id="Pandas应用"><a href="#Pandas应用" class="headerlink" title="Pandas应用"></a><font size="5" color="red">Pandas应用</font></h1><h2 id="Pandas创建表格"><a href="#Pandas创建表格" class="headerlink" title="Pandas创建表格"></a><font size="4">Pandas创建表格</font></h2><h3 id="series方法"><a href="#series方法" class="headerlink" title="series方法"></a><font size="3">series方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># pd.Series(list, index) 将list转换为一维表格型数据结构，index为标签名称，默认从0开始0,1, ...</span><br><span class="line">a = pd.Series([1, 'hello', 3.1415, True])</span><br><span class="line">b = pd.Series([1, 'hello', 3.1415, True], index=['int', 'string', 'float', 'bool'])</span><br><span class="line"></span><br><span class="line"># pd.Series(dict) 将dict转换为一维表格型数据结构</span><br><span class="line">c = pd.Series({'int':1, 'string':'hello', 'float':3.1415, 'bool':True})</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas1.png" alt="1"></p>
<h3 id="DataFrame方法"><a href="#DataFrame方法" class="headerlink" title="DataFrame方法"></a><font size="3">DataFrame方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># pd.DataFrame(array, index, columns) 生成行标签为index，列标签为columns，数据为array的二维表格型数据结构</span><br><span class="line">a = pd.DataFrame(np.arange(12).reshape(3, 4), index=['row_0', 'row_1', 'row_2'], columns=['columns_0', 'columns_1', 'columns_2', 'columns_3']) </span><br><span class="line"></span><br><span class="line"># pd.DataFrame(dict, index) 生成行标签为index，数据为dict的二维表格型数据结构，dict中的每一个key是每一列的列标签，value是每一列的数据</span><br><span class="line">b = pd.DataFrame({'columns_0':[0, 4, 8], 'columns_1':[1, 5, 9], 'columns_2':[2, 6, 10], 'columns_3':[3, 7, 11]}, index=['row_0', 'row_1', 'row_2'])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas2.png" alt="2"></p>
<h2 id="Pandas属性"><a href="#Pandas属性" class="headerlink" title="Pandas属性"></a><font size="4">Pandas属性</font></h2><h3 id="dtypes，index，columns，values属性"><a href="#dtypes，index，columns，values属性" class="headerlink" title="dtypes，index，columns，values属性"></a><font size="3">dtypes，index，columns，values属性</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame({'col_0':[0, 4, 8], 'col_1':[2.71, 3.14, 5], 'col_2':[True, False, False]}, index=['row_0', 'row_1', 'row_2']) </span><br><span class="line"></span><br><span class="line"># obj.dtypes 查看每一列的数据形式</span><br><span class="line">a.dtypes</span><br><span class="line"></span><br><span class="line"># obj.index 查看列的序号</span><br><span class="line">a.index</span><br><span class="line"></span><br><span class="line"># obj.columns 查看行的序号</span><br><span class="line">a.columns</span><br><span class="line"></span><br><span class="line"># obj.values 查看列表中的数据内容</span><br><span class="line">a.values</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas3.png" alt="3"></p>
<h3 id="describe，head，tail属性"><a href="#describe，head，tail属性" class="headerlink" title="describe，head，tail属性"></a><font size="3">describe，head，tail属性</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame({'col_0':[0, 4, 8], 'col_1':[2.71, 3.14, 5], 'col_2':[True, False, False]}, index=['row_0', 'row_1', 'row_2']) </span><br><span class="line"></span><br><span class="line"># obj.describe() 查看内容统计，只统计数字内容</span><br><span class="line">a.describe()</span><br><span class="line"></span><br><span class="line"># obj.head(n) 查看前n行</span><br><span class="line">a.head(2)</span><br><span class="line"></span><br><span class="line"># obj.tail(n) 查看后n行</span><br><span class="line">a.tail(2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas4.png" alt="4"></p>
<h2 id="Pandas表格排序"><a href="#Pandas表格排序" class="headerlink" title="Pandas表格排序"></a><font size="4">Pandas表格排序</font></h2><h3 id="sort-index方法"><a href="#sort-index方法" class="headerlink" title="sort_index方法"></a><font size="3">sort_index方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(np.random.randint(1, 6, (3, 4)), index=['row_2', 'row_1', 'row_3'], columns=['col_2', 'col_0', 'col_3', 'col_1'])</span><br><span class="line"></span><br><span class="line"># obj.sort_index(axis=0, ascending=True) 对obj的标签进行排序，axis=0(默认)为行标签，axis=1为列标签，ascending=True(默认)为递增顺序，ascending=False为递减顺序</span><br><span class="line">b = a.sort_index()</span><br><span class="line">c = a.sort_index(axis=1, ascending=False)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas5.png" alt="5"></p>
<h3 id="sort-values方法"><a href="#sort-values方法" class="headerlink" title="sort_values方法"></a><font size="3">sort_values方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(np.random.randint(1, 6, (3, 4)), index=['row_2', 'row_1', 'row_3'], columns=['col_2', 'col_0', 'col_3', 'col_1'])</span><br><span class="line"></span><br><span class="line"># obj.sort_values(by, axis=0, ascending) 对obj的数据内容进行排序，by指定要排序的行或者列，axis=0(默认)为行标签，axis=1为列标签，ascending=True(默认)为递增顺序，ascending=False为递减顺序</span><br><span class="line">b = a.sort_values(by='col_0')</span><br><span class="line">c = a.sort_values(by='row_1', axis=1, ascending=False)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas6.png" alt="6"></p>
<h2 id="pandas切片与索引"><a href="#pandas切片与索引" class="headerlink" title="pandas切片与索引"></a><font size="4">pandas切片与索引</font></h2><h3 id="方法"><a href="#方法" class="headerlink" title="[]方法"></a><font size="3">[]方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(np.arange(12).reshape(3, 4), index=['row_0', 'row_1', 'row_2'], columns=['col_0', 'col_1', 'col_2', 'col_3']) </span><br><span class="line"></span><br><span class="line"># obj[col_name] 索引obj中的col_name列</span><br><span class="line">b = a[['col_3', 'col_0']]</span><br><span class="line"></span><br><span class="line"># obj[m:n] 索引obj中的[m, n)行</span><br><span class="line">c = a[1:3]</span><br><span class="line"></span><br><span class="line"># obj[obj.col_name op x] 索引obj的col_name列中对x操作后为True的行</span><br><span class="line">d = a[a.col_0  &gt; 3]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas7.png" alt="7"></p>
<h3 id="loc，iloc方法"><a href="#loc，iloc方法" class="headerlink" title="loc，iloc方法"></a><font size="3">loc，iloc方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(np.arange(12).reshape(3, 4), index=['row_0', 'row_1', 'row_2'], columns=['col_0', 'col_1', 'col_2', 'col_3']) </span><br><span class="line"></span><br><span class="line"># obj.loc[row_name，col_name=None] 索引obj中行标签为row_name,列标签为col_name(默认是全部列)的所有数据</span><br><span class="line">b = a.loc[['row_1', 'row_2']]</span><br><span class="line"></span><br><span class="line"># obj.iloc[row_index, col_index] 索引obj中的第row_index行和第col_index列</span><br><span class="line">c = a.iloc[[1, 2], [1, 2]]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas8.png" alt="8"></p>
<h2 id="pandas修改内容"><a href="#pandas修改内容" class="headerlink" title="pandas修改内容"></a><font size="4">pandas修改内容</font></h2><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="[]方法"></a><font size="3">[]方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(np.arange(12).reshape(3, 4), index=['row_0', 'row_1', 'row_2'], columns=['col_0', 'col_1', 'col_2', 'col_3']) </span><br><span class="line"></span><br><span class="line"># obj[col_name] 将obj中的col_name列中的数据改为x</span><br><span class="line">a[['col_3','col_2']] = -1</span><br><span class="line"></span><br><span class="line"># obj[m:n] = x 将obj中的[m, n)行中的所有数据改为x</span><br><span class="line">a[2:3] = -2</span><br><span class="line"></span><br><span class="line"># obj[obj[col_name] op x] = x 将obj的col_name列中对x操作后为True的行中的所有数据改为x</span><br><span class="line">a[a['col_0']  &gt; 3] = -3</span><br><span class="line"></span><br><span class="line"># obj.col_name[obj.col_name op x] = x 将obj的col_name列中对x操作后为True的所有数据改为x</span><br><span class="line">a.col_0[a['col_0']  != -3] =-4</span><br><span class="line"></span><br><span class="line"># obj[col_name] = x 将obj的col_name列修改为x，如果没有该列则增加一列</span><br><span class="line">a['col_4'] =-5</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas9.png" alt="9"></p>
<h3 id="dropna，fillna方法"><a href="#dropna，fillna方法" class="headerlink" title="dropna，fillna方法"></a><font size="3">dropna，fillna方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame({'col_0':[0, 4, np.nan], 'col_1':[2.71, np.nan, np.nan], 'col_2':[np.nan, np.nan, np.nan]}, index=['row_0', 'row_1', 'row_2']) </span><br><span class="line">b = pd.DataFrame({'col_0':[0, 4, 2.5], 'col_1':[2.71, np.nan, np.nan], 'col_2':[np.nan, np.nan, np.nan]}, index=['row_0', 'row_1', 'row_2']) </span><br><span class="line"></span><br><span class="line"># obj.dropna(axis=0, how='any') 将obj中的nan删除，axis=0(默认)为删除行，axis=1为删除列，how='any'(默认)为只要存在nan就删除，how='all'为全部为nan才删除</span><br><span class="line">c = a.dropna()</span><br><span class="line">d = b.dropna(1, 'all')</span><br><span class="line"></span><br><span class="line"># obj.fillna(value) 将obj中的nan用value填充,value可以为数字或者字典，如果是字典则按照字典的对应关系按列填充</span><br><span class="line">e = a.fillna(-1)</span><br><span class="line">f = a.fillna({'col_0':-1, 'col_1':-2, 'col_2':-3})</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas10.png" alt="10"></p>
<h2 id="pandas合并"><a href="#pandas合并" class="headerlink" title="pandas合并"></a><font size="4">pandas合并</font></h2><h3 id="concat方法"><a href="#concat方法" class="headerlink" title="concat方法"></a><font size="3">concat方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">index_a = ['A', 'B']</span><br><span class="line">index_b = ['B', 'C']</span><br><span class="line">col_a = ['a', 'b']</span><br><span class="line">col_b = ['b', 'c']</span><br><span class="line">a = pd.DataFrame(np.arange(4).reshape(2, 2), index=index_a, columns=col_a) </span><br><span class="line">b = pd.DataFrame(np.arange(4).reshape(2, 2), index=index_b, columns=col_b) </span><br><span class="line"></span><br><span class="line"># pd.concat([obj1, obj2, ...], axis=0, join='outer', ignore_index=False) 将多个对象按照轴进行连接，join为连接方式，'outer'代表将没有相应标签的对象补NaN，'inner'代表只保留共有的标签，ignore_index为是否重新开始排列标签</span><br><span class="line">c = pd.concat([a, b])</span><br><span class="line">d = pd.concat([a, b], axis=1)</span><br><span class="line">e = pd.concat([a, b], join='inner')</span><br><span class="line">f = pd.concat([a, b],ignore_index=True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas11.png" alt="11"></p>
<h3 id="append方法"><a href="#append方法" class="headerlink" title="append方法"></a><font size="3">append方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">index_a = ['A', 'B']</span><br><span class="line">index_b = ['B', 'C']</span><br><span class="line">col_a = ['a', 'b']</span><br><span class="line">col_b = ['b', 'c']</span><br><span class="line">a = pd.DataFrame(np.arange(4).reshape(2, 2), index=index_a, columns=col_a) </span><br><span class="line">b = pd.DataFrame(np.arange(4).reshape(2, 2), index=index_b, columns=col_b) </span><br><span class="line"></span><br><span class="line"># obj.append([obj1, obj2, ...], ignore_index=False) 在纵向在obj后追加obj1, obj2,......，如果没有对应的列标签，则补NaN</span><br><span class="line">c = a.append([a])</span><br><span class="line">d = a.append([b])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas12.png" alt="12"></p>
<h3 id="merge方法"><a href="#merge方法" class="headerlink" title="merge方法"></a><font size="3">merge方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">index_a = ['A', 'B']</span><br><span class="line">index_b = ['B', 'C']</span><br><span class="line">col_a = ['a', 'b']</span><br><span class="line">col_b = ['b', 'c']</span><br><span class="line">a = pd.DataFrame(np.array([1, 3, 5, 7]).reshape(2, 2), index=index_a, columns=col_a) </span><br><span class="line">b = pd.DataFrame(np.array([3, 4, 5, 6]).reshape(2, 2), index=index_b, columns=col_b) </span><br><span class="line"></span><br><span class="line"># pd.merge(left, right, how='inner', on='col_name',left_index=False,right_index=False) 按照on进行合并两个表格,how='inner'，行标签为两个表格行标签的交集，'outer'，行标签为两个表格行标签的并集，将不相交的部分取NaN，'left'，行标签为left的行标签，'right'，行标签为left的行标签。left_index和right_index指是否按照标签合并，为False根据值合并表格，True根据标签合并表格</span><br><span class="line">c = pd.merge(a, b, on='b')</span><br><span class="line">d = pd.merge(a, b, how='outer', on='b')</span><br><span class="line">e = pd.merge(a, b, how='left', on='b')</span><br><span class="line">f = pd.merge(a, b, how='right', on='b')</span><br><span class="line">g = pd.merge(a, b, how='outer', left_index=True,right_index=True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas13.png" alt="13"></p>
<h2 id="Pandas修改行列名"><a href="#Pandas修改行列名" class="headerlink" title="Pandas修改行列名"></a><font size="4">Pandas修改行列名</font></h2><h3 id="replace，rename方法"><a href="#replace，rename方法" class="headerlink" title="replace，rename方法"></a><font size="4">replace，rename方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame([[1, 3], [5, 7]], index=['row_0', 'row_1'], columns=['col_0', 'col_1']) </span><br><span class="line"></span><br><span class="line"># obj.columns = list，obj.index = list 将列标签改为list，将行标签改为list</span><br><span class="line">a.columns = ['new_col_0', 'new_col_1']</span><br><span class="line">a.index = ['new_row_0', 'new_row_1']</span><br><span class="line"></span><br><span class="line"># obj.replace(list1, list2) 将obj中list1中的数值替换为list2</span><br><span class="line">b = a.replace([1, 7], [2, 6])</span><br><span class="line"></span><br><span class="line"># obj.rename(columns=dict/func, index=dict/func) 用字典或函数来更改行列名</span><br><span class="line">c = a.rename(columns={'new_col_0':'A', 'new_col_1':'B'}, index={'new_row_0':'a', 'new_row_1':'b'})</span><br><span class="line">d = a.rename(columns=lambda x: x[-1], index=lambda x: x[-1])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas14.png" alt="14"></p>
<h2 id="pandas数理统计"><a href="#pandas数理统计" class="headerlink" title="pandas数理统计"></a><font size="4">pandas数理统计</font></h2><h3 id="notnull，isnull方法"><a href="#notnull，isnull方法" class="headerlink" title="notnull，isnull方法"></a><font size="3">notnull，isnull方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame([[1, np.nan], [5, 7]], index=['row_0', 'row_1'], columns=['col_0', 'col_1']) </span><br><span class="line"></span><br><span class="line"># obj.isnull() 判断obj中每一项是否为NaN</span><br><span class="line">a.isnull()</span><br><span class="line"></span><br><span class="line"># obj.notnull() 判断obj中每一项是否不为NaN</span><br><span class="line">a.notnull()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas15.png" alt="15"></p>
<h3 id="统计方法"><a href="#统计方法" class="headerlink" title="统计方法"></a><font size="3">统计方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame([[1, 4, 7], [2, 5, 8], [5, 4, 1]], index=['r_0', 'r_1', 'r_2'], columns=['c_0', 'c_1', 'c_2']) </span><br><span class="line">b = pd.DataFrame([[1, 4, 7], [2, np.nan, 8], [5, np.nan, np.nan]], index=['r_0', 'r_1', 'r_2'], columns=['c_0', 'c_1', 'c_2']) </span><br><span class="line"></span><br><span class="line"># obj.max/min(axis=0) 统计最大值/最小者，axis=0为列，axis=1为行</span><br><span class="line">a.max(0)</span><br><span class="line">a.min(1)</span><br><span class="line"></span><br><span class="line"># obj.count(axis=0) 统计非空个数，axis用法同pd.max</span><br><span class="line">b.count()</span><br><span class="line"></span><br><span class="line"># obj.mean(axis=0) 统计均值，axis用法同pd.max</span><br><span class="line">a.mean()</span><br><span class="line"></span><br><span class="line"># obj.median(axis=0) 统计中位数，axis用法同pd.max</span><br><span class="line">a.median()</span><br><span class="line"></span><br><span class="line"># obj.std(axis=0) 统计标准差，axis用法同pd.max</span><br><span class="line">a.std()</span><br><span class="line"></span><br><span class="line"># obj.var(obj, axis=None) 统计方差，axis用法同pd.max</span><br><span class="line">a.var()</span><br><span class="line"></span><br><span class="line"># obj.corr(obj, axis=None) 统计相关系数，axis用法同pd.max</span><br><span class="line">a.corr()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas16.png" alt="16"></p>
<h2 id="pandas数据保存"><a href="#pandas数据保存" class="headerlink" title="pandas数据保存"></a><font size="4">pandas数据保存</font></h2><h3 id="to-csv，read-csv方法"><a href="#to-csv，read-csv方法" class="headerlink" title="to_csv，read_csv方法"></a><font size="3">to_csv，read_csv方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(np.arange(12).reshape(3, 4), index=['row_0', 'row_1', 'row_2'], columns=['col_0', 'col_1', 'col_2', 'col_3']) </span><br><span class="line"></span><br><span class="line"># obj.to_csv/pickle(filename) 将obj保存在文件名为filename的.csv/pickle文件中(要加.csv/pickle扩展名)</span><br><span class="line">a.to_csv('save1.csv')</span><br><span class="line">a.to_pickle('save2.pickle')</span><br><span class="line"></span><br><span class="line"># pd.read_csv(filename) 读取文件名为filename的数组数据(要加.csv/pickle扩展名)</span><br><span class="line">b = pd.read_csv('save1.csv')</span><br><span class="line">c = pd.read_pickle('save2.pickle')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas17.png" alt="17"></p>
<h2 id="pandas数据显示"><a href="#pandas数据显示" class="headerlink" title="pandas数据显示"></a><font size="4">pandas数据显示</font></h2><h3 id="plot，plot-scatter方法"><a href="#plot，plot-scatter方法" class="headerlink" title="plot，plot.scatter方法"></a><font size="3">plot，plot.scatter方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">x = np. arange(10)</span><br><span class="line">y = np.log(x)</span><br><span class="line">a = pd.DataFrame({'x':x, 'y':y}) </span><br><span class="line"></span><br><span class="line"># obj.plot.scatter(x, y) 画出x-y对应的散点图，可参考matplotlib</span><br><span class="line">a.plot.scatter('x', 'y')</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/pandas18.png" alt="18"></p>
<h1 id="Pandas小结"><a href="#Pandas小结" class="headerlink" title="Pandas小结"></a><font size="5" color="red">Pandas小结</font></h1><p>  Pandas可处理的数据更接近来源于生活中的数据，在数据分析，机器学习中，大量的数据都是具有标签的，不只是纯数字的数据，需要借助Pandas的帮助，因此pandas也作为机器学习三剑客之一。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python常用库</category>
      </categories>
  </entry>
  <entry>
    <title>Scikit-Learn</title>
    <url>/2019/08/12/library%20Sklearn/</url>
    <content><![CDATA[<p><img src="/images/LIBRARY/sklearn.jpg" alt="0"></p>
<h1 id="Scikit-Learn介绍"><a href="#Scikit-Learn介绍" class="headerlink" title="Scikit-Learn介绍"></a><font size="5" color="red">Scikit-Learn介绍</font></h1><p>  Scikit-Learn库自2007年发布以来，已经称为最受欢迎的机器学习库之一，基于广受欢迎的Numpy和Scipy库构建，能够提供用于机器学习的算法，数据预处理等功能。<br><a id="more"></a></p>
<h1 id="Scikit-Learn应用"><a href="#Scikit-Learn应用" class="headerlink" title="Scikit-Learn应用"></a><font size="5" color="red">Scikit-Learn应用</font></h1><h2 id="Scikit-Learn线性回归"><a href="#Scikit-Learn线性回归" class="headerlink" title="Scikit-Learn线性回归"></a><font size="4">Scikit-Learn线性回归</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">x_train = np.array([[6], [8], [10], [14], [18]]).reshape(-1, 1)</span><br><span class="line">y_train = np.array([7, 9, 13, 17.5, 18])</span><br><span class="line"></span><br><span class="line"># model = LinearRegression() 创建线性回归模型</span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"># model.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">x_test = np.array([[12]]).reshape(-1, 1)</span><br><span class="line"></span><br><span class="line"># model.predict(X) 用训练后的模型预测数据X</span><br><span class="line">y_test = model.predict(x_test)[0]</span><br><span class="line"></span><br><span class="line">x_max, x_min = max(x_train), min(x_train)</span><br><span class="line">y_max, y_min = model.predict([x_max, x_min])</span><br><span class="line"></span><br><span class="line"># model.coef_ 获取模型的权值系数</span><br><span class="line">k = model.coef_[0]</span><br><span class="line">x_mean, y_mean = np.mean(x_train), np.mean(y_train)</span><br><span class="line">b = y_mean - k * x_mean</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.title('Pizza price against diameter:\n' + str(k) + 'x + ' + str(b) + '= y')</span><br><span class="line">plt.xlabel('Pizza diamter')</span><br><span class="line">plt.ylabel('Pizza price')</span><br><span class="line">plt.plot(x_train, y_train, 'k.', label='train_dot')</span><br><span class="line">plt.plot(x_test, y_test, 'ro', label='predict_dot')</span><br><span class="line">plt.plot([x_max, x_min], [y_max, y_min])</span><br><span class="line">plt.text(x_test, y_test, '(' + str(x_test[0][0]) + ',' + str(y_test) + ')')</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn1.png" alt="1"></p>
<h2 id="Scikit-LearnK近邻分类算法"><a href="#Scikit-LearnK近邻分类算法" class="headerlink" title="Scikit-LearnK近邻分类算法"></a><font size="4">Scikit-LearnK近邻分类算法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import LabelBinarizer</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.metrics import precision_score</span><br><span class="line">from sklearn.metrics import recall_score</span><br><span class="line">from sklearn.metrics import f1_score</span><br><span class="line">from sklearn.metrics import matthews_corrcoef</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">def classify(x, y):</span><br><span class="line">    male_height, male_weight, female_height, female_weight = [], [], [], []</span><br><span class="line">    for i in range(len(x)):</span><br><span class="line">        if y[i] == 'male':</span><br><span class="line">            male_height.append(x[i][0])</span><br><span class="line">            male_weight.append(x[i][1])</span><br><span class="line">        else:</span><br><span class="line">            female_height.append(x[i][0])</span><br><span class="line">            female_weight.append(x[i][1])</span><br><span class="line">    return male_height, male_weight, female_height, female_weight</span><br><span class="line"></span><br><span class="line">x_train = np.array([[158, 64], [170, 66], [183, 84], [191, 80], [155, 49], [163, 59], [180, 67], [158, 54], [178, 77]])</span><br><span class="line">y_train = ['male', 'male', 'male', 'male', 'female', 'female', 'female', 'female', 'female'] </span><br><span class="line"></span><br><span class="line"># lb = LabelBinarizer() 创建一个标签转换器接口，将标签变成整数</span><br><span class="line">lb = LabelBinarizer()</span><br><span class="line"></span><br><span class="line"># lb.fit_transform(y) 在训练数据集上对标签进行拟合并转换为整数</span><br><span class="line">y_train_binarized = lb.fit_transform(y_train)</span><br><span class="line"></span><br><span class="line">k = 3</span><br><span class="line"></span><br><span class="line"># clf = KNeighborsClassifier(n_neighbors=k) 创建KNN分类器模型</span><br><span class="line">clf = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train,y_train_binarized.reshape(-1))</span><br><span class="line"></span><br><span class="line">x_test = np.array([[168, 65], [170, 61], [160, 52], [169, 67]])</span><br><span class="line">y_test = ['male', 'male', 'female', 'female']</span><br><span class="line"></span><br><span class="line"># clf.predict(X) 用训练后的模型预测数据X</span><br><span class="line">y_pre_binarized = clf.predict(x_test)</span><br><span class="line"></span><br><span class="line"># lb.inverse_transform(Y) 将预测后的整数转换成标签</span><br><span class="line">y_pre = lb.inverse_transform(y_pre_binarized)</span><br><span class="line"></span><br><span class="line">male_height_train, male_weight_train, female_height_train, female_weight_train = classify(x_train, y_train)</span><br><span class="line">male_height_pre, male_weight_pre, female_height_pre, female_weight_pre = classify(x_test, y_pre)</span><br><span class="line"></span><br><span class="line">y_test_binarized = lb.transform(y_test).T[0]</span><br><span class="line">print(y_test_binarized)</span><br><span class="line">print(y_pre_binarized)</span><br><span class="line"></span><br><span class="line"># accuracy_score(y_test, y_predict) 求真实值与预测值的准确率</span><br><span class="line">print('预测准确率为:%.2f' %accuracy_score(y_test_binarized, y_pre_binarized))</span><br><span class="line"></span><br><span class="line"># precision_score(y_test, y_predict) 求真实值与预测值的精准率</span><br><span class="line">print('预测精准率为:%.2f' %precision_score(y_test_binarized, y_pre_binarized))</span><br><span class="line"></span><br><span class="line"># recall_score(y_test, y_predict) 求真实值与预测值的召回率</span><br><span class="line">print('预测召回率为:%.2f' %recall_score(y_test_binarized, y_pre_binarized))</span><br><span class="line"></span><br><span class="line"># f1_score(y_test, y_predict) 求真实值与预测值的F1得分</span><br><span class="line">print('预测F1得分为:%.2f' %f1_score(y_test_binarized, y_pre_binarized))</span><br><span class="line"></span><br><span class="line"># matthews_corrcoef(y_test, y_predict) 求真实值与预测值的马修斯系数</span><br><span class="line">print('马修斯系数为:%.2f' %matthews_corrcoef(y_test_binarized, y_pre_binarized))</span><br><span class="line"></span><br><span class="line"># classification_report(y_test, y_predict, target_names=None, labels=None) 同时生成真实值与预测值的精准率，召回率和F1得分，目标标签为target_name，对应的值为label</span><br><span class="line">print(classification_report(y_test_binarized, y_pre_binarized, target_names={'male'}, labels=[1]))</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line">plt.figure()</span><br><span class="line">plt.title('Human Height and Weight By Sex:')</span><br><span class="line">plt.xlabel('Height')</span><br><span class="line">plt.ylabel('Weight')</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.scatter(male_height_train, male_weight_train, color='b', marker='o', label='train_male')</span><br><span class="line">plt.scatter(female_height_train, female_weight_train, color='r', marker='o', label='train_female')</span><br><span class="line">plt.scatter(male_height_pre, male_weight_pre, color='b', marker='*', label='pre_male')</span><br><span class="line">plt.scatter(female_height_pre, female_weight_pre, color='r', marker='*', label='pre_female')</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn2.png" alt="2"></p>
<h2 id="Scikit-LearnK近邻回归算法"><a href="#Scikit-LearnK近邻回归算法" class="headerlink" title="Scikit-LearnK近邻回归算法"></a><font size="4">Scikit-LearnK近邻回归算法</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.neighbors import KNeighborsRegressor</span><br><span class="line">from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">x_train = np.array([[158, 1], [170, 1], [183, 1], [191, 1], [155, 0], [163, 0], [180, 0], [158, 0], [170, 0]])</span><br><span class="line">y_train = np.array([64, 86, 84, 80, 49, 59, 67, 54, 67])</span><br><span class="line">x_test = np.array([[168, 1], [180, 1], [160, 0], [169, 0]])</span><br><span class="line">y_test = [65, 96, 52, 67]</span><br><span class="line">k = 3</span><br><span class="line"></span><br><span class="line"># clf = KNeighborsRegressor(n_neighbors=k) 创建KNN回归模型</span><br><span class="line">clf = KNeighborsRegressor(n_neighbors=k)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"># clf.predict(X) 用训练后的模型预测数据X</span><br><span class="line">pre = clf.predict(x_test)</span><br><span class="line"></span><br><span class="line">print([np.around(x, 2) for x in pre])</span><br><span class="line"></span><br><span class="line"># r2_score(y_test, y_predict) 求真实值与预测值的决定系数</span><br><span class="line">print('Coefficiet of determination: %.2f' %r2_score(y_test, pre))</span><br><span class="line"></span><br><span class="line"># mean_absolute_erro(y_test, y_predict) 求真实值与预测值的平均绝对误差MAE</span><br><span class="line">print('Mean absolute error: %.2f' %mean_absolute_error(y_test, pre))</span><br><span class="line"></span><br><span class="line"># mean_squared_error(y_test, y_predict) 求真实值与预测值的均方误差MSE</span><br><span class="line">print('Mean squared error: %.2f' %mean_squared_error(y_test, pre))</span><br><span class="line"></span><br><span class="line">print('\n' + 'Scaled Processing'.center(30, '~') + '\n')</span><br><span class="line"></span><br><span class="line"># ss = StandardScaler() 创建一个特征缩放转换接口</span><br><span class="line">ss = StandardScaler()</span><br><span class="line"></span><br><span class="line"># ss.fit_transform(x) 在训练数据集上对数据特征进行缩放</span><br><span class="line">x_train_scaled = ss.fit_transform(x_train)</span><br><span class="line"></span><br><span class="line"># ss.transform(x) 在测试数据集上对数据特征进行缩放</span><br><span class="line">x_test_scaled = ss.transform(x_test) </span><br><span class="line"></span><br><span class="line">clf.fit(x_train_scaled, y_train)</span><br><span class="line"></span><br><span class="line">pre_scaled = clf.predict(x_test_scaled)</span><br><span class="line"></span><br><span class="line">print([np.around(x, 2) for x in pre_scaled])</span><br><span class="line">print('Coefficiet of determination: %.2f' %r2_score(y_test, pre_scaled))</span><br><span class="line">print('Mean absolute error: %.2f' %mean_absolute_error(y_test, pre_scaled))</span><br><span class="line">print('Mean squared error: %.2f' %mean_squared_error(y_test, pre_scaled))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn3.png" alt="3"></p>
<h2 id="Scikit-Learn独热编码"><a href="#Scikit-Learn独热编码" class="headerlink" title="Scikit-Learn独热编码"></a><font size="4">Scikit-Learn独热编码</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.feature_extraction import DictVectorizer</span><br><span class="line"></span><br><span class="line"># onehot_encoder = DictVectorizer() 创建独热编码转换器</span><br><span class="line">onehot_encoder = DictVectorizer()</span><br><span class="line"></span><br><span class="line">x = [{'city': 'New York'}, {'city': 'San Francisco'}, {'city:': 'Chapel Hill'}]</span><br><span class="line"></span><br><span class="line"># onehot_encoder.fit_transform(x).toarray() 将字典的值value进行独热编码</span><br><span class="line">onehot_x = onehot_encoder.fit_transform(x).toarray()</span><br><span class="line"></span><br><span class="line">print(onehot_x)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn4.png" alt="4"></p>
<h2 id="Scikit-Learn特征标准化"><a href="#Scikit-Learn特征标准化" class="headerlink" title="Scikit-Learn特征标准化"></a><font size="4">Scikit-Learn特征标准化</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn import preprocessing</span><br><span class="line"></span><br><span class="line">x = np.array([[0., 0., 5., 13., 9., 1.], [0., 0., 13., 15., 10., 15.], [0., 3., 15., 2., 0., 11.]])</span><br><span class="line"></span><br><span class="line"># preprocessing.StandardScaler().fit_transform(x) 使用标准化转换器类函数</span><br><span class="line">x_standard_scaled = preprocessing.StandardScaler().fit_transform(x)</span><br><span class="line">print(x_standard_scaled)</span><br><span class="line"></span><br><span class="line"># preprocessing.scale(x) 使用标准化函数scale</span><br><span class="line">x_scaled = preprocessing.scale(x)</span><br><span class="line">print(x_scaled)</span><br><span class="line"></span><br><span class="line"># preprocessing.robust_scale(x) 使用鲁棒性标准化函数robust_scale</span><br><span class="line">x_robust_scaled = preprocessing.robust_scale(x)</span><br><span class="line">print(x_robust_scaled)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn5.png" alt="5"></p>
<h2 id="Scikit-Learn多元线性回归"><a href="#Scikit-Learn多元线性回归" class="headerlink" title="Scikit-Learn多元线性回归"></a><font size="4">Scikit-Learn多元线性回归</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">x = [[6, 2], [8, 1], [10, 0], [14, 2], [18, 0]]</span><br><span class="line">y = [[7], [9], [13], [17.5], [18]]</span><br><span class="line"></span><br><span class="line"># model = LinearRegression() 创建线性回归模型</span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"># model.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">model.fit(x, y)</span><br><span class="line"></span><br><span class="line">x_test = [[8, 2], [9, 0], [11, 2], [16, 2], [12, 0]]</span><br><span class="line">y_test = [[11], [8.5], [15], [18], [11]]</span><br><span class="line"></span><br><span class="line"># model.predict(X) 用训练后的模型预测数据X</span><br><span class="line">predictions = model.predict(x_test)</span><br><span class="line"></span><br><span class="line">for i, prediction in enumerate(predictions):</span><br><span class="line">    print('prediction: %s, truth: %s' %(prediction, y_test[i]))</span><br><span class="line"></span><br><span class="line"># model.score(x, y) 求模型的决定系数</span><br><span class="line">print('R-squared: %.2f' %model.score(x_test, y_test))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn6.png" alt="6"></p>
<h2 id="Scikit-Learn多项式回归"><a href="#Scikit-Learn多项式回归" class="headerlink" title="Scikit-Learn多项式回归"></a><font size="4">Scikit-Learn多项式回归</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line"></span><br><span class="line">plt.style.use('ggplot')</span><br><span class="line"></span><br><span class="line">x_train = [[6], [8], [10], [14], [18]]</span><br><span class="line">y_train = [[7], [9], [13], [17.5], [18]]</span><br><span class="line">x_test = [[6], [8], [11], [16]]</span><br><span class="line">y_test = [[8], [12], [15], [18]]</span><br><span class="line"></span><br><span class="line"># model = LinearRegression() 创建线性回归模型</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line"></span><br><span class="line"># model.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">regressor.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">xx = np.linspace(0, 26, 100)</span><br><span class="line"></span><br><span class="line"># model.predict(X) 用训练后的模型预测数据X</span><br><span class="line">yy = regressor.predict(xx.reshape(xx.shape[0], 1))</span><br><span class="line"></span><br><span class="line">plt.plot(xx, yy, c='b', label='Linear_poly')</span><br><span class="line"></span><br><span class="line"># quadratic_featurizer = PolynomialFeatures(degree=n) 创建n阶多项式转换器</span><br><span class="line">quadratic_featurizer = PolynomialFeatures(degree=2)</span><br><span class="line"></span><br><span class="line"># quadratic_featurizer.fit_transform(x_train) 在训练数据集上对数据特征进行多项式变换</span><br><span class="line">x_train_quadratic = quadratic_featurizer.fit_transform(x_train)</span><br><span class="line"></span><br><span class="line"># ss.fit_transform(x) 在训练数据集上对数据特征进行多项式变换</span><br><span class="line">x_test_quadratic = quadratic_featurizer.transform(x_test)</span><br><span class="line"></span><br><span class="line"># model = LinearRegression() 创建线性回归模型</span><br><span class="line">regressor_quadratic = LinearRegression()</span><br><span class="line"></span><br><span class="line"># model.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">regressor_quadratic.fit(x_train_quadratic, y_train)</span><br><span class="line"></span><br><span class="line"># ss.fit_transform(x) 对数据特征进行多项式变换</span><br><span class="line">xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[0], 1))</span><br><span class="line"></span><br><span class="line"># model.predict(X) 用训练后的模型预测数据X</span><br><span class="line">yy_quadratic = regressor_quadratic.predict(xx_quadratic)</span><br><span class="line"></span><br><span class="line">print('linear regression r-squared', regressor.score(x_test, y_test))</span><br><span class="line">print('quadratic regression r-squared', regressor_quadratic.score(x_test_quadratic, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(xx, yy_quadratic, c='r', label='square_poly')</span><br><span class="line">plt.scatter(x_train, y_train, label='data')</span><br><span class="line">plt.axis([0, 25, 0, 25])</span><br><span class="line">plt.title('Pizza price and diameter')</span><br><span class="line">plt.xlabel('Diameter in inches')</span><br><span class="line">plt.ylabel('Pizza Price')</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn7.png" alt="7"></p>
<h2 id="Scikit-Learn逻辑回归和朴素贝叶斯"><a href="#Scikit-Learn逻辑回归和朴素贝叶斯" class="headerlink" title="Scikit-Learn逻辑回归和朴素贝叶斯"></a><font size="4">Scikit-Learn逻辑回归和朴素贝叶斯</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.datasets import load_breast_cancer</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># from sklearn.datasets import load_breast_cancer 从sklearn数据集中导入胸部癌症的数据</span><br><span class="line">x, y = load_breast_cancer(return_X_y=True)</span><br><span class="line"></span><br><span class="line"># train_test_split(x, y, stratify=y, test_size=n) 将x和y按照test_size划分成数据集和测试集，stratify=y按照y中的比例分配</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=31)</span><br><span class="line"></span><br><span class="line"># lr = LogisticRegression() 创建逻辑回归模型</span><br><span class="line">lr = LogisticRegression(solver='liblinear')</span><br><span class="line"></span><br><span class="line"># nb = GaussianNB() 创建朴素贝叶斯模型</span><br><span class="line">nb = GaussianNB()</span><br><span class="line"></span><br><span class="line">lr_scores = []</span><br><span class="line">nb_scores = []</span><br><span class="line"></span><br><span class="line">train_sizes = range(10, len(x_train), 25)</span><br><span class="line">for train_size in train_sizes:</span><br><span class="line">    # train_test_split(x, y, stratify=y, train_size=n) 将x和y按照test_size划分成数据集和测试集，stratify=y按照y中的比例分配</span><br><span class="line">    x_slice, _, y_slice, _ = train_test_split(x_train, y_train, train_size=train_size, stratify=y_train, random_state=31)</span><br><span class="line"></span><br><span class="line">    # nb.fit(X, y) 用训练数据X，y拟合朴素贝叶斯模型</span><br><span class="line">    nb.fit(x_slice, y_slice)</span><br><span class="line"></span><br><span class="line">    # nb.score(x, y) 求朴素贝叶斯模型的决定系数</span><br><span class="line">    nb_scores.append(nb.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line">    # lr.fit(X, y) 用训练数据X，y拟合逻辑回归模型</span><br><span class="line">    lr.fit(x_slice, y_slice)</span><br><span class="line"></span><br><span class="line">    # lr.score(x, y) 求逻辑回归模型的决定系数</span><br><span class="line">    lr_scores.append(lr.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(train_sizes, nb_scores, label='Naive Bayes')</span><br><span class="line">plt.plot(train_sizes, lr_scores, linestyle='--', label='Logistic Regression')</span><br><span class="line">plt.title('Naive Bayes and Logistic Regression accuracies')</span><br><span class="line">plt.xlabel('Number of training instances')</span><br><span class="line">plt.ylabel('Test set accuracy')</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn8.png" alt="8"></p>
<h2 id="Scikit-Learn决策树和袋装集成学习"><a href="#Scikit-Learn决策树和袋装集成学习" class="headerlink" title="Scikit-Learn决策树和袋装集成学习"></a><font size="4">Scikit-Learn决策树和袋装集成学习</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.datasets import make_classification</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line"># from sklearn.datasets import make_classification 从sklearn数据集中导入make_classification用于创建分类数据集，样本数为n_samples，特征数为n_features，有用的特征数为n_informative，每一类的簇的个数为n_clusters_per_class</span><br><span class="line">x, y = make_classification(n_samples=1000, n_features=100, n_informative=20, n_clusters_per_class=2, random_state=11)</span><br><span class="line"></span><br><span class="line"># train_test_split(x, y) 将x和y划分成数据集和测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf = DecisionTreeClassifier() 创建决策树模型</span><br><span class="line">clf = DecisionTreeClassifier(random_state=11)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"># clf.predict(X) 用训练后的模型预测数据X</span><br><span class="line">predictions = clf.predict(x_test)</span><br><span class="line"></span><br><span class="line"># classification_report(y_test, y_predict, target_names=None, labels=None) 同时生成真实值与预测值的精准率，召回率和F1得分，目标标签为target_name，对应的值为label</span><br><span class="line">print(classification_report(y_test, predictions))</span><br><span class="line"></span><br><span class="line"># clf = RandomForestClassifier(n_estimators=n) 创建包含n个树的随机森林分类器</span><br><span class="line">clf = RandomForestClassifier(n_estimators=10, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"># clf.predict(X) 用训练后的模型预测数据X</span><br><span class="line">predictions = clf.predict(x_test)</span><br><span class="line"></span><br><span class="line"># classification_report(y_test, y_predict, target_names=None, labels=None) 同时生成真实值与预测值的精准率，召回率和F1得分，目标标签为target_name，对应的值为label</span><br><span class="line">print(classification_report(y_test, predictions))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn9.png" alt="9"></p>
<h2 id="Scikit-Learn推进集成学习"><a href="#Scikit-Learn推进集成学习" class="headerlink" title="Scikit-Learn推进集成学习"></a><font size="4">Scikit-Learn推进集成学习</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.ensemble import AdaBoostClassifier</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.datasets import make_classification</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># from sklearn.datasets import make_classification 从sklearn数据集中导入make_classification用于创建分类数据集，样本数为n_samples，特征数为n_features，有用的特征数为n_informative，每一类的簇的个数为n_clusters_per_class</span><br><span class="line">x, y = make_classification(n_samples=1000, n_features=50, n_informative=30, n_clusters_per_class=3, random_state=11)</span><br><span class="line"></span><br><span class="line"># train_test_split(x, y) 将x和y划分成数据集和测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf = DecisionTreeClassifier() 创建决策树模型</span><br><span class="line">clf = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"># clf.score(x, y) 求模型的决定系数</span><br><span class="line">print('DecisionTree accuracy:%s' %clf.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line"># clf = AdaBoostClassifier(n_estimators=n) 创建具有n个弱学习器的AdaBoost模型</span><br><span class="line">clf = AdaBoostClassifier(n_estimators=50, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">plt.title('Ensemble Accuracy')</span><br><span class="line">plt.xlabel('Accuracy')</span><br><span class="line">plt.ylabel('Number of base estimators in ensemble')</span><br><span class="line"></span><br><span class="line"># clf.staged_score(x, y) 求AdaBoost模型的弱分类器个数的决定系数</span><br><span class="line">plt.plot(range(1, 51), [accuracy for accuracy in clf.staged_score(x_test, y_test)])</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn10.png" alt="10"></p>
<h2 id="Scikit-Learn感知机"><a href="#Scikit-Learn感知机" class="headerlink" title="Scikit-Learn感知机"></a><font size="4">Scikit-Learn感知机</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.datasets import make_classification</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line">from sklearn.linear_model import Perceptron</span><br><span class="line"></span><br><span class="line"># from sklearn.datasets import make_classification 从sklearn数据集中导入make_classification用于创建分类数据集，样本数为n_samples，特征数为n_features，有用的特征数为n_informative，每一类的簇的个数为n_clusters_per_class</span><br><span class="line">x, y = make_classification(n_samples=1000, n_features=100, n_informative=20, n_clusters_per_class=2, random_state=11)</span><br><span class="line"></span><br><span class="line"># train_test_split(x, y) 将x和y划分成数据集和测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf = Perceptron() 创建感知机模型</span><br><span class="line">clf = Perceptron(random_state=11)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"># clf.predict(X) 用训练后的模型预测数据X</span><br><span class="line">predictions = clf.predict(x_test)</span><br><span class="line"></span><br><span class="line"># classification_report(y_test, y_predict, target_names=None, labels=None) 同时生成真实值与预测值的精准率，召回率和F1得分，目标标签为target_name，对应的值为label</span><br><span class="line">print(classification_report(y_test, predictions))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn11.png" alt="11"></p>
<h2 id="Scikit-Learn支持向量机"><a href="#Scikit-Learn支持向量机" class="headerlink" title="Scikit-Learn支持向量机"></a><font size="4">Scikit-Learn支持向量机</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.datasets import make_classification</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line"># from sklearn.datasets import make_classification 从sklearn数据集中导入make_classification用于创建分类数据集，样本数为n_samples，特征数为n_features，有用的特征数为n_informative，每一类的簇的个数为n_clusters_per_class</span><br><span class="line">x, y = make_classification(n_samples=1000, n_features=100, n_informative=20, n_clusters_per_class=2, random_state=11)</span><br><span class="line"></span><br><span class="line"># train_test_split(x, y) 将x和y划分成数据集和测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf = SVC(kernel='rbf', gamma='auto deprecated', C=1.0) 创建支持向量机模型，核函数默认为rbf高斯核，正则化参数C默认为1.0，核系数参数gamma默认为不使用</span><br><span class="line">clf = SVC(kernel='rbf', gamma=0.01, C=100, random_state=11)</span><br><span class="line"></span><br><span class="line"># clf.fit(X, y) 用训练数据X，y拟合模型</span><br><span class="line">clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"># clf.predict(X) 用训练后的模型预测数据X</span><br><span class="line">predictions = clf.predict(x_test)</span><br><span class="line"></span><br><span class="line"># classification_report(y_test, y_predict, target_names=None, labels=None) 同时生成真实值与预测值的精准率，召回率和F1得分，目标标签为target_name，对应的值为label</span><br><span class="line">print(classification_report(y_test, predictions))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn12.png" alt="12"></p>
<h2 id="Scikit-Learn多层感知机"><a href="#Scikit-Learn多层感知机" class="headerlink" title="Scikit-Learn多层感知机"></a><font size="4">Scikit-Learn多层感知机</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from sklearn.datasets import load_digits</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from sklearn.neural_network.multilayer_perceptron import MLPClassifier</span><br><span class="line"></span><br><span class="line"># from sklearn.datasets import load_digits 从sklearn数据集中导入手写数字的数据</span><br><span class="line">digits = load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line"># clf = MLPClassifier(hidden_layer_sizes=(100,), alpha=0.0001, max_iter=200, random_state=20) 创建多层感知机模型，每一层的神经元个数为hidden_layer_sizes，正则化参数alpha默认为0.0001，最大迭代次数默认为200</span><br><span class="line">clf = MLPClassifier(hidden_layer_sizes=(150, 100), alpha=0.1, max_iter=500)</span><br><span class="line"></span><br><span class="line"># cross_val_score(estimator, X, y, n_jobs=None, cv=n) n折交叉验证，估计器为estimator，数据为X和y，同时工作的CPU个数为1</span><br><span class="line">print(cross_val_score(clf, x, y, n_jobs=-1, cv=5))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn13.png" alt="13"></p>
<h2 id="Scikit-LearnKmeans聚类"><a href="#Scikit-LearnKmeans聚类" class="headerlink" title="Scikit-LearnKmeans聚类"></a><font size="4">Scikit-LearnKmeans聚类</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.subplot(3, 2, 1)</span><br><span class="line">x1 = np.array([1, 2, 3, 1, 5, 6, 5, 5, 6, 7, 8, 9, 7, 9])</span><br><span class="line">x2 = np.array([1, 3, 2, 2, 8, 6, 7, 6, 7, 1, 2, 1, 1, 3])</span><br><span class="line">x = np.vstack((x1, x2)).T</span><br><span class="line">plt.xlim([0, 10])</span><br><span class="line">plt.ylim([0, 10])</span><br><span class="line">plt.title('Instances')</span><br><span class="line">plt.scatter(x1, x2)</span><br><span class="line"></span><br><span class="line">colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'b']</span><br><span class="line">markers = ['o', 's', 'D', 'v', '^', 'p', '*', '+']</span><br><span class="line">tests = [2, 3, 4, 5, 8]</span><br><span class="line">subplot_counter = 1</span><br><span class="line"></span><br><span class="line">for t in tests:</span><br><span class="line">    subplot_counter +=1</span><br><span class="line">    plt.subplot(3, 2, subplot_counter)</span><br><span class="line"></span><br><span class="line">    # kmeans_model = KMeans(n_clusters=n) 创建Kmeans模型，类别个数为n</span><br><span class="line">    kmeans_model = KMeans(n_clusters=t)</span><br><span class="line"></span><br><span class="line">    # kmeans_model.fit(x) 用训练数据X拟合模型</span><br><span class="line">    kmeans_model.fit(x)</span><br><span class="line"></span><br><span class="line">    for i, l in enumerate(kmeans_model.labels_):</span><br><span class="line">        plt.plot(x1[i], x2[i], color=colors[l], marker=markers[l])</span><br><span class="line"></span><br><span class="line">    plt.xlim([0, 10])</span><br><span class="line">    plt.ylim([0, 10])</span><br><span class="line">    plt.title('k=%s' %t)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn14.png" alt="14"></p>
<h3 id="Scikit-LearnPCA降维"><a href="#Scikit-LearnPCA降维" class="headerlink" title="Scikit-LearnPCA降维"></a><font size="3">Scikit-LearnPCA降维</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line"></span><br><span class="line">data = load_iris()</span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"># pca = PCA(n_components=n) 创建n维PCA转换器</span><br><span class="line">pca = PCA(n_components=2)</span><br><span class="line"></span><br><span class="line"># pca.fit_transform(X) 在训练数据集进行PCA降维</span><br><span class="line">reduced_x = pca.fit_transform(x) </span><br><span class="line"></span><br><span class="line">red_x, red_y = [], []</span><br><span class="line">blue_x, blue_y = [], []</span><br><span class="line">green_x, green_y = [], []</span><br><span class="line"></span><br><span class="line">for i in range(len(reduced_x)):</span><br><span class="line">    if y[i] == 0:</span><br><span class="line">        red_x.append(reduced_x[i][0])</span><br><span class="line">        red_y.append(reduced_x[i][1])</span><br><span class="line">    elif y[i] == 1:</span><br><span class="line">        blue_x.append(reduced_x[i][0])</span><br><span class="line">        blue_y.append(reduced_x[i][1])</span><br><span class="line">    else:</span><br><span class="line">        green_x.append(reduced_x[i][0])</span><br><span class="line">        green_y.append(reduced_x[i][1])</span><br><span class="line"></span><br><span class="line">plt.scatter(red_x, red_y, c='r', marker='x')</span><br><span class="line">plt.scatter(blue_x, blue_y, c='b', marker='D')</span><br><span class="line">plt.scatter(green_x, green_y, c='g', marker='.')</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/sklearn15.png" alt="15"></p>
<h1 id="Scikit-Learn小结"><a href="#Scikit-Learn小结" class="headerlink" title="Scikit-Learn小结"></a><font size="5" color="red">Scikit-Learn小结</font></h1><p>  由于Scikit-Learn集成了许多常用的机器学习算法，如决策树，SVM，多层感知机，Kmeans等，可以让使用者节约大量的时间。而且其拥有很好的官方文档，让开发者，研究者可以方便的入门和使用。因此Scikit-Learn在机器学习领域受到广大使用者的喜爱。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python常用库</category>
      </categories>
  </entry>
  <entry>
    <title>Numpy</title>
    <url>/2019/08/12/library%20Numpy/</url>
    <content><![CDATA[<p><img src="/images/LIBRARY/numpy.jpg" alt="0"></p>
<h1 id="Numpy介绍"><a href="#Numpy介绍" class="headerlink" title="Numpy介绍"></a><font size="5" color="red">Numpy介绍</font></h1><p>  NumPy是Python的一种开源的数值计算扩展，这种工具可用来存储和处理大型矩阵，专为进行严格的数字处理而产生。<br><a id="more"></a></p>
<h1 id="Numpy特点"><a href="#Numpy特点" class="headerlink" title="Numpy特点"></a><font size="5" color="red">Numpy特点</font></h1><p>  <font size="3">NumPy提供了一个N维数组类型ndarray，它描述了相同类型的的集合。</font><br>  <font size="3">numpy内置了并行运算功能，当系统有多个核心时，做某种计算时，numpy会自动做并行计算。</font><br>  <font size="3">Numpy底层使用C语言编写，内部解除了GIL（全局解释器锁），其对数组的操作速度不受Python解释器的限制，效率远高于纯Python代码。</font></p>
<h1 id="Numpy应用"><a href="#Numpy应用" class="headerlink" title="Numpy应用"></a><font size="5" color="red">Numpy应用</font></h1><h2 id="Numpy创建数组"><a href="#Numpy创建数组" class="headerlink" title="Numpy创建数组"></a><font size="4">Numpy创建数组</font></h2><h3 id="array方法"><a href="#array方法" class="headerlink" title="array方法"></a><font size="3">array方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># np.array(list) 将list转换为数组类型</span><br><span class="line">a = np.array([[1, 2, 3], [4, 5, 6]])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy1.png" alt="1"></p>
<h3 id="zeros，ones，eye方法"><a href="#zeros，ones，eye方法" class="headerlink" title="zeros，ones，eye方法"></a><font size="3">zeros，ones，eye方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># np.zeros(shape, dtype=None) 生成形状为shape的全0数组(默认为float64)</span><br><span class="line">a = np.zeros((2,3))</span><br><span class="line"></span><br><span class="line"># np.ones(shape, dtype=None) 生成形状为shape的全1数组(默认为float64)</span><br><span class="line">b = np.ones((2,3))</span><br><span class="line"></span><br><span class="line"># np.zeros_like(array, dtype=None) 生成形状与array相同的全0数组(默认为float64)</span><br><span class="line">c = np.zeros_like(b)</span><br><span class="line"></span><br><span class="line"># np.ones_like(array, dtype=None) 生成形状与array相同的全1数组(默认为float64)</span><br><span class="line">d = np.ones_like(a)</span><br><span class="line"></span><br><span class="line"># np.eye(m, n, k=0) 生成m行n列的单位矩阵，n默认等于m，k为上下的偏移量，默认为0(默认为float64)</span><br><span class="line">e = np.eye(3, 4, 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy3.png" alt="3"></p>
<h3 id="arange方法"><a href="#arange方法" class="headerlink" title="arange方法"></a><font size="3">arange方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># np.arange(start, stop, step, dtype=None) 生成start到stop，步长为step的数组</span><br><span class="line">a = np.arange(10, 20, 2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy4.png" alt="4"></p>
<h3 id="linspace，logspace方法"><a href="#linspace，logspace方法" class="headerlink" title="linspace，logspace方法"></a><font size="3">linspace，logspace方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None) 将start到stop等分成num个点，endpoint=True代表包括stop</span><br><span class="line">a = np.linspace(10, 20, 6)</span><br><span class="line"></span><br><span class="line"># np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None) 将start到stop等分成num个点，每一个点i的值为base的i次幂</span><br><span class="line">b = np.logspace(1, 2, 10)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy5.png" alt="5"></p>
<h3 id="random方法"><a href="#random方法" class="headerlink" title="random方法"></a><font size="3">random方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># np.random.seed(n) 设定随机种子，以备后面的结果可以复现</span><br><span class="line">np.random.seed(1)</span><br><span class="line"></span><br><span class="line"># np.random.randint(low, high, shape=None) 产生形状为shape的分布区间为[low, high)的随机整数</span><br><span class="line">a = np.random.randint(0, 10, (3, 3))</span><br><span class="line"></span><br><span class="line"># np.random.rand(shape=None) 产生形状为shape的[0-1)均匀随机数</span><br><span class="line">b = np.random.rand(3,3)</span><br><span class="line"></span><br><span class="line"># np.random.uniform(low=0.0, high=1.0, shape=None) 产生形状为shape的分布区间为[low, high)的均匀随机数</span><br><span class="line">c = np.random.uniform(0, 10, (3, 3))</span><br><span class="line"></span><br><span class="line"># np.random.randn(shape=None) 产生形状为shape的均值为0，方差为1的高斯随机数</span><br><span class="line">d = np.random.rand(3,3)</span><br><span class="line"></span><br><span class="line"># np.random.normal(loc=0.0, scale=1.0, shape=None) 产生形状为shape的均值为loc，标准差为scale的高斯随机数</span><br><span class="line">e = np.random.normal(5, 5, (3,3))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy6.png" alt="6"></p>
<h2 id="Numpy属性"><a href="#Numpy属性" class="headerlink" title="Numpy属性"></a><font size="4">Numpy属性</font></h2><h3 id="ndim，shape，size，dtype属性"><a href="#ndim，shape，size，dtype属性" class="headerlink" title="ndim，shape，size，dtype属性"></a><font size="3">ndim，shape，size，dtype属性</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2, 3], [4, 5, 6]])</span><br><span class="line"></span><br><span class="line"># obj.ndim 查看对象的维度</span><br><span class="line">a.ndim</span><br><span class="line"></span><br><span class="line"># obj.shape 查看对象的形状</span><br><span class="line">a.shape</span><br><span class="line"></span><br><span class="line"># obj.size 查看对象的元素个数</span><br><span class="line">a.size</span><br><span class="line"></span><br><span class="line"># obj.dtype 查看对象的类型(整数默认为int32，浮点数默认为float64)</span><br><span class="line">a.dtype</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy2.png" alt="2"></p>
<h2 id="Numpy切片与索引"><a href="#Numpy切片与索引" class="headerlink" title="Numpy切片与索引"></a><font size="4">Numpy切片与索引</font></h2><h3 id="冒号-方法"><a href="#冒号-方法" class="headerlink" title=":(冒号)方法"></a><font size="3">:(冒号)方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape((3, 4))</span><br><span class="line"></span><br><span class="line"># obj[start:stop:step, ...]，指在某一维度上，从start开始，到stop结束，不包括stop，间隔为step，start省略为从第一个元素开始，stop省略为到最后一个元素结束，step省略为间隔为1</span><br><span class="line">b = a[1:, 0:4:2]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy8.png" alt="8"></p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a><font size="3"><a href="列表"></a>方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape((3, 4))</span><br><span class="line"></span><br><span class="line"># obj[[x1, x2, ...], ...]，指在某一维度上，取出x1,x2,...所在位置的元素</span><br><span class="line">b = a[[[1, 1], [2, 2]], [[0, 2], [0, 2]]]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy9.png" alt="9"></p>
<h3 id="nonzero方法"><a href="#nonzero方法" class="headerlink" title="nonzero方法"></a><font size="3">nonzero方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 3, (3, 3))</span><br><span class="line"></span><br><span class="line"># np.nonzero(obj) 返回obj中非0的索引</span><br><span class="line">b = a &gt; 1</span><br><span class="line">c = np.nonzero(a)</span><br><span class="line">d = np.nonzero(b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy34.png" alt="34"></p>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a><font size="3"><a href="逻辑值索引"></a>方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape((3, 4))</span><br><span class="line"></span><br><span class="line"># obj1[obj1 op obj2] 返回obj1对obj2操作后值为True的值，并用一维数组保存</span><br><span class="line">b = a[a &gt; 5]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy26.png" alt="26"></p>
<h3 id="ix-方法"><a href="#ix-方法" class="headerlink" title="ix_方法"></a><font size="3">ix_方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape((3, 4))</span><br><span class="line"></span><br><span class="line"># obj[np.ix_(array1, array2, ...)] 按照array1,array2,...的顺序取出元素</span><br><span class="line">b = a[np.ix_([1, 2], [0, 2])]</span><br><span class="line"></span><br><span class="line"># 与列表操作对比</span><br><span class="line">c = a[[1, 2], [0, 2]]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy10.png" alt="10"></p>
<h3 id="split方法"><a href="#split方法" class="headerlink" title="split方法"></a><font size="3">split方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape((2, 6))</span><br><span class="line"></span><br><span class="line"># np.split(obj, indices, axis=0) 将obj按照axis的方向(0代表横向，1代表纵向)切分。indices为整数指平均切分成indices份，为列表指按照列表进行切分。</span><br><span class="line">b = np.split(a, 3, axis=1)</span><br><span class="line">c = np.split(a, [1, 3], axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy11.png" alt="11"></p>
<h2 id="Numpy插入，连接与删除"><a href="#Numpy插入，连接与删除" class="headerlink" title="Numpy插入，连接与删除"></a><font size="4">Numpy插入，连接与删除</font></h2><h3 id="append方法"><a href="#append方法" class="headerlink" title="append方法"></a><font size="3">append方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># np.append(obj, array, axis=None) axis=None时，将obj展开为一维数组，然后再与array连接，axis=0，在纵向连接在下方，axis=1，在横向连接在右方</span><br><span class="line">b = np.append(a, [[9], [10], [11]])</span><br><span class="line">c = np.append(a, [[9,10,11]], axis=0)</span><br><span class="line">d = np.append(a, [[9], [10], [11]], axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy12.png" alt="12"></p>
<h3 id="insert方法"><a href="#insert方法" class="headerlink" title="insert方法"></a><font size="3">insert方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># np.insert(obj, index, array, axis=None) axis的用法同append一样，多了index项，可以插入到任意位置,且位数不相同时可以进行广播操作</span><br><span class="line">b = np.insert(a, 2, 9)</span><br><span class="line">c = np.insert(a, 2, 9, axis=0)</span><br><span class="line">d = np.insert(a, 2, 9, axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy13.png" alt="13"></p>
<h3 id="concatenate方法"><a href="#concatenate方法" class="headerlink" title="concatenate方法"></a><font size="3">concatenate方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2], [3, 4]])</span><br><span class="line">b = np.array([[5, 6], [7, 8]])</span><br><span class="line"></span><br><span class="line"># np.concatenate((obj1, obj2, ...), axis=0) 在axis轴上连接两个数组，默认为axis=0</span><br><span class="line">c = np.concatenate((a, b))</span><br><span class="line">d = np.concatenate((a, b), axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy15.png" alt="15"></p>
<h3 id="stack方法"><a href="#stack方法" class="headerlink" title="stack方法"></a><font size="3">stack方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2], [3, 4]])</span><br><span class="line">b = np.array([[5, 6], [7, 8]])</span><br><span class="line"></span><br><span class="line"># np.stack((obj1, obj2, ...), axis=0) 在axis维度上新建一个轴，并在此轴上连接数组，默认为axis=0</span><br><span class="line">c = np.stack((a, b))</span><br><span class="line">d = np.stack((a, b), axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy16.png" alt="16"></p>
<h3 id="delete方法"><a href="#delete方法" class="headerlink" title="delete方法"></a><font size="3">delete方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(9).reshape((3, 3))</span><br><span class="line"></span><br><span class="line"># np.delete(obj, index, axis=None) axis的用法同append一样，多了index项，可以删除任意位置的元素</span><br><span class="line">b = np.delete(a, 1)</span><br><span class="line">c = np.delete(a, 1, axis=0)</span><br><span class="line">d = np.delete(a, 1, axis=1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy14.png" alt="14"></p>
<h2 id="Numpy广播与复制"><a href="#Numpy广播与复制" class="headerlink" title="Numpy广播与复制"></a><font size="4">Numpy广播与复制</font></h2><h3 id="broadcast-to方法"><a href="#broadcast-to方法" class="headerlink" title="broadcast_to方法"></a><font size="3">broadcast_to方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2, 3]])</span><br><span class="line">b = np.array([[1], [2], [3]])</span><br><span class="line">c = np.array([1])</span><br><span class="line"></span><br><span class="line"># np.broadcast_to(obj, shape) 将obj广播至shape形状</span><br><span class="line"># 原理是如果obj的维度数小于shape，则在对应维度位置上补1，扩展成相同维度，然后将所有的1维度复制i次，i为shape中相应的维度</span><br><span class="line">d = np.broadcast_to(a, (3, 3)) # a的维度为(1, 3),维度与(3, 3)数量相同，则将1复制3次，变成(3, 3)</span><br><span class="line">e = np.broadcast_to(b, (3, 3)) # b的维度为(3, 1),维度与(3, 3)数量相同，则将1复制3次，变成(3, 3)</span><br><span class="line">f = np.broadcast_to(c, (3, 3)) # c的维度为(1),维度与(3, 3)数量不相同，则在对应维度位置上补1，扩展成相同维度，变成(1, 1)，然后将1复制3次，变成(3, 3)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy17.png" alt="17"></p>
<h3 id="tile方法"><a href="#tile方法" class="headerlink" title="tile方法"></a><font size="3">tile方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a=np.array([[1, 2], [3, 4]])</span><br><span class="line"></span><br><span class="line"># np.tile(obj, (m, n, ...)) 将obj的维度复制(m, n, ...)次</span><br><span class="line">b = np.tile(a, (2, 3))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy18.png" alt="18"></p>
<h2 id="Numpy改变数组形状"><a href="#Numpy改变数组形状" class="headerlink" title="Numpy改变数组形状"></a><font size="4">Numpy改变数组形状</font></h2><h3 id="reshape方法"><a href="#reshape方法" class="headerlink" title="reshape方法"></a><font size="3">reshape方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a=np.array([[1, 2, 3], [4, 5, 6]])</span><br><span class="line"></span><br><span class="line"># obj.reshape(shape) 将obj的形状改变为shape</span><br><span class="line">b = a.reshape((3, 2))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy7.png" alt="7"></p>
<h3 id="resize方法"><a href="#resize方法" class="headerlink" title="resize方法"></a><font size="3">resize方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(9).reshape(3, 3)</span><br><span class="line"></span><br><span class="line"># np.resize(obj, shape) 将obj的大小调整为shape，先按顺序读取，少则从头补入数据，多则删除多余数据</span><br><span class="line">b = np.resize(a, (2, 2))</span><br><span class="line">c = np.resize(a, (4, 4))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy19.png" alt="19"></p>
<h3 id="T-transpose-方法"><a href="#T-transpose-方法" class="headerlink" title="T(transpose)方法"></a><font size="3">T(transpose)方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2, 3], [4, 5, 6]])</span><br><span class="line"></span><br><span class="line"># obj.T 将obj转置，等价于np.transpose(obj)</span><br><span class="line">b = a.T</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy20.png" alt="20"></p>
<h3 id="swapaxes方法"><a href="#swapaxes方法" class="headerlink" title="swapaxes方法"></a><font size="3">swapaxes方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(8).reshape(2, 2, 2)</span><br><span class="line"></span><br><span class="line"># np.swapaxes(obj, axis1, axis2) 交换obj的两个轴</span><br><span class="line">b = np.swapaxes(a, 0, 2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy21.png" alt="21"></p>
<h3 id="expand-dims方法"><a href="#expand-dims方法" class="headerlink" title="expand_dims方法"></a><font size="3">expand_dims方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([1, 2, 3])</span><br><span class="line"></span><br><span class="line"># np.expand_dims(obj, axis) 在指定axis插入一个新的轴</span><br><span class="line">b = np.expand_dims(a, 0)</span><br><span class="line">c = np.expand_dims(a, 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy22.png" alt="22"></p>
<h3 id="squeeze方法"><a href="#squeeze方法" class="headerlink" title="squeeze方法"></a><font size="3">squeeze方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[1, 2, 3]])</span><br><span class="line">b = np.array([[1], [2], [3]])</span><br><span class="line"></span><br><span class="line"># np.squeeze(obj, axis) 在指定axis删除轴，如果该轴的大小不为1，则无法删除报错</span><br><span class="line">c = np.squeeze(a, 0)</span><br><span class="line">d = np.squeeze(b, 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy23.png" alt="23"></p>
<h3 id="ravel，flatten方法"><a href="#ravel，flatten方法" class="headerlink" title="ravel，flatten方法"></a><font size="3">ravel，flatten方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(9).reshape(3, 3)</span><br><span class="line">b = np.arange(9).reshape(3, 3)</span><br><span class="line"></span><br><span class="line"># obj.ravel(order='C') 将obj展平为一位数组，且修改按行展平后的数据，原数据受到改变。order='C'(按行展平元素)，'F' (按列展平元素)，'A' (按原顺序展平元素)，'K'(按内存中的出现顺序展平元素)</span><br><span class="line">c = a.ravel()</span><br><span class="line">d = a.ravel('F')</span><br><span class="line">c[1] += 1</span><br><span class="line"></span><br><span class="line"># obj.flatten(order='C') 将obj展平为一位数组，且修改按行展平后的数据，原数据不受到改变。order用法同ravel</span><br><span class="line">e = b.flatten()</span><br><span class="line">e[1] += 1</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy24.png" alt="24"></p>
<h2 id="Numpy数学运算"><a href="#Numpy数学运算" class="headerlink" title="Numpy数学运算"></a><font size="4">Numpy数学运算</font></h2><h3 id="运算符方法"><a href="#运算符方法" class="headerlink" title="运算符方法"></a><font size="3">运算符方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(2, 10, 2).reshape(2, 2)</span><br><span class="line">b = np.arange(1, 5).reshape(2, 2)</span><br><span class="line"></span><br><span class="line"># 算术运算(+，-，*，/，//，%，**，&gt;，&gt;=，&lt;，&lt;=，==，!=，&amp;，|，^，~，&gt;&gt;，&lt;&lt;)要求两个数组具有同样的形状或者可广播为同样形状，逻辑运算返回值为True或者False</span><br><span class="line">c = a + b</span><br><span class="line">d = a - b</span><br><span class="line">e = a * b</span><br><span class="line">f = a / b</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy25.png" alt="25"></p>
<h3 id="特殊值，对数函数，三角函数方法"><a href="#特殊值，对数函数，三角函数方法" class="headerlink" title="特殊值，对数函数，三角函数方法"></a><font size="3">特殊值，对数函数，三角函数方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 特殊值(π，e，∞，Nan)</span><br><span class="line">a = np.pi / 2</span><br><span class="line">b = np.e</span><br><span class="line">c = np.inf</span><br><span class="line">d = np.nan</span><br><span class="line"></span><br><span class="line"># np.log(obj)，np.log2(obj)，np.log10(obj) 对obj求以e为底，2为底，10为底的对数</span><br><span class="line">e = np.log([b, 2, 10])</span><br><span class="line">f = np.log2([b, 2, 10])</span><br><span class="line">g = np.log10([b, 2, 10])</span><br><span class="line"></span><br><span class="line"># np.sin(obj)，np.arcsin(obj) 对obj求sin值和arcsin值，所用的为弧度值</span><br><span class="line">h = np.sin(a)</span><br><span class="line">i = np.arcsin(h)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy27.png" alt="27"></p>
<h3 id="around，floor，ceil方法"><a href="#around，floor，ceil方法" class="headerlink" title="around，floor，ceil方法"></a><font size="3">around，floor，ceil方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([3.33, 5.55, 88.88])</span><br><span class="line"></span><br><span class="line"># np.around(obj, decimals=0) 四舍五入操作，decimals大于0，四舍五入到小数点右侧，小于0，四舍五入到小数点左侧</span><br><span class="line">b = np.around(a)</span><br><span class="line">c = np.around(a, 1)</span><br><span class="line">d = np.around(a, -1)</span><br><span class="line"></span><br><span class="line"># np.floor(obj) 向下取整</span><br><span class="line">e = np.floor(a)</span><br><span class="line"></span><br><span class="line"># np.ceil(obj) 向上取整</span><br><span class="line">f = np.ceil(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy28.png" alt="28"></p>
<h3 id="sum，cumsum，cumprod方法"><a href="#sum，cumsum，cumprod方法" class="headerlink" title="sum，cumsum，cumprod方法"></a><font size="3">sum，cumsum，cumprod方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 5, (3, 3))</span><br><span class="line"></span><br><span class="line"># np.sum(obj, axis=None) 将obj元素累加，axis=None代表全局，axis=0代表每列，axis=1代表每行</span><br><span class="line">b = np.sum(a)</span><br><span class="line"></span><br><span class="line"># np.cumsum(obj, axis=None) 将obj逐项累加，axis用法同np.sum</span><br><span class="line">c = np.cumsum(a)</span><br><span class="line">d = np.cumsum(a, 0)</span><br><span class="line"></span><br><span class="line"># np.cumprod(obj, axis=None) 将obj逐项累乘，axis用法同np.sum</span><br><span class="line">e = np.cumprod(a)</span><br><span class="line">f = np.cumprod(a, 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy32.png" alt="32"></p>
<h3 id="ptp方法"><a href="#ptp方法" class="headerlink" title="ptp方法"></a><font size="3">ptp方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 5, (3, 3))</span><br><span class="line"></span><br><span class="line"># np.ptp(obj, axis=None) 计算axis轴上最大值减最小值的结果，axis用法同np.sum</span><br><span class="line">b = np.ptp(a)</span><br><span class="line">c = np.ptp(a, 0)</span><br><span class="line">d = np.ptp(a, 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy33.png" alt="33"></p>
<h3 id="diff方法"><a href="#diff方法" class="headerlink" title="diff方法"></a><font size="3">diff方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 10, (5, 5))</span><br><span class="line"></span><br><span class="line"># np.diff(obj, n, axis) 计算n阶差分运算，axis默认为最后一个维度</span><br><span class="line">b = np.diff(a, 1)</span><br><span class="line">c = np.diff(a, 2)</span><br><span class="line">d = np.diff(a, 1, 0)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy36.png" alt="36"></p>
<h3 id="clip方法"><a href="#clip方法" class="headerlink" title="clip方法"></a><font size="3">clip方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 10, (5, 5))</span><br><span class="line"></span><br><span class="line"># np.clip(obj, min_, max_) 将obj中小于min_的值赋值为min_，将obj中大于max_的值赋值为max_</span><br><span class="line">b = np.clip(a, 3, 7)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy37.png" alt="37"></p>
<h2 id="Numpy数理统计"><a href="#Numpy数理统计" class="headerlink" title="Numpy数理统计"></a><font size="4">Numpy数理统计</font></h2><h3 id="unique方法"><a href="#unique方法" class="headerlink" title="unique方法"></a><font size="3">unique方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 10, (5, 5))</span><br><span class="line"></span><br><span class="line"># np.unique(obj, return_index, return_inverse, return_counts) 统计得到不重复元素，如果不是一维数组，会将数组展开。return_index=True返回不重复元素在原数组中第一次出现的索引，return_inverse=返回原数组在不重复元素中的索引, return_counts=返回每个不重复元素在原数组中出现的次数</span><br><span class="line">b, index, inverse, counts = np.unique(a, True, True, True)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy29.png" alt="29"></p>
<h3 id="any，all方法"><a href="#any，all方法" class="headerlink" title="any，all方法"></a><font size="3">any，all方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 10, (5, 5))</span><br><span class="line"></span><br><span class="line"># np.any(obj) 判断obj中是否存在True</span><br><span class="line">b = np.any(a &gt; 5)</span><br><span class="line">c = np.any(a &gt; 10)</span><br><span class="line"></span><br><span class="line"># np.all(obj) 判断obj中是否全都是True</span><br><span class="line">d = np.all(a &gt;= 0)</span><br><span class="line">e = np.all(a &gt; 5)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy35.png" alt="35"></p>
<h3 id="统计方法"><a href="#统计方法" class="headerlink" title="统计方法"></a><font size="3">统计方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 10, (5, 5))</span><br><span class="line"></span><br><span class="line"># np.amax(obj, axis=None)，np.amin(obj, axis=None) 统计最大最小值，axis用法同np.sum</span><br><span class="line">np.amax(a)</span><br><span class="line">np.amax(a,0)</span><br><span class="line">np.amax(a,1)</span><br><span class="line"></span><br><span class="line"># np.argmax(obj, axis=None)，np.argmin(obj, axis=None) 统计最大最小值的索引，axis用法同np.sum</span><br><span class="line">np.argmax(a)</span><br><span class="line">np.argmax(a,0)</span><br><span class="line">np.argmax(a,1)</span><br><span class="line"></span><br><span class="line"># np.mean(obj, axis=None) 统计中位数，axis用法同np.sum</span><br><span class="line">np.median(a)</span><br><span class="line"></span><br><span class="line"># np.mean(obj, axis=None) 统计均值，axis用法同np.sum</span><br><span class="line">np.mean(a)</span><br><span class="line"></span><br><span class="line"># np.mean(obj, axis=None, weights=None) 统计加权平均值，axis用法同np.sum</span><br><span class="line">np.average(a, None, a)</span><br><span class="line"></span><br><span class="line"># np.mean(obj, axis=None) 统计标准差，axis用法同np.sum</span><br><span class="line">np.std(a)</span><br><span class="line"></span><br><span class="line"># np.mean(obj, axis=None) 统计方差，axis用法同np.sum</span><br><span class="line">np.var(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy30.png" alt="30"></p>
<h3 id="sort，argsort方法"><a href="#sort，argsort方法" class="headerlink" title="sort，argsort方法"></a><font size="3">sort，argsort方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.random.randint(0, 5, (3, 3))</span><br><span class="line"></span><br><span class="line"># np.sort(obj, axis, kind='quicksort', order=None) 对obj进行从小到达排序，axis为指定要排序的轴，axis=0按列排序，axis=1按行排序。kind为排序算法，可以选择'quicksort'(快速排序，默认)，'mergesort'(归并排序)，'heapsort'(堆排序)，order为要排序的字段，一般数学运算不用</span><br><span class="line">b = np.sort(a, 0)</span><br><span class="line">c = np.sort(a, 1)</span><br><span class="line"></span><br><span class="line"># np.argsort(obj, axis, kind='quicksort', order=None) 返回排序后的数组在原数组的索引，用法同sort</span><br><span class="line">d = np.argsort(a, 0)</span><br><span class="line">e = np.argsort(a, 1)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy31.png" alt="31"></p>
<h2 id="Numpy线性代数"><a href="#Numpy线性代数" class="headerlink" title="Numpy线性代数"></a><font size="4">Numpy线性代数</font></h2><h3 id="dot，matmul方法"><a href="#dot，matmul方法" class="headerlink" title="dot，matmul方法"></a><font size="3">dot，matmul方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(6).reshape(2, 3)</span><br><span class="line">b = np.arange(6).reshape(3, 2)</span><br><span class="line"></span><br><span class="line"># np.dot(obj1, obj2) 等价于np.matmul(obj1, obj2)，矩阵乘法</span><br><span class="line">c = np.dot(a, b)</span><br><span class="line">d = np.matmul(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy38.png" alt="38"></p>
<h3 id="det，eig，pinv方法"><a href="#det，eig，pinv方法" class="headerlink" title="det，eig，pinv方法"></a><font size="3">det，eig，pinv方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[-2, 1, 1], [0, 2, 0], [-4, 1, 3]])</span><br><span class="line"></span><br><span class="line"># np.linalg.det(obj) 计算obj的行列式</span><br><span class="line">b = np.linalg.det(a)</span><br><span class="line"></span><br><span class="line"># np.linalg.eig(obj) 计算obj的特征值和特征向量</span><br><span class="line">c = np.linalg.eig(a)</span><br><span class="line"></span><br><span class="line"># np.linalg.pinv(obj) 计算obj的伪逆矩阵</span><br><span class="line">d = np.linalg.pinv(a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy39.png" alt="39"></p>
<h3 id="solve方法"><a href="#solve方法" class="headerlink" title="solve方法"></a><font size="3">solve方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([[2, 2, -1], [1, -2, 4], [5, 8, -1]])</span><br><span class="line">b = np.array([[6], [3], [27]])</span><br><span class="line"></span><br><span class="line"># np.linalg.solve(A, b) 求线性方程组Ax = b的解</span><br><span class="line">c = np.linalg.solve(a, b)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy31.png" alt="31"></p>
<h2 id="Numpy数据保存"><a href="#Numpy数据保存" class="headerlink" title="Numpy数据保存"></a><font size="4">Numpy数据保存</font></h2><h3 id="save，load方法"><a href="#save，load方法" class="headerlink" title="save，load方法"></a><font size="3">save，load方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape(3, 4)</span><br><span class="line"></span><br><span class="line"># np.save(filename, obj) 将obj保存在文件名为filename的.npy文件中(可以不加.npy扩展名)</span><br><span class="line">np.save('save1', a)</span><br><span class="line"></span><br><span class="line"># np.load(filename) 读取文件名为filename的数组数据(要加.npy扩展名)</span><br><span class="line">b = np.load('save1.npy')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy41.png" alt="41"></p>
<h3 id="savez方法"><a href="#savez方法" class="headerlink" title="savez方法"></a><font size="3">savez方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape(3, 4)</span><br><span class="line">b = np.arange(6).reshape(2, 3)</span><br><span class="line"></span><br><span class="line"># np.savez(filename, name1=obj1, name2=obj2, ...) 将多个数据保存在文件名为filename的.npz文件中(可以不加.npz扩展名)，obj1的变量名为name1，obj2的变量名为name2，……(变量的默认名称为arr_0，arr_1，……)</span><br><span class="line">np.savez('save2', no_1=a, no_2=b)</span><br><span class="line">np.savez('save3', a, b)</span><br><span class="line"></span><br><span class="line"># np.load(filename) 读取文件名为filename的数组数据(要加.npz扩展名)</span><br><span class="line">c = np.load('save2.npz')</span><br><span class="line">d = np.load('save3.npz')</span><br><span class="line"></span><br><span class="line"># 提取数据时要使用数组的名称</span><br><span class="line">e = c['no_1']</span><br><span class="line">f = c['no_2']</span><br><span class="line">g = d['arr_0']</span><br><span class="line">h = d['arr_1']</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy42.png" alt="42"></p>
<h3 id="savetxt，loadtxt方法"><a href="#savetxt，loadtxt方法" class="headerlink" title="savetxt，loadtxt方法"></a><font size="3">savetxt，loadtxt方法</font></h3><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(12).reshape(3, 4)</span><br><span class="line">b = np.array([1,2,3,4])</span><br><span class="line">c = np.array([5,6,7,8])</span><br><span class="line"></span><br><span class="line"># np.savetxt(filename, obj, fmt='%f', delimiter=' ') 将多个一维数据(相同大小)或者一个二维维数据保存在文件名为filename的.txt文件中(要加.txt扩展名)，格式为fmt(默认为浮点型)，分隔符为delimiter(默认为' ')，保存时会将多个一维数组转化成一个二维数组</span><br><span class="line">np.savetxt('save4.txt', a)</span><br><span class="line">np.savetxt('save5.txt', (b, c))</span><br><span class="line"></span><br><span class="line"># np.loadtxt(filename, dtype='float', delimiter=' ') 读取文件名为filename的数组数据(要加.txt扩展名)，类型为dtypefloat(默认为浮点型)，分隔符为delimiter(默认为' ')</span><br><span class="line">d = np.loadtxt('save4.txt')</span><br><span class="line">e = np.loadtxt('save5.txt')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/LIBRARY/numpy43.png" alt="43"></p>
<h1 id="Numpy小结"><a href="#Numpy小结" class="headerlink" title="Numpy小结"></a><font size="5" color="red">Numpy小结</font></h1><p>  由于numpy支持各种矩阵运算，且运算效率非常高，因此numpy库广泛应用于数据分析，机器学习，深度学习等各个领域，其作为机器学习三剑客之一，也受到广大使用者的喜爱。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>语言学习</category>
        <category>Python常用库</category>
      </categories>
  </entry>
  <entry>
    <title>线性规划(Linear Programming)</title>
    <url>/2019/08/08/algorithm%20linear%20programming/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">线性规划</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Linear Programming:线性规划</strong>，是<strong>运筹学</strong>中的一个重要分支，<strong>研究线性约束条件下线性目标函数的极值问题</strong>的数学理论和方法，能从各种限制条件的组合中，选择出最为合理的计算方法，建立线性规划模型，从而求得最佳结果。广泛应用于军事作战、经济分析、经营管理和工程技术等方面。为合理地利用有限的人力、物力、财力等资源作出的<strong>最优决策</strong>，提供科学的依据。<br><a id="more"></a></p>
<h1 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a><font size="5" color="red">算法基础</font></h1><h2 id="线性规划标准型"><a href="#线性规划标准型" class="headerlink" title="线性规划标准型"></a><font size="4">线性规划标准型</font></h2><p>  <font size="3">对于复杂的线性规划问题，很难采用初中数学的画图法解决，一般要把问题转化为线性规划标准型。</font><br><img src="/images/ALGORITHM/line1.png" alt="1"></p>
<h2 id="线性规划标准型转化方法"><a href="#线性规划标准型转化方法" class="headerlink" title="线性规划标准型转化方法"></a><font size="4">线性规划标准型转化方法</font></h2><p>  <font size="3">(1)一般线性规划形式中目标函数如果求最小值，即$\min z = \sum<em>{i=1}^n c_ix_i$，那么令$z’ = -z$，则求解$\max z’ = \sum</em>{i=1}^n c_ix_i$，得到最优解后加负号即可。</font><br>  <font size="3">(2)右端常数项小于零时，则不等式两边同时乘-1，将其变为大于零，并改变不等式方向，保证恒等变形。</font><br>  <font size="3">(3)约束条件大于等于约束时，则在不等式左边减去一个新的非负变量，将不等式约束改为等式约束。</font><br>  <font size="3">(4)约束条件小于等于约束时，则在不等式左边加上一个新的非负变量，将不等式约束改为等式约束。</font><br>  <font size="3">(5)无约束的决策变量x，则引入两个新的非负变量x’，x’’，令$x=x’-x’’, \ x’ \ge 0, \ x’’ \ge 0$，将x’，x’’带入模型</font><br>  <font size="3">(6)决策变量x小于等于0时，令x’=-x，将x’带入模型</font></p>
<script type="math/tex; mode=display">\min z = x_2 - 3 \ x_3 + 2 \ x_4</script><script type="math/tex; mode=display">\begin{cases} x_1 + 3 \ x_2 - x_3 + 2 \ x_4 =7 \\ -2 \ x_2 + 4 \ x_3 \le 12 \\ -4 \ x_2 + 3 \ x_3 + 8 \ x_4 \le 10 \\ x_i \ge 0 \ (i = 1, \ 2, \ 3, \ 4) \end{cases}</script><p>  <font size="3">将其转化为线性规划标准型:z’=-z</font></p>
<script type="math/tex; mode=display">\min z' = -x_2 + 3 \ x_3 - 2 \ x_4</script><script type="math/tex; mode=display">\begin{cases} x_1 + 3 \ x_2 - x_3 + 2 \ x_4 =7 \\ -2 \ x_2 + 4 \ x_3 + x_5 = 12 \\ -4 \ x_2 + 3 \ x_3 + 8 \ x_4 + x_6 = 10 \\ x_i \ge 0 \ (i = 1, \ 2, \ 3, \ 4, \ 5, \ 6) \end{cases}</script><h2 id="单纯行算法"><a href="#单纯行算法" class="headerlink" title="单纯行算法"></a><font size="4">单纯行算法</font></h2><p>  <font size="3">基本变量：每个约束条件中的系数为正且只出现在一个约束条件中的变量</font><br>  <font size="3">非基本变量：除基本变量外的变量全部为非基本变量</font><br>  <font size="3">基本可行解：满足标准形式约束条件的可行解称为基本可行解</font><br>  <font size="3">检验数：目标函数中非基本变量的系数</font></p>
<h2 id="最优解的判别"><a href="#最优解的判别" class="headerlink" title="最优解的判别"></a><font size="4">最优解的判别</font></h2><p>  <font size="3">(1)若目标函数中关于非基本变量的所有系数小于等于0，则当前基本可行解就是最优解。</font><br>  <font size="3">(2)若目标函数中关于非基本变量的所有系数小于等于0，同时存在某个非基本变量的检验数等于0，则线性规划问题有无穷多个最优解。</font><br>  <font size="3">(3)如果某个非基本变量的系数大于0，而该变量对应的列向量的各个分量都小于等于0，则该线性规划问题有无界解。</font></p>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a><font size="5" color="red">算法步骤</font></h1><h2 id="建立初始单纯形表"><a href="#建立初始单纯形表" class="headerlink" title="建立初始单纯形表"></a><font size="4">建立初始单纯形表</font></h2><p>  <font size="3">(1)从构建出的线性规划标准型中找出基本变量和非基本变量，且让目标函数由非基本变量表示。</font><br>  <font size="3">(2)基本变量的系数要缩放到1，基本变量做列，非基本变量做行。</font><br>  <font size="3">(2)检验数放第一行，常数项放第一列，约束条件中的非基本变量的系数作为值，构造初始单纯形表。</font><br><img src="/images/ALGORITHM/line2.png" alt="2"></p>
<h2 id="根据单纯形表判断是否得到最优解"><a href="#根据单纯形表判断是否得到最优解" class="headerlink" title="根据单纯形表判断是否得到最优解"></a><font size="4">根据单纯形表判断是否得到最优解</font></h2><p>  <font size="3">(1)如果所有的检验数都小于等于0，则已获得最优解，算法结束，取出左上角的值即为最优解。</font><br>  <font size="3">(2)如果所有的检验数有些为正数，但其中某一正的检验数对应的列向量的所有分量均小于等于0，则线性规划问题无解，算法结束。</font><br>  <font size="3">(3)如果所有的检验数有些为正数，但其中某一正的检验数对应的列向量中有正的分量，则继续下一步。</font></p>
<h2 id="选择入基变量"><a href="#选择入基变量" class="headerlink" title="选择入基变量"></a><font size="4">选择入基变量</font></h2><p>  <font size="3">选取检验数中最大的一个，其对应的非基本变量称为入基变量，该列称为入基列</font></p>
<h2 id="选择离基变量"><a href="#选择离基变量" class="headerlink" title="选择离基变量"></a><font size="4">选择离基变量</font></h2><p>  <font size="3">选取常数列元素与入基列元素的比值中，正数的最小者所对应的基本变量为离基变量。</font></p>
<h2 id="换基变换"><a href="#换基变换" class="headerlink" title="换基变换"></a><font size="4">换基变换</font></h2><p>  <font size="3">将单纯形表上的入基变量和离基变量互换位置。</font><br><img src="/images/ALGORITHM/line3.png" alt="3"></p>
<h2 id="计算新的单纯形表"><a href="#计算新的单纯形表" class="headerlink" title="计算新的单纯形表"></a><font size="4">计算新的单纯形表</font></h2><p>  <font size="3">入基列=-原值/交叉位值。</font><br>  <font size="3">离基行=原值/交叉位值。</font><br>  <font size="3">交叉位=原值去倒数。</font><br>  <font size="3">左上角值=原值+同行入基列元素值*同列离基行元素值/交叉位值。</font></p>
<p><img src="/images/ALGORITHM/line4.png" alt="4"></p>
<p>  <font size="3">其余值=原值-同行入基列元素值*同列离基行元素值/交叉位值。</font></p>
<p><img src="/images/ALGORITHM/line5.png" alt="5"></p>
<p>  <font size="3">得到新的单纯形表再返回第二步重新判断。直到满足终止条件。</font><br>  <font size="3">本题的最终的单纯形表如下，可知最优解为z’=11，由于此题要求最小值，即z=-z=-11。</font><br><img src="/images/ALGORITHM/line6.png" alt="6"><br>  <font size="3">其最优解为基本变量对应的常数项组成，非基本变量全部置为0，即解为</font></p>
<script type="math/tex; mode=display">\begin{pmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \\ x_6 \end{pmatrix} = \begin{pmatrix} 0 \\ 4 \\ 5 \\ 0 \\ 0 \\ 11 \end{pmatrix}</script><h1 id="经典例题-最大利润"><a href="#经典例题-最大利润" class="headerlink" title="经典例题(最大利润)"></a><font size="5" color="red">经典例题(最大利润)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  某工厂有3个车间，第一个车间用1个单位的原料N可以加工5个单位的产品A和2个单位的产品B。<br>  如果产品A直接售出，售价为10元，如果在第二个车间继续加工，则需要加工费5元，加工后售价为19元。<br>  如果产品B直接售出，售价为16元，如果在第三个车间继续加工，则需要加工费4元，加工后售价为24元。<br>  原材料N的单位购入价为5元，每工时的工资是15元，第一个车间加工一个单位的N需要0.05个工时，第二个车间加工一个单位需要0.1个工时，第三个车间加工一个单位需要0.08个工时。<br>  每个月最多能得到12000单位的原材料N，工时最多为1000工时，问如何安排生产才能得到最高的收益？</p>
<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a><font size="4">问题分析</font></h2><p>  假设A直接卖出的数量为x<sub>1</sub>，收获的利润为$10 \ x_1$<br>  假设A在第二车间加工后的出售量为x<sub>2</sub>，收获的利润为$(19-5-0.1 \times 15) \ x_2 = 12.5 \ x_2$<br>  假设B直接卖出的数量为x<sub>3</sub>，收获的利润为$16 \ x_3$<br>  假设B在第三车间加工后的出售量为x<sub>4</sub>，收获的利润为$(24-4-0.08 \times 15) \ x_4 = 18.8 \ x_4$<br>  假设所用的原材料数量为x<sub>5</sub>，所用的成本为$(5+0.05 \times 15) \ x_5 = 5.75 \ x_5$<br>  根据分析可得目标函数和约束条件如下:</p>
<script type="math/tex; mode=display">\max z = 10 \ x_1 + 12.5 \ x_2 + 16 \ x_4 +18.8 \ x_4 - 5.75 \ x_5</script><script type="math/tex; mode=display">\begin{cases} x_1 + x_2 - 5 \ x_5 =0 \\ x_3 + x_4 - 2 \ x_5 = 0 \\  x_5 \le 12000 \\ 0.1 \ x_1 + 0.08 \ x_4 +0.05 \ x_5 \le 1000 \\ x_i \ge 0 \ (i = 1, \ 2, \ 3, \ 4, \ 5) \end{cases}</script><p>  将其转换为标准型可知:</p>
<script type="math/tex; mode=display">\max z = 10 \ x_1 + 12.5 \ x_2 + 16 \ x_4 +18.8 \ x_4 - 5.75 \ x_5</script><script type="math/tex; mode=display">\begin{cases} x_1 + x_2 - 5 \ x_5 =0 \\ x_3 + x_4 - 2 \ x_5 = 0 \\  x_5 + x_6 = 12000 \\ 0.1 \ x_1 + 0.08 \ x_4 +0.05 \ x_5 + x_7 = 1000 \\ x_i \ge 0 \ (i = 1, \ 2, \ 3, \ 4, \ 5, \ 6, \ 7) \end{cases}</script><p>  找出基本变量$x_1, \ x_3, \ x_6, \ x_7$和非基本变量$x_2, \ x_4, \ x_5$<br>  将目标函数由非基本变量表示，即用$x_1 = 5 \ x_5 - x_2, \ x_3 = 2 \ x_5 - x_4$替换，目标函数转化为:</p>
<script type="math/tex; mode=display">\begin{align} z & =10(5 \ x_5 - x_2) + 12.5 \ x_2 + 16(2 \ x_5 - x_4) + 18.8 \ x_4 - 5.75 \ x_5 \\ & = 2.5 \ x_2 + 2.8 \ x_4 + 76.25 \ x_5 \\ \end{align}</script><p>  构造初始单纯形表<br><img src="/images/ALGORITHM/line7.png" alt="7"></p>
<p>  第一行输入基本变量的下标，第二行输入非基本变量的下标，然后输入初始单纯形表。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">1 3 6 7 # 基本变量下标</span><br><span class="line">2 4 5 # 非基本变量下标</span><br><span class="line">0 2.5 2.8 76.25 # 初始单纯形表</span><br><span class="line">0 1 0 -5</span><br><span class="line">0 0 1 -2</span><br><span class="line">12000 0 0 1</span><br><span class="line">1000 0.1 0.08 0.05</span><br></pre></td></tr></tbody></table></figure>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def display_simplex_table(simplex_table):</span><br><span class="line">    print('-----单纯形表如下-----')</span><br><span class="line">    print(' '.join([' '] + nonbase_subscript))</span><br><span class="line">    for i in range(base_num):</span><br><span class="line">        print(' '.join([base_subscript[i]] + [str(x) for x in simplex_table[i]]))</span><br><span class="line"></span><br><span class="line">def judge_simplex_table(simplex_table):</span><br><span class="line">    global solve</span><br><span class="line">    display_simplex_table(simplex_table)</span><br><span class="line">    all_negative_j_flag = True</span><br><span class="line">    for j in range(1, nonbase_num):</span><br><span class="line">        if simplex_table[0][j] &gt; 0:</span><br><span class="line">            all_negative_j_flag = False</span><br><span class="line">            all_negative_i_flag = True</span><br><span class="line">            for i in range(1, base_num):</span><br><span class="line">                if simplex_table[i][j] &gt; 0:</span><br><span class="line">                    all_negative_i_flag = False</span><br><span class="line">            if all_negative_i_flag:</span><br><span class="line">                print('该线性规划问题无界，无法求得最优解')</span><br><span class="line">                return</span><br><span class="line">    if all_negative_j_flag:</span><br><span class="line">        for i in range(1, base_num):</span><br><span class="line">            solve.append(base_subscript[i] + '=' + str(simplex_table[i][0]))</span><br><span class="line">        for j in range(1, nonbase_num):</span><br><span class="line">            solve.append(nonbase_subscript[j] + '=' + str(simplex_table[0][j]))</span><br><span class="line">        print('该问题的最优解为:', simplex_table[0][0])</span><br><span class="line">        print('该问题的解向量为:', ', '.join(solve))</span><br><span class="line">        return</span><br><span class="line">    else:</span><br><span class="line">        update_simplex_table(simplex_table)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">def update_simplex_table(simplex_table):</span><br><span class="line">    global base_subscript, nonbase_subscript</span><br><span class="line">    in_base_var = simplex_table[0][1:].index(max(simplex_table[0][1:])) + 1</span><br><span class="line">    ratio = []</span><br><span class="line">    for i in range(1, base_num):</span><br><span class="line">        ratio = ratio + [0]  if simplex_table[i][in_base_var] == 0 else ratio + [simplex_table[i][0]/simplex_table[i][in_base_var]]</span><br><span class="line">    out_base_value = max(ratio) + 1</span><br><span class="line">    out_base_var = 0</span><br><span class="line">    for i in range(len(ratio)):</span><br><span class="line">        out_base_value, out_base_var = [ratio[i], i] if 0 &lt; ratio[i] &lt; out_base_value else [out_base_value, out_base_var]</span><br><span class="line">    out_base_var += 1</span><br><span class="line">    tmp_table = [[0 for i in range(nonbase_num)] for j in range(base_num)]</span><br><span class="line">    for i in range(base_num):</span><br><span class="line">        for j in range(nonbase_num):</span><br><span class="line">            if i == 0 and j == 0:</span><br><span class="line">                tmp_table[i][j] = simplex_table[i][j] + simplex_table[out_base_var][j] * simplex_table[i][in_base_var] / simplex_table[out_base_var][in_base_var]</span><br><span class="line">                continue</span><br><span class="line">            if i != out_base_var and j != in_base_var:</span><br><span class="line">                tmp_table[i][j] = simplex_table[i][j] - simplex_table[out_base_var][j] * simplex_table[i][in_base_var] / simplex_table[out_base_var][in_base_var]</span><br><span class="line">                continue</span><br><span class="line">            if i != out_base_var and j == in_base_var:</span><br><span class="line">                tmp_table[i][j] = -1 * simplex_table[i][j] / simplex_table[out_base_var][in_base_var]</span><br><span class="line">                continue</span><br><span class="line">            if i == out_base_var and j != in_base_var:</span><br><span class="line">                tmp_table[i][j] = simplex_table[i][j] / simplex_table[out_base_var][in_base_var]</span><br><span class="line">                continue</span><br><span class="line">            if i == out_base_var and j == in_base_var:</span><br><span class="line">                tmp_table[i][j] = 1 / simplex_table[i][j]</span><br><span class="line">                continue</span><br><span class="line">    simplex_table = [x[:] for x in tmp_table]</span><br><span class="line">    base_subscript[out_base_var], nonbase_subscript[in_base_var] = nonbase_subscript[in_base_var], base_subscript[out_base_var]</span><br><span class="line">    judge_simplex_table(simplex_table)</span><br><span class="line"></span><br><span class="line">print('输入基本变量下标:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    base_subscript = ['c'] + ['x' + x for x in line.strip().split()]</span><br><span class="line">    print('输入非基本变量下标:')</span><br><span class="line">    nonbase_subscript = ['b'] + ['x' + x for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    base_num, nonbase_num = len(base_subscript), len(nonbase_subscript)</span><br><span class="line">    simplex_table, solve = [], []</span><br><span class="line">    print('请输入初始单纯形表:')</span><br><span class="line">    for i in range(base_num):</span><br><span class="line">        simplex_table.append([float(x) for x in sys.stdin.readline().strip().split()])</span><br><span class="line">    judge_simplex_table(simplex_table)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/line8.png" alt="8"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  线性规划问题的难点不在于算法的设计，而是在于如何从文字描述中寻找到合适的模型，如何建立线性规划方程组。线性规划在实际的生产生活中有着重要的应用，虽然该算法理解起来较为复杂，但是记住其求解形式，遇到此类问题直接仿照使用即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>并查集(Union Find)</title>
    <url>/2019/08/07/algorithm%20union%20find/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">并查集</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Union Find:并查集</strong>，是一种<strong>树型</strong>的数据结构，用于处理一些<strong>不相交集合的合并及查询</strong>问题。在一些有N个元素的集合应用问题中，我们通常是在开始时让每个元素构成一个单元素的集合，然后按一定顺序将属于<strong>同一组</strong>的元素所在的<strong>集合合并</strong>。<br><a id="more"></a></p>
<p><img src="/images/ALGORITHM/union1.jpg" alt="1"></p>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a><font size="5" color="red">算法步骤</font></h1><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a><font size="4">初始化</font></h2><p>  把每个点所在集合初始化为其自身，通常来说，这个步骤在每次使用该数据结构时只需要执行一次。</p>
<h2 id="查找根结点"><a href="#查找根结点" class="headerlink" title="查找根结点"></a><font size="4">查找根结点</font></h2><p>  查找元素所在的集合，即根节点。为了以后的查找方便，可以在查询时将该结点以及该结点的所有父节点都直接指向根结点，再次查询时即可直接查找到根结点。</p>
<h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a><font size="4">合并</font></h2><p>  将两个元素所在的集合合并为一个集合，合并之前，应先判断两个元素是否属于同一集合，这可用上面的“查找根结点”操作实现，判断两个根结点是否相同来判断是否属于同一集合。</p>
<h1 id="经典例题-岛屿数量"><a href="#经典例题-岛屿数量" class="headerlink" title="经典例题(岛屿数量)"></a><font size="5" color="red">经典例题(岛屿数量)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  有一个二维的网格地图，其中1代表陆地0代表水，并且该网格的四周全部由水包围。我们对岛屿的定义是四面环水，由相邻的陆地水平或垂直连接形成，现在需要统计岛屿的数量。<br>  输入一行数据，使用空格分隔二维地图的每一行，使用逗号分隔一行中的每一项。<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">1,1,0,0,0 1,1,0,0,0 0,0,1,0,0 0,0,0,1,1 # 输入4×5的地图</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/ALGORITHM/union2.png" alt="2"></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  初始时将每个值为1的点都指向自己(即单独一个点作为一个岛)，count等于值为1的点的个数。然后遍历整个地图，如果该点上下左右有值为1的点则查找两个点的根结点，如果根结点相同说明已经在同一个岛上，否则合并两个岛，count值减1。<br>  将所有点都遍历以后，此时相邻的点都具有同样的根结点，此时的count个数即为岛屿的数量。</p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">class Union_find:</span><br><span class="line">    def __init__(self, grid):</span><br><span class="line">        row_num, col_num = len(grid), len(grid[0])</span><br><span class="line">        self.count = 0</span><br><span class="line">        self.parent = [-1] * (row_num * col_num)</span><br><span class="line">        self.rank = [0] * (row_num * col_num)</span><br><span class="line">        for i in range(row_num):</span><br><span class="line">            for j in range(col_num):</span><br><span class="line">                if grid[i][j] == '1':</span><br><span class="line">                    self.parent[i * col_num + j] = i * col_num + j</span><br><span class="line">                    self.count += 1</span><br><span class="line"></span><br><span class="line">    def find(self, i):</span><br><span class="line">        root = i</span><br><span class="line">        while self.parent[root] != root: </span><br><span class="line">            root = self.parent[root]</span><br><span class="line">        while self.parent[i] != root:</span><br><span class="line">            i, self.parent[i] = self.parent[i], root</span><br><span class="line">        return root</span><br><span class="line"></span><br><span class="line">    def connection(self, p, q):</span><br><span class="line">        return self.find(p) == self.find(q)</span><br><span class="line"></span><br><span class="line">    def union(self, p, q):</span><br><span class="line">        proot = self.find(p)         </span><br><span class="line">        qroot = self.find(q)</span><br><span class="line">        if qroot != proot:</span><br><span class="line">            self.parent[proot] = qroot</span><br><span class="line">            self.count -= 1</span><br><span class="line"></span><br><span class="line">print('请输入要查询的地图:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    line = line.strip().split()</span><br><span class="line">    row_num, col_num, grid, direction = len(line), (len(line[0]) + 1) // 2, [], [[1, 0], [0, 1]]</span><br><span class="line">    for tmp in line:</span><br><span class="line">        grid.append(tmp.split(','))</span><br><span class="line">    uf = Union_find(grid)</span><br><span class="line">    for i in range(row_num):</span><br><span class="line">        for j in range(col_num):</span><br><span class="line">            if grid[i][j] == '1':</span><br><span class="line">                for x, y in direction:</span><br><span class="line">                    new_i, new_j = i + x, j + y</span><br><span class="line">                    if new_i &lt; row_num and new_j &lt; col_num and grid[new_i][new_j] == '1':</span><br><span class="line">                        uf.union(i * col_num + j, new_i * col_num + new_j)</span><br><span class="line">    print('该地图中岛屿的数量为:', uf.count)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/union.png" alt="0"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  并查集是一个较为复杂且不太常用的算法，但是可以解决一些特定问题，尤其是解决一些集合关系的问题。该算法可以使具有某些特定关系的点作为一个群体，然后统计整体的群体个数即为整体的类别个数，某个群体中个体的数量即为整体中某一类别的数量。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>位运算(Bit Operation)</title>
    <url>/2019/08/02/algorithm%20bit%20operation/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">位运算</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Bit Operation:位运算</strong>，程序中的所有数在计算机内存中都是以<strong>二进制的形式储存</strong>的，位运算就是直接对整数在内存中的二进制位进行操作，所以运算速度相对较快。位运算主要包括<strong>按位与(&amp;)</strong>、<strong>按位或(|)</strong>、<strong>按位异或(^)</strong>、<strong>取反(~)</strong>、<strong>左移(&lt;&lt;)</strong>、<strong>右移(&gt;&gt;)</strong>这几种，其中除了取反(~)以外，其他的都是二目运算符，即要求运算符左右两侧均有一个运算量。<br><a id="more"></a></p>
<h1 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a><font size="5" color="red">算法基础</font></h1><h2 id="原码"><a href="#原码" class="headerlink" title="原码"></a><font size="4">原码</font></h2><p>  <font size="3">原码是二进制的一种表现方式。取该整数的绝对值的二进制，再加上符号位。该原码只是为了让我们看二进制更直观，直接看出正负数和比较大小。但原码不是计算机保存的二进制，所以不能直接参与计算。</font><br><img src="/images/ALGORITHM/bit1.png" alt="1"></p>
<h2 id="反码"><a href="#反码" class="headerlink" title="反码"></a><font size="4">反码</font></h2><p>  <font size="3">反码主要是针对负数的处理。非负数的反码等于其原码，负数的反码在原码的基础上，符号位不变，其他数值位取反，即把1变成0，把0变成1。反码是为了在计算机中存储二进制，但非真正的二进制值，所以也不直接参与计算。</font><br><img src="/images/ALGORITHM/bit2.png" alt="2"></p>
<h2 id="补码"><a href="#补码" class="headerlink" title="补码"></a><font size="4">补码</font></h2><p>  <font size="3">补码是真正的二进制值了，主要也是针对负数。非负数不变，而负数是在反码的基础上加1，为了方便正数和负数之间进行运算。</font><br><img src="/images/ALGORITHM/bit3.png" alt="3"></p>
<h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a><font size="4">位运算</font></h2><p><img src="/images/ALGORITHM/bit.jpg" alt="4"></p>
<h2 id="位运算技巧"><a href="#位运算技巧" class="headerlink" title="位运算技巧"></a><font size="4">位运算技巧</font></h2><script type="math/tex; mode=display">x \ >> \ n \iff \left \lfloor x \div \ 2^n \right \rfloor \ , \ x的二进制值右移n位</script><script type="math/tex; mode=display">x \ << \ n \iff x \ \times \ 2^n \ , \ x的二进制值右移n位</script><script type="math/tex; mode=display">x \ \& \ 1 \ == \ 1 \iff x \ % \ 2 \ == \ 1 \ , \ 判断x是否为奇数</script><script type="math/tex; mode=display">x \ \& \ (x -1) \ , \ 清除x最后一位的1</script><script type="math/tex; mode=display">x \ \& \ (-x) \ , \ 得到x最后一位的1</script><h1 id="经典例题-二进制中1的个数"><a href="#经典例题-二进制中1的个数" class="headerlink" title="经典例题(二进制中1的个数)"></a><font size="5" color="red">经典例题(二进制中1的个数)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  给定一个正整数n，输出从0到n的每个数的二进制中有多少个1？<br>  输入正整数n</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">10 # 输入正整数10</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  分析一个数的二进制中有多少个1，可以使用传统的方法，一直模2(mod 2)然后再除以2，知道结果为0即可。这样做虽然也不慢，但是如果二进制中1的个数很少，这样做效率就很低。<br>  可以采用$x \ \&amp; \ (x -1)$的方法，每次清除x最后一位的1，清除了多少次即有多少个1。并且使用动态规划的思想，保存之前做过的记录，即求6的二进制位(110)有多少1，将做后一位的1去掉之后为(100)，即求4的二进制位有多少1，然后加1即可。</p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('请输入一个正整数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    number = int(line.strip())</span><br><span class="line">    number_one_bit = [0] * (number + 1)</span><br><span class="line">    for i in range(1, number + 1):</span><br><span class="line">        number_one_bit[i] = number_one_bit[i &amp; (i - 1)] + 1</span><br><span class="line">    print('从0到' + str(number) + '的二进制表示中1的个数为:', number_one_bit)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/bit4.png" alt="4"></p>
<h1 id="经典例题-N皇后问题"><a href="#经典例题-N皇后问题" class="headerlink" title="经典例题(N皇后问题)"></a><font size="5" color="red">经典例题(N皇后问题)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  在n×n的国际棋盘上放置彼此不受攻击的n个皇后，按照规则，皇后可以攻击与之在同一行、同一列、统一斜线上的棋子。现在已知又n个皇后，问有多少种不同的放法？<br>  输入皇后的个数n</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">6 # 皇后的个数</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  之前再深度优先搜索中提到过N皇后的一般解法，确实深度优先是最容易想到的一种做法，但是并不是最快的一种做法，可以尝试采用深度优先+位运算提高效率。<br>  以4皇后为例，每个皇后有四个格子可以放置，可以当作二进制的四个bit。如8(1000)代表皇后放在第1个格子，4(0100)代表皇后放在第二个格子。某一个皇后可以放置的位置由列，斜线和反斜线三个方向限制。<br>  设第i个皇后放置的行数为row，被攻击的列数为col，被攻击的斜线为pie，被攻击的反斜线为na。因此所有被攻击的点为$col \ | \ pie \ | \ na$，因此可以放置的位置为$~(col \ | \ pie \ | \ na) \ \&amp; \ ((1 &lt;&lt; queen_num) - 1)$，保证高位都为0，不可以放置。<br>  上述操作之后说明该数中二进制位的1就是当前可以放置的位置。每次$x \ \&amp; \ (-x)$得到x最后一位的1，并将皇后放置于该位置p，并使用$x \ \&amp; \ (x -1)$并将此位的1清除，并进入下一行，下一行被攻击的列为$col \ | \ p$，下一行被攻击的斜线为$(pie \ | \ p) \ &lt;&lt; \ 1$，下一行被攻击的反斜线为$(na \ | \ p) \ &gt;&gt; \ 1$</p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def dfs(row, col, pie, na):</span><br><span class="line">    global res_num</span><br><span class="line">    if row &gt;= queen_num:</span><br><span class="line">        res_num += 1</span><br><span class="line">        return</span><br><span class="line">    bits = (~(col | pie | na) &amp; ((1 &lt;&lt; queen_num) - 1))</span><br><span class="line">    while bits &gt; 0:</span><br><span class="line">        p = bits &amp; -bits</span><br><span class="line">        dfs(row + 1, col | p, (pie | p) &lt;&lt; 1, (na | p) &gt;&gt; 1)</span><br><span class="line">        bits &amp;= bits - 1</span><br><span class="line"></span><br><span class="line">print('请输入皇后的个数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    queen_num, res_num = int(line.strip()), 0</span><br><span class="line">    chess = [[0 for i in range(queen_num)] for j in range(queen_num)]</span><br><span class="line">    dfs(0, 0, 0, 0)</span><br><span class="line">    print('一共有' + str(res_num) + '种皇后放置方法')</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/bit5.png" alt="5"></p>
<h1 id="经典例题-斐波那契数列"><a href="#经典例题-斐波那契数列" class="headerlink" title="经典例题(斐波那契数列)"></a><font size="5" color="red">经典例题(斐波那契数列)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  假设第一个月有一对刚诞生的兔子，第二个月进入成熟期，第三个月开始生育兔子，而一对成熟的兔子每月回生一对兔子，如果兔子永不死去，那么n个月后有多少对兔子？<br>  输入月份数n</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">10 # 求第10个月的兔子数</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  斐波那契数列是一个典型的算法问题，有多个不同版本的解法，也代表着不同的思想。<br>  首先就是递归解法，根据$f(n)=f(n-1)+f(n-2), \ f(1)=f(2)=1$求解，不过这种解法的时间复杂度为$O(({\frac{\sqrt5 + 1}{2}})^n)$，算f(10)还是非常快的，但是算f(100)简直是天方夜谭。<br>  其次是动态规划解法，建立一个大小为n+1的矩阵，每次计算的值存放于矩阵中此时计算$f(n)=f(n-1)+f(n-2)$时，f(n-1)和f(n-2)就不需要递归计算，只要查表即可，时间复杂度为O(n)。<br>  最快的解法为矩阵解法，根据$\begin{pmatrix} f(n-1) \ f(n) \end{pmatrix} = \begin{pmatrix} 1 &amp; 1 \ 1 &amp; 2 \end{pmatrix} \ \begin{pmatrix} f(n-2) \ f(n-3) \end{pmatrix}$可得</p>
<script type="math/tex; mode=display">\begin{pmatrix} f(\left \lfloor \frac{n}{2} \right \rfloor \times 2) \\ f(\left \lfloor \frac{n}{2} \right \rfloor \times 2+1) \end{pmatrix} = {\begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix}}^{\left \lfloor \frac{n}{2} \right \rfloor} \ \begin{pmatrix} 0 \\ 1 \end{pmatrix}</script><p>  即问题转化为求矩阵${\begin{pmatrix} 1 &amp; 1 \ 1 &amp; 2 \end{pmatrix}}^{\left \lfloor \frac{n}{2} \right \rfloor}$，时间复杂度为O(n)。乘方问题可以用位运算提高效率，时间复杂度可以提升到O(log(n))</p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def matrix_mul(array_1, array_2):</span><br><span class="line">    row_1, mid, col_2 = len(array_1), len(array_2), len(array_2[0])</span><br><span class="line">    array=[[0 for i in range(col_2)] for j in range(row_1)]</span><br><span class="line">    for i in range(row_1):</span><br><span class="line">        for j in range(col_2):</span><br><span class="line">                array[i][j] = array_1[i][0] * array_2[0][j] + array_1[i][1] * array_2[1][j]</span><br><span class="line">    return array</span><br><span class="line"></span><br><span class="line">def matrix_pow(array, m):</span><br><span class="line">    binary, n = [int(x) for x in bin(m)[2:]], len(array)</span><br><span class="line">    res, temp = [[1, 0], [0, 1]], [x[:] for x in array]</span><br><span class="line">    while binary:</span><br><span class="line">        if binary.pop() == 1:</span><br><span class="line">            res = matrix_mul(res, temp)</span><br><span class="line">        temp = matrix_mul(temp, temp)</span><br><span class="line">    return res</span><br><span class="line"></span><br><span class="line">print('请输入月份数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    month = int(line.strip())</span><br><span class="line">    print('第' + str(month) + '月的兔子数量为:', matrix_mul(matrix_pow([[1, 1], [1, 2]], month//2), [[0], [1]])[month % 2][0])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/bit6.png" alt="6"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  位运算说是一种算法，实际上应该说是一种方法。许多问题都可以用位运算来提高效率，位运算很少单独使用，往往同其他的算法一起使用，作为其中的一个步骤，能够在特定的情况下发挥出特殊的效果。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>广度优先搜索(Breadth-First-Search)</title>
    <url>/2019/07/31/algorithm%20BFS/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Breadth-First-Search</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Breadth-First-Search(BFS):深度优先搜索</strong>，属于<strong>图算法</strong>的一种，是一种盲目搜寻法，目的是系统地<strong>展开并检查图中的所有节点</strong>，以找寻结果。在树搜索算法中，从上到下为纵，从左向右为横，纵向搜索为深度优先，而横向搜索是广度优先。简言之就是<strong>先访问图的顶点</strong>，然后<strong>优先访问其邻接点</strong>，然后再依次<strong>进行被访问点的邻接点</strong>，<strong>一层一层</strong>访问，直至访问完所有点，遍历结束，通常根据<strong>队列的先进先出</strong>性质将各结点遍历。<br><a id="more"></a></p>
<p><img src="/images/ALGORITHM/bfs1.jpg" alt="bfs"></p>
<h1 id="算法条件"><a href="#算法条件" class="headerlink" title="算法条件"></a><font size="5" color="red">算法条件</font></h1><h2 id="解空间"><a href="#解空间" class="headerlink" title="解空间"></a><font size="4">解空间</font></h2><p>  <font size="3">解的组织形式可以规范为一个n元组${x_1,x_2,\ldots,x_n}$，并且对解有取值范围的限定，一般为有穷个，解的个数代表一个结点的分支个数。解空间越小，搜索效率越高，解空间大犹如大海捞针，搜索效率很低。</font></p>
<h2 id="剪枝函数"><a href="#剪枝函数" class="headerlink" title="剪枝函数"></a><font size="4">剪枝函数</font></h2><p>  <font size="3">剪枝函数又称为隐约束，对能否得到问题的可行解的约束称为约束函数，对能否得到问题的最优解的约束称为限界函数。有了剪枝函数，我们就可以剪掉得不到可行解或最优解的分支，避免了无效搜索，提高搜索的效率。因此剪枝函数的设计是十分重要的。</font></p>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a><font size="5" color="red">算法步骤</font></h1><p>  <font size="3">(1)分析题意，了解题目要求</font><br>  <font size="3">(2)根据问题分析解空间的形式</font><br>  <font size="3">(3)根据解空间设计合适的剪枝函数</font></p>
<h1 id="经典例题-0-1背包"><a href="#经典例题-0-1背包" class="headerlink" title="经典例题(0-1背包)"></a><font size="5" color="red">经典例题(0-1背包)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  假设山洞里有n个宝物，每种宝物有一定重量w和相应的价值v，背包的装载能力有限，只能运走重量为m的宝物，宝物不可以分割，如何使背包运走物品的价值最大？<br>  第一行先输入宝物的数量n，和背包的承载重量m，然后每一行输出一个宝物对应的重量w和价值v(用空格分开)<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 10 # 宝物数n和背包能装载的重量m</span><br><span class="line">2 6 #每个宝物的重量w和价值v</span><br><span class="line">5 3</span><br><span class="line">4 5</span><br><span class="line">2 4</span><br><span class="line">3 6</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  0-1背包问题和普通背包问题不同的是其解空间为{0，1}，即每一个物品都有两种状态，装入或者不装入，因此满足解空间的条件。<br>  分析剪枝函数，如果剩余的价值加上当前的价值都没有已经搜索到的最大价值高，则没有必要继续搜索。</p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def bfs(treasure_queue):</span><br><span class="line">    global max_value, max_plan</span><br><span class="line">    while treasure_queue:</span><br><span class="line">        n, out_node = treasure_queue[0][0], treasure_queue.pop(0)</span><br><span class="line">        if n &gt;= count:</span><br><span class="line">            max_value, max_plan = [out_node[2], out_node[3][:]] if out_node[2] &gt; max_value else [max_value, max_plan[:]]</span><br><span class="line">            continue</span><br><span class="line">        if out_node[1] - treasure[n][1] &gt;= 0:</span><br><span class="line">            treasure_queue.append([n + 1, out_node[1] - treasure[n][1], out_node[2] + treasure[n][2], out_node[3][:n] + [True] + out_node[3][n + 1:]])</span><br><span class="line">        if out_node[2] + leave_value[n] &gt; max_value:</span><br><span class="line">            treasure_queue.append([n + 1, out_node[1], out_node[2], out_node[3][:]])</span><br><span class="line"></span><br><span class="line">print('请输入宝物数量和驴子承载重量:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    count, weight = line.strip().split()</span><br><span class="line">    count, weight, treasure, max_plan, max_value, leave_value, res = int(count), float(weight), [], [False] * int(count), 0, [0], []</span><br><span class="line">    print('请输入每个宝物的重量和价值')</span><br><span class="line">    for i in range(count):</span><br><span class="line">        tmp = [float(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        treasure.append([i + 1] + tmp + [tmp[1] / tmp[0]])</span><br><span class="line">    treasure.sort(key=lambda x: (-x[3]))</span><br><span class="line">    for i in reversed(range(1, count)):</span><br><span class="line">        leave_value = [leave_value[0] + treasure[i][2]] + leave_value</span><br><span class="line">    bfs([[0, weight, 0, [False] * count]])</span><br><span class="line">    print('最优的方案为:\n' + ''.join(['' + ('装入第' + str(j) + '个宝物\n') * (j != 0) for j in sorted([treasure[i][0] * max_plan[i] for i in range(count)])]) + '装入宝物的最大价值为:', max_value)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/bfs2.png" alt="2"></p>
<h1 id="经典例题-旅行商问题"><a href="#经典例题-旅行商问题" class="headerlink" title="经典例题(旅行商问题)"></a><font size="5" color="red">经典例题(旅行商问题)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  现有n个景点，从第一个景点出发，两个景点之间有数字代表可以直接到达，问如何找到一个路径能够不重复的走遍所有景点回到出发点，而且所经过的路径长度是最短的。<br>  第一行输入景点的个数，第二行输入两地之间可以直接到达的数量，然后每行输入两地和之间的距离</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 # 景点个数</span><br><span class="line">9 # 景点之间的连接数</span><br><span class="line">1 2 3 # 景点1和景点2之间的距离为3</span><br><span class="line">1 4 8</span><br><span class="line">1 5 9</span><br><span class="line">2 3 3</span><br><span class="line">2 4 10</span><br><span class="line">2 5 5</span><br><span class="line">3 4 4</span><br><span class="line">3 5 3</span><br><span class="line">4 5 20</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  旅行商问题(TSP)是一个典型的问题，此问题的解空间为n，每一个景点都可以到与之相连的所有点，因此当景点数很多时，最优解的搜索是十分缓慢的。<br>  分析剪枝函数，剪枝函数容易看出，由于不是任何两个景点都是相连的，而且走过的景点不能再走一次，所以这也大大减少了解空间的个数。</p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def bfs(tour_queue):</span><br><span class="line">    global  min_dist, min_route</span><br><span class="line">    while tour_queue:</span><br><span class="line">        n, out_node = tour_queue[0][0], tour_queue.pop(0)</span><br><span class="line">        if n &gt;= scenic_spot_num:</span><br><span class="line">            min_dist, min_route = [out_node[1] + connection[out_node[2][-1]][0], out_node[2][:] + [0]] if out_node[1] + connection[out_node[2][-1]][0] &lt; min_dist else [min_dist, min_route[:]]</span><br><span class="line">        for i in range(scenic_spot_num):</span><br><span class="line">            if i not in out_node[2] and connection[out_node[2][-1]][i] != 0 and out_node[1] + connection[out_node[2][-1]][i] + connection[i][0] &lt; min_dist:</span><br><span class="line">                tour_queue.append([n + 1, out_node[1] + connection[out_node[2][-1]][i], out_node[2] + [i]])</span><br><span class="line"></span><br><span class="line">print('请输入景点数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    scenic_spot_num, min_dist, min_route = int(line.strip()), 65535, []</span><br><span class="line">    print('请输入连通的景点数:')</span><br><span class="line">    connection_num, connection = int(sys.stdin.readline().strip()), [[0 for i in range(scenic_spot_num)] for j in range(scenic_spot_num)]</span><br><span class="line">    print('请依次输入两个景点之间的距离:')</span><br><span class="line">    for i in range(connection_num):</span><br><span class="line">        begin, end, weight = [int(i) for i in sys.stdin.readline().strip().split()]</span><br><span class="line">        connection[begin - 1][end - 1], connection[end - 1][begin - 1] = weight, weight</span><br><span class="line">    bfs([[1, 0, [0]]])</span><br><span class="line">    print('最短的路径为:' + '-&gt;'.join([str(x + 1) for x in min_route]) + '\n最短的路径长度为:', min_dist)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/bfs3.png" alt="3"></p>
<h1 id="经典例题-迷宫问题"><a href="#经典例题-迷宫问题" class="headerlink" title="经典例题(迷宫问题)"></a><font size="5" color="red">经典例题(迷宫问题)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  在一个m×n的地图上，有许多障碍物，给定起始点坐标和目的地坐标，问从起始点开始通过上下左右四个方向移动如何找到一条最短路径能够到达目的地？<br>  第一行输入地图的大小m和n，然后每一行输入障碍物的坐标，输入0，0时结束，接着输入起始点坐标和目的地坐标。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 6 # 地图的大小m,n</span><br><span class="line">1 6 # 障碍物的坐标</span><br><span class="line">2 3 </span><br><span class="line">3 4</span><br><span class="line">3 5</span><br><span class="line">5 1</span><br><span class="line">0 0 #输入0,0结束</span><br><span class="line">2 1 #起始点坐标</span><br><span class="line">4 6 #目的地坐标</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/ALGORITHM/bfs5.png" alt="5"></p>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  迷宫问题是一个典型的搜索问题，每个点都有四个移动方向，因此每一个结点都有四个子节点，可以通过广度优先算法来求解此问题。<br>  分析剪枝函数，此题比较特殊，特别适合于用广度优先，广度优先是一层一层遍历，后面访问的结点的层数一定不小于前面结点的层数。判断新加入的坐标是否为目的地坐标，如果是则为最优解，不需要再搜索其他路径。</p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def bfs(circuit_board_queue):</span><br><span class="line">    global min_spend</span><br><span class="line">    while circuit_board_queue:</span><br><span class="line">        out_node_value, out_node_site = circuit_board_queue[0][0], circuit_board_queue.pop(0)[1]</span><br><span class="line">        if [end_x - 1, end_y - 1] == out_node_site[-1]:</span><br><span class="line">            return out_node_value, [x[:] for x in out_node_site]</span><br><span class="line">        for x, y in direction:</span><br><span class="line">            if 0 &lt;= out_node_site[-1][0] + x &lt; m_size and 0 &lt;= out_node_site[-1][1] + y &lt; n_size and out_node_value + 1 &lt; min_spend[out_node_site[-1][0] + x][out_node_site[-1][1] + y]:</span><br><span class="line">                min_spend[out_node_site[-1][0] + x][out_node_site[-1][1] + y] = out_node_value + 1</span><br><span class="line">                circuit_board_queue.append([out_node_value + 1, out_node_site + [[out_node_site[-1][0] + x, out_node_site[-1][1] + y]]])</span><br><span class="line"></span><br><span class="line">print('请输入地图大小:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    m_size, n_size = [int(x) for x in line.strip().split()]</span><br><span class="line">    circuit_board, min_spend, direction = [[1 for i in range(n_size)] for j in range(m_size)], [[65535 for i in range(n_size)] for j in range(m_size)], [[1, 0], [0, 1], [-1, 0], [0, -1]]</span><br><span class="line">    while True:</span><br><span class="line">        print('请输入障碍物坐标:')</span><br><span class="line">        x, y = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        if x == 0 and y == 0:</span><br><span class="line">            break</span><br><span class="line">        circuit_board[x - 1][y - 1] = 0</span><br><span class="line">    print('请输入起点坐标')</span><br><span class="line">    begin_x, begin_y = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    min_spend[begin_x - 1][begin_y - 1] = 0</span><br><span class="line">    print('请输入终点坐标')</span><br><span class="line">    end_x, end_y = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    min_dist, min_route = bfs([[0, [[begin_x - 1, begin_y - 1]]]])</span><br><span class="line">    print('这条最短路径的长度为:', min_dist, '\n最佳的路径为:' + '-&gt;'.join([str(tuple([y + 1 for y in x])) for x in min_route]))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/bfs4.png" alt="4"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  广度优先搜索是一个基本搜索方法，和深度优先有异曲同工之妙，对于许多问题都可以同时用这两种方法解决。和深度优先相同，都是指数级的时间复杂度，但是对于有些问题不得不使用广度优先进行遍历，因此寻找合适的约束条件可以大大减少时间的开销。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>深度优先搜索(Depth-First-Search)</title>
    <url>/2019/07/27/algorithm%20DFS/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">Depth-First-Search</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Depth-First-Search(DFS):深度优先搜索</strong>，属于<strong>图算法</strong>的一种，是一种盲目搜寻法，从<strong>初始状态出发</strong>，当搜索到某一步时，发现原先选择并不是最优或达不到目标，就<strong>退回一步重新选择</strong>。根据产生子节点的条件约束，搜索问题的最优解。因此又名<strong>回溯法</strong>，是一种<strong>能进则进，进不了则换，换不了则退</strong>的搜索方法。<br><a id="more"></a></p>
<p><img src="/images/ALGORITHM/dfs1.jpg" alt="dfs"></p>
<h1 id="算法条件"><a href="#算法条件" class="headerlink" title="算法条件"></a><font size="5" color="red">算法条件</font></h1><h2 id="解空间"><a href="#解空间" class="headerlink" title="解空间"></a><font size="4">解空间</font></h2><p>  <font size="3">解的组织形式可以规范为一个n元组${x_1,x_2,\ldots,x_n}$，并且对解有取值范围的限定，一般为有穷个，解的个数代表一个结点的分支个数。解空间越小，搜索效率越高，解空间大犹如大海捞针，搜索效率很低。</font></p>
<h2 id="剪枝函数"><a href="#剪枝函数" class="headerlink" title="剪枝函数"></a><font size="4">剪枝函数</font></h2><p>  <font size="3">剪枝函数又称为隐约束，对能否得到问题的可行解的约束称为约束函数，对能否得到问题的最优解的约束称为限界函数。有了剪枝函数，我们就可以剪掉得不到可行解或最优解的分支，避免了无效搜索，提高搜索的效率。因此剪枝函数的设计是十分重要的。</font></p>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a><font size="5" color="red">算法步骤</font></h1><p>  <font size="3">(1)分析题意，了解题目要求</font><br>  <font size="3">(2)根据问题分析解空间的形式</font><br>  <font size="3">(3)根据解空间设计合适的剪枝函数</font></p>
<h1 id="经典例题-0-1背包"><a href="#经典例题-0-1背包" class="headerlink" title="经典例题(0-1背包)"></a><font size="5" color="red">经典例题(0-1背包)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  假设山洞里有n个宝物，每种宝物有一定重量w和相应的价值v，背包的装载能力有限，只能运走重量为m的宝物，宝物不可以分割，如何使背包运走物品的价值最大？<br>  第一行先输入宝物的数量n，和背包的承载重量m，然后每一行输出一个宝物对应的重量w和价值v(用空格分开)<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 10 # 宝物数n和背包能装载的重量m</span><br><span class="line">2 6 #每个宝物的重量w和价值v</span><br><span class="line">5 3</span><br><span class="line">4 5</span><br><span class="line">2 4</span><br><span class="line">3 6</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  0-1背包问题和普通背包问题不同的是其解空间为{0，1}，即每一个物品都有两种状态，装入或者不装入，因此满足解空间的条件。<br>  分析剪枝函数，如果剩余的价值加上当前的价值都没有已经搜索到的最大价值高，则没有必要继续搜索。</p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def dfs(n, current_plan, leave_weight, current_value):</span><br><span class="line">    global  max_value, max_plan</span><br><span class="line">    if n &gt;= count:</span><br><span class="line">        max_value, max_plan = [current_value, current_plan[:]] if current_value &gt; max_value else [max_value, max_plan[:]]</span><br><span class="line">        return</span><br><span class="line">    if leave_weight - treasure[n][1] &gt;= 0:</span><br><span class="line">        leave_weight, current_value, current_plan[n] = [leave_weight - treasure[n][1], current_value + treasure[n][2], True]</span><br><span class="line">        dfs(n + 1, current_plan, leave_weight, current_value)</span><br><span class="line">        leave_weight, current_value, current_plan[n] = [leave_weight + treasure[n][1], current_value - treasure[n][2], False]</span><br><span class="line">    if leave_value[n] + current_value &gt; max_value:</span><br><span class="line">        dfs(n + 1, current_plan, leave_weight, current_value)</span><br><span class="line"></span><br><span class="line">print('请输入宝物数量和驴子承载重量:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    count, weight = line.strip().split()</span><br><span class="line">    count, weight, treasure, max_plan, max_value, leave_value, res = int(count), float(weight), [], [False] * int(count), 0, [0], []</span><br><span class="line">    print('请输入每个宝物的重量和价值')</span><br><span class="line">    for i in range(count):</span><br><span class="line">        tmp = [float(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        treasure.append([i + 1] + tmp + [tmp[1] / tmp[0]])</span><br><span class="line">    treasure.sort(key=lambda x: (-x[3]))</span><br><span class="line">    for i in reversed(range(1, count)):</span><br><span class="line">        leave_value = [leave_value[0] + treasure[i][2]] + leave_value</span><br><span class="line">    dfs(0, [False] * count, weight, 0)</span><br><span class="line">    print('最优的方案为:\n' + ''.join(['' + ('装入第' + str(j) + '个宝物\n') * (j != 0) for j in sorted([treasure[i][0] * max_plan[i] for i in range(count)])]) + '装入宝物的最大价值为:', max_value)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/dfs2.png" alt="2"></p>
<h1 id="经典例题-n皇后问题"><a href="#经典例题-n皇后问题" class="headerlink" title="经典例题(n皇后问题)"></a><font size="5" color="red">经典例题(n皇后问题)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  在n×n的国际棋盘上放置彼此不受攻击的n个皇后，按照规则，皇后可以攻击与之在同一行、同一列、统一斜线上的棋子。现在已知又n个皇后，问有多少种不同的放法？<br>  输入皇后的个数n</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">4 # 皇后的个数</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/ALGORITHM/dfs2.jpg" alt="7"></p>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  n皇后问题不同于0-1背包问题，n皇后的解空间为n，每一个皇后都有n种放法，因此当n很大时，解法的搜索非常缓慢。<br>  分析剪枝函数，已经放置了k个皇后之后，就没有n种不同的放法了，可以通过判断和以前的皇后放法是否冲突来缩小解空间的搜索。</p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def judge_n(n, col, current_queen):</span><br><span class="line">    for i in range(len(current_queen)):</span><br><span class="line">        if current_queen[i] == col or (n - i) == col - current_queen[i] or (n - i) == current_queen[i] - col:</span><br><span class="line">            return False</span><br><span class="line">    return True</span><br><span class="line"></span><br><span class="line">def dfs(n, current_queen):</span><br><span class="line">    global  res, res_num</span><br><span class="line">    if n &gt;= queen_num:</span><br><span class="line">        res, res_num = [res + '第' + str(res_num + 1) + '种皇后放置方法为:' + ''.join(str([(x + 1) for x in current_queen])) + '\n', res_num + 1]</span><br><span class="line">        return</span><br><span class="line">    for i in range(queen_num):</span><br><span class="line">        if judge_n(n, i, current_queen):</span><br><span class="line">            dfs(n + 1, current_queen + [i])</span><br><span class="line"></span><br><span class="line">print('请输入皇后的个数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    queen_num, res, res_num = int(line.strip()), '', 0</span><br><span class="line">    chess = [[0 for i in range(queen_num)] for j in range(queen_num)]</span><br><span class="line">    dfs(0, [])</span><br><span class="line">    print('一共有' + str(res_num) + '种皇后放置方法\n' + res)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/dfs3.png" alt="3"></p>
<h1 id="经典例题-旅行商问题TSP"><a href="#经典例题-旅行商问题TSP" class="headerlink" title="经典例题(旅行商问题TSP)"></a><font size="5" color="red">经典例题(旅行商问题TSP)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  现有n个景点，从第一个景点出发，两个景点之间有数字代表可以直接到达，问如何找到一个路径能够不重复的走遍所有景点回到出发点，而且所经过的路径长度是最短的。<br>  第一行输入景点的个数，第二行输入两地之间可以直接到达的数量，然后每行输入两地和之间的距离</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 # 景点个数</span><br><span class="line">9 # 景点之间的连接数</span><br><span class="line">1 2 3 # 景点1和景点2之间的距离为3</span><br><span class="line">1 4 8</span><br><span class="line">1 5 9</span><br><span class="line">2 3 3</span><br><span class="line">2 4 10</span><br><span class="line">2 5 5</span><br><span class="line">3 4 4</span><br><span class="line">3 5 3</span><br><span class="line">4 5 20</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  旅行商问题(TSP)是一个典型的问题，此问题的解空间为n，每一个景点都可以到与之相连的所有点，因此当景点数很多时，最优解的搜索是十分缓慢的。<br>  分析剪枝函数，剪枝函数容易看出，由于不是任何两个景点都是相连的，而且走过的景点不能再走一次，所以这也大大减少了解空间的个数。</p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def dfs(n, current_dist, current_route):</span><br><span class="line">    global min_dist, min_route</span><br><span class="line">    if n &gt;= scenic_spot_num:</span><br><span class="line">        min_dist, min_route = [current_dist + connection[current_route[-1]][0], current_route[:] + [0]] if current_dist + connection[current_route[-1]][0] &lt; min_dist else [min_dist, min_route[:]]</span><br><span class="line">        return</span><br><span class="line">    for i in range(scenic_spot_num):</span><br><span class="line">        if i not in current_route and connection[current_route[-1]][i] != 0 and current_dist + connection[current_route[-1]][i] + connection[i][0] &lt; min_dist:</span><br><span class="line">            dfs(n + 1, current_dist + connection[current_route[-1]][i], current_route + [i])</span><br><span class="line"></span><br><span class="line">print('请输入景点数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    scenic_spot_num, min_dist, min_route = int(line.strip()), 65535, []</span><br><span class="line">    print('请输入连通的景点数:')</span><br><span class="line">    connection_num, connection = int(sys.stdin.readline().strip()), [[0 for i in range(scenic_spot_num)] for j in range(scenic_spot_num)]</span><br><span class="line">    print('请依次输入两个景点之间的距离:')</span><br><span class="line">    for i in range(connection_num):</span><br><span class="line">        begin, end, weight = [int(i) for i in sys.stdin.readline().strip().split()]</span><br><span class="line">        connection[begin - 1][end - 1], connection[end - 1][begin - 1] = weight, weight</span><br><span class="line">    dfs(1, 0, [0])</span><br><span class="line">    print('最短的路径为:' + '-&gt;'.join([str(x + 1) for x in min_route]) + '\n最短的路径长度为:', min_dist)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/dfs4.png" alt="4"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  深度优先搜索是一个基本搜索方法，对于很多问题来说都可以用深度优先搜索来解决。但不一定是最优的解法，因为深度优先搜索是指数级的时间复杂度，但是对于有些问题不得不使用深度优先进行遍历，因此寻找合适的约束条件可以大大减少时间的开销。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>动态规划(Dynamic Programming)</title>
    <url>/2019/07/25/algorithm%20Dynamic_Programming/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">动态规划</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Dynamic Programming(DP):动态规划</strong>，是运筹学的一个分支，是求解决策过程最优化的数学方法。于1957年被Richard Bellman(理查德·贝尔曼)提出。其中的Programming不是编程的意思，而是指一种表格处理法，把每一步得到的子问题的结果<strong>存储在表格</strong>里，每次遇到子问题时不需要再求解一遍。其本质也是一种分治算法，其不同点在于分治算法将原问题分解为若干子问题，自顶向下求解各子问题，再合并子问题的解。动态规划也是把原问题分解为若干子问题，然后<strong>自底向上</strong>，先求解最小的子问题，把结果存储起来，求解大问题时直接查询小问题的解，<strong>避免了大量的重复计算</strong>，提高了算法效率。<strong>其本质为：递归+记忆化</strong><br><a id="more"></a></p>
<p><img src="/images/ALGORITHM/dynamic.png" alt="dynamic"></p>
<h1 id="问题条件"><a href="#问题条件" class="headerlink" title="问题条件"></a><font size="5" color="red">问题条件</font></h1><h2 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a><font size="4">最优子结构</font></h2><p>  <font size="3">最优子结构性质是指问题的最优解包含其子问题的最优解。最优子结构是使用动态规划的最基本条件，如果问题不具有最优子结构性质，就不可以使用动态规划解决。</font></p>
<h2 id="子问题重叠"><a href="#子问题重叠" class="headerlink" title="子问题重叠"></a><font size="4">子问题重叠</font></h2><p>  <font size="3">子问题重叠是指再求解子问题的过程中，有大量的子问题是重复的，那么只需要求解依次，然后存储在表格中，以便使用时查询。这不是动态规划的必要条件，但是可以充分体现动态规划的优势。</font></p>
<h1 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a><font size="5" color="red">算法步骤</font></h1><p>  <font size="3">(1)分析最优解的结构特征</font><br>  <font size="3">(2)定义状态转移方程(递归式)</font><br>  <font size="3">(3)自底向上计算最优解并记录</font></p>
<h1 id="经典例题-0-1背包"><a href="#经典例题-0-1背包" class="headerlink" title="经典例题(0-1背包)"></a><font size="5" color="red">经典例题(0-1背包)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  假设山洞里有n个宝物，每种宝物有一定重量w和相应的价值v，背包的装载能力有限，只能运走重量为m的宝物，宝物不可以分割，如何使背包运走物品的价值最大？<br>  第一行先输入宝物的数量n，和背包的承载重量m，然后每一行输出一个宝物对应的重量w和价值v(用空格分开)<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 10 # 宝物数n和背包能装载的重量m</span><br><span class="line">2 6 #每个宝物的重量w和价值v</span><br><span class="line">5 3</span><br><span class="line">4 5</span><br><span class="line">2 4</span><br><span class="line">3 6</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  和普通背包问题不同，如果盲目的装入当前单位重量价值最高的物品，可能导致背包剩余空间较大，达不到最优解。首先分析问题的结构特征，如果第i个宝物装入背包是问题的最优解，背包总重量$m-w_i$一定是问题$\lbrace a_1, a_2, \ldots, a_n \rbrace$的最优解。因此该问题具有最优子结构性质。<br>  根据分析可知，判断第i个宝物装入重量为j的背包时会转化为两种可能，装入或者不装入，不放入时，问题变为前i-1个宝物装入重量为j的背包的最大价值。放入时，问题变为前i-1个宝物装入重量为j-w<sub>i</sub>的背包的最大价值加上第i个宝物的价值v<sub>i</sub>。即比较两者的最大值，用donkey[i][j]表示第i个宝物装入容量为j的背包里的最大价值。<br>$donkey[i][j] = \begin{cases} donkey[i-1][j], &amp; j&lt;w_i \ \max{donkey[i-1][j], donkey[i-1][j-w[i]]+v[i]}, &amp; j \ge w_i \end{cases}$</p>
<h2 id="0-1背包图解"><a href="#0-1背包图解" class="headerlink" title="0-1背包图解"></a><font size="4">0-1背包图解</font></h2><p><img src="/images/ALGORITHM/dynamic1.png" alt="1"></p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('请输入宝物数量和驴子承载重量:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    count, weight = line.strip().split()</span><br><span class="line">    count, weight, treasure, donkey, i, j, plan = int(count), int(weight), [], [[0 for i in range(int(weight) + 1)] for j in range(int(count) + 1)], 0, 0, []</span><br><span class="line">    print('请输入每个宝物的重量和价值')</span><br><span class="line">    for i in range(count):</span><br><span class="line">        treasure.append([int(x) for x in sys.stdin.readline().strip().split()])</span><br><span class="line">    for i in range(1, count + 1):</span><br><span class="line">        for j in range(1, weight + 1):</span><br><span class="line">                donkey[i][j] = max(donkey[i - 1][j - treasure[i - 1][0]] + treasure[i - 1][1], donkey[i - 1][j]) if j &gt;= treasure[i - 1][0] else donkey[i - 1][j]</span><br><span class="line">    while donkey[i][j] != 0:</span><br><span class="line">        plan, i, j = [['放入第' + str(i) + '个宝物'] + ['\n'] + plan, i - 1, j - treasure[i - 1][0]] if donkey[i][j] != donkey[i - 1][j] else [plan, i - 1, j]</span><br><span class="line">    print('无法放入任何一个宝物') if donkey[-1][-1] == 0 else print(''.join(plan) + '装入宝物的最大价值为:', donkey[-1][-1])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/dynamic6.png" alt="6"></p>
<h1 id="经典例题-最长公共序列"><a href="#经典例题-最长公共序列" class="headerlink" title="经典例题(最长公共序列)"></a><font size="5" color="red">经典例题(最长公共序列)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  给定两个序列，如何找出最长公共子序列<br>  第一行输入字符串s1，第二行输入字符串s2</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">ABCADAB # 字符串s1</span><br><span class="line">BACDBA # 字符串s2</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  首先分析问题是否具有最优子结构的性质，假设$Z<em>k={z_1,z_2,z_3,\ldots,z_k}$是$X_m={x_1,x_2,x_3,\ldots,x_m}$和$Y_n={y_1,y_2,y_3,\ldots,y_n}$的最长公共组序列，可以有三种情况讨论：<br>  (1)当$z_k=x_m=y_n$时，则$Z_k={z_1,z_2,z_3,\ldots,z</em>{k-1}}$是$X<em>m={x_1,x_2,x_3,\ldots,x</em>{m-1}}$和$Y<em>n={y_1,y_2,y_3,\ldots,y</em>{n-1}}$的最长公共组序列。<br>  (2)当$z<em>k \neq x_m,x_m \neq y_n$时，则$Z_k={z_1,z_2,z_3,\ldots,z_k}$是$X_m={x_1,x_2,x_3,\ldots,x</em>{m-1}}$和$Y<em>n={y_1,y_2,y_3,\ldots,y_n}$的最长公共组序列。<br>  (3)当$z_k \neq y_n,x_m \neq y_n$时，则$Z_k={z_1,z_2,z_3,\ldots,z_k}$是$X_m={x_1,x_2,x_3,\ldots,x_m}$和$Y_n={y_1,y_2,y_3,\ldots,y</em>{n-1}}$的最长公共组序列。<br>  因此问题满足最优子结构性质，用char[i][j]表示X<sub>i</sub>和Y<sub>j</sub>的最长公共子序列长度。<br>$char[i][j] = \begin{cases} char[i-1][j-1]+1, &amp; x_i=y_j \ \max{char[i][j-1], char[i-1][j]}, &amp; x_i \neq y_j  \end{cases}$</p>
<h2 id="公共子序列图解"><a href="#公共子序列图解" class="headerlink" title="公共子序列图解"></a><font size="4">公共子序列图解</font></h2><p><img src="/images/ALGORITHM/dynamic2.png" alt="2"></p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('输入字符串s1:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    s1 = line.strip()</span><br><span class="line">    print('输入字符串s2:')</span><br><span class="line">    s2 = sys.stdin.readline().strip()</span><br><span class="line">    s1_length, s2_length, i, j, route = len(s1), len(s2), 0, 0, ''</span><br><span class="line">    compare_array, route_array = [[0 for m in range(s2_length + 1)] for n in range(s1_length + 1)], [[0 for m in range(s2_length + 1)] for n in range(s1_length + 1)]</span><br><span class="line">    for i in range(1, s1_length + 1):</span><br><span class="line">        for j in range(1, s2_length + 1):</span><br><span class="line">            compare_array[i][j], route_array[i][j] = [compare_array[i - 1][j - 1] + 1, 1] if s1[i - 1] == s2[j - 1] else([compare_array[i][j - 1], 2] if compare_array[i][j - 1] &gt;= compare_array[i - 1][j] else [compare_array[i - 1][j], 3])</span><br><span class="line">    while i &gt; 0 and j &gt; 0:</span><br><span class="line">        route, i, j = [route + s1[i - 1], i - 1, j - 1] if route_array[i][j] == 1 else ([route, i, j - 1] if route_array[i][j] == 2 else [route , i - 1, j])</span><br><span class="line">    print(s1 + '和' + s2 + '无公共序列') if len(route) == 0 else print(s1 + '和' + s2 + '的最长公共序列的长度为:', len(route), '\n' + s1 + '和' + s2 +'的最长公共序列是:' + route[::-1])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/dynamic4.png" alt="4"></p>
<h1 id="经典例题-字符串编辑距离"><a href="#经典例题-字符串编辑距离" class="headerlink" title="经典例题(字符串编辑距离)"></a><font size="5" color="red">经典例题(字符串编辑距离)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  给定两个序列，如何使用最少的增加字符，删除字符，替换字符操作，使两个序列相同？<br>  第一行输入字符串str1，第二行输入字符串str2</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">family # 字符串str1</span><br><span class="line">frame # 字符串str2</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  分析此题是否具有最优子结构性质，假设char[i][j]是$X_i={x_1,x_2,x_3,\ldots,x_i}$和$Y_j={y_1,y_2,y_3,\ldots,y_j}$的编辑距离的最优解，可以有两种情况讨论：<br>  (1)当两个字符串满足$x_i=y_j$时，则char[i-1][j-1]是$X_m={x_1,x_2,x_3,\ldots,x_i}$和$Y_n={y_1,y_2,y_3,\ldots,y_j}$的编辑距离的最优解。<br>  (2)当两个字符串满足$x_i \neq y_j$时，则可以删除字符x<sub>i</sub>或删除字符y<sub>j</sub>或将字符x<sub>i</sub>替换为字符y<sub>j</sub>，即满足下列条件$\max(char[i-1][j],char[i][j-1],char[i-1][j-1])+1$是$X_m={x_1,x_2,x_3,\ldots,x_i}$和$Y_n={y_1,y_2,y_3,\ldots,y_j}$的编辑距离的最优解。<br>  因此问题满足最优子结构性质，写出其状态转移方程。<br>$char[i][j] = \begin{cases} char[i-1][j-1], &amp; x_i=y_j \ \max{char[i][j-1], char[i-1][j],char[i-1][j-1]}+1, &amp; x_i \neq y_j  \end{cases}$</p>
<h2 id="字符串距离图解"><a href="#字符串距离图解" class="headerlink" title="字符串距离图解"></a><font size="4">字符串距离图解</font></h2><p><img src="/images/ALGORITHM/dynamic3.png" alt="3"></p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('输入字符串str1:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    str1 = line.strip()</span><br><span class="line">    print('输入字符串str2:')</span><br><span class="line">    str2 = sys.stdin.readline().strip()</span><br><span class="line">    str1_length, str2_length, i, j, route = len(str1), len(str2), 0 ,0, []</span><br><span class="line">    compare_array = [list(range(str2_length + 1))] + [[x] + [0] * str2_length for x in range(1,str1_length + 1)]</span><br><span class="line">    for i in range(1, str1_length + 1):</span><br><span class="line">        for j in range(1, str2_length + 1):</span><br><span class="line">            compare_array[i][j] = compare_array[i - 1][j - 1] if str1[i - 1] == str2[j - 1] else min(compare_array[i - 1][j - 1], compare_array[i][j - 1], compare_array[i - 1][j]) + 1</span><br><span class="line">    while i &gt; 0 and j &gt; 0:</span><br><span class="line">        route, i, j = [route, i - 1, j - 1] if str1[i - 1] == str2[j - 1] else ([['将' + str1 + '中' + str(i) + '处的' + str1[i - 1] + '替换为' + str2[j - 1]] + ['\n'] + route, i - 1, j - 1] if compare_array[i - 1][j - 1] + 1 == compare_array[i][j] else([['将' + str1 + '中' + str(i) + '处插入' + str2[j - 1]] + ['\n'] + route, i, j - 1] if compare_array[i][j - 1] + 1 == compare_array[i][j] else [['将' + str1 + '中' + str(i) + '处的' + str1[i - 1] + '删除'] + ['\n'] + route, i - 1, j]))</span><br><span class="line">    print(str1 + '和' + str2 + '的编辑距离是:', compare_array[-1][-1], '\n' + '将' + str1 + '转换为' + str2 + '的操作为:' + '\n' + ''.join(route[:-1]))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/dynamic5.png" alt="5"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  由于动态规划不局限于眼前的最优状态，而是记录了以前的所有状态，因此动态规划具有很强的大局观，可以较为容易地得到全局最优解，因此在实际的生产生活中使用较广。动态规划的关键是分析问题是否具有最优子结构，如果问题具有该性质，说明可以使用动态规划来解决问题。然后是找到其状态转移方程，这也是最难考虑的一个问题。得到了状态转移方程，此问题迎刃而解。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>分治算法(Divide and Conquer)</title>
    <url>/2019/07/21/algorithm%20divide_and_conquer/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">分治算法</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Divide and Conquer:分治算法</strong>，分而治之。山高皇帝远，治理国家，不可能所有的事情都由皇帝解决，国家分省、市、县、镇、村，层层管理，最终汇总合并到皇帝。借鉴于这种思想，将一个规模为n的问题<strong>分解</strong>为k个规模较小的子问题，这些子问题<strong>互相独立</strong>且<strong>与原问题相同</strong>（如果子问题的规模仍然不够小，则再继续划分），然后<strong>递归求解</strong>这些问题，最好用适当的方法将各子问题的解<strong>合并</strong>成原问题的解。<br><a id="more"></a></p>
<p><img src="/images/ALGORITHM/divide.jpg" alt="divide"></p>
<h1 id="解题步骤"><a href="#解题步骤" class="headerlink" title="解题步骤"></a><font size="5" color="red">解题步骤</font></h1><h2 id="分解"><a href="#分解" class="headerlink" title="分解"></a><font size="4">分解</font></h2><p>  <font size="3">将要解决的问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题。</font></p>
<h2 id="治理"><a href="#治理" class="headerlink" title="治理"></a><font size="4">治理</font></h2><p>  <font size="3">求解各个子问题，由于子问题的形式与原问题相同，只是规模较小而已，而当子问题划分得足够小时，就可以用简单得方法解决。</font></p>
<h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a><font size="4">合并</font></h2><p>  <font size="3">按照原问题的要求，将各个子问题的解逐层合并，构成原问题的解。</font></p>
<h1 id="经典例题-合并排序"><a href="#经典例题-合并排序" class="headerlink" title="经典例题(合并排序)"></a><font size="5" color="red">经典例题(合并排序)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  给定一个无序数列，将其排成有序数列。<br>  第一行输出元素的个数n，第二行依次输出数列中的元素(用空格分开)<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">8 # 元素的个数</span><br><span class="line">42 15 20 6 8 38 50 12 # 数列中的元素</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  在数列排序中，数越少越容易排序，基于这个思想，可以考虑将长序列分成短序列，当序列分为只有一个元素时，其本身即为有序。<br>  然后执行合并操作，将两个有序序列合并为一个有序序列也是较为容易的。</p>
<h2 id="归并图解"><a href="#归并图解" class="headerlink" title="归并图解"></a><font size="4">归并图解</font></h2><p><img src="/images/ALGORITHM/divide4.png" alt="4"></p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def merge_sort(list_, begin, end):</span><br><span class="line">    if begin &lt; end:</span><br><span class="line">        merge_sort(list_, begin, (begin + end) // 2)</span><br><span class="line">        merge_sort(list_, (begin + end) // 2 + 1, end)</span><br><span class="line">        merge(list_, begin, (begin + end) // 2, end)</span><br><span class="line"></span><br><span class="line">def merge(list_, begin, mid, end):</span><br><span class="line">    new_list = []</span><br><span class="line">    p_1, p_2 = begin, mid + 1</span><br><span class="line">    while p_1&lt;=mid and p_2 &lt;=end:</span><br><span class="line">        new_list, p_1, p_2 = [new_list + [list_[p_1]], p_1 + 1, p_2 + 0] if list_[p_1] &lt;= list_[p_2] else [new_list + [list_[p_2]], p_1 + 0, p_2 + 1]</span><br><span class="line">    new_list += list_[p_2:end + 1] if p_1 &gt; mid else list_[p_1:mid + 1]</span><br><span class="line">    list_[begin:end + 1] = new_list</span><br><span class="line"></span><br><span class="line">print('请输入数列中元素的个数')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    num_number = int(line.strip().split()[0])</span><br><span class="line">    print('请依次输入数列中的元素，并用空格分开')</span><br><span class="line">    num_list = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    merge_sort(num_list, 0, num_number - 1)</span><br><span class="line">    print('合并排序的结果为:', num_list)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/divide1.png" alt="1"></p>
<h1 id="经典例题-快速排序"><a href="#经典例题-快速排序" class="headerlink" title="经典例题(快速排序)"></a><font size="5" color="red">经典例题(快速排序)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  给定一个无序数列，将其排成有序数列。<br>  第一行输出元素的个数n，第二行依次输出数列中的元素(用空格分开)</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">9 # 元素的个数</span><br><span class="line">30 24 5 58 18 36 12 42 39 # 数列中的元素</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  快速排序的思想和合并排序类似，都是采用分治算法，区别之处在于，合并排序通过先分裂，再合并，合并的同时进行排序。而快速排序是先进行排序，生成两段有序的数列，然后找到分裂点再进行分裂，最后再合并。<br>  如何找到分裂点是快速排序的难点<br>(1)首先取数组的第一个元素作为基准元素base，建立一个头指针和一个尾指针。<br>(2)从左向右进行扫描，如果找到大于base的元素，头指针停留在此处，进入步骤(3)。<br>(3)从右向左进行扫描，如果找到小于等于base的元素，尾指针停留在此处，然后交换头尾指针的值，并且头指针向右移动一个距离，尾指针向左移动一个距离。<br>(4)重复(2)和(3)，直到头指针大于等于尾指针的位置。此时头指针之前的元素都是小于等于基准元素的，头指针之后的元素都是大于基准元素的。<br>  找到分裂点以后，根据分裂点将长数列分解成短数列重复上述方法进行分裂，最终将分裂的结果按顺序合并即可。</p>
<h2 id="快排图解"><a href="#快排图解" class="headerlink" title="快排图解"></a><font size="4">快排图解</font></h2><p><img src="/images/ALGORITHM/divide5.png" alt="5"></p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">def quick_sort(list_, begin, end):</span><br><span class="line">    if begin &lt; end:</span><br><span class="line">        base_element, head, tail = list_[begin], begin, end</span><br><span class="line">        while head &lt; tail:</span><br><span class="line">            while head &lt; tail and list_[head] &lt;= base_element:</span><br><span class="line">                head += 1</span><br><span class="line">            while head &lt; tail and list_[tail] &gt; base_element:</span><br><span class="line">                tail -= 1</span><br><span class="line">            list_[head], list_[tail], head, tail = [list_[tail], list_[head], head + 1, tail - 1] if head &lt; tail else [list_[head], list_[tail], head, tail]</span><br><span class="line">        if list_[head] &lt; list_[begin]:</span><br><span class="line">            list_[head], list_[begin] = list_[begin], list_[head]</span><br><span class="line">            quick_sort(list_, begin, head - 1)</span><br><span class="line">            quick_sort(list_, head + 1, end)</span><br><span class="line">        else:</span><br><span class="line">            list_[head - 1], list_[begin] = list_[begin], list_[head - 1]</span><br><span class="line">            quick_sort(list_, begin, head - 2)</span><br><span class="line">            quick_sort(list_, head, end)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print('请输入要排序的数据个数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    num_number = int(line.strip().split()[0])</span><br><span class="line">    print('请输入要排序的数据，并用空格分开')</span><br><span class="line">    list_number = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">    quick_sort(list_number, 0, num_number - 1)</span><br><span class="line">    print('快速排序的结果为:', list_number)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/divide2.png" alt="2"></p>
<h1 id="经典例题-大数乘法"><a href="#经典例题-大数乘法" class="headerlink" title="经典例题(大数乘法)"></a><font size="5" color="red">经典例题(大数乘法)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  现有两个很大的数据，由于计算机硬件的限制，无法用乘法直接进行求解，如何设计算法求解出正确的结果？<br>  第一行输入乘数a，第二行输入乘数b</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">1122334455667788998877665544332211 #乘数 a</span><br><span class="line">9988776655443322112233445566778899 # 乘数 b</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  由于计算机的硬件限制，无法对大值数据进行操作，因此需要根据运算的法则对数据进行分解。<br>  假设要计算$3278 * 41926$，可以将两个数进行分解，将3278分解为$(32*10^2)+(78*10^0)$，将41926分解为$(419*10^2)+(26*10^0)$，然后根据乘法的运算性质$(a+b)*(c+d)=ac+ad+bc+bd$可得原式为$(32*419*10^4)+(32*26*10^2)+(78*419*10^2)+(78*26*10^0)$。<br>  然后发现上式的第一项$(32*419*10^4)$还可以进行分解，将32分解为$(3*10^1)+(2*10^0)$，将419分解为$(41*10^1)+(9*10^0)$，……，直到分解出的两个数中有一个为一位数则不需要分解，因为一位数的乘法很简单。</p>
<h2 id="乘法图解"><a href="#乘法图解" class="headerlink" title="乘法图解"></a><font size="4">乘法图解</font></h2><p><img src="/images/ALGORITHM/divide6.png" alt="6"></p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">class Number:</span><br><span class="line">    def __init__(self, value = None, length = 0, ten = 0):</span><br><span class="line">        self.value = value</span><br><span class="line">        self.length = length</span><br><span class="line">        self.ten = ten</span><br><span class="line"></span><br><span class="line">def big_add(number_a, number_b, ans):</span><br><span class="line">    number_a, number_b = [number_b, number_a] if number_a.ten &lt; number_b.ten else [number_a, number_b]</span><br><span class="line">    ans.ten, tmp, temp, number_a_len, number_b_len = number_b.ten, 0, number_a.ten - number_b.ten, number_a.length + number_a.ten, number_b.length + number_b.ten</span><br><span class="line">    ans_length = max(number_a_len, number_b_len)</span><br><span class="line">    for i in range(ans_length - ans.ten):</span><br><span class="line">        ta = 0 if i &lt; temp or i &gt;= number_a.length + temp else number_a.value[i - temp]</span><br><span class="line">        tb = number_b.value[i] if i &lt; number_b.length else 0</span><br><span class="line">        ans.value[i], tmp = (ta + tb + tmp) % 10, (ta + tb + tmp) // 10</span><br><span class="line">    ans.length = ans_length - ans.ten</span><br><span class="line">    if tmp &gt; 0:</span><br><span class="line">        ans.value[ans_length - ans.ten], ans.length = [tmp, ans_length - ans.ten + 1]</span><br><span class="line"></span><br><span class="line">def big_mul(number_a, number_b, ans):</span><br><span class="line">    mid_a, mid_b = [number_a.length &gt;&gt; 1, number_b.length &gt;&gt; 1]</span><br><span class="line">    if number_a.length == 1 or number_b.length == 1:</span><br><span class="line">        if number_a.length == 1:</span><br><span class="line">            number_a, number_b = number_b, number_a</span><br><span class="line">        ans.ten, w, tmp = number_a.ten + number_b.ten, number_b.value[0], 0</span><br><span class="line">        for i in range(number_a.length):</span><br><span class="line">            ans.value[i], tmp = (w * number_a.value[i] + tmp) % 10, (w * number_a.value[i] + tmp) // 10</span><br><span class="line">        ans.length = number_a.length</span><br><span class="line">        if tmp &gt; 0:</span><br><span class="line">            ans.value[number_a.length], ans.length = [tmp, number_a.length + 1]</span><br><span class="line">        return</span><br><span class="line">    high_a, low_a, high_b, low_b = [Number(number_a.value[mid_a:], number_a.length - mid_a, number_a.ten + mid_a), Number(number_a.value[:mid_a], mid_a, number_a.ten), Number(number_b.value[mid_b:], number_b.length - mid_b, number_b.ten + mid_b), Number(number_b.value[:mid_b], mid_b, number_b.ten)]</span><br><span class="line">    t_1, t_2, t_3, t_4, tmp_ans = [Number([0] * (high_a.length + high_a.ten + high_b.length + high_b.ten)), Number([0] * (high_a.length + high_a.ten + low_b.length + low_b.ten)), Number([0] * (low_a.length + low_a.ten + high_b.length + high_b.ten)),Number([0] * (low_a.length + low_a.ten + low_b.length + low_b.ten)), Number([0] * (len(ans.value) + ans.ten))]</span><br><span class="line">    big_mul(high_a, high_b, t_1)</span><br><span class="line">    big_mul(high_a, low_b, t_2)</span><br><span class="line">    big_mul(low_a, high_b, t_3)</span><br><span class="line">    big_mul(low_a, low_b, t_4)</span><br><span class="line">    big_add(t_1, t_2, ans)</span><br><span class="line">    big_add(t_3, ans, tmp_ans)</span><br><span class="line">    big_add(t_4, tmp_ans, ans)</span><br><span class="line"></span><br><span class="line">print('输入大整数a:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    number_a = list(line.strip().split()[0])</span><br><span class="line">    print('输入大整数b:')</span><br><span class="line">    number_b = list(sys.stdin.readline().strip().split()[0])</span><br><span class="line">    char, number_a = [-1, number_a[1:]] if number_a[0] == '-' else [1, number_a]</span><br><span class="line">    char, number_b = [char * -1, number_b[1:]] if number_b[0] =='-' else [char, number_b]</span><br><span class="line">    number_a, number_b, ans = Number(list(reversed([int(x) for x in number_a])), len(number_a), 0), Number(list(reversed([int(x) for x in number_b])), len(number_b), 0), Number([0] * (len(number_a) + len(number_b)))</span><br><span class="line">    big_mul(number_a, number_b, ans)</span><br><span class="line">    print(''.join([str(x) for x in ans.value[::-1]]).lstrip('0'))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/divide3.png" alt="3"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  分治算法的难点是如何进行分解，就像盗梦空间的梦境一样，层层深入，却要清醒在每一层应该做什么事情。是应该先分裂再做事情还是先做事情在分裂也是需要考虑的。最重要的一点是梦境不能永远深入，一定要在某一个时机回到现实，即要拥有截止条件，判断是否已经达到需要的深度。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>贪心算法(Greedy)</title>
    <url>/2019/07/19/algorithm%20greedy/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">贪心算法</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>   <strong>Greedy:贪心算法</strong>，又称贪婪算法，人要活在当下，看清楚眼前，这种思想就是贪心思想。是指在对问题求解时，总是做出<strong>当前最好</strong>的选择，不从整体最优上加以考虑。也就是说，它期望通过<strong>局部最优选择</strong>从而得到全局最优的解决方案。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><h2 id="贪心选择"><a href="#贪心选择" class="headerlink" title="贪心选择"></a><font size="4">贪心选择</font></h2><p>  贪心选择指原问题的整体最优解可以通过一系列局部最优的选择得到。应用同一规则，将原问题变为一个相似的但规模更小的子问题，而后的每一步都是当前最佳的选择。这种选择依赖于已做出的选择，但不依赖于未做出的选择。</p>
<h2 id="最优子结构"><a href="#最优子结构" class="headerlink" title="最优子结构"></a><font size="4">最优子结构</font></h2><p>  当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质。问题的最优子结构性质是该问题能否可用贪心算法求解的关键。如原问题$S=\lbrace a_1, a_2, a_3, \ldots, a_n \rbrace$,通过贪心选择出一个当前最优解${a_i}$之后，转化为求解子问题$S- \lbrace a_i \rbrace $，如果原问题的最优解包含子问题的最优解，则说明该问题满足最优子结构性质。</p>
<h1 id="经典例题-背包问题"><a href="#经典例题-背包问题" class="headerlink" title="经典例题(背包问题)"></a><font size="5" color="red">经典例题(背包问题)</font></h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  假设山洞里有n个宝物，每种宝物有一定重量w和相应的价值v，背包的装载能力有限，只能运走重量为m的宝物，宝物可以分割，如何使背包运走物品的价值最大？<br>  第一行先输入宝物的数量n，和背包的承载重量m，然后每一行输出一个宝物对应的重量w和价值v(用空格分开)<br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">6 19 # 宝物数n和背包能装载的重量m</span><br><span class="line">2 8 #每个宝物的重量w和价值v</span><br><span class="line">6 1</span><br><span class="line">7 9</span><br><span class="line">4 3</span><br><span class="line">10 2</span><br><span class="line">3 4</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  对于普通背包问题，宝物可以分割，当前取得的宝物不会受到后面宝物的影响，如果是0-1背包，即物品不可以分割，当前宝物就会受到后面宝物的影响。假设该问题的最优解为S，拿走当前最优解第i个宝物，现在转换成一个新问题，有n-1个宝物，背包重量为$m-w_i$，可以得到最优解为$S- \lbrace a_i \rbrace$。因此可以使用贪心算法。<br>  该问题有三个思考方向<br>(1)选择价值最大的宝物装入背包<br>(2)选择重量最小的宝物装入背包<br>(3)选择单位重量价值最大的宝物装入背包<br>选择价值最大的宝物，如果重量也很大，则不是最优解；选择重量最小的宝物，如果价值也很小，则也不是最优解；因此应该选择单位重量价值最大的宝物。</p>
<h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a><font size="4">流程图</font></h2><p><img src="/images/ALGORITHM/greedy8.png" alt="8"></p>
<h2 id="python代码实战"><a href="#python代码实战" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('请输入宝物数量和驴子承载重量:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    count, weight = line.strip().split()</span><br><span class="line">    count, weight, treasure, price, plan = int(count), float(weight), [], 0, ''</span><br><span class="line">    print('请输入每个宝物的重量和价值')</span><br><span class="line">    for i in range(count):</span><br><span class="line">        tmp = [float(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        treasure.append([i + 1] + tmp + [tmp[1] / tmp[0]])</span><br><span class="line">    treasure.sort(key=lambda x: (-x[3]))</span><br><span class="line">    for i in treasure:</span><br><span class="line">        if weight &gt; i[1]:</span><br><span class="line">            price, weight, plan = price + i[2], weight - i[1], plan + '将第' + str(i[0]) +'个宝物全部装入\n'</span><br><span class="line">        else:</span><br><span class="line">            price, plan = price + weight * i[3], plan + '剩余重量全部装入第' + str(i[0]) + '个宝物\n'</span><br><span class="line">            break</span><br><span class="line">    print('最优的方案为:\n' + plan + '装入的最大价值为:', price)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果"><a href="#代码运行结果" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/greedy1.png" alt="1"></p>
<h1 id="经典例题-最短路径"><a href="#经典例题-最短路径" class="headerlink" title="经典例题(最短路径)"></a><font size="5" color="red">经典例题(最短路径)</font></h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  现有一个景点地图，有n个城市，m条路径(路径是有向的，即来回的距离不同)，假设从某一结点出发，求到其他各个结点的最短路径。<br>  第一行先输入城市数n，第二行输入总路径数m，然后每一行输入A市，B市，以及A到B的距离(用空格分开)，最后输入起始位置和目的地位置。<br><img src="/images/ALGORITHM/greedy4.png" alt="4"><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">5 # 城市数n</span><br><span class="line">8 # 路径数m</span><br><span class="line">1 2 2 #从1号城市到2号城市的距离为2</span><br><span class="line">1 3 5</span><br><span class="line">2 3 2</span><br><span class="line">2 4 6</span><br><span class="line">3 4 7</span><br><span class="line">3 5 1</span><br><span class="line">4 3 2</span><br><span class="line">4 5 4</span><br><span class="line">1 #起始位置</span><br><span class="line">5 #目的地位置</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/ALGORITHM/greedy2.png" alt="2"></p>
<h2 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  最短路径算法是1959年由荷兰图灵奖得主Edsger Wybe Dijkstra(艾兹格·迪科斯彻)提出的，从起始点开始，逐渐增加结点数，依次求出源点到各个定点的最短路径，直到求出目标结点。<br>  首先建立一个数组dist，存放从源点到各点的最短路径，列表S，代表已经包含的结点数，初始值为空。S中的结点，代表从源点到该点的最短路径已确定。列表V,代表没有包含的结点数，初始值为全部结点，然后从这些结点中寻找距离源点最近的结点(贪心算法)。假如找到某一点i，说明从源点通过S，到达i的最短路径为dist[i]，将i加入S，并从V中剔除。更新V中其余的点到源点的最短路径，即检查其余各点是否可以通过i点到达源点。</p>
<h2 id="流程图-1"><a href="#流程图-1" class="headerlink" title="流程图"></a><font size="4">流程图</font></h2><p><img src="/images/ALGORITHM/greedy9.png" alt="9"></p>
<h2 id="python代码实战-1"><a href="#python代码实战-1" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('请输入城市个数:')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    num_city = int(line.strip().split()[0])</span><br><span class="line">    print('请输入路线个数:')</span><br><span class="line">    num_route = int(sys.stdin.readline().strip().split()[0])</span><br><span class="line">    print('请输入城市之间的路线及距离')</span><br><span class="line">    map = [[65535*(i!=j) for i in range(num_city+1)] for j in range(num_city+1)]</span><br><span class="line">    for i in range(num_route):</span><br><span class="line">        begin, end, length = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        map[begin][end] = length</span><br><span class="line">    print('请输入小明所在的位置:')</span><br><span class="line">    begin = int(sys.stdin.readline().strip().split()[0])</span><br><span class="line">    print('请输入终点的位置:')</span><br><span class="line">    end = int(sys.stdin.readline().strip().split()[0])</span><br><span class="line">    dist, route = [0 | x for x in map[begin]], [0 for i in range(num_city+1)]</span><br><span class="line">    un_used = list(range(num_city+1))</span><br><span class="line">    while len(un_used) &gt; 1:</span><br><span class="line">        tmp_loc, tmp_length = [0, 65535]</span><br><span class="line">        for i in un_used[1:]:</span><br><span class="line">            tmp_length, tmp_loc = [dist[i], i] if dist[i] &lt; tmp_length else [tmp_length, tmp_loc]</span><br><span class="line">        if tmp_loc == end or tmp_loc == 0:</span><br><span class="line">            break</span><br><span class="line">        un_used.remove(tmp_loc)</span><br><span class="line">        for j in un_used[1:]:</span><br><span class="line">            dist[j], route[j] = [dist[tmp_loc] + map[tmp_loc][j], tmp_loc] if dist[tmp_loc] + map[tmp_loc][j] &lt; dist[j] else [dist[j], route[j]]</span><br><span class="line">    if route[end] == 0:</span><br><span class="line">        print('目的地不可达')</span><br><span class="line">    else:</span><br><span class="line">        terminal, res = end, str(end)</span><br><span class="line">        while route[terminal] != 0:</span><br><span class="line">            terminal = route[terminal]</span><br><span class="line">            res = str(terminal) + '-&gt;' + res</span><br><span class="line">        print('所走过的路径为:' + str(begin) + '-&gt;' + res + ' 最短距离为:',dist[end])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-1"><a href="#代码运行结果-1" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/greedy3.png" alt="3"></p>
<h1 id="经典例题-最小生成树"><a href="#经典例题-最小生成树" class="headerlink" title="经典例题(最小生成树)"></a><font size="5" color="red">经典例题(最小生成树)</font></h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a><font size="4">问题描述</font></h2><p>  现有一个学校，下面有n个学院，m条路经(路径是无向的，即来回的距离相同)现在设计一条网络布线，将各个学院联通起来，问如何设计可以使费用最少。<br>  第一行先输入结点数n和边数，然后每一行输入A，B，以及A到B的距离(用空格分开)，最后输入起始位置。</p>
<p><img src="/images/ALGORITHM/greedy5.png" alt="5"></p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">7 12 #输入结点数和边数</span><br><span class="line">1 2 23 # 从1号学院到2号学院的距离为23</span><br><span class="line">1 6 28</span><br><span class="line">1 7 36</span><br><span class="line">2 3 20</span><br><span class="line">2 7 1</span><br><span class="line">3 4 15</span><br><span class="line">3 7 4</span><br><span class="line">4 5 3</span><br><span class="line">4 7 9</span><br><span class="line">5 6 17</span><br><span class="line">5 7 16</span><br><span class="line">6 7 25</span><br><span class="line">1 #起始位置</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/ALGORITHM/greedy6.png" alt="6"></p>
<h2 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a><font size="4">算法分析</font></h2><p>  最小生成树算法是1957年由Robert C. Prim(普里姆)提出的，和dijkstra算法类似，从起始点开始，逐渐增加结点数，依次求出每一步的最小生成树，直到包含所有结点。<br>  首先建立一个列表S，代表已经包含的结点数，初始值为空。S中的结点，代表从源点到该点的最短路径已确定。列表V,代表没有包含的结点数，初始值为全部结点。建立一个数组cost，存放从V中结点到S中最近邻点的距离，然后从这些距离中寻找最短的距离(贪心算法)。假如找到某一点i，将i加入S中，说明此时S是最小的生成树，并将i从V中剔除。更新V中其余的结点通过i结点到达S中结点的最近邻的路径。</p>
<h2 id="流程图-2"><a href="#流程图-2" class="headerlink" title="流程图"></a><font size="4">流程图</font></h2><p><img src="/images/ALGORITHM/greedy10.png" alt="10"></p>
<h2 id="python代码实战-2"><a href="#python代码实战-2" class="headerlink" title="python代码实战"></a><font size="4">python代码实战</font></h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print('输入结点数和边数')</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    num_node, num_side = [int(x) for x in line.strip().split()]</span><br><span class="line">    map_node = [[65535*(i!=j) for i in range(num_node + 1)] for j in range(num_node + 1)]</span><br><span class="line">    print('输入结点及之间的边值')</span><br><span class="line">    for i in range(num_side):</span><br><span class="line">        begin, end, weight = [int(x) for x in sys.stdin.readline().strip().split()]</span><br><span class="line">        map_node[begin][end], map_node[end][begin] = weight, weight</span><br><span class="line">    print('请输入起始结点')</span><br><span class="line">    begin_node = int(sys.stdin.readline().strip().split()[0])</span><br><span class="line">    un_used, low_cost, close_node = list(range(num_node + 1)), [0 | x for x in map_node[begin_node]], [0 for i in range(num_node + 1)]</span><br><span class="line">    while len(un_used) &gt; 1:</span><br><span class="line">        tmp_loc, tmp_length = 0, 65535</span><br><span class="line">        for i in un_used[1:]:</span><br><span class="line">            tmp_loc, tmp_length = [i, low_cost[i]] if low_cost[i] &lt; tmp_length else [tmp_loc, tmp_length]</span><br><span class="line">        if tmp_loc == 0:</span><br><span class="line">            break</span><br><span class="line">        un_used.remove(tmp_loc)</span><br><span class="line">        for i in un_used[1:]:</span><br><span class="line">            low_cost[i], close_node[i] = [map_node[tmp_loc][i], tmp_loc] if map_node[tmp_loc][i] &lt; low_cost[i] else [low_cost[i], close_node[i]]</span><br><span class="line">    if len(un_used) &gt; 1:</span><br><span class="line">        print('无法将所有的边连接')</span><br><span class="line">    else:</span><br><span class="line">        for i in range(1,len(close_node)):</span><br><span class="line">            if i == begin_node:</span><br><span class="line">                continue</span><br><span class="line">            print(str(begin_node) + '-&gt;' + str(i)) if close_node[i] == 0 else print(str(close_node[i]) + '-&gt;' + str(i))</span><br><span class="line">        print('最小的花费为:' + str(sum(low_cost[1:])))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="代码运行结果-2"><a href="#代码运行结果-2" class="headerlink" title="代码运行结果"></a><font size="4">代码运行结果</font></h2><p><img src="/images/ALGORITHM/greedy7.png" alt="7"></p>
<h1 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a><font size="5" color="red">算法总结</font></h1><p>  贪心算法相对简单，代码易于实现。但是由于其只关注于当前的最优解，很难得到全局最优解，不符合人类的思维习惯，因此在日常生活中，很少见到贪心算法处理的问题。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>数据结构和算法</category>
        <category>算法部分</category>
      </categories>
  </entry>
  <entry>
    <title>MLP(Multi-Layer Perceptron)</title>
    <url>/2019/07/12/classfication%20MLP/</url>
    <content><![CDATA[<p><img src="/images/MACHINE/mlp.png" alt="mlp"></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  <strong>MLP(Multi-Layer Perceptron)</strong>:多层感知机<strong>本质上是一种全连接的深度神经网络(DNN)</strong>，感知机只有一层功能神经元进行学习和训练，其能力非常有限，难以解决非线性可分的问题。为了解决这个问题，需要考虑使用多层神经元进行学习。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><h2 id="反向传播-BP-BackPropagation"><a href="#反向传播-BP-BackPropagation" class="headerlink" title="反向传播(BP, BackPropagation)"></a>反向传播(BP, BackPropagation)</h2><p>神经网络的学习过程可真是太牛B了，人类的学习过程是，从小学到大学，学习知识以后，都需要考试，然后根据得分修正以往的错误部分。BP的思想也是一样，一开始神经网络什么都不知道，给予网络随机的权重，然后进行学习，每次得到一个结果，我们将其与标准结果进行对比(这类似于考试成绩与标准答案进行对比)。然后根据差异寻找问题的根源。</p>
<p>BP算法基于梯度下降策略，以目标的负梯度方向对参数进行调整。<br>下面我举一个简单的例子，小伙伴们就可以清晰的知道BP的原理。<br>假设有N个样本，样本的特征数为F，因此输入矩阵的大小为[F, N]，只有一个隐藏层，且神经元的个数为F1，因此w1的大小为[F1, F]，b1的大小为[F, 1]，经过计算后z1的大小为[F1, N]，激活函数为ReLu，第一层的输出a1的大小为[F1, N]，对于一个二分类问题，输出神经元的个数为1，因此w2的大小为[1, F1]，b2的大小为[1, 1]，经过计算后z2的大小为[1, N]，激活函数为Sigmoid，第二层的输出$\hat{y}$的大小为[1, N]。</p>
<p>我们使用以下记号表示前向计算过程</p>
<script type="math/tex; mode=display">z1 = w1 \cdot x + b1</script><script type="math/tex; mode=display">a1 = ReLu(z1)</script><script type="math/tex; mode=display">z2 = w2 \cdot a1 + b2</script><script type="math/tex; mode=display">\hat{y} = Sigmoid(z2)</script><script type="math/tex; mode=display">J(\hat{y}, y) = -[y \cdot log(\hat{y}) + (1 - y) \cdot log(1 - \hat{y})]</script><p>下面推导误差反向传播过程，我们只要计算出各个参数的梯度即可</p>
<script type="math/tex; mode=display">\begin{align} \frac{\partial J}{\partial \hat{y}} & = -(\frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}) \\ \frac{\partial J}{\partial z2} & = \frac{\partial J}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z2} \\ & = -(\frac{y}{\hat{y}} \hat{y}(1 - \hat{y}) - \frac{1 - y}{1 - \hat{y}} \hat{y}(1 - \hat{y})) \\ & = \hat{y} - y \\ \frac{\partial J}{\partial w2} & = \frac{\partial J}{\partial z2} \cdot \frac{\partial z2}{\partial w2} \\ & = \frac{\partial J}{\partial z2} \cdot a2^T \\ \frac{\partial J}{\partial b2} & = \frac{\partial J}{\partial z2} \cdot \frac{\partial z2}{\partial b2} \\ & = \frac{1}{N}\sum_{1}^{N}\frac{\partial J}{\partial z2} \\ \frac{\partial J}{\partial a1} & = \frac{\partial J}{\partial z2} \cdot \frac{\partial z2}{\partial a1} \\ & = w2^T \cdot \frac{\partial J}{\partial z2} \\ \frac{\partial J}{\partial z1} & = \frac{\partial J}{\partial a1} \cdot \frac{\partial a1}{\partial z1} \\ & = \frac{\partial J}{\partial a1} * dReLu(z1) \\ \frac{\partial J}{\partial w1} & = \frac{\partial J}{\partial z1} \cdot \frac{\partial z1}{\partial w1} \\ & = \frac{\partial J}{\partial z1} \cdot a1^T \\ \frac{\partial J}{\partial b1} & = \frac{\partial J}{\partial z1} \cdot \frac{\partial z1}{\partial b1} \\ & = \frac{1}{N}\sum_{1}^{N}\frac{\partial J}{\partial z1} \end{align}</script><h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="mlp-train-m"><a href="#mlp-train-m" class="headerlink" title="mlp_train.m"></a>mlp_train.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;</span><br><span class="line">%激活函数</span><br><span class="line">f_leaky_relu=@(x)max(0.01*x,x);</span><br><span class="line">f_sigmod=@(x)1./(1+exp(-x));</span><br><span class="line">df_leaky_relu=@(x)max(0.01*x,x)./x;</span><br><span class="line">%学习率</span><br><span class="line">learn_rate=0.01;</span><br><span class="line">%输入x的矩阵</span><br><span class="line">train_x=[0.6,0.1,0.1,0.4,0.8,0.5,0.9,0.1,0.5,0.9,0.5,0.4,0.5,0.6;...</span><br><span class="line">    0.4,0.1,0.8,0.6,0.1,0.6,0.9,0.5,0.1,0.5,0.9,0.4,0.4,0.6];</span><br><span class="line">%  x=[0.8,0.1,0.4;...</span><br><span class="line">%      0.6,0.1,0.8];</span><br><span class="line">%输入y的矩阵,y为行向量</span><br><span class="line">train_y=[1,0,0,1,0,1,0,0,0,0,0,1,1,1];</span><br><span class="line">% y=[1,0,1];</span><br><span class="line">%样本数</span><br><span class="line">train_num=length(train_y);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(train_x,1);</span><br><span class="line">%各层的节点数</span><br><span class="line">node=[200,1];</span><br><span class="line">%网络层数</span><br><span class="line">network_num=length(node);</span><br><span class="line">%w的矩阵大小,wi,i+1=A 维度为node(i)*node(i-1)</span><br><span class="line">max_col=max([feat_num,node(1:end-1)]);</span><br><span class="line">max_row=max(node);</span><br><span class="line">w(:,:,:)=zeros(max_row,max_col,network_num);</span><br><span class="line">for i=1:network_num</span><br><span class="line">    if i==1</span><br><span class="line">        w(1:node(i),1:feat_num,i)=rand(node(i),feat_num)*0.1;</span><br><span class="line">    else</span><br><span class="line">        w(1:node(i),1:node(i-1),i)=rand(node(i),node(i-1))*0.1;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">dw(:,:,:)=zeros(max_row,max_col,network_num);</span><br><span class="line">%b的矩阵大小，bi,i+1=A 维度为node(i)*1</span><br><span class="line">b(:,:,:)=zeros(max_row,1,network_num);</span><br><span class="line">db(:,:,:)=zeros(max_row,1,network_num);</span><br><span class="line">%z的矩阵大小,zi,i+1=A 维度为node(i)*sample_num</span><br><span class="line">z(max_row,train_num,network_num)=0;</span><br><span class="line">dz(max_row,train_num,network_num)=0;</span><br><span class="line">%a的矩阵大小,ai,i+1=A 维度为node(i)*sample_num</span><br><span class="line">a(max_row,train_num,network_num)=0;</span><br><span class="line">fprintf('开始训练...\n\n');</span><br><span class="line">for times=1:5000</span><br><span class="line">    %% %forward propagation</span><br><span class="line">    for i=1:network_num</span><br><span class="line">        b_broadcast=zeros(node(i),train_num);</span><br><span class="line">        for j=1:train_num</span><br><span class="line">            b_broadcast(:,j)=b(1:node(i),1,i);</span><br><span class="line">        end</span><br><span class="line">        if i==1</span><br><span class="line">            %z1=w[1]x+b[1]</span><br><span class="line">            z(1:node(i),1:train_num,i)=w(1:node(i),1:feat_num,i)*train_x+b_broadcast;</span><br><span class="line">        else</span><br><span class="line">            %z[n]=w[n]a[n-1]+b[n]</span><br><span class="line">            z(1:node(i),1:train_num,i)=w(1:node(i),1:node(i-1),i)*a(1:node(i-1),1:train_num,i-1)+b_broadcast;</span><br><span class="line">        end</span><br><span class="line">        if i==network_num</span><br><span class="line">            %a[network_num]=sigmod(z[network_num])</span><br><span class="line">            a(1:node(i),1:train_num,i)=f_sigmod(z(1:node(i),1:train_num,i));</span><br><span class="line">        else</span><br><span class="line">            %a[n]=leaky_relu(z[n])</span><br><span class="line">            a(1:node(i),1:train_num,i)=f_leaky_relu(z(1:node(i),1:train_num,i));</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    </span><br><span class="line">    %% %error</span><br><span class="line">    e=0;</span><br><span class="line">    for k=1:train_num</span><br><span class="line">        %损失函数e=-1/m∑(ylog(y_hat)+(1-y)log(1-y_hat))</span><br><span class="line">        e=e-(train_y(k)*log(a(1,k,network_num))+(1-train_y(k))*log(1-a(1,k,network_num)));</span><br><span class="line">    end</span><br><span class="line">    e=e/train_num;</span><br><span class="line">    </span><br><span class="line">    %% %back propagation</span><br><span class="line">    for i=network_num:-1:1</span><br><span class="line">        if i==network_num</span><br><span class="line">            %dz[network_num]=y_hat-y</span><br><span class="line">            dz(1:node(i),1:train_num,i)=a(1,:,network_num)-train_y;</span><br><span class="line">        else</span><br><span class="line">            %dz[n]=w[n+1]'dz[n+1].*df_leaky_relu(z[n])</span><br><span class="line">            dz(1:node(i),1:train_num,i)=w(1:node(i+1),1:node(i),i+1)'*dz(1:node(i+1),1:train_num,i+1).*df_leaky_relu(z(1:node(i),1:train_num,i));</span><br><span class="line">        end</span><br><span class="line">        if i==1</span><br><span class="line">            %dw[1]=dz[1]*x'</span><br><span class="line">            dw(1:node(i),1:feat_num,i)=dz(1:node(i),1:train_num,i)*train_x';</span><br><span class="line">        else</span><br><span class="line">            %dw[n]=dz[n]*a[n-1]'</span><br><span class="line">            dw(1:node(i),1:node(i-1),i)=dz(1:node(i),1:train_num,i)*a(1:node(i-1),1:train_num,i-1)';</span><br><span class="line">        end</span><br><span class="line">        db(1:node(i),1,i)=sum(dz(1:node(i),1:train_num,i),2)/train_num;</span><br><span class="line">    end</span><br><span class="line">    </span><br><span class="line">    %% %weight</span><br><span class="line">    %利用梯度下降法更新权值</span><br><span class="line">    for i=1:network_num</span><br><span class="line">        if i==1</span><br><span class="line">            w(1:node(i),1:feat_num,i)=w(1:node(i),1:feat_num,i)-learn_rate*dw(1:node(i),1:feat_num,i);</span><br><span class="line">        else</span><br><span class="line">            w(1:node(i),1:node(i-1),i)=w(1:node(i),1:node(i-1),i)-learn_rate*dw(1:node(i),1:node(i-1),i);</span><br><span class="line">        end</span><br><span class="line">        b(1:node(i),1,i)=b(1:node(i),1,i)-learn_rate*db(1:node(i),1,i);</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%% %判断训练是否完成</span><br><span class="line">if e&gt;0.01</span><br><span class="line">    disp('请调整参数重新训练');</span><br><span class="line">else</span><br><span class="line">    disp('训练完成,运行bp_test开始测试');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="mlp-test-m"><a href="#mlp-test-m" class="headerlink" title="mlp_test.m"></a>mlp_test.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clc;close all;</span><br><span class="line">%输入测试集</span><br><span class="line">test_x=rand(2,500);</span><br><span class="line">%测试集样本数</span><br><span class="line">test_num=size(test_x,2);</span><br><span class="line">%z的矩阵大小,zi,i+1=A node(i)*sample_num,eg z1,2=A3*50</span><br><span class="line">test_z(max_row,test_num,network_num)=0;</span><br><span class="line">%a的矩阵大小,ai,i+1=A node(i)*sample_num,eg a1,2=A3*50</span><br><span class="line">test_a(max_row,test_num,network_num)=0;</span><br><span class="line"></span><br><span class="line">for i=1:network_num</span><br><span class="line">    b_broadcast=zeros(node(i),test_num);</span><br><span class="line">    for j=1:test_num</span><br><span class="line">        b_broadcast(:,j)=b(1:node(i),1,i);</span><br><span class="line">    end</span><br><span class="line">    if i==1</span><br><span class="line">        %z1=w[1]x+b[1]</span><br><span class="line">        test_z(1:node(i),1:test_num,i)=w(1:node(i),1:feat_num,i)*test_x+b_broadcast;</span><br><span class="line">    else</span><br><span class="line">        %z[n]=w[n]a[n-1]+b[n]</span><br><span class="line">        test_z(1:node(i),1:test_num,i)=w(1:node(i),1:node(i-1),i)*test_a(1:node(i-1),1:test_num,i-1)+b_broadcast;</span><br><span class="line">    end</span><br><span class="line">    if i==network_num</span><br><span class="line">        %a[network_num]=sigmod(z[network_num])</span><br><span class="line">        test_a(1:node(i),1:test_num,i)=f_sigmod(test_z(1:node(i),1:test_num,i));</span><br><span class="line">    else</span><br><span class="line">        %a[n]=leaky_relu(z[n])</span><br><span class="line">        test_a(1:node(i),1:test_num,i)=f_leaky_relu(test_z(1:node(i),1:test_num,i));</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%test_y为BP的输出</span><br><span class="line">test_y=test_a(1,:,network_num);</span><br><span class="line">%小于0.5则为第一类，大于0.5则为第二类,否则拒绝判决</span><br><span class="line">for i=1:test_num</span><br><span class="line">    if test_y(i)&gt;0.5</span><br><span class="line">        fprintf('第%d个是第二类，概率为:%f\n',i,test_y(i));</span><br><span class="line">    elseif test_y(i)&lt;0.5</span><br><span class="line">        fprintf('第%d个是第一类，概率为:%f\n',i,1-test_y(i));</span><br><span class="line">    else</span><br><span class="line">        fprintf('拒绝判决\n');</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    hold on;</span><br><span class="line">    %画出训练集，用*表示</span><br><span class="line">    for i=1:train_num</span><br><span class="line">        if train_y(i)==1</span><br><span class="line">            plot(train_x(1,i),train_x(2,i),'r*')</span><br><span class="line">        else</span><br><span class="line">            plot(train_x(1,i),train_x(2,i),'b*')</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    %画出测试集，用o表示</span><br><span class="line">    for i=1:test_num</span><br><span class="line">        if test_y(i)&gt;0.5</span><br><span class="line">            plot(test_x(1,i),test_x(2,i),'ro')</span><br><span class="line">        elseif test_y(i)&lt;0.5</span><br><span class="line">            plot(test_x(1,i),test_x(2,i),'bo')</span><br><span class="line">        else</span><br><span class="line">            plot(test_x(1,i),test_x(2,i),'go')</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    hold off;</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional ')</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/mlp1.png" alt="mlp"></p>
<h1 id="MLP-Multi-Layer-Perceptron-优缺点"><a href="#MLP-Multi-Layer-Perceptron-优缺点" class="headerlink" title="MLP(Multi-Layer Perceptron)优缺点"></a><font size="5" color="red">MLP(Multi-Layer Perceptron)优缺点</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>可以实现多分类任务。</li>
<li>参数量和迭代次数满足条件时，可以拟合线性不可分任务。</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>计算量较大，训练时间较长。</li>
<li>算法可能陷入局部最优解，导致训练失败。</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>有监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>逻辑回归(Logistics Regression)</title>
    <url>/2019/07/02/classification%20LR/</url>
    <content><![CDATA[<p><img src="/images/MACHINE/lr.jpg" alt="lr"></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  逻辑回归(Logistics Regression):是一种<strong>广义线性回归</strong>，都具有 w’x+b，其中w和b是待求参数，其区别在于他们的<strong>因变量不同</strong>，多重线性回归直接将w’x+b作为因变量，即y =w’x+b，而logistic回归则通过函数g将w’x+b对应一个隐状态p，p =g(w’x+b),然后<strong>根据p 与1-p的大小决定因变量的值</strong>。如果g是logistic函数，就是logistic回归。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><h2 id="预测函数"><a href="#预测函数" class="headerlink" title="预测函数"></a><font size="4">预测函数</font></h2><p>对于二分类问题，$y \in \lbrace 0,1 \rbrace$，1表示正例，0表示负例。逻辑回归是在线性函数$W^Tx$输出预测实际值的基础上，寻找一个假设函数函数$h_W(x)=g(W^Tx)$，将实际值映射到到0，1之间，如果</p>
<script type="math/tex; mode=display">y =\begin{cases} 1 & h_W(x) \ge 0.5 \\ 0 & h_W(x) <0.5 \end{cases}</script><p><strong>逻辑回归中选择对数几率函数(logistic function)</strong></p>
<script type="math/tex; mode=display">g(z)=\frac{1}{1+e^(-z)}</script><p><img src="/images/MACHINE/lr1.png" alt="sigmod"><br><strong>有一个非常重要的性质，可以方便我们的计算</strong>。</p>
<script type="math/tex; mode=display">g(z)'=g(z) \cdot (1 - g(z))</script><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><font size="4">损失函数</font></h2><p>我们假设</p>
<script type="math/tex; mode=display">\begin{cases}P(Y=1|X) = p(x) \\ P(Y=0|X) = 1 - p(x) \end{cases}</script><p>根据<strong>极大似然估计</strong>可知</p>
<script type="math/tex; mode=display">\hat{w} = \underset{w}{argmax} \ L(w) = \underset{w}{argmax} \prod_{i = 1}^{N} [p(x_i)]^{y_i} \cdot [1 - p(x_i)]^{1 - y_i}</script><p><strong>两边同时取对数，计算对数似然函数</strong>。</p>
<script type="math/tex; mode=display">\hat{w} = \underset{w}{argmax} \ ln(L(w)) = \underset{w}{argmax} \sum_{i = 1}^{N} [y_i \cdot ln(p(x_i)) + (1 - y_i) \cdot ln(1 - p(x_i))]</script><p><strong>因为我们在计算时常常求最小值，因此我们设计损失函数</strong>，令$J(w) = -\frac{1}{N} ln(L(w))$</p>
<script type="math/tex; mode=display">\hat{w} = \underset{w}{argmin} \ J(w)=-\frac{1}{N} \underset{w}{argmax} \ ln(L(w))</script><script type="math/tex; mode=display">\hat{w} = -\underset{w}{argmin} \frac{1}{N} \sum_{i = 1}^{N} [y_i \cdot ln(p(x_i)) + (1 - y_i) \cdot ln(1 - p(x_i))]</script><p>下面转化为求$\underset{w}{argmin} \ J(w)$，<strong>使用常见的梯度下降法进行求解</strong>。</p>
<script type="math/tex; mode=display">g_i = \frac{\partial J(w)}{\partial w_i} = (p(x_i) - y_i) \cdot x_i</script><script type="math/tex; mode=display">w_i^{k + 1} = w_i^k - \alpha \cdot g_i</script><h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="LR-train-m"><a href="#LR-train-m" class="headerlink" title="LR_train.m"></a>LR_train.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;</span><br><span class="line">f_sigmod=@(x)1./(1+exp(-x));</span><br><span class="line">%x为样本，行数代表特征数，列数代表样本数,以列向量的形式输出，label为样本所对应的类别</span><br><span class="line">train_x=[0.5,0.5,0.8,0.2,0.1;...</span><br><span class="line">    0.8,0.7,0.6,0.2,0.4];</span><br><span class="line">%1为第一类，2为第二类</span><br><span class="line">train_y=[1,1,1,0,0];</span><br><span class="line">%特征数</span><br><span class="line">feat_num=size(train_x,1);</span><br><span class="line">%样本数</span><br><span class="line">train_num=size(train_x,2);</span><br><span class="line">%设置最大迭代次数</span><br><span class="line">times=10000;</span><br><span class="line">%学习率</span><br><span class="line">a=0.1;</span><br><span class="line">%权向量</span><br><span class="line">w=rand(1,feat_num+1);</span><br><span class="line">%增广矩阵</span><br><span class="line">x_expend=[train_x;ones(1,train_num)];</span><br><span class="line">for i=1:times</span><br><span class="line">    tem=w;</span><br><span class="line">    %w=w-a/m*Σ(sigmod(wx)-y)x</span><br><span class="line">    w=w-a/train_num*sum(repmat((f_sigmod(w*x_expend)-train_y),feat_num+1,1).*x_expend,2)';</span><br><span class="line">    if sum(abs(w-tem))&lt;5e-3</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">disp(i)</span><br><span class="line">if i&gt;=times</span><br><span class="line">    disp('The question is not Linearly Separable');</span><br><span class="line">%否则线性可分，写出函数表达式</span><br><span class="line">else</span><br><span class="line">    express=[];</span><br><span class="line">    %输出表达式</span><br><span class="line">    for i=1:feat_num</span><br><span class="line">        if w(i)&gt;0</span><br><span class="line">            express=[express,num2str(w(i)),'x',num2str(i),'+'];</span><br><span class="line">        elseif w(i)&lt;0</span><br><span class="line">            express=[express(1:end-1),num2str(w(i)),'x',num2str(i),'+'];</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    if w(feat_num+1)==0</span><br><span class="line">        express=[express(1:end-1),'=0'];</span><br><span class="line">    elseif w(feat_num+1)&gt;0</span><br><span class="line">        express=[express(1:end),num2str(w(feat_num+1)),'=0'];</span><br><span class="line">    else</span><br><span class="line">        express=[express(1:end-1),num2str(w(feat_num+1)),'=0'];</span><br><span class="line">    end</span><br><span class="line">    fprintf(['决策面函数为:',express,'\n\n']);</span><br><span class="line">    disp('运行LR_test开始测试');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="LR-test-m"><a href="#LR-test-m" class="headerlink" title="LR_test.m"></a>LR_test.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">close all;</span><br><span class="line">%输入测试集</span><br><span class="line">test_x=rand(2,10);</span><br><span class="line">%测试集样本数</span><br><span class="line">test_num=size(test_x,2);</span><br><span class="line">%如果误差不能满足条件，此为线性不可分问题</span><br><span class="line">if i&gt;=times</span><br><span class="line">    disp('The question is not Linearly Separable');</span><br><span class="line">%如果满足条件可以找到一个超平面</span><br><span class="line">else</span><br><span class="line">    %如果是二维特征，可以用平面坐标系绘图表示</span><br><span class="line">    if feat_num==2</span><br><span class="line">        hold on;</span><br><span class="line">        axis([0,1,0,1])</span><br><span class="line">        if w(1)==0</span><br><span class="line">            line_x=[0,1];</span><br><span class="line">            line_y=[-w(3)/w(2),-w(3)/w(2)];</span><br><span class="line">        elseif w(2)==0</span><br><span class="line">            line_x=[-w(3)/w(1),-w(3)/w(1)];</span><br><span class="line">            line_y=[0,1];</span><br><span class="line">        else</span><br><span class="line">            line_x=[0,1];</span><br><span class="line">            line_y=[-w(3)/w(2),(-w(3)-w(1))/w(2)];</span><br><span class="line">        end</span><br><span class="line">        %用黑色绘制分界线</span><br><span class="line">        plot(line_x,line_y,'k');</span><br><span class="line">        %绘制测试集样本点</span><br><span class="line">        test_y=w*[test_x;ones(1,test_num)];</span><br><span class="line">        for i=1:test_num</span><br><span class="line">            %如果大于0，则归为一类，用红色的圈表示</span><br><span class="line">            if test_y(i)&gt;0</span><br><span class="line">                plot(test_x(1,i),test_x(2,i),'ro');</span><br><span class="line">            %如果小于0，则归为一类，用蓝色的圈表示</span><br><span class="line">            elseif test_y(i)&lt;0</span><br><span class="line">                plot(test_x(1,i),test_x(2,i),'bo');</span><br><span class="line">            %否则用绿色的圈表示</span><br><span class="line">            else</span><br><span class="line">                plot(test_x(1,i),test_x(2,i),'go');</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        %说明1类对应红色，2类对应蓝色</span><br><span class="line">        if (train_x(1,1)*w(1)+train_x(2,1)*w(2)+w(3)&gt;=0&amp;&amp;train_y(1)==1)||(train_x(1,i)*w(1)+train_x(2,i)*w(2)+w(3)&lt;0&amp;&amp;train_y(1)==0)</span><br><span class="line">            %绘制训练集样本点</span><br><span class="line">            for i=1:train_num</span><br><span class="line">                %如果大于0，则归为一类，用红色的*表示</span><br><span class="line">                if train_y(i)==1</span><br><span class="line">                    plot(train_x(1,i),train_x(2,i),'r*')</span><br><span class="line">                %如果小于0，则归为一类，用蓝色的*表示</span><br><span class="line">                else</span><br><span class="line">                    plot(train_x(1,i),train_x(2,i),'b*')</span><br><span class="line">                end</span><br><span class="line">            end</span><br><span class="line">        %说明1类对应蓝色，2类对应红色</span><br><span class="line">        else</span><br><span class="line">            for i=1:train_num</span><br><span class="line">                %如果大于0，则归为一类，用红色的*表示</span><br><span class="line">                if train_y(i)==1</span><br><span class="line">                    plot(train_x(1,i),train_x(2,i),'b*')</span><br><span class="line">                %如果小于0，则归为一类，用蓝色的*表示</span><br><span class="line">                else</span><br><span class="line">                    plot(train_x(1,i),train_x(2,i),'r*')</span><br><span class="line">                end</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        hold off</span><br><span class="line">    %如果不是两个特征不能用平面坐标系表示</span><br><span class="line">    else</span><br><span class="line">        disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/lr2.png" alt="LR"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>适合于大多数线性分类的任务</li>
<li>鲁棒性较好，能够抵挡轻微噪声的影响</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>容易欠拟合</li>
<li>在多分类任务或者非线性任务上难以使用</li>
<li>特征空间较大或者特征缺失情况下表现较差</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>有监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>朴素贝叶斯</title>
    <url>/2019/06/28/classfication%20Bayes/</url>
    <content><![CDATA[<p><img src="/images/MACHINE/bayes.png" alt="bayes"></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  <strong>朴素贝叶斯</strong>:基于<strong>贝叶斯定理</strong>，采用了<strong>属性条件独立性假设</strong>，对已知类别，假设所有属性相互独立，也就是假设每个属性独立地对分类结果发生影响。发源于古典数学理论，而且所需估计的参数很少，算法也较为简单，但是<strong>正是因为其假设属性之间相互独立，因此在实际应用中往往是不成立的，所以给模型的正确性带来了一定的影响</strong>。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><script type="math/tex; mode=display">P(c|x) = \frac{P(c)P(x|c)}{P(x)}</script><p>介绍一些非常重要的概念，<strong>$P(c)$称为先验概率</strong>，<strong>$P(x|c)$是样本x相对于类标记c的类条件概率</strong>，<strong>$P(x)$是用于归一化的因子</strong>，给定样本x，归一化因子$P(x)$与类标记无关。因此<strong>估计$P(c|x)$就转化为如何基于训练数据集来估计先验$P(c)$和类条件概率$P(x|c)$</strong>。</p>
<h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>朴素贝叶斯模型的训练过程就是一个参数估计的过程，对于这个问题，机器学习分成了两派，频率派和贝叶斯派。<br><strong>频率派认为：参数虽然未知，但是却存在着固定值，可以通过优化似然函数等准则确定参数值</strong>。<br><strong>贝叶斯派认为：参数是未观察到的随机变量，其本身也有分布，因此可以假设参数服从一个先验分布，然后基于观测到的数据计算参数的后验分布</strong>。</p>
<p><strong>极大似然估计(MLE, Maximum Likelihood Estimation)是根据数据采样来估计概率分布的经典方法</strong>。令$D_c$表示训练集D中第c类样本组成的集合，假设这些样本是独立同分布的，则参数$\theta_c$对于数据集$D_c$的似然是</p>
<script type="math/tex; mode=display">P(D_c|\theta_c) = \prod_{x \in D_c} P(x|\theta_c)</script><p><strong>对$\theta_c$进行极大似然估计，就是去寻找能最大化似然$P(D_c|\theta_c)$的参数值$\hat{\theta}_c$。通常为了计算方便，使用对数似然</strong>。</p>
<script type="math/tex; mode=display">\begin{align} LL(\theta_c) & = log(P(D_c|\theta_c)) \\ & = \sum_{x \in D_c} log(P(x|\theta_c)) \end{align}</script><p>此时参数$\theta_c$的极大似然估计$\hat{\theta}_c$为</p>
<script type="math/tex; mode=display">\hat{\theta}_c = \underset{\theta_c}{argmax} \ LL(\theta_c)</script><p>在连续属性情形下，假设概率密度函数$p(x|c) ~ N(\mu_c, \sigma_c^2)$，则参数$\mu_c$和$\sigma_c^2$的极大似然估计为</p>
<script type="math/tex; mode=display">\hat{\mu}_c = \frac{1}{|D_c|}\sum_{x \in D_c}x</script><script type="math/tex; mode=display">\hat{\sigma}_c^2 = \frac{1}{|D_c|}\sum_{x \in D_c}(x - \hat{\mu}_c)(x - \hat{\mu}_c)^T</script><h2 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h2><p>基于条件独立性假设，因此贝叶斯定理可以重写为</p>
<script type="math/tex; mode=display">\begin{align} P(c|x) & = \frac{P(c)P(x|c)}{P(x)} \\ & = \frac{P(c)}{P(x)}\prod_{i = 1}^{d}P(x_i|c) \end{align}</script><p>因为对所有类别来说，$P(x)$相同，可以看出朴素贝叶斯分类器的训练过程就是基于训练集D来估计先验概率$P(c)$和类条件概率$P(x_i|c)$。</p>
<p>令$D_c$表示训练集D中第c类样本组成的集合，则<strong>先验概率为</strong></p>
<script type="math/tex; mode=display">P(c) = \frac{|D_c|}{D}</script><p>令$D_{c, x_i}$表示$D_c$中第i个属性取值为$x_i$的样本组成的集合，则<strong>离散属性类条件概率为</strong></p>
<script type="math/tex; mode=display">P(x_i|c) = \frac{|D_{c, x_i}|}{|D_c|}</script><p>对于连续属性的类条件概率求解时，假定$P(x<em>i|c) ~ N(\mu</em>{c, i}, \sigma_{c, i}^2)$，则<strong>连续属性类条件概率为</strong></p>
<script type="math/tex; mode=display">P(x_i|c) = \frac{1}{\sqrt{2 \pi}\sigma_{c, i}}exp(-\frac{(x - \mu_{c, i})^2}{2 \sigma_{c, i}^2})</script><p>计算好上面这两个参数后，直接代入公式</p>
<script type="math/tex; mode=display">\hat{c} = \underset{c \in \gamma}{argmax} \ P(c) \prod_{i = 1}^{d}P(x_i|c)</script><p>其中$\gamma$为所有类别数，<strong>对每一个类别都进行计算，哪一个类别得到的值最大，则将样本分到哪一个类别中去即可</strong>。</p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="BAYES-train-m"><a href="#BAYES-train-m" class="headerlink" title="BAYES_train.m"></a>BAYES_train.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;</span><br><span class="line">%x为样本，行数代表特征数，列数代表样本数,以列向量的形式输出</span><br><span class="line">train_x=[0.8,0.9,0.1,0.2,0.1,0.2;...</span><br><span class="line">    0.8,0.9,0.9,0.2,0.1,0.8];</span><br><span class="line">%1为第一类，2为第二类，3为第三类</span><br><span class="line">train_y=[1,1,3,2,2,3];</span><br><span class="line">%特征数</span><br><span class="line">feat_num=size(train_x,1);</span><br><span class="line">%样本数</span><br><span class="line">train_num=size(train_x,2);</span><br><span class="line">tem=tabulate(train_y);</span><br><span class="line">%p_y为先验概率</span><br><span class="line">p_y=tem(:,3)/100;</span><br><span class="line">u_sigma=zeros(feat_num,2,length(p_y));</span><br><span class="line">for i=1:length(p_y)</span><br><span class="line">   for j=1:feat_num</span><br><span class="line">       %u_sigma(j,:,i)代表第i类，第j个特征的均值和方差</span><br><span class="line">       u_sigma(j,:,i)=[mean(train_x(j,train_y==i)),std(train_x(j,train_y==i))];</span><br><span class="line">   end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="BAYES-test-m"><a href="#BAYES-test-m" class="headerlink" title="BAYES_test.m"></a>BAYES_test.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">close all;</span><br><span class="line">%输入测试集</span><br><span class="line">test_x=rand(2,100);</span><br><span class="line">%测试集样本数</span><br><span class="line">test_num=size(test_x,2);</span><br><span class="line">%temp保存类条件概率</span><br><span class="line">temp=zeros(feat_num,size(u_sigma,3));</span><br><span class="line">test_y=zeros(1,test_num);</span><br><span class="line">for i=1:test_num</span><br><span class="line">    for j=1:feat_num</span><br><span class="line">        for k=1:size(u_sigma,3)</span><br><span class="line">            %第j行第k列代表第i个样本第k类第j个特征的概率，即类条件概率P(x_j|y=k)</span><br><span class="line">            temp(j,k)=normpdf(test_x(j,i),u_sigma(j,1,k),u_sigma(j,2,k));</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    %根据条件独立性假设，将类条件概率相乘得到后验概率</span><br><span class="line">    p=prod(temp);</span><br><span class="line">    %求出最大后验概率的类别</span><br><span class="line">    [~,test_y(i)]=max(p);</span><br><span class="line">end</span><br><span class="line">if feat_num==2</span><br><span class="line">    hold on;</span><br><span class="line">    color_bar=rand(size(u_sigma,3),3);</span><br><span class="line">    for i=1:train_num</span><br><span class="line">        plot(train_x(1,i),train_x(2,i),'color',color_bar(train_y(i),:),'marker','*');</span><br><span class="line">    end</span><br><span class="line">    for i=1:test_num</span><br><span class="line">        plot(test_x(1,i),test_x(2,i),'color',color_bar(test_y(i),:),'marker','o');</span><br><span class="line">    end</span><br><span class="line">    hold off;</span><br><span class="line">    %如果不是两个特征不能用平面坐标系表示</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/bayes1.png" alt="bayes"></p>
<h1 id="朴素贝叶斯优缺点"><a href="#朴素贝叶斯优缺点" class="headerlink" title="朴素贝叶斯优缺点"></a><font size="5" color="red">朴素贝叶斯优缺点</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，易于理解和实现，且模型无需训练。</li>
<li>计算量小，能够达到实时的效率。</li>
<li>同样适合于对于多分类问题。</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>因为假设各属性独立，因此实际生活中可能出现问题。</li>
<li>样本不平衡时，尤其是一类样本多，其他类样本少时会产生严重的问题。</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>有监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>决策树(Decision Tree)</title>
    <url>/2019/06/24/classification%20DT/</url>
    <content><![CDATA[<p><img src="/images/MACHINE/dt.jpg" alt="dt"></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  决策树(Decision Tree):是在已知各种情况发生概率的基础上，直观运用概率分析的一种<strong>图解法</strong>。决策树是一种<strong>树形结构</strong>，其中每个<strong>内部节点表示一个属性上的测试</strong>，每个<strong>分支代表一个测试输出</strong>，每个<strong>叶节点代表一种类别</strong>。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><h2 id="树的构建"><a href="#树的构建" class="headerlink" title="树的构建"></a><font size="4">树的构建</font></h2><ul>
<li>步骤1：<strong>将所有的数据看成是一个节点（根节点），进入步骤2</strong></li>
<li>步骤2：<strong>根据划分准则，从所有属性中挑选一个对节点进行分割，进入步骤3</strong></li>
<li>步骤3：<strong>生成若干个子节点，对每一个子节点进行判断，如果满足停止分裂的条件，进入步骤4；否则，进入步骤2</strong></li>
<li>步骤4：<strong>设置该节点是叶子节点，其输出的结果为该节点数量占比最大的类别</strong></li>
</ul>
<h2 id="划分准则"><a href="#划分准则" class="headerlink" title="划分准则"></a><font size="4">划分准则</font></h2><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>信息熵：假设样本集合D中第k类样本所占的比例为$p_k(k=1,2,\ldots,y)$，则D的信息熵定义为：</p>
<script type="math/tex; mode=display">Ent(D)=-\displaystyle \sum_{k=1}^y p_klog_2p_k</script><p><strong>Ent(D)的值越小，则D的纯度越高</strong>。</p>
<h3 id="信息增益-ID3"><a href="#信息增益-ID3" class="headerlink" title="信息增益(ID3)"></a>信息增益(ID3)</h3><p>假设离散属性a有V个不同的取值$\lbrace a^1,a^2,\ldots,a^V \rbrace$，若使用a来对样本集D进行划分，则会产生V个分支节点，其中第v个分支节点包含了D中所有在属性a上取值为$a^v$的样本，记为$D^v$。我们可以计算出$D^v$的信息熵，再给分支结点赋予权重$\frac{\left| D^v \right|}{\left| D \right|}$<br>则可以计算出用属性a对样本集D进行划分所获得的”信息增益”。</p>
<script type="math/tex; mode=display">Gain(D,a)=Ent(D)-\displaystyle \sum_{v=1}^V \frac{\left| D^v \right|}{\left| D \right|}Ent(D^v)</script><p><strong>一般而言，信息增益越大，则意味着使用属性a来进行划分所获得的纯度提升越大，ID3决策树学习算法就是以信息增益为准则来划分属性</strong>。</p>
<h3 id="增益率-C4-5"><a href="#增益率-C4-5" class="headerlink" title="增益率(C4.5)"></a>增益率(C4.5)</h3><p>实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的C4.5决策树算法不直接使用信息增益，而是使用”增益率”来选择最优划分属性。<br>增益率定义为</p>
<script type="math/tex; mode=display">Gain\_ratio=\frac{Gain(D,a)}{IV(a)}</script><script type="math/tex; mode=display">IV(a)=-\displaystyle \sum_{v=1}^V \frac{\left| D^v \right|}{\left| D \right|} log_2 \frac{\left| D^v \right|}{\left| D \right|}</script><p><strong>需要注意的是，增益率准则对可取值数目较少的属性有所偏好，因此C4.5算法先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的</strong>。</p>
<h3 id="基尼指数-CART"><a href="#基尼指数-CART" class="headerlink" title="基尼指数(CART)"></a>基尼指数(CART)</h3><p><strong>基尼指数反应了从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此基尼指数越小，则数据集D的纯度越高</strong>。</p>
<script type="math/tex; mode=display">Gini(D)=1-\displaystyle \sum_{k=1}^y {p_k}^2</script><p>属性a的基尼指数定义为</p>
<script type="math/tex; mode=display">Gini\_index(D,a)=\displaystyle \sum_{v=1}^V \frac{\left| D^v \right|}{\left| D \right|} Gini(D^v)</script><p><strong>在选择属性集合时，选择使划分后基尼指数最小的属性作为最优划分属性</strong>。</p>
<h2 id="剪枝处理"><a href="#剪枝处理" class="headerlink" title="剪枝处理"></a><font size="4">剪枝处理</font></h2><p><strong>剪枝(pruning)是决策树学习算法对付”过拟合”的主要手段</strong>。<br>决策树剪枝的基本策略有”预剪枝(prepruning)”和”后剪枝(postpruning)”。</p>
<h3 id="预剪枝-prepruning"><a href="#预剪枝-prepruning" class="headerlink" title="预剪枝(prepruning)"></a>预剪枝(prepruning)</h3><p><strong>预剪枝：是在决策树生长过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶子结点</strong>。<br>预剪枝优点：</p>
<ul>
<li><strong>降低过拟合风险</strong></li>
<li><strong>显著减少决策树的训练时间开销和测试时间开销</strong><br>预剪枝缺点：</li>
<li><strong>因为”贪心”本质，可能带来欠拟合的风险</strong></li>
</ul>
<h3 id="后剪枝-postpruning"><a href="#后剪枝-postpruning" class="headerlink" title="后剪枝(postpruning)"></a>后剪枝(postpruning)</h3><p><strong>后剪枝：先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶节点</strong>。<br>后剪枝优点：</p>
<ul>
<li><strong>泛化性能较好</strong></li>
<li><strong>欠拟合风险较小</strong><br>后剪枝缺点：</li>
<li><strong>生成完全决策树后进行，并且自底向上对所有非叶结点进行逐一考察，时间开销大</strong></li>
</ul>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/dt.png" alt="DT"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据为罗斯.昆兰(Ross Quinlan)当年所用的高尔夫模型</font><br>其实这里使用的算法并不是ID3，因为老师上课讲错了，误把ID3讲成最小熵，ID3应该是最小熵增益。但是作业要求是实现最小熵的ID3算法，所以我起名为ID3。但是<strong>标准的ID3，还需要一个比较的过程，确定哪一种分割是最小熵增益</strong>。<br><img src="/images/MACHINE/dt2.png" alt="DATA"></p>
<h2 id="ID3-main-m"><a href="#ID3-main-m" class="headerlink" title="ID3_main.m"></a>ID3_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">%% %获取基本信息</span><br><span class="line">clear;clc;close all;</span><br><span class="line">%设置类别和标签最长为100字符</span><br><span class="line">char_len=100;</span><br><span class="line">%生成一个长度为100的空串</span><br><span class="line">space(1:char_len)=' ';</span><br><span class="line">%读取文本文档</span><br><span class="line">fo=fopen('data1.txt','rt');</span><br><span class="line">txt=textscan(fo,'%s');</span><br><span class="line">fclose(fo);</span><br><span class="line">%class_name为类别名称，如outlook，temperature等等</span><br><span class="line">class_name=strsplit(txt{1}{1},',');</span><br><span class="line">class_name=class_name(1:end-1);</span><br><span class="line">%class_num为类别数</span><br><span class="line">class_num=length(class_name);</span><br><span class="line">%sample_num为样本数</span><br><span class="line">sample_num=length(txt{1})-1;</span><br><span class="line">data{sample_num,class_num+1}=[];</span><br><span class="line">%读入数据</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    temp=strsplit(txt{1}{i+1},',');</span><br><span class="line">    for j=1:class_num</span><br><span class="line">        data{i,j}=[temp{j},'_',class_name{1,j}];</span><br><span class="line">    end</span><br><span class="line">    data{i,j+1}=temp{j+1};</span><br><span class="line">end</span><br><span class="line">%class_info存放每一个类别的标签信息，如第一个元胞中存放rain，sunny，overcast</span><br><span class="line">class_info{1,class_num}=[];</span><br><span class="line">for i=1:class_num</span><br><span class="line">    temp=unique(data(:,i));</span><br><span class="line">    class_info{i}=temp;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%% %生成树</span><br><span class="line">No=1;</span><br><span class="line">%创建100*100的字符矩阵存放树的信息。</span><br><span class="line">tree(1:char_len,1:char_len)=' ';</span><br><span class="line">[tree,No] = ID3_creat(data,class_name,tree,No);</span><br><span class="line"></span><br><span class="line">%% %构建连接矩阵</span><br><span class="line">%获取树的节点</span><br><span class="line">tree_node=tree(1:2:No,:);</span><br><span class="line">%获取树的标签</span><br><span class="line">tree_label=tree(2:2:No,:);</span><br><span class="line">%创建连接矩阵</span><br><span class="line">vect{size(tree_node,1),size(tree_node,1)}=[];</span><br><span class="line">%vect元胞记录父子关系</span><br><span class="line">for i=1:size(tree_node,1)</span><br><span class="line">    tem=find(ismember(class_name,deblank(tree_node(i,:))));</span><br><span class="line">    if isempty(tem)</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    num=size(class_info{1,tem},1);</span><br><span class="line">    for j=1:num</span><br><span class="line">        temp=space;</span><br><span class="line">        temp(1:length(class_info{1,tem}{j}))=class_info{1,tem}{j};</span><br><span class="line">        for k=1:size(tree_label,1)</span><br><span class="line">            if isequal(tree_label(k,:),temp)</span><br><span class="line">                break;</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        vect{i,k+1}=temp;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%% %绘制树图</span><br><span class="line">node=zeros(1,size(tree_node,1));</span><br><span class="line">%根据vect元胞中的父子关系画出树图</span><br><span class="line">for i=1:size(vect,2)</span><br><span class="line">    tem=vect(:,i);</span><br><span class="line">    for j=1:size(tem,1)</span><br><span class="line">        if ~isempty(tem{j})</span><br><span class="line">            node(i)=j;</span><br><span class="line">            break;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">treeplot(node);</span><br><span class="line"></span><br><span class="line">%% %写树的类别（节点）</span><br><span class="line">[x,y]=treelayout(node);</span><br><span class="line">x=x';</span><br><span class="line">y=y';</span><br><span class="line">text(x(:,1),y(:,1),tree_node);</span><br><span class="line"></span><br><span class="line">%% %写树的标签（枝条）</span><br><span class="line">x1=zeros(size(tree_label,1));</span><br><span class="line">y1=zeros(size(tree_label,1));</span><br><span class="line">%根据父子关系在父子节点中点写入标签</span><br><span class="line">for i=2:length(node)</span><br><span class="line">    x1(i-1,1)=(x(i,1)+x(node(i),1))/2;</span><br><span class="line">    y1(i-1,1)=(y(i,1)+y(node(i),1))/2;</span><br><span class="line">end</span><br><span class="line">for i=1:size(tree_label)</span><br><span class="line">    temp=strsplit(tree_label(i,:),'_');</span><br><span class="line">    tree_label(i,:)=[temp{1},space(length(temp{1})+1:end)];</span><br><span class="line">end</span><br><span class="line">text(x1(:,1),y1(:,1),tree_label);</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ID3-split-m"><a href="#ID3-split-m" class="headerlink" title="ID3_split.m"></a>ID3_split.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function bestfeature=ID3_split(data)</span><br><span class="line">%求最小熵的分割算法</span><br><span class="line">numfeatures = size(data,2) -1 ;</span><br><span class="line">bestent = log2(numfeatures);</span><br><span class="line">bestfeature = -1;</span><br><span class="line">for i =1:numfeatures</span><br><span class="line">    ent = ID3_ent(data,i);</span><br><span class="line">    if ent &lt; bestent</span><br><span class="line">        bestent = ent;</span><br><span class="line">        bestfeature = i;</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ID3-ent-m"><a href="#ID3-ent-m" class="headerlink" title="ID3_ent.m"></a>ID3_ent.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function ent=ID3_ent(data,i)</span><br><span class="line">%求最小熵</span><br><span class="line">info=tabulate(data(:,i));</span><br><span class="line">ent=0;</span><br><span class="line">for k=1:size(info,1)</span><br><span class="line">    loc=ismember(data(:,i),info{k,1});</span><br><span class="line">    info1=tabulate(data(loc,end));</span><br><span class="line">    temp=0;</span><br><span class="line">    for n=1:size(info1,1)</span><br><span class="line">        temp=temp-info1{n,3}/100*log2(info1{n,3}/100);</span><br><span class="line">    end</span><br><span class="line">    ent=ent+info{k,3}/100*temp;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ID3-creat-m"><a href="#ID3-creat-m" class="headerlink" title="ID3_creat.m"></a>ID3_creat.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [tree,No]=ID3_creat(data,class_name,tree,No)</span><br><span class="line">classlist=data(:,end);</span><br><span class="line">%如果标签全为yes或no则已经分完，返回</span><br><span class="line">if size(tabulate(classlist),1)==1</span><br><span class="line">    tree(No,1:length(classlist{1}))=classlist{1};</span><br><span class="line">    return</span><br><span class="line">end</span><br><span class="line">%如果没有分完找到最好的特征，递归生成树</span><br><span class="line">bestfeature_loc = ID3_split(data);</span><br><span class="line">bestfeature=class_name{1,bestfeature_loc};</span><br><span class="line">tree(No,1:length(bestfeature))=bestfeature;</span><br><span class="line">featureValues=tabulate(data(:,bestfeature_loc));</span><br><span class="line">for m=1:size(featureValues,1)</span><br><span class="line">    tree(No+1,1:length(featureValues{m,1}))=featureValues{m,1};</span><br><span class="line">    loc=ismember(data(:,bestfeature_loc),featureValues{m,1});</span><br><span class="line">    data1=data(loc,[1:bestfeature_loc-1,bestfeature_loc+1:end]);</span><br><span class="line">    [tree,No] = ID3_creat(data1,class_name(:,[1:bestfeature_loc-1,bestfeature_loc+1:end]),tree,No+2);</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/dt1.png" alt="DT"></p>
<h1 id="ID3-C4-5-CART性能比较"><a href="#ID3-C4-5-CART性能比较" class="headerlink" title="ID3, C4.5, CART性能比较"></a><font size="5" color="red">ID3, C4.5, CART性能比较</font></h1><script type="math/tex; mode=display">\begin{array}{|c|c|c|c|c|} 算法 & 结构 & 特征选择 & 连续值 & 缺失值  \\ \hline ID3&多叉树&信息增益&不支持&不支持\\ C4.5&多叉树&信息增益比&支持&支持\\ CART&二叉树&基尼系数&支持&支持\\  \end{array}</script><h1 id="决策树分类优缺点"><a href="#决策树分类优缺点" class="headerlink" title="决策树分类优缺点"></a><font size="5" color="red">决策树分类优缺点</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>数据量一般不会太大</li>
<li>具有很强的可解释性</li>
<li>生成的决策树简单直观</li>
<li>可以处理多维度输出的分类问题。</li>
<li>既可以处理离散值也可以处理连续值</li>
<li>可以通过剪枝来权衡欠拟合和过拟合</li>
<li>基本不需要预处理，不需要提前归一化，处理缺失值。</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>树结构受样本影响较大</li>
<li>复杂的模型很难用决策树解决</li>
<li>寻找最优的决策树是一个NP难的问题</li>
<li>如果某些特征的样本比例过大，生成决策树容易偏向于这些特征，这个可以通过调节样本权重来改善</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>有监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>Fisher线性判别</title>
    <url>/2019/06/20/classfication%20FISHER/</url>
    <content><![CDATA[<p><img src="/images/MACHINE/fisher.png" alt="fisher"></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  <strong>Fisher线性判别</strong>:由<strong>Fisher于1936年提出</strong>，是一种经典的线性学习方法，其根据<strong>方差分析的思想建立起来的一种线性判别法</strong>，该判别方法<strong>对总体的分布不做任何要求</strong>。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>核心思想非常朴素，用周志华老师的话就是：<strong>给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近，异类样例的投影点尽可能远离。在对新样本进行分类时，将其投影到同样的这条直线上，根据投影点的位置来确定新样本的类别</strong>。</p>
<p>设$\mu_i, \Sigma_i, i \in {0, 1}$分别表示第i类样本的均值向量和协方差矩阵。<br>设投影直线的表达式为$y = \omega x$，则将样本点投影到直线上，两类样本的投影中心分别为$\omega^T \mu_0, \omega^T \mu_0$，两类样本的协方差分别为$\omega^T \Sigma_0 \omega, \omega^T \Sigma_1 \omega$</p>
<p><strong>为了寻找一个最优的投影直线，因此我们要尽量使得类内距离越小越好，类间距离越大越好。可以认为是一种高内聚，低耦合的思想</strong>。</p>
<p><strong>要使同类样例投影点的协方差尽可能小，即$\omega^T \Sigma_0 \omega + \omega^T \Sigma_1 \omega$尽可能小，要使不同样例投影中心的距离尽可能大，即$||\omega^T \mu_0 - \omega^T \mu_1||_2^2$尽可能大</strong>。</p>
<p>因此得到了我们的<strong>目标函数</strong></p>
<script type="math/tex; mode=display">\begin{align} J & = \frac{||\omega^T \mu_0 - \omega^T \mu_1||_2^2}{\omega^T \Sigma_0 \omega + \omega^T \Sigma_1 \omega}  \\ & = \frac{\omega^T (\mu_0 - \mu_1)(\mu_0 - \mu_1)^T \omega}{\omega^T (\Sigma_0 + \Sigma_1) \omega} \end{align}</script><p>我们定义<strong>类内散度矩阵</strong></p>
<script type="math/tex; mode=display">S_{\omega} = \Sigma_0 + \Sigma_1 = \sum_{x \in X_0}(x - \mu_0)(x - \mu_0)^T + \sum_{x \in X_1}(x - \mu_1)(x - \mu_1)^T</script><p>我们定义<strong>类间散度矩阵</strong></p>
<script type="math/tex; mode=display">S_b = (\mu_0 - \mu_1)(\mu_0 - \mu_1)^T</script><p>则目标函数可以重写为</p>
<script type="math/tex; mode=display">J = \frac{\omega^T S_b \omega}{\omega^T S_{\omega} \omega}</script><h1 id="求解过程"><a href="#求解过程" class="headerlink" title="求解过程"></a><font size="5" color="red">求解过程</font></h1><p><strong>因为分子和分母都是关于$\omega$的二次项，因此解与$\omega$的长度无关，仅仅与其方向有关</strong>，也就是说，若$\omega$是这个问题的一个解，那么对于任意常数$\alpha$，有$\alpha \omega$也是这个问题的解。因此令$\omega^T S_{\omega} \omega = 1$，则目标函数等价于</p>
<script type="math/tex; mode=display">\underset{\omega}{argmin} \ -\omega^T S_b \omega, \ s.t. \ \omega^T S_{\omega} \omega = 1</script><p>使用拉格朗日乘子法可求得</p>
<script type="math/tex; mode=display">S_b \omega = \lambda S_{\omega} \omega</script><p>因为$S_b \omega = (\mu_0 - \mu_1)(\mu_0 - \mu_1)^T \omega, \ (\mu_0 - \mu_1)^T \omega$是标量，因此可以设</p>
<script type="math/tex; mode=display">S_b \omega = \lambda (\mu_0 - \mu_1)</script><p>综合上面两个式子可以得到</p>
<script type="math/tex; mode=display">\omega = S_{\omega}^{-1}(\mu_0 - \mu_1)</script><h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="FISHER-train-m"><a href="#FISHER-train-m" class="headerlink" title="FISHER_train.m"></a>FISHER_train.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">% x为样本，行数代表特征数，列数代表样本数,以列向量的形式输出，label为样本所对应的类别</span><br><span class="line">train_x=[0.5,0.5,0.8,0.2,0.1;...</span><br><span class="line">    0.8,0.7,0.6,0.2,0.4];</span><br><span class="line">% 1为第一类，0为第二类</span><br><span class="line">train_y=[1,1,1,0,0];</span><br><span class="line">%样本数</span><br><span class="line">train_num=size(train_x,2);</span><br><span class="line">%特征数</span><br><span class="line">feat_num=size(train_x,1);</span><br><span class="line">x1=mean(train_x(:,train_y==1),2);</span><br><span class="line">x2=mean(train_x(:,train_y==0),2);</span><br><span class="line">sw=(train_x(:,train_y==1)-repmat(x1,1,sum(train_y==1)))*(train_x(:,train_y==1)-repmat(x1,1,sum(train_y==1)))'...</span><br><span class="line">    +(train_x(:,train_y==0)-repmat(x2,1,sum(train_y==0)))*(train_x(:,train_y==0)-repmat(x2,1,sum(train_y==0)))';</span><br><span class="line">%求出权向量</span><br><span class="line">w=(sw\(x1-x2))';</span><br><span class="line">fprintf('权向量为:');</span><br><span class="line">disp(w);</span><br><span class="line">fprintf('\n\n');</span><br><span class="line">disp('运行FISHER_test开始测试');</span><br></pre></td></tr></tbody></table></figure>
<h2 id="FISHER-test-m"><a href="#FISHER-test-m" class="headerlink" title="FISHER_test.m"></a>FISHER_test.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">close all;</span><br><span class="line">%输入测试集</span><br><span class="line">test_x=rand(2,10);</span><br><span class="line">%测试集样本数</span><br><span class="line">test_num=size(test_x,2);</span><br><span class="line">b_test=w*test_x;</span><br><span class="line">%找到分割平面</span><br><span class="line">tem=w*train_x;</span><br><span class="line">if min(tem(train_y==1))&gt;max(tem(train_y==0))</span><br><span class="line">    mid=(min(tem(train_y==1))+max(tem(train_y==0)))/2;</span><br><span class="line">    test_y=b_test&gt;mid;</span><br><span class="line">else</span><br><span class="line">    mid=(max(tem(train_y==1))+min(tem(train_y==0)))/2;</span><br><span class="line">    test_y=b_test&lt;mid;</span><br><span class="line">end</span><br><span class="line">%如果是二维特征，可以用平面坐标系绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    hold on;</span><br><span class="line">    axis equal;</span><br><span class="line">    k1=w(2)/w(1);</span><br><span class="line">    if w(1)==0</span><br><span class="line">        line1_x=[1,1];</span><br><span class="line">        line1_y=[-1,1];</span><br><span class="line">        x_mid=[-1,1];</span><br><span class="line">        y_mid=[mid,mid];</span><br><span class="line">    elseif w(2)==0</span><br><span class="line">        line1_x=[-1,1];</span><br><span class="line">        line1_y=[1,1];</span><br><span class="line">        x_mid=[mid,mid];</span><br><span class="line">        y_mid=[-1,1];</span><br><span class="line">    else</span><br><span class="line">        line1_x=[-1,1];</span><br><span class="line">        line1_y=k1*line1_x+1;</span><br><span class="line">        x_mid=[-1,1];</span><br><span class="line">        y_mid=(mid-w(1)*x_mid)/w(2);</span><br><span class="line">    end</span><br><span class="line">    %画出投影到一维直线的形状</span><br><span class="line">    plot(line1_x,line1_y,'k');</span><br><span class="line">    plot(x_mid,y_mid,'k');</span><br><span class="line">    </span><br><span class="line">    b_train=w*train_x;</span><br><span class="line">    point_train=zeros(2,train_num);</span><br><span class="line">    %画出训练集投影直线</span><br><span class="line">    for i=1:train_num</span><br><span class="line">        if train_y(i)==1</span><br><span class="line">            point_train(:,i)=[w(1),w(2);k1,-1]\[b_train(i);-1];</span><br><span class="line">            plot([train_x(1,i),point_train(1,i)],[train_x(2,i),point_train(2,i)]','r');</span><br><span class="line">            plot(train_x(1,i),train_x(2,i),'r*');</span><br><span class="line">        else</span><br><span class="line">            point_train(:,i)=[w(1),w(2);k1,-1]\[b_train(i);-1];</span><br><span class="line">            plot([train_x(1,i),point_train(1,i)],[train_x(2,i),point_train(2,i)]','g');</span><br><span class="line">            plot(train_x(1,i),train_x(2,i),'g*')</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    point_test=zeros(2,test_num);</span><br><span class="line">%     画出测试集投影直线</span><br><span class="line">    for i=1:test_num</span><br><span class="line">        if test_y(i)==1</span><br><span class="line">            point_test(:,i)=[w(1),w(2);k1,-1]\[b_test(i);-1];</span><br><span class="line">            plot([test_x(1,i),point_test(1,i)],[test_x(2,i),point_test(2,i)]','r');</span><br><span class="line">            plot(test_x(1,i),test_x(2,i),'ro');</span><br><span class="line">        else</span><br><span class="line">            point_test(:,i)=[w(1),w(2);k1,-1]\[b_test(i);-1];</span><br><span class="line">            plot([test_x(1,i),point_test(1,i)],[test_x(2,i),point_test(2,i)]','g');</span><br><span class="line">            plot(test_x(1,i),test_x(2,i),'go')</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/fisher1.png" alt="fisher"></p>
<h1 id="Fisher优缺点"><a href="#Fisher优缺点" class="headerlink" title="Fisher优缺点"></a><font size="5" color="red">Fisher优缺点</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>无需参数估计，无需训练。</li>
<li>算法简单，易于理解和实现。</li>
<li>计算量小，能够达到实时的效率。</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对于多分类问题，实现起来较为复杂。</li>
<li>样本不平衡时，尤其是一类样本多，其他类样本少时会产生严重的问题。</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>有监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>KNN(K Nearest Neighbor)</title>
    <url>/2019/06/15/classfication%20KNN/</url>
    <content><![CDATA[<p><img src="/images/MACHINE/knn.jpg" alt="knn"></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  KNN(K Nearest Neighbor):又称K近邻，是一种基本分类方法，给定测试实例，基于<strong>某种距离度量</strong>找出训练集中与其<strong>最靠近的k个</strong>实例点，然后基于这k个最近邻的信息使用<strong>投票法</strong>，即选择这k个实例中<strong>出现最多</strong>的标记类别作为分类结果。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><h2 id="距离的度量"><a href="#距离的度量" class="headerlink" title="距离的度量"></a><font size="4">距离的度量</font></h2><p>  <font size="4">1. 欧式距离(Euclidean Distance)</font></p>
<script type="math/tex; mode=display">L_2(x_i,x_j)=\sqrt{\displaystyle \sum_{k=1}^n ({x_i}^{(k)}-{x_j}^{(k)})^2}</script><p>  <font size="4">2. 曼哈顿距离(Manhattan distance)</font></p>
<script type="math/tex; mode=display">L_1(x_i,x_j)=\displaystyle \sum_{k=1}^n \lvert{x_i}^{(k)}-{x_j}^{(k)} \rvert</script><p>  <font size="4">3.余弦距离(Cosine Distance)</font></p>
<script type="math/tex; mode=display">L_{cos}(x_i,x_j)=1-\frac{x_i \cdot x_j}{\lVert x_i \rVert_2 \ \lVert x_j \rVert_2}</script><h2 id="K值的选择"><a href="#K值的选择" class="headerlink" title="K值的选择"></a><font size="4">K值的选择</font></h2><p>  K值的选择会对K近邻法的结果产生重大影响，在应用中，k值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。<br>  K=1时K近邻算法退化成最近邻，即数据的类别为距离最近的样本的类别。</p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/knn.png" alt="KNN"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="KNN-main-m"><a href="#KNN-main-m" class="headerlink" title="KNN_main.m"></a>KNN_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%类别数目，请输入大于1的数</span><br><span class="line">class_num=2;</span><br><span class="line">%k近邻数目</span><br><span class="line">knn=3;</span><br><span class="line">%训练集样本</span><br><span class="line">train_x=[0.7,0.8,0.1,0.4,0.2;...</span><br><span class="line">     0.5,0.6,0.1,0.8,0.2];</span><br><span class="line">train_y=[1,1,2,1,2];</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(train_x,1);</span><br><span class="line">%测试集样本</span><br><span class="line">test_x=[rand(1,50);rand(1,50)];</span><br><span class="line">%训练集样本数</span><br><span class="line">train_num=size(train_x,2);</span><br><span class="line">%测试集样本数</span><br><span class="line">test_num=size(test_x,2);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">train_x_scale=zeros(size(train_x));</span><br><span class="line">test_x_scale=zeros(size(test_x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    train_x_scale(i,:)=(train_x(i,:)-min(train_x(i,:)))/(max(train_x(i,:))-min(train_x(i,:)));</span><br><span class="line">    test_x_scale(i,:)=(test_x(i,:)-min(train_x(i,:)))/(max(train_x(i,:))-min(train_x(i,:)));</span><br><span class="line">end</span><br><span class="line">%如果knn大于样本数，则无法判别</span><br><span class="line">if knn&gt;train_num</span><br><span class="line">    disp('Error');</span><br><span class="line">else</span><br><span class="line">    test_y=KNN_classify(train_x_scale,train_y,test_x_scale,train_num,test_num,knn);</span><br><span class="line">    %如果数据的特征是二维的，可以绘图表示</span><br><span class="line">    if feat_num==2</span><br><span class="line">        KNN_display(train_x,train_y,test_x,test_y,train_num,test_num,class_num);</span><br><span class="line">    else</span><br><span class="line">        disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="KNN-classify-m"><a href="#KNN-classify-m" class="headerlink" title="KNN_classify.m"></a>KNN_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function test_y=KNN_classify(train_x_scale,train_y,test_x_scale,train_num,test_num,knn)</span><br><span class="line">test_y=zeros(1,test_num);</span><br><span class="line">distance=zeros(test_num,train_num);</span><br><span class="line">for i=1:test_num</span><br><span class="line">    %distance(i,j)代表第i个测试集到第j个训练集的距离</span><br><span class="line">    distance(i,:)=sum((train_x_scale-repmat(test_x_scale(:,i),1,train_num)).^2);</span><br><span class="line">    temp=sort(distance(i,:));</span><br><span class="line">    %找到最近的knn个数据</span><br><span class="line">    tem=tabulate(train_y(distance(i,:)&lt;=temp(knn)));</span><br><span class="line">    %找到最近的数据中最多的类别</span><br><span class="line">    test_y(i)=tem(find(tem(:,2)==max(tem(:,2)),1),1);</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="KNN-display-m"><a href="#KNN-display-m" class="headerlink" title="KNN_display.m"></a>KNN_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function KNN_display(train_x,train_y,test_x,test_y,train_num,test_num,class_num)</span><br><span class="line">hold on;</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">end</span><br><span class="line">%画出每一类的训练数据，用*表示</span><br><span class="line">for i=1:train_num</span><br><span class="line">    plot(train_x(1,i),train_x(2,i),'color',color_bar(train_y(i),:),'marker','*');</span><br><span class="line">end</span><br><span class="line">%画出每一类的测试数据，用o表示</span><br><span class="line">for j=1:test_num</span><br><span class="line">    plot(test_x(1,j),test_x(2,j),'color',color_bar(test_y(j),:),'marker','o');</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/knn1.png" alt="KNN"></p>
<h1 id="KNN优缺点"><a href="#KNN优缺点" class="headerlink" title="KNN优缺点"></a><font size="5" color="red">KNN优缺点</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>无需参数估计，无需训练</li>
<li>算法简单，易于理解和实现</li>
<li>适合于对稀有数据进行分类</li>
<li>特别适合于多分类问题，KNN的表现超过SVM</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>无法给出分类规则</li>
<li>对于高维特征，距离的选择和衡量不准确</li>
<li>计算量较大，对每一个测试样本都需要计算与其他样本的距离</li>
<li>样本不平衡时，尤其是一类样本多，其他类样本少时会产生严重的问题</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>有监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>差分进化算法(DE)</title>
    <url>/2019/05/27/optimization_DE/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">差分进化算法</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  DE(Differential Evolution Algorithm):是一种高效的全局优化算法。它也是基于群体的启发式搜索算法，群中的每个个体对应一个解向量。差分进化算法的进化流程则与遗传算法非常类似，都包括变异、杂交和选择操作，但这些操作的具体定义与遗传算法有所不同。</p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 随机产生一些初始种群</font></p>
<p>  <font size="4">2. 根据适应度对种群采用某种方式进行自然选择</font></p>
<p>  <font size="4">3. 对选择剩余的种群进行差分遗传，产生新的种群</font></p>
<p>  <font size="4">4. 对父代和子代留一处理，回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">5. 此时剩余的是适应度较好的种群，比较可得该算法的最优解</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/de2.png" alt="DE"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="DE-main-m"><a href="#DE-main-m" class="headerlink" title="DE_main.m"></a>DE_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%种群数量</span><br><span class="line">gn=100;</span><br><span class="line">%迭代次数</span><br><span class="line">times=1000;</span><br><span class="line">%交叉概率</span><br><span class="line">cr=0.5;</span><br><span class="line">%随机产生一些种群</span><br><span class="line">group=zeros(n,gn);</span><br><span class="line">for k=1:n</span><br><span class="line">    group(k,:)=(rand(1,gn))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">end</span><br><span class="line">%设置当前最优解</span><br><span class="line">best_value=zeros(1,times);</span><br><span class="line">tic;</span><br><span class="line">for k=1:times</span><br><span class="line">    for i=1:gn</span><br><span class="line">        %基因重组的过程中可能发生染色体变异</span><br><span class="line">        exchange=randperm(gn,3);</span><br><span class="line">        h=group(:,exchange(1))+rand(1)*(group(:,exchange(2))-group(:,exchange(3)));</span><br><span class="line">        h(h&gt;500)=500;</span><br><span class="line">        h(h&lt;-500)=-500;</span><br><span class="line">        v=group(:,i);</span><br><span class="line">        %染色体交换,保留的物种产生后代时发生基因重组</span><br><span class="line">        for j=1:n</span><br><span class="line">            if cr&gt;rand(1)</span><br><span class="line">                v(j)=h(j);</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        if f(v)&lt;f(group(:,i))</span><br><span class="line">            group(:,i)=v;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    best_value(k)=min(f(group));</span><br><span class="line">    if k&gt;100&amp;&amp;abs(best_value(k)-best_value(k-100))&lt;1e-5</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(group));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(group(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(group(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    %所求最小值的函数</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(group(1,index),group(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/de1.png" alt="DE"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.975929624477)=-418.982887272434</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>受到参数影响较小</li>
<li>不会产生早熟收敛问题</li>
<li>适用于多维的最优值求解</li>
<li>从群体出发，具有并行性</li>
<li>算法不依赖初始种群的选择</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>使用概率机制进行迭代，具有随机性</li>
<li>具有可扩展性，容易与其他算法结合</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对问题编码表示较为困难</li>
<li>因为有大量的比较和选择，可能速度稍慢于遗传算法</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>全局搜索算法比较(Global Search Algorithm Comparison)</title>
    <url>/2019/05/26/optimization_compare/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">全局搜索算法比较</font></strong></center><p></p>
<h1 id="全局搜索"><a href="#全局搜索" class="headerlink" title="全局搜索"></a><font size="5" color="red">全局搜索</font></h1><p>  梯度方法，牛顿法，共轭梯度法，拟牛顿法等，能够从初始点出发，产生一个迭代序列。但是很多时候，往往只能收敛到<strong>局部极小点</strong>。因此为了保证算法能够收敛到<strong>全局最小点</strong>，需要借助于<strong>全局搜索算法</strong>来实现。<br><a id="more"></a></p>
<h1 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a><font size="5" color="red">算法分类</font></h1><p><img src="/images/OPTIMIZATION/compare.png" alt="COMPARE"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><p><font size="4">所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="模拟退火算法-SA"><a href="#模拟退火算法-SA" class="headerlink" title="模拟退火算法(SA)"></a><a href="https://ustccoder.github.io/2019/05/20/optimization_SA/">模拟退火算法(SA)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>计算过程简单</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>相比梯度下降，增加了逃离局部最小的可能</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>参数敏感</li>
<li>收敛速度慢</li>
<li>执行时间长</li>
<li>算法性能与初始值有关</li>
<li>可能落入其他的局部最小值</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/sa1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_sa_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_sa_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_sa_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="遗传算法-GA"><a href="#遗传算法-GA" class="headerlink" title="遗传算法(GA)"></a><a href="https://ustccoder.github.io/2019/05/21/optimization_GA/">遗传算法(GA)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>从群体出发，具有并行性</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>使用概率机制进行迭代，具有随机性</li>
<li>具有可扩展性，容易与其他算法结合</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>受到参数影响较大</li>
<li>可能产生早熟收敛问题</li>
<li>对问题编码表示较为困难</li>
<li>算法对初始种群的选择有一定的依赖性</li>
<li>搜索速度比较慢，要得到较精确的解需要较多的训练时间</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/ga1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_ga_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_ga_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_ga_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="免疫算法-IA"><a href="#免疫算法-IA" class="headerlink" title="免疫算法(IA)"></a><a href="https://ustccoder.github.io/2019/05/22/optimization_IA/">免疫算法(IA)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>受到参数影响较小</li>
<li>解决早熟收敛问题</li>
<li>从群体出发，具有并行性</li>
<li>对抗体选择的依赖性降低</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>使用概率机制进行迭代，具有随机性</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对问题编码表示较为困难</li>
<li>要进行多次免疫应答，因此速度慢于遗传算法</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/ia1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_ia_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_ia_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_ia_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="蚁群算法-ACO"><a href="#蚁群算法-ACO" class="headerlink" title="蚁群算法(ACO)"></a><a href="https://ustccoder.github.io/2019/05/23/optimization_ACO/">蚁群算法(ACO)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>搜索速度较快</li>
<li>受到参数影响较小</li>
<li>从群体出发，具有并行性</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>具有可扩展性，容易与其他算法结合</li>
<li><font size="4"><strong>缺点：</strong></font></li>
<li>对初始蚂蚁的数量有很高的要求</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/aco1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_aco_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_aco_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_aco_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="粒子群算法-PSO"><a href="#粒子群算法-PSO" class="headerlink" title="粒子群算法(PSO)"></a><a href="https://ustccoder.github.io/2019/05/24/optimization_PSO/">粒子群算法(PSO)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>搜索能力最快</li>
<li>从群体出发，具有并行性</li>
<li>可用于求解复杂的非线性优化问题</li>
<li><font size="4"><strong>缺点：</strong></font></li>
<li>受到参数影响较大</li>
<li>存在早熟收敛问题</li>
<li>对初始粒子群的数量有很高的要求</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/pso1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_pso_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_pso_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_pso_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="单纯形法-Nelder-Mead"><a href="#单纯形法-Nelder-Mead" class="headerlink" title="单纯形法(Nelder-Mead)"></a><a href="https://ustccoder.github.io/2019/05/25/optimization_NM/">单纯形法(Nelder-Mead)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>受到参数影响较小</li>
<li>具有快速随机的搜索能力</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>每次迭代都更接近最优解，精度最高</li>
<li><font size="4"><strong>缺点：</strong></font></li>
<li>算法性能与初始值有关</li>
<li>不适用于多维的最优值求解</li>
<li>可能落入其他的局部最小值</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/nm1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_nm_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_nm_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_nm_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="遗传差分算法-DE"><a href="#遗传差分算法-DE" class="headerlink" title="遗传差分算法(DE)"></a><a href="https://ustccoder.github.io/2019/05/27/optimization_DE/">遗传差分算法(DE)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>受到参数影响较小</li>
<li>不会产生早熟收敛问题</li>
<li>适用于多维的最优值求解</li>
<li>从群体出发，具有并行性</li>
<li>算法不依赖初始种群的选择</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>使用概率机制进行迭代，具有随机性</li>
<li>具有可扩展性，容易与其他算法结合</li>
<li><font size="4"><strong>缺点：</strong></font></li>
<li>对问题编码表示较为困难</li>
<li>因为有大量的比较和选择，可能速度稍慢于遗传算法</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/de1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_de_2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<p></p><center><div style="float:left;margin-left:50px"><img src="/images/OPTIMIZATION/compare_de_3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/OPTIMIZATION/compare_de_4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h2 id="算法对比"><a href="#算法对比" class="headerlink" title="算法对比"></a>算法对比</h2><p></p><center><img src="/images/OPTIMIZATION/compare1.png">搜索精度分析</center><p></p>
<div style="float:none;clear:both;"></div>
<center><img src="/images/OPTIMIZATION/compare2.png">所用时间分析</center>
<div style="float:none;clear:both;"></div>

<h1 id="特点小结"><a href="#特点小结" class="headerlink" title="特点小结"></a><font size="5" color="red">特点小结</font></h1><h2 id="模拟退火算法-SA-1"><a href="#模拟退火算法-SA-1" class="headerlink" title="模拟退火算法(SA)"></a>模拟退火算法(SA)</h2><ul>
<li>不同问题对温度要求不同，起始温度和温度变化率都会影响搜索精度和时间</li>
<li>每次都随机产生一个解，有时很难跳出较深较远的局部最优</li>
<li>可以重复运算多次，取多次的最小值，这样可以保证得到全局最优</li>
</ul>
<h2 id="遗传算法-GA-1"><a href="#遗传算法-GA-1" class="headerlink" title="遗传算法(GA)"></a>遗传算法(GA)</h2><ul>
<li>不同的问题需要的种群个数不同，种群个数越多，搜索精度越高，用时越长</li>
<li>迭代次数越高，自然选择越强，保留的结果越好，搜索精度越高，用时越长</li>
<li>问题的表示影响遗传算法的效率，用二进制基因串表示还是用十进制表示需要考虑</li>
<li>自然选择的方式很重要，采用精英选择或轮盘赌会产生不同的效果</li>
<li>遗传算子对算法的影响很大，采用何种交叉方式和多大的变异率最合适</li>
</ul>
<h2 id="免疫算法-IA-1"><a href="#免疫算法-IA-1" class="headerlink" title="免疫算法(IA)"></a>免疫算法(IA)</h2><ul>
<li>免疫算法包含遗传算法的所有特点</li>
<li>免疫过程从记忆细胞中取出部分，提高搜索效率</li>
<li>免疫过程随机产生另一部分抗体，给搜索到其他更优点创造了可能性</li>
<li>每次的免疫过程都相当于一次遗传算法，因此免疫次数越多，精度越高，时间越长</li>
</ul>
<h2 id="蚁群算法-ACO-1"><a href="#蚁群算法-ACO-1" class="headerlink" title="蚁群算法(ACO)"></a>蚁群算法(ACO)</h2><ul>
<li>和自然界中蚁群一样，蚂蚁越多，搜索精度越高，但是计算量大，用时更长</li>
<li>迭代次数越高，信息素的作用时间越长，所求结果更好，精度更高，用时更长</li>
</ul>
<h2 id="粒子群算法-PSO-1"><a href="#粒子群算法-PSO-1" class="headerlink" title="粒子群算法(PSO)"></a>粒子群算法(PSO)</h2><ul>
<li>和自然界中飞鸟一样，飞鸟越多越容易遇到全局最优解，搜索精度越高，用时更长</li>
<li>迭代次数越高，飞鸟之间的信息交换越多，所求结果更好，精度更高，用时更长</li>
<li>粒子群算法可以实现高度的并行计算，因此在搜索函数最值方面速度最快</li>
</ul>
<h2 id="单纯形法-Nelder-Mead-1"><a href="#单纯形法-Nelder-Mead-1" class="headerlink" title="单纯形法(Nelder-Mead)"></a>单纯形法(Nelder-Mead)</h2><ul>
<li>单纯形法是一种收缩算法，如果初始点选择在局部极小值区域，会收缩到局部最小</li>
<li>和SA相同，可以重复运算多次，取多次的最小值，这样可以保证得到全局最优。</li>
<li>和其他算法不同，没有随机性，每次迭代都产生比上一次更优的解，搜索精度最高</li>
</ul>
<h2 id="差分进化算法-DE"><a href="#差分进化算法-DE" class="headerlink" title="差分进化算法(DE)"></a>差分进化算法(DE)</h2><ul>
<li>差分进化算法类似于改进版的遗传算法，更加适合于多维最优值求解</li>
<li>和遗传算法不同的是具有差分性质，能够更容易地跳出当前的局部解</li>
<li>淘汰机制也十分简单，将子代和父代对比，直接淘汰表现差的解，精英选择</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>单纯形法(Nelder-Mead)</title>
    <url>/2019/05/25/optimization_NM/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">单纯形法</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  Nelder-Mead:单纯形法秉承<strong>保证每一次迭代比前一次更优</strong>的基本思想，先找出一个基本可行解，看是否是最优解，若不是，则按照一定法则转换到另一改进后<strong>更优的基本可行解</strong>，再鉴别，若仍不是，则再转换，按此重复进行。因基本可行解的个数有限，故经<strong>有限次转换必能得出问题的最优解</strong>。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 随机产生N+1个点，构造单纯形，N为所求极值的维度</font></p>
<p>  <font size="4">2. 对这些点的函数值进行从小到大排序，求出最优N个点的重心p<sub>g</sub></font></p>
<script type="math/tex; mode=display">f(p_0) \leq f(p_1) \leq \ldots \leq f(p_N)</script><script type="math/tex; mode=display">p_{g}=\displaystyle \sum_{i=0}^{N-1}\frac {p_{i}}{N}</script><p>  <font size="4">3. 对最差的点进行反射得到p<sub>r</sub></font></p>
<script type="math/tex; mode=display">p_{r}=p_{g}+\rho \cdot (p_{g}-p_{N}) \ , \ 其中 \rho 为反射系数</script><p>  <font size="4">4. 如果f(p<sub>0</sub>)≤f(p<sub>r</sub>)<f(p<sub>N-1&lt;/sub&gt;)，p<sub>r</sub>代替p<sub>N</sub>，回到步骤2</f(p<sub></font></p>
<p>  <font size="4">5. 如果f(p<sub>r</sub>)<f(p<sub>0&lt;/sub&gt;)，说明p<sub>r</sub>方向有利于函数值下降</f(p<sub></font></p>
<script type="math/tex; mode=display">p_{e}=p_{g}+ \chi \cdot (p_{r}-p_{g}) \ , \ 其中 \chi 为延伸系数</script><p>  <font size="4">6. 如果f(p<sub>e</sub>)<f(p<sub>r&lt;/sub&gt;)，p<sub>e</sub>代替p<sub>N</sub>，否则p<sub>r</sub>代替p<sub>N</sub>，回到步骤2</f(p<sub></font></p>
<p>  <font size="4">7. f(p<sub>r</sub>)≥f(p<sub>N-1</sub>)，说明要进行收缩操作</font></p>
<script type="math/tex; mode=display">p_{c}= \begin{cases} p_{g}+ \gamma \cdot (p_{r}-p_{g}) &  f(p_{r}) < f(p_{N}) \\ p_{g}+ \gamma \cdot (p_{l}-p_{r}) & f(p_{r}) \ge f(p_{N}) \end{cases} \ , \ 其中 \gamma 为收缩系数</script><p>  <font size="4">8. 如果f(p<sub>c</sub>)≤f(p<sub>N</sub>)，p<sub>c</sub>代替p<sub>N</sub>，回到步骤2</font></p>
<p>  <font size="4">9. f(p<sub>c</sub>)&gt;f(p<sub>r</sub>)，只保留p<sub>0</sub>，其他点到p<sub>0</sub>距离减半，收缩单纯形</font></p>
<p>  <font size="4">10.如果不满足某个终止条件，回到步骤2</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/nm2.png" alt="NelderMead"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="NelderMead-main-m"><a href="#NelderMead-main-m" class="headerlink" title="NelderMead_main.m"></a>NelderMead_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%反射系数rho</span><br><span class="line">rho=1;</span><br><span class="line">%延伸系数</span><br><span class="line">ka1=2;</span><br><span class="line">%收缩系数</span><br><span class="line">ka2=0.5;</span><br><span class="line">%迭代次数</span><br><span class="line">times=100;</span><br><span class="line">%尝试解次数</span><br><span class="line">num=50;</span><br><span class="line">value=zeros(n,num);</span><br><span class="line">tic;</span><br><span class="line">for i=1:num</span><br><span class="line">    %给x赋初值</span><br><span class="line">    x=zeros(n,n+1);</span><br><span class="line">    for k=1:n</span><br><span class="line">        x(k,:)=(rand(1,n+1))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">    end</span><br><span class="line">    best_value=zeros(1,times);</span><br><span class="line">    for j=1:times</span><br><span class="line">        [~,index]=sort(f(x));</span><br><span class="line">        %将小的值排在前面</span><br><span class="line">        x=x(:,index);</span><br><span class="line">        %求重心pg</span><br><span class="line">        xg=sum(x(:,1:end-1),2)/n;</span><br><span class="line">        %进行反射</span><br><span class="line">        xr=xg+rho*(xg-x(:,n+1));</span><br><span class="line">        %判断自变量是否在范围</span><br><span class="line">        for k=1:n</span><br><span class="line">            if xr(k)&lt;range_x(k,1)</span><br><span class="line">                xr(k)=range_x(k,1);</span><br><span class="line">            end</span><br><span class="line">            if xr(k)&gt;range_x(k,2)</span><br><span class="line">                xr(k)=range_x(k,2);</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        %如果目标函数值在最好和最坏之间</span><br><span class="line">        if f(xr)&gt;=f(x(:,1))&amp;&amp;f(xr)&lt;f(x(:,n))</span><br><span class="line">            x(:,n+1)=xr;</span><br><span class="line">        %如果新产生的点比最小的点还要小，说明这个方向有利于值的减小</span><br><span class="line">        elseif f(xr)&lt;f(x(:,1))</span><br><span class="line">            %进一步向这个方向延伸</span><br><span class="line">            xe=xg+ka1*(xr-xg);</span><br><span class="line">            for k=1:n</span><br><span class="line">                if xe(k)&lt;range_x(k,1)</span><br><span class="line">                    xe(k)=range_x(k,1);</span><br><span class="line">                end</span><br><span class="line">                if xe(k)&gt;range_x(k,2)</span><br><span class="line">                    xe(k)=range_x(k,2);</span><br><span class="line">                end</span><br><span class="line">            end</span><br><span class="line">            %如果第二次延伸后的点比第一次延伸后产生的点小，则用第二次延伸后的点替换原来最大的点</span><br><span class="line">            if f(xe)&lt;f(xr)</span><br><span class="line">                x(:,n+1)=xe;</span><br><span class="line">            %否则用第一次延伸后的点替换原来最大的点</span><br><span class="line">            else</span><br><span class="line">                x(:,n+1)=xr;</span><br><span class="line">            end</span><br><span class="line">        %如果新产生的点比最小的点还要大</span><br><span class="line">        else</span><br><span class="line">            %如果新产生的点比最大的点小，说明要进行外收缩</span><br><span class="line">            if f(xr)&lt;f(x(:,n+1))</span><br><span class="line">                xc=xg+ka2*(xr-xg);</span><br><span class="line">            %如果新产生的点比最大的点大，说明要进行内收缩</span><br><span class="line">            else</span><br><span class="line">                xc=xg+ka2*(x(:,n+1)-xg);</span><br><span class="line">            end</span><br><span class="line">            %如果无论进行内收缩还是外收缩产生的值都比最大值要小，则替换最大值</span><br><span class="line">            if f(xc)&lt;=f(x(:,n+1))</span><br><span class="line">                x(:,n+1)=xc;</span><br><span class="line">            %%如果无论进行内收缩还是外收缩产生的值都比最大值要大，则缩小范围继续搜索</span><br><span class="line">            else</span><br><span class="line">                for k=2:n+1</span><br><span class="line">                    x(:,k)=(x(:,1)+x(:,k))/2;</span><br><span class="line">                end</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        best_value(j)=x(find(f(x)==min(f(x)),1));</span><br><span class="line">        if j&gt;5&amp;&amp;abs(best_value(j)-best_value(j-5))&lt;1e-5</span><br><span class="line">            break;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    value(:,i)=x(:,find(f(x)==min(f(x)),1));</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(value));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(value(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(value(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(value(1,index),value(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/nm1.png" alt="NelderMead"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.968746504328)=-418.982887272434</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>受到参数影响较小</li>
<li>具有快速随机的搜索能力</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>每次迭代都更接近最优解，精度最高</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>算法性能与初始值有关</li>
<li>不适用于多维的最优值求解</li>
<li>可能落入其他的局部最小值</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>粒子群算法(PSO)</title>
    <url>/2019/05/24/optimization_PSO/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">粒子群算法</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  PSO(Particle Swarm Optimization):受到飞鸟集群活动的规律性启发，进而利用群体智能建立的一个简化模型。粒子群算法在对动物集群活动行为观察基础上，利用群体中的个体对信息的<strong>共享</strong>使整个群体的运动在问题求解空间中产生<strong>从无序到有序</strong>的演化过程，从而获得最优解。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 随机产生一些粒子</font></p>
<p>  <font size="4">2. 找出所有粒子中适应度最优的粒子g<sub>best</sub></font></p>
<script type="math/tex; mode=display">g_{best}=\underset{x}{arg \ min} \ f(x)</script><p>  <font size="4">3. 更新每一个粒子的飞行速度</font></p>
<script type="math/tex; mode=display">v_{i}'=w \cdot v_{i}+c1 \cdot r_{i} \cdot (p_{i}-x_{i})+c2 \cdot s_{i} \cdot (g_{best}-x_{i})</script><p>  <font size="4">4. 获得每个粒子当前位置x<sub>i</sub>和该粒子在飞行中到达过的最优位置p<sub>i</sub></font></p>
<script type="math/tex; mode=display">x_{i}'=x_{i}+v_{i}'</script><script type="math/tex; mode=display">p_{i}'= \begin{cases} x_{i}' &  f(x_{i}') < f(p_{i}) \\ p_{i} & f(x_{i}') \ge f(p_{i}) \end{cases}</script><p>  <font size="4">5. 回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">6. 此时粒子集群，粒子群位置为极小值，最小的p为算法的最优解</font></p>
<p>  <font size="4">7. 回到步骤2，直到满足某个终止条件</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/pso2.png" alt="PSO"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="PSO-main-m"><a href="#PSO-main-m" class="headerlink" title="PSO_main.m"></a>PSO_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%迭代次数</span><br><span class="line">times=100;</span><br><span class="line">%w为惯性权重</span><br><span class="line">w=0.8;</span><br><span class="line">%c1为自身认知权重</span><br><span class="line">c1=1;</span><br><span class="line">%c2为社会认知权重</span><br><span class="line">c2=1;</span><br><span class="line">%粒子群的个数</span><br><span class="line">gn=1000;</span><br><span class="line">%粒子群的初始位置</span><br><span class="line">x=zeros(n,gn);</span><br><span class="line">for k=1:n</span><br><span class="line">    x(k,:)=(rand(1,gn))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">end</span><br><span class="line">%个体极值</span><br><span class="line">p=x;</span><br><span class="line">%v代表粒子的速度</span><br><span class="line">v=zeros(n,gn);</span><br><span class="line">%设置当前最优解</span><br><span class="line">best_value=zeros(1,times);</span><br><span class="line">tic;</span><br><span class="line">for i=1:times</span><br><span class="line">    [solve,gbest]=min(f(x));</span><br><span class="line">    for j=1:gn</span><br><span class="line">        %速度分为3个部分，惯性速度，该点最优和全局最优</span><br><span class="line">        v(:,j)=w*v(:,j)+c1*rand(n,1).*(p(:,j)-x(:,j))+c2*rand(n,1).*(x(:,gbest)-x(:,j));</span><br><span class="line">        x(:,j)=x(:,j)+v(:,j);</span><br><span class="line">        %限制解的范围</span><br><span class="line">        for k=1:n</span><br><span class="line">            if x(k,j)&lt;range_x(k,1)</span><br><span class="line">                x(k,j)=range_x(k,1);</span><br><span class="line">            end</span><br><span class="line">            if x(k,j)&gt;range_x(k,2)</span><br><span class="line">                x(k,j)=range_x(k,2);</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        if f(x(:,j))&lt;f(p(:,j))</span><br><span class="line">            p(:,j)=x(:,j);</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    best_value(i)=min(f(p));</span><br><span class="line">    if i&gt;5&amp;&amp;abs(best_value(i)-best_value(i-5))&lt;1e-5</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(p));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(p(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(p(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    %所求最小值的函数</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(p(1,index),p(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/pso1.png" alt="PSO"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.968750420615)=-418.982887272432</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>搜索能力最快</li>
<li>从群体出发，具有并行性</li>
<li>可用于求解复杂的非线性优化问题</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>受到参数影响较大</li>
<li>存在早熟收敛问题</li>
<li>对初始粒子群的数量有很高的要求</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>蚁群算法(ACO)</title>
    <url>/2019/05/23/optimization_ACO/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">蚁群算法</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  ACO(ant colony optimization):研究蚂蚁觅食的过程中，发现单个蚂蚁的行为比较简单，但是蚁群整体却可以体现一些智能的行为。例如蚁群可以在不同的环境下，寻找最短到达食物源的路径。蚂蚁会在其经过的路径上释放一种可以称之为<strong>信息素</strong>的物质，蚁群内的蚂蚁对信息素具有感知能力，它们会<strong>沿着信息素浓度较高路径行走</strong>，而每只路过的蚂蚁都会在路上留下信息素，形成一种类似<strong>正反馈</strong>的机制。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 随机产生一些蚂蚁</font></p>
<p>  <font size="4">2. 判断蚂蚁所在位置的值越小，信息素越多</font></p>
<p>  <font size="4">3. 如果信息素较多，蚂蚁小幅移动，信息素较少，蚂蚁大幅移动</font></p>
<p>  <font size="4">4. 如果蚂蚁移动之后值变小，则说明移动方向正确</font></p>
<p>  <font size="4">5. 回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">6. 此时蚂蚁集群，蚁群位置为极小值，比较可得该算法的最优解</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/aco2.png" alt="ACO"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="ACO-main-m"><a href="#ACO-main-m" class="headerlink" title="ACO_main.m"></a>ACO_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%蚂蚁数</span><br><span class="line">m=1000;</span><br><span class="line">%迭代次数</span><br><span class="line">times=100;</span><br><span class="line">%信息素挥发系数</span><br><span class="line">rho=0.8;</span><br><span class="line">%转移概率常数</span><br><span class="line">p0=1;</span><br><span class="line">%转移概率</span><br><span class="line">p=zeros(1,m);</span><br><span class="line">%x为蚁群的初始位置</span><br><span class="line">x=zeros(n,m);</span><br><span class="line">for k=1:n</span><br><span class="line">    x(k,:)=(rand(1,m))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">end</span><br><span class="line">%tau为信息素</span><br><span class="line">tau=-f(x);</span><br><span class="line">%设置当前最优解</span><br><span class="line">best_value=zeros(1,times);</span><br><span class="line">tic;</span><br><span class="line">for i=1:times</span><br><span class="line">    [~,bestindex]=max(tau);</span><br><span class="line">    for j=1:m</span><br><span class="line">        %信息素越大越不容易转移</span><br><span class="line">        p(j)=(tau(bestindex)-tau(j))/tau(bestindex);</span><br><span class="line">        if p(j)&lt;p0</span><br><span class="line">            %如果信息素较多，转移步伐就较小</span><br><span class="line">            temp=x(:,j)+(rand(n,1)*2-1)/i;</span><br><span class="line">        else</span><br><span class="line">            temp=zeros(n,1);</span><br><span class="line">            %如果信息素较少，转移步伐就较大</span><br><span class="line">            for k=1:n</span><br><span class="line">                temp(k)=x(k,j)+(rand(1,1)-0.5)*(range(k,2)-range(k,1));</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        %限制边界条件</span><br><span class="line">        for k=1:n</span><br><span class="line">            if temp(k)&lt;range_x(k,1)</span><br><span class="line">                temp(k)=range_x(k,1);</span><br><span class="line">            end</span><br><span class="line">            if temp(k)&gt;range_x(k,2)</span><br><span class="line">                temp(k)=range_x(k,2);</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        %如果移动后值变小，则移动</span><br><span class="line">        if f(temp)&lt;f(x(:,j))</span><br><span class="line">            x(:,j)=temp;</span><br><span class="line">        end</span><br><span class="line">        %更新信息素，函数值越小，信息量越大</span><br><span class="line">        tau(j)=(1-rho)*tau(j)-f(x(:,j));</span><br><span class="line">    end</span><br><span class="line">    best_value(i)=min(f(x));</span><br><span class="line">    if i&gt;5&amp;&amp;abs(best_value(i)-best_value(i-5))&lt;1e-5</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(x));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(x(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(x(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(x(1,index),x(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/aco1.png" alt="ACO"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.959294517745)=-418.982875999576</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>搜索速度较快</li>
<li>受到参数影响较小</li>
<li>从群体出发，具有并行性</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>具有可扩展性，容易与其他算法结合</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对初始蚂蚁的数量有很高的要求</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>免疫算法(IA)</title>
    <url>/2019/05/22/optimization_IA/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">测试函数说明</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  IA(Immune Algorithm):免疫算法基于<strong>生物免疫系统</strong>的基本机制，模仿了人体的免疫系统，解决了遗传算法的<strong>早熟收敛</strong>问题。因为免疫系统具有<strong>辨识记忆</strong>的特点，所以可以更快识别群体，面对待求解问题时，相当于面对各种抗原，可以提前<strong>注射疫苗</strong>抑制退化问题，从而更加保持优胜劣汰的特点。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 随机产生一些记忆细胞</font></p>
<p>  <font size="4">2. 取出部分记忆细胞，剩下抗体由随机产生</font></p>
<p>  <font size="4">3. 根据适应度对抗体采用某种方式进行选择</font></p>
<p>  <font size="4">4. 对选择剩余的抗体进行遗传操作，产生新的抗体</font></p>
<p>  <font size="4">5. 回到步骤3，直到满足某个终止条件</font></p>
<p>  <font size="4">6. 将产生的新抗体和记忆细胞比较，产生新的记忆细胞</font></p>
<p>  <font size="4">7. 回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">8. 此时得到免疫力最好的记忆细胞，比较可得该算法的最优解</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/ia2.png" alt="IA"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="IA-main-m"><a href="#IA-main-m" class="headerlink" title="IA_main.m"></a>IA_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%种群数量</span><br><span class="line">gn=400;</span><br><span class="line">%遗传迭代时进入下一代的数量</span><br><span class="line">m=50    ;</span><br><span class="line">%从记忆细胞种拿出的个数</span><br><span class="line">l=200;</span><br><span class="line">%迭代次数</span><br><span class="line">times=200;</span><br><span class="line">%免疫作用次数</span><br><span class="line">t=10;</span><br><span class="line">%记忆细胞</span><br><span class="line">remember=zeros(n,gn);</span><br><span class="line">for k=1:n</span><br><span class="line">    remember(k,:)=(rand(1,gn))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">end</span><br><span class="line">tic</span><br><span class="line">for p=1:t</span><br><span class="line">    tem=zeros(n,gn-l);</span><br><span class="line">    for k=1:n</span><br><span class="line">        tem(k,:)=(rand(1,gn-l))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">    end</span><br><span class="line">    group=[remember(:,randperm(gn,l)),tem];</span><br><span class="line">    %设置当前最优解</span><br><span class="line">    best_value=zeros(1,times);</span><br><span class="line">    for k=1:times</span><br><span class="line">        y=f(group);</span><br><span class="line">        %全部变成正值</span><br><span class="line">        if min(y)&lt;0</span><br><span class="line">            tem=y-min(y)*1.0001;</span><br><span class="line">        else</span><br><span class="line">            tem=y+0.1;</span><br><span class="line">        end</span><br><span class="line">        %值越小适应越好</span><br><span class="line">        tem=1./tem;</span><br><span class="line">        child=zeros(n,gn);</span><br><span class="line">        %挑选m个种群进入下一代</span><br><span class="line">        for i=1:m</span><br><span class="line">            %轮盘赌选择，适应大的选择概率大</span><br><span class="line">            temp=zeros(1,gn-i+1);</span><br><span class="line">            for j=1:gn-i+1</span><br><span class="line">                temp(j)=sum(tem(1:j));</span><br><span class="line">            end</span><br><span class="line">            temp=temp/temp(gn-i+1);</span><br><span class="line">            %保留最合适的物种</span><br><span class="line">            choose=find(temp&gt;rand(1),1);</span><br><span class="line">            child(:,i)=group(:,choose);</span><br><span class="line">            group=[group(:,1:choose-1),group(:,choose+1:end)];</span><br><span class="line">            tem=[tem(1:choose-1),tem(choose+1:end)];</span><br><span class="line">        end</span><br><span class="line">        %染色体交换,保留的物种产生后代时发生基因重组</span><br><span class="line">        for i=1:floor((gn-m)/2)</span><br><span class="line">            exchange=randperm(m,2);</span><br><span class="line">            a=rand(n,1);</span><br><span class="line">            child(:,i*2-1+m)=a.*child(:,exchange(1))+(1-a).*child(:,exchange(2));</span><br><span class="line">            child(:,i*2+m)=(1-a).*child(:,exchange(1))+a.*child(:,exchange(2));</span><br><span class="line">        end</span><br><span class="line">        if mod(gn-m,2)==1</span><br><span class="line">            exchange=randperm(m,2);</span><br><span class="line">            child(:,gn)=(child(:,exchange(1))+child(:,exchange(2)))/2;</span><br><span class="line">        end</span><br><span class="line">        %基因重组的过程中可能发生染色体变异</span><br><span class="line">        if rand(1)&lt;0.1</span><br><span class="line">            exchange=randperm(gn-m,1);</span><br><span class="line">            a=rand(1);</span><br><span class="line">            for j=1:n</span><br><span class="line">                child(j,exchange+m)=a.*child(j,exchange+m)+(1-a).*(rand(1)*(range(j,2)-range(j,1))+range(j,1));</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        %重组之后后代变成当前种群</span><br><span class="line">        group=child;</span><br><span class="line">        best_value(k)=min(f(group));</span><br><span class="line">        if k&gt;5&amp;&amp;abs(best_value(k)-best_value(k-5))&lt;1e-5</span><br><span class="line">            break;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    %将本次免疫过程中最好的和记忆细胞比较，选取最好的作为记忆细胞</span><br><span class="line">    if min(f(group))&lt;=min(f(remember))</span><br><span class="line">        [~,index]=min(f(group));</span><br><span class="line">        remember=ones(n,gn).*repmat(group(:,index),1,gn);</span><br><span class="line">    else</span><br><span class="line">        [~,index]=min(f(remember));</span><br><span class="line">        remember=ones(n,gn).*repmat(group(:,index),1,gn);</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(remember));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(remember(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(remember(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    %所求最小值的函数</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(remember(1,index),remember(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/ia1.png" alt="IA"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.966448106285)=-418.982886605937</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>受到参数影响较小</li>
<li>解决早熟收敛问题</li>
<li>从群体出发，具有并行性</li>
<li>对抗体选择的依赖性降低</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>使用概率机制进行迭代，具有随机性</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对问题编码表示较为困难</li>
<li>要进行多次免疫应答，因此速度慢于遗传算法</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>遗传算法(GA)</title>
    <url>/2019/05/21/optimization_GA/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">遗传算法</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  GA(Genetic Algorithm):是模拟达尔文生物进化论的<strong>自然选择</strong>和<strong>遗传学机理</strong>的生物进化过程的计算模型，不需要确定的规则就能自动获取和指导优化的搜索空间，<strong>自适应</strong>地调整搜索方向，是一种通过模拟自然进化过程搜索最优解的方法。<a id="more"></a><br>初代种群产生之后，按照<strong>适者生存</strong>和<strong>优胜劣汰</strong>的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的<strong>适应度（fitness）</strong>大小选择个体，并借助于自然遗传学的<strong>遗传算子</strong>进行组合<strong>交叉（crossover）</strong>和<strong>变异（mutation）</strong>，产生出代表新的解集的种群。</p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 随机产生一些初始种群</font></p>
<p>  <font size="4">2. 根据适应度对种群采用某种方式进行自然选择</font></p>
<p>  <font size="4">3. 对选择剩余的种群进行遗传操作，产生新的种群</font></p>
<p>  <font size="4">4. 回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">5. 此时剩余的是适应度较好的种群，比较可得该算法的最优解</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/ga2.png" alt="GA"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="GA-main-m"><a href="#GA-main-m" class="headerlink" title="GA_main.m"></a>GA_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%种群数量</span><br><span class="line">gn=400;</span><br><span class="line">%进入下一代的数量</span><br><span class="line">m=50;</span><br><span class="line">%迭代次数</span><br><span class="line">times=200;</span><br><span class="line">%随机产生一些种群</span><br><span class="line">group=zeros(n,gn);</span><br><span class="line">for k=1:n</span><br><span class="line">    group(k,:)=(rand(1,gn))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">end</span><br><span class="line">%设置当前最优解</span><br><span class="line">best_value=zeros(1,times);</span><br><span class="line">tic;</span><br><span class="line">for k=1:times</span><br><span class="line">    y=f(group);</span><br><span class="line">    %全部变成正值</span><br><span class="line">    if min(y)&lt;0</span><br><span class="line">        tem=y-min(y)*1.0001;</span><br><span class="line">    else</span><br><span class="line">        tem=y+0.1;</span><br><span class="line">    end</span><br><span class="line">    %值越小适应越好</span><br><span class="line">    tem=1./tem;</span><br><span class="line">    child=zeros(n,gn);</span><br><span class="line">    %挑选m个种群进入下一代</span><br><span class="line">    for i=1:m</span><br><span class="line">        %轮盘赌选择，适应大的选择概率大</span><br><span class="line">        temp=zeros(1,gn-i+1);</span><br><span class="line">        for j=1:gn-i+1</span><br><span class="line">            temp(j)=sum(tem(1:j));</span><br><span class="line">        end</span><br><span class="line">        temp=temp/temp(gn-i+1);</span><br><span class="line">        %保留最合适的物种</span><br><span class="line">        choose=find(temp&gt;rand(1),1);</span><br><span class="line">        child(:,i)=group(:,choose);</span><br><span class="line">        group=[group(:,1:choose-1),group(:,choose+1:end)];</span><br><span class="line">        tem=[tem(1:choose-1),tem(choose+1:end)];</span><br><span class="line">    end</span><br><span class="line">    %染色体交换,保留的物种产生后代时发生基因重组</span><br><span class="line">    for i=1:floor((gn-m)/2)</span><br><span class="line">        exchange=randperm(m,2);</span><br><span class="line">        a=rand(n,1);</span><br><span class="line">        child(:,i*2-1+m)=a.*child(:,exchange(1))+(1-a).*child(:,exchange(2));</span><br><span class="line">        child(:,i*2+m)=(1-a).*child(:,exchange(1))+a.*child(:,exchange(2));</span><br><span class="line">    end</span><br><span class="line">    if mod(gn-m,2)==1</span><br><span class="line">        exchange=randperm(m,2);</span><br><span class="line">        child(:,gn)=(child(:,exchange(1))+child(:,exchange(2)))/2;</span><br><span class="line">    end</span><br><span class="line">    %基因重组的过程中可能发生染色体变异</span><br><span class="line">    if rand(1)&lt;0.1</span><br><span class="line">        exchange=randperm(gn-m,1);</span><br><span class="line">        a=rand(1);</span><br><span class="line">        for j=1:n</span><br><span class="line">            child(j,exchange+m)=a.*child(j,exchange+m)+(1-a).*(rand(1)*(range(j,2)-range(j,1))+range(j,1));</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    %重组之后后代变成当前种群</span><br><span class="line">    group=child;</span><br><span class="line">    best_value(k)=min(f(group));</span><br><span class="line">    if k&gt;5&amp;&amp;abs(best_value(k)-best_value(k-5))&lt;1e-5</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(group));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(group(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(group(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    %所求最小值的函数</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(group(1,index),group(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/ga1.png" alt="GA"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.975929624477)=-418.982880761435</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>从群体出发，具有并行性</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>使用概率机制进行迭代，具有随机性</li>
<li>具有可扩展性，容易与其他算法结合</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>受到参数影响较大</li>
<li>可能产生早熟收敛问题</li>
<li>对问题编码表示较为困难</li>
<li>算法对初始种群的选择有一定的依赖性</li>
<li>搜索速度比较慢，要得到较精确的解需要较多的训练时间</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>模拟退火算法(SA)</title>
    <url>/2019/05/20/optimization_SA/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">模拟退火算法</font></strong></center><p></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font size="5" color="red">背景介绍</font></h1><p>  SA(Simulate Anneal):是一种基于<strong>Mentcarlo迭代求解法</strong>的一种启发式随机搜索方法，基于物理中固体物质的退火过程与一般组合优化问题之间的相似性，通过<strong>模拟退火过程</strong>，用来在一个大的搜寻空间内找寻命题的最优解（或近似最优解）。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 任选一初始状态S<sub>0</sub>作为当前解，设置初始温度T<sub>0</sub></font></p>
<p>  <font size="4">2. 对该温度下的状态S<sub>0</sub>产生一个扰动S’，并按概率接收</font></p>
<script type="math/tex; mode=display">\Delta C=f(S')-f(S)</script><script type="math/tex; mode=display">P= \begin{cases} 1 &  \Delta C \leq 0 \\ e^{\frac {- \Delta C}{T} } & \Delta C > 0 \end{cases}</script><p>  <font size="4">3. 按照某种方式降温T=T-ΔT，回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">4. 此时达到的状态S即为该算法的最优解</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/OPTIMIZATION/sa2.png" alt="SA"></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用测试函数可以查看相关文档，<a href="https://ustccoder.github.io/2019/05/19/optimization_Testfunction/">测试函数(Test Function)</a></font></p>
<h2 id="SA-ap-m"><a href="#SA-ap-m" class="headerlink" title="SA_ap.m"></a>SA_ap.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">%自变量取值范围</span><br><span class="line">range_x=[ones(1,1),-ones(1,1)]*500;</span><br><span class="line">%维度</span><br><span class="line">n=size(range_x,1);</span><br><span class="line">%尝试解次数</span><br><span class="line">num=10;</span><br><span class="line">value=zeros(n,num);</span><br><span class="line">delta_t=0.2;</span><br><span class="line">tic;</span><br><span class="line">for i=1:num</span><br><span class="line">    %给x赋初值</span><br><span class="line">    x=zeros(n,1);</span><br><span class="line">    for k=1:n</span><br><span class="line">        x(k)=(rand(1))*(range_x(k,2)-range_x(k,1))+range_x(k,1);</span><br><span class="line">    end</span><br><span class="line">    %初始温度t</span><br><span class="line">    t=100;</span><br><span class="line">    while t&gt;1e-5</span><br><span class="line">        x=SA_metripolis(range_x,t,x,n);</span><br><span class="line">        %温度每次下降delta_t</span><br><span class="line">        t=t-delta_t;</span><br><span class="line">    end</span><br><span class="line">    value(:,i)=x;</span><br><span class="line">end</span><br><span class="line">time=toc;</span><br><span class="line">disp(['用时：',num2str(time),'秒'])</span><br><span class="line">[mini,index]=min(f(value));</span><br><span class="line">disp(['fmin=',num2str(mini)]);</span><br><span class="line">for k=1:n</span><br><span class="line">    disp(['x',num2str(k),'=',num2str(value(k,index))]);</span><br><span class="line">end</span><br><span class="line">if n==1</span><br><span class="line">    hold on;</span><br><span class="line">    plot(value(index),mini,'ro');</span><br><span class="line">    plot_x=range_x(1):(range_x(2)-range_x(1))/1000:range_x(2);</span><br><span class="line">    plot_y=f(plot_x);</span><br><span class="line">    plot(plot_x,plot_y);</span><br><span class="line">    text((range_x(1)+range_x(2))/2,max(plot_y)+0.1*(max(plot_y)-min(plot_y)),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br><span class="line">if n==2</span><br><span class="line">    %所求最小值的函数</span><br><span class="line">    func=@(x1,x2)x1.*sin(sqrt(abs(x1)))+x2.*sin(sqrt(abs(x2)));</span><br><span class="line">    plot_x=range_x(1,1):(range_x(1,2)-range_x(1,1))/1000:range_x(1,2);</span><br><span class="line">    plot_y=range_x(2,1):(range_x(2,2)-range_x(2,1))/1000:range_x(2,2);</span><br><span class="line">    [plot_x,plot_y] =meshgrid(plot_x,plot_y);</span><br><span class="line">    plot_z=func(plot_x,plot_y);</span><br><span class="line">    surf(plot_x,plot_y,plot_z);</span><br><span class="line">    xlabel('x1');</span><br><span class="line">    ylabel('x2');</span><br><span class="line">    zlabel('y');</span><br><span class="line">    hold on;</span><br><span class="line">    plot3(value(1,index),value(2,index),mini,'ko')</span><br><span class="line">    text((range_x(1,1)+range_x(1,2))/2,(range_x(2,1)+range_x(2,2))/2,max(max(plot_z))+0.5*(max(max(plot_z))-min(min(plot_z))),['用时：',num2str(time),'秒']);</span><br><span class="line">    hold off;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="SA-metripolis-m"><a href="#SA-metripolis-m" class="headerlink" title="SA_metripolis.m"></a>SA_metripolis.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function x=SA_metripolis(range_x,t,x,n)</span><br><span class="line">delta=1;</span><br><span class="line">for i=1:100</span><br><span class="line">    %产生一个随机扰动</span><br><span class="line">    x_new=(rand(n,1)-0.5)*delta+x;</span><br><span class="line">    %限制解的范围</span><br><span class="line">    for j=1:n</span><br><span class="line">        if x_new(j)&lt;range_x(j,2)</span><br><span class="line">            x_new(j)=range_x(j,2);</span><br><span class="line">        end</span><br><span class="line">        if x_new(j)&gt;range_x(j,1)</span><br><span class="line">            x_new(j)=range_x(j,1);</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    dc=f(x_new)-f(x);</span><br><span class="line">    if dc&lt;0</span><br><span class="line">        x=x_new;</span><br><span class="line">        %如果扰动的结果比原来大，则有概率的保留</span><br><span class="line">    else</span><br><span class="line">        p=exp(-dc/t);</span><br><span class="line">        if rand(1)&lt;=p</span><br><span class="line">            x=x_new;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="f-m"><a href="#f-m" class="headerlink" title="f.m"></a>f.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function res=f(x)</span><br><span class="line">func=@(x)(x).*sin(sqrt(abs(x)));</span><br><span class="line">res=zeros(1,size(x,2));</span><br><span class="line">for i=1:size(x,1)</span><br><span class="line">    res=res+func(x(i,:));</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/OPTIMIZATION/sa1.png" alt="SA"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">理论值：f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><script type="math/tex; mode=display">所求值：f(x)_{min}=f(-420.967823415805)=-418.982887164947</script><h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>计算过程简单</li>
<li>可用于求解复杂的非线性优化问题</li>
<li>相比梯度下降，增加了逃离局部最小的可能</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>参数敏感</li>
<li>收敛速度慢</li>
<li>执行时间长</li>
<li>算法性能与初始值有关</li>
<li>可能落入其他的局部最小值</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>测试函数(Test Function)</title>
    <url>/2019/05/19/optimization_Testfunction/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">测试函数说明</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>  Test Function:对于全局最优解来说，测试函数的选择是<strong>至关重要</strong>的，测试函数的好坏往往可以体现出<strong>搜索算法的优劣</strong>。有时性能一般的算法在某个特定的函数下发挥的很好，但是在别的函数下就很难搜索到全局最优解。因此我们需要设计各种测试函数，从<strong>搜索效率，搜索精度，适应程度</strong>多个方面综合比较各个算法，只有这样，在今后的使用中才能得心应手。<br><a id="more"></a></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="Function-one-m"><a href="#Function-one-m" class="headerlink" title="Function_one.m"></a>Function_one.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">f=@(x)x.*sin(sqrt(abs(x)));</span><br><span class="line">x=-5000:1:5000;</span><br><span class="line">y=f(x);</span><br><span class="line">plot(x,y)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/OPTIMIZATION/test_function1.png" alt="one"></p>
<script type="math/tex; mode=display">f(x)=x \cdot \sin(\sqrt{\lvert x \rvert}) \ , \ x \in [-500,500]</script><script type="math/tex; mode=display">f(x)_{min}=f(-420.96874592006)=-418.982887272434</script><h2 id="Function-two-m"><a href="#Function-two-m" class="headerlink" title="Function_two.m"></a>Function_two.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">f=@(x)((x+1).*(x+2).*(x+3).*(x+4).*(x+5)+5);</span><br><span class="line">x=-5:0.01:0;</span><br><span class="line">y=f(x);</span><br><span class="line">plot(x,y)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/OPTIMIZATION/test_function2.png" alt="two"></p>
<script type="math/tex; mode=display">f(x)=x \cdot (x+1) \cdot (x+2) \cdot (x+3) \cdot (x+4) \cdot (x+5) + 5 \ , \ x \in [-5,0]</script><script type="math/tex; mode=display">f(x)_{min}=f(-1.35556713184173)=1.36856779155116</script><h2 id="Function-three-m"><a href="#Function-three-m" class="headerlink" title="Function_three.m"></a>Function_three.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">f=@(x)((x+2).*cos(9*x)+sin(7*x));</span><br><span class="line">x=0:0.01:4;</span><br><span class="line">y=f(x);</span><br><span class="line">plot(x,y)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/OPTIMIZATION/test_function3.png" alt="three"></p>
<script type="math/tex; mode=display">f(x)=(x+2) \cdot \cos(9 \ x) + \sin(7 \ x) \ , \ x \in [0,4]</script><script type="math/tex; mode=display">f(x)_{min}=f(2.44888001781347)=-5.43427465397202</script><h2 id="Function-four-m"><a href="#Function-four-m" class="headerlink" title="Function_four.m"></a>Function_four.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">f=@(x)(5*exp(-0.5*x).*sin(30*x)+exp(0.2*x).*sin(20*x)+6);</span><br><span class="line">x=0:0.01:8;</span><br><span class="line">y=f(x);</span><br><span class="line">plot(x,y)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/OPTIMIZATION/test_function4.png" alt="four"></p>
<script type="math/tex; mode=display">f(x)=5 \ e^{-0.5 \ x} \cdot \sin(30 \ x) + e^{0.2 \ x} \cdot \sin(20 \ x) + 6 \ , \ x \in [0,8]</script><script type="math/tex; mode=display">f(x)_{min}=f(0.5725)=1.2573</script><script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>全局搜索方法</category>
      </categories>
  </entry>
  <entry>
    <title>聚类算法比较(Clustering Algorithms Comparison)</title>
    <url>/2019/05/17/clustering_compare/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">聚类算法比较</font></strong></center><p></p>
<h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a><font size="5" color="red">无监督学习</font></h1><p>  现实生活中常常会<strong>缺乏足够的先验知识</strong>，因此<strong>难以人工标注类别或进行人工类别标注的成本太高</strong>。很自然地，我们希望计算机能代我们完成这些工作，或至少提供一些帮助。根据<strong>类别未知(没有被标记)</strong>的训练样本解决模式识别中的各种问题，称之为<strong>无监督学习</strong>。<br><a id="more"></a></p>
<h1 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a><font size="5" color="red">算法分类</font></h1><p><img src="/images/MACHINE/compare5.png" alt="COMPARE"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><p><font size="4">所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="凝聚的层次聚类-AGNES"><a href="#凝聚的层次聚类-AGNES" class="headerlink" title="凝聚的层次聚类(AGNES)"></a><a href="https://ustccoder.github.io/2019/05/01/clustering_AGNES/">凝聚的层次聚类(AGNES)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>对噪声数据不敏感</li>
<li>算法简单，容易理解</li>
<li>不依赖初始值的选择</li>
<li>对于类别较多的训练集分类较快</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>合并操作不能撤销</li>
<li>需要在测试前知道类别的个数</li>
<li>对于类别较少的训练集分类较慢</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/agnes.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_agnes2.png" width="200" height="260"><center>圆形数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="分裂的层次聚类-DIANA"><a href="#分裂的层次聚类-DIANA" class="headerlink" title="分裂的层次聚类(DIANA)"></a><a href="https://ustccoder.github.io/2019/05/02/clustering_DIANA/">分裂的层次聚类(DIANA)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>不依赖初始值的选择</li>
<li>对于类别较少的训练集分类较快</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对噪声数据敏感</li>
<li>分裂操作不能撤销</li>
<li>需要在测试前知道类别的个数</li>
<li>对于类别较多的训练集分类较慢</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/diana.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_diana4.png" width="200" height="260"><center>混合型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="K均值聚类-K-MEANS"><a href="#K均值聚类-K-MEANS" class="headerlink" title="K均值聚类(K-MEANS)"></a><a href="https://ustccoder.github.io/2019/05/03/clustering_KMEANS/">K均值聚类(K-MEANS)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>大数据集时，对噪声数据不敏感</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对初始中心点敏感</li>
<li>需要在测试前知道类别的个数</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/kmeans.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_kmeans3.png" width="200" height="260"><center>直线型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="迭代自组织分析聚类-ISODATA"><a href="#迭代自组织分析聚类-ISODATA" class="headerlink" title="迭代自组织分析聚类(ISODATA)"></a><a href="https://ustccoder.github.io/2019/05/04/clustering_ISODATA/">迭代自组织分析聚类(ISODATA)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>大数据集时，对噪声数据不敏感</li>
<li>可以动态调整类别个数和类别中心</li>
<li>在先验知识不足的情况下有较好的分类能力</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对初始中心点敏感</li>
<li>算法复杂，分类速度较慢</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/isodata.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_isodata3.png" width="200" height="260"><center>直线型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="密度聚类-DBSCAN"><a href="#密度聚类-DBSCAN" class="headerlink" title="密度聚类(DBSCAN)"></a><a href="https://ustccoder.github.io/2019/05/05/clustering_DBSCAN/">密度聚类(DBSCAN)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>不依赖初始数据点的选择</li>
<li>可以完成任意形状的聚类</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对噪声数据敏感</li>
<li>需要在测试前确定eps和minPts</li>
<li>不适合数据集中密度差异较大的情况</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/dbscan.png" width="200" height="260"><center>圆形数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_dbscan3.png" width="200" height="260"><center>直线型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="密度最大值聚类-MDCA"><a href="#密度最大值聚类-MDCA" class="headerlink" title="密度最大值聚类(MDCA)"></a><a href="https://ustccoder.github.io/2019/05/07/clustering_MDCA/">密度最大值聚类(MDCA)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>对噪声数据不敏感</li>
<li>不依赖初始数据点的选择</li>
<li>可以完成任意形状的聚类</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>算法复杂，分类速度较慢</li>
<li>需要在测试前确定密度阈值</li>
<li>对于高维数据，距离的度量并不是很好</li>
<li>不适合数据集密度差异较大或整体密度基本相同的情况</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/mdca.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_mdca4.png" width="200" height="260"><center>混合型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="快速搜索聚类-CFDP"><a href="#快速搜索聚类-CFDP" class="headerlink" title="快速搜索聚类(CFDP)"></a><a href="https://ustccoder.github.io/2019/05/09/clustering_CFDP/">快速搜索聚类(CFDP)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>对噪声数据不敏感</li>
<li>不依赖初始数据点的选择</li>
<li>可以完成任意形状的聚类</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>离群点的确定非常复杂</li>
<li>算法复杂，分类速度较慢</li>
<li>对于高维数据，距离的度量并不是很好</li>
<li>不适合数据集整体密度基本相同的情况</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/compare_cfdp1.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_cfdp4.png" width="200" height="260"><center>混合型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="谱聚类-Spectral-Clustering"><a href="#谱聚类-Spectral-Clustering" class="headerlink" title="谱聚类(Spectral Clustering)"></a><a href="https://ustccoder.github.io/2019/05/11/clustering_SPECTRAL/">谱聚类(Spectral Clustering)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>不依赖初始数据点的选择</li>
<li>使用了降维技术，适合于高维数据的聚类</li>
<li>建立在谱图理论，能在大部分形状聚类，收敛于全局最优解</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>难以对圆形数据聚类</li>
<li>对噪声数据非常敏感</li>
<li>需要在测试前知道类别的个数</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/compare_spectral3.png" width="200" height="260"><center>直线型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/spectral.png" width="200" height="260"><center>混合型数据</center></div>
<div style="float:none;clear:both;"></div>

<h2 id="高斯混合模型聚类-GMM"><a href="#高斯混合模型聚类-GMM" class="headerlink" title="高斯混合模型聚类(GMM)"></a><a href="https://ustccoder.github.io/2019/05/12/clustering_GMM/">高斯混合模型聚类(GMM)</a></h2><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>可以完成大部分形状的聚类</li>
<li>大数据集时，对噪声数据不敏感</li>
<li>对于距离或密度聚类，更适合高维特征</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>计算复杂，速度较慢</li>
<li>难以对圆形数据聚类</li>
<li>需要在测试前知道类别的个数</li>
<li>初始化参数会对聚类结果产生影响</li>
</ul>
</font></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/compare_gmm1.png" width="200" height="260"><center>高斯型数据</center>&lt;/div&gt;</div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/compare_gmm3.png" width="200" height="260"><center>直线型数据</center></div>
<div style="float:none;clear:both;"></div>

<h1 id="特点小结"><a href="#特点小结" class="headerlink" title="特点小结"></a><font size="5" color="red">特点小结</font></h1><ul>
<li>凸型或者球形分布的数据集，绝大部分算法都是可以适用的</li>
<li>圆形分布的数据集，DBSCAN算法最为合适</li>
<li>线型分布的数据集，DBSCAN，Spectral Clustering，GMM都可以使用</li>
<li>高维特征最好使用Spectral Clustering或者GMM算法</li>
<li>密度算法大多适用于各类的密度峰值相差不大的情况</li>
<li>实际中可以通过已知的某些先验知识尝试去选择合适的算法</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>高斯混合模型聚类(GMM)</title>
    <url>/2019/05/12/clustering_GMM/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">高斯混合模型聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  GMM(Gaussian Mixture Model,):是一个将事物分解为若干的基于<strong>高斯概率密度函数（正态分布曲线）</strong>形成的模型，混合高斯分布( MoG )由多个混合成分组成，每一个混合成分对应一个高斯分布。当聚类问题中<strong>各个类别的尺寸不同</strong>、聚类间<strong>有相关关系</strong>的时候，往往使用 MoG 更合适。<a id="more"></a>对一个样本来说， MoG 得到的是<strong>其属于各个类的概率</strong>(通过计算后验概率得到)，而不是完全的属于某个类，这种聚类方法被成为<strong>软聚类</strong>。一般说来， <strong>任意形状</strong>的概率分布都可以用多个高斯分布函数去近似，因而，MoG 的应用也比较广泛。</p>
<h1 id="步骤分析"><a href="#步骤分析" class="headerlink" title="步骤分析"></a><font size="5" color="red">步骤分析</font></h1><p>  <font size="4">1. 选择高斯模型个数K，初始化参数</font></p>
<p>  <font size="4">2. 根据贝叶斯定理，求出z<sub>j</sub>的后验分布概率</font></p>
<script type="math/tex; mode=display">p(z_j=i | x_j) = \frac{\alpha_i \cdot p(x_j | \mu_i , \Sigma_i)}{\displaystyle \sum_{l=1}^k \alpha_l \cdot p(x_j | \mu_l , \Sigma_l)}</script><p>  <font size="4">3. 使用EM算法进行迭代</font></p>
<ul>
<li><p>计算均值向量：</p>
<script type="math/tex; mode=display">\mu_i '=\frac{\displaystyle \sum_{j=1}^m p(z_j=i | x_j) \cdot x_j}{\displaystyle \sum_{j=1}^m p(z_j=i | x_j)}</script></li>
<li><p>计算协方差矩阵：</p>
<script type="math/tex; mode=display">\Sigma_i '=\frac{\displaystyle \sum_{j=1}^m p(z_j=i | x_j) \ (x_j - \mu_i ') \ (x_j - \mu_i ')^T}{\displaystyle \sum_{j=1}^m p(z_j=i | x_j)}</script></li>
<li><p>计算混合系数：</p>
<script type="math/tex; mode=display">\alpha_i '=\frac{\displaystyle \sum_{j=1}^m p(z_j=i | x_j)}{m}</script></li>
</ul>
<p>  <font size="4">4. 重复步骤1，2，直到满足某个终止条件</font></p>
<p>  <font size="4">5. 定义高斯混合分布</font><br>  根据所求得的均值向量，协方差矩阵和混合系数可以定义如下函数：</p>
<script type="math/tex; mode=display">p(x)=\displaystyle \sum_{l=1}^k \alpha_i \cdot p(x | \mu_i , \Sigma_i) \ , \ s.t. \displaystyle \sum_{l=1}^k \alpha_i=1</script><p><img src="/images/MACHINE/gmm5.png" alt="GMM"></p>
<p>  <font size="4">6. 对样本进行标记</font></p>
<script type="math/tex; mode=display">\lambda_j=\underset{i \in \{ 1,2, \cdots ,k\}}{arg\ max} \ p(z_j=i | x_j)</script><h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/gmm9.png" alt="GMM"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="GMM-main-m"><a href="#GMM-main-m" class="headerlink" title="GMM_main.m"></a>GMM_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_mixture.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%混合高斯个数</span><br><span class="line">class_num=3;</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">y=GMM_classify(x_scale,sample_num,class_num,feat_num);</span><br><span class="line">% 如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    GMM_display(x,y,sample_num,class_num);</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="GMM-classify-m"><a href="#GMM-classify-m" class="headerlink" title="GMM_classify.m"></a>GMM_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function y=GMM_classify(x_scale,sample_num,class_num,feat_num)</span><br><span class="line">%初始化均值向量,协方差矩阵，混合系数</span><br><span class="line">a=ones(1,class_num)/class_num;</span><br><span class="line">u=zeros(feat_num,class_num);</span><br><span class="line">sigma=zeros(feat_num,feat_num,class_num);</span><br><span class="line">randIndex = randperm(size(x_scale,2));</span><br><span class="line">u(:,1:class_num)=x_scale(:,randIndex(1:class_num));</span><br><span class="line">for i=1:class_num</span><br><span class="line">    sigma(:,:,i)=eye(feat_num)/10;</span><br><span class="line">end</span><br><span class="line">for t=1:50</span><br><span class="line">    %判断sigma是否正定</span><br><span class="line">    if sum(sum(sum(isnan(sigma))))&gt;0||sum(sum(sum(isinf(sigma))))&gt;0</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">    pm_x=zeros(1,sample_num);</span><br><span class="line">    %计算每个样本的全概率</span><br><span class="line">    for i=1:sample_num</span><br><span class="line">        tem=0;</span><br><span class="line">        for j=1:class_num</span><br><span class="line">            tem=tem+a(j)*mvnpdf(x_scale(:,i), u(:,j), sigma(:,:,j));</span><br><span class="line">        end</span><br><span class="line">        pm_x(i)=tem;</span><br><span class="line">    end</span><br><span class="line">    %计算第i个样本属于第j类的后验概率</span><br><span class="line">    pm=zeros(sample_num,class_num);</span><br><span class="line">    for i=1:sample_num</span><br><span class="line">        for j=1:class_num</span><br><span class="line">            pm(i,j)=a(j)*mvnpdf(x_scale(:,i), u(:,j), sigma(:,:,j))/pm_x(i);</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    %计算均值向量,协方差矩阵，混合系数</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        sum_pm=sum(pm(:,i));</span><br><span class="line">        u(:,i)=sum(repmat(pm(:,i)',feat_num,1).*x_scale,2)/sum_pm;</span><br><span class="line">        for j=1:sample_num</span><br><span class="line">            sigma(:,:,i)=sigma(:,:,i)+pm(j,i)*(x_scale(:,j)-u(:,i))*(x_scale(:,j)-u(:,i))';</span><br><span class="line">        end</span><br><span class="line">        sigma(:,:,i)=sigma(:,:,i)/sum_pm;</span><br><span class="line">        a(i)=sum_pm/sample_num;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%把每个样本中混合系数最大的一个类别作为其标签</span><br><span class="line">[~,y]=max(pm,[],2);</span><br></pre></td></tr></tbody></table></figure>
<h2 id="GMM-display-m"><a href="#GMM-display-m" class="headerlink" title="GMM_display.m"></a>GMM_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function GMM_display(x,y,sample_num,class_num)</span><br><span class="line">figure;</span><br><span class="line">hold on;</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    if y(i)==0</span><br><span class="line">        %画出噪声点，用*表示</span><br><span class="line">        plot(x(1,i),x(2,i),'k*')</span><br><span class="line">    else</span><br><span class="line">        %画出每一类的样本数据，用o表示</span><br><span class="line">        plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/gmm.png" alt="GMM"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>可以完成大部分形状的聚类</li>
<li>大数据集时，对噪声数据不敏感</li>
<li>对于距离或密度聚类，更适合高维特征</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>计算复杂，速度较慢</li>
<li>难以对圆形数据聚类</li>
<li>需要在测试前知道类别的个数</li>
<li>初始化参数会对聚类结果产生影响</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>谱聚类(Spectral Clustering)</title>
    <url>/2019/05/11/clustering_SPECTRAL/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">谱聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  Spectral Clustering:是一种基于<strong>图论</strong>的聚类算法，第一步是<strong>构图</strong>：将数据集中的每个对象看做空间中的点V，将这些点之用边E连接起来，距离较远的两个点之间的边权重值较低、距离较近的两个点之间的边权重值较高，这样就构成了一个<strong>基于相似度的无向权重图G(V,E)</strong>。第二步是<strong>切图</strong>：按照一定的切边规则将图切分为不同的子图，规则是使子图内的边权重和尽可能大，不同子图间的边权重和尽可能小，从而达到聚类目的。</p>
<a id="more"></a>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 邻接矩阵W的构建</font></p>
<script type="math/tex; mode=display">w_{ij}=\begin{cases}exp(-\frac{\lVert x_i-x_j \rVert ^2}{2 \sigma ^2})  & i \neq j \\\\[2ex] 0 & i=j \end{cases}</script><p>  <font size="4">2. 度矩阵W的构建</font></p>
<script type="math/tex; mode=display">d_{ij}=\begin{cases}0  & i \neq j \\\\[2ex] \displaystyle \sum_{j=1} w_{ij} & i=j \end{cases}</script><p>  <font size="4">3. 目标函数</font></p>
<ul>
<li><p>权重切图</p>
<script type="math/tex; mode=display">W(A,B)=\displaystyle \sum_{i \in A, j \in B} w_{ij}</script></li>
<li><p>Ncut切图<br>\begin{align}<br>Ncut(A<em>1,A_2, \cdots ,A_n) &amp;=\displaystyle \sum</em>{i=1}^n \frac{W(A<em>i, \overline {A_i})}{\displaystyle \sum</em>{j \in A<em>i} \displaystyle \sum</em>{k=1} w_{jk}} \\<br>&amp;=\underset{F}{\underbrace{arg\ min}}\ {tr(F^TD^{-1/2}LD^{-1/2}F)} \ , \ s.t. \ H^TDH=\mathrm{I}<br>\end{align}</p>
</li>
</ul>
<p>  <font size="4">4. 求标准化拉普拉斯矩阵</font></p>
<script type="math/tex; mode=display">L_{sym}=D^{-1/2}LD^{-1/2}=D^{-1/2}(D-W)D^{-1/2}</script><p>  <font size="4">5. 取前K个特征值对应的特征向量</font></p>
<p>  <font size="4">6. 用K-Means对归一化的特征向量进行分类</font></p>
<p>  <font size="4">7. 一个便于理解的实例</font><br><img src="/images/MACHINE/spectral2.png" alt="SPECTRAL"></p>
<script type="math/tex; mode=display">x=\begin{bmatrix} 0.7 & 0.8 & 0.1 & 0.4 & 0.2 & 0.5 & 0.6 \\\\ 0.5 & 0.6 & 0.1 & 0.8 & 0.2 & 0.8 & 0.7 \end{bmatrix}</script><p><br><br></p>
<script type="math/tex; mode=display">w=\begin{bmatrix} 0 & 0.990 & 0.771 & 0.914 & 0.844 & 0.937 & 0.975 \\\\ 0.990 & 0 & 0.691 & 0.905 & 0.771 & 0.937 & 0.975 \\\\ 0.771 & 0.691 & 0 & 0.748 & 0.990 & 0.723 & 0.737 \\\\ 0.914 & 0.905 & 0.748 & 0 & 0.819 & 0.995 & 0.975 \\\\ 0.844 & 0.771 & 0.990 & 0.819 & 0 & 0.799 & 0.815 \\\\ 0.937 & 0.937 & 0.723 & 0.995 & 0.799 & 0 & 0.990 \\\\ 0.975 & 0.975 & 0.737 & 0.975 & 0.815 & 0.990 & 0 \end{bmatrix}</script><p><br><br></p>
<script type="math/tex; mode=display">d=\begin{bmatrix} 5.43 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 5.27 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 4.66 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 5.36 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 5.04 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 5.38 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 5.47 \end{bmatrix}</script><p><br><br></p>
<script type="math/tex; mode=display">L_{sym}=\begin{bmatrix} 1 & -0.185 & -0.153 & -0.169 & -0.161 & -0.173 & -0.179 \\\\ -0.185 & 1 & -0.139 & -0.170 & -0.150 & -0.176 & -0.182 \\\\ -0.153 & -0.139 & 1 & -0.150 & -0.204 & -0.144 & -0.146 \\\\ -0.169 & -0.170 & -0.150 & 1 & -0.158 & -0.185 & -0.180 \\\\ -0.161 & -0.150 & -0.204 & -0.158 & 1 & -0.153 & -0.155 \\\\ -0.173 & -0.176 & -0.144 & -0.185 & -0.153 & 1 & -0.183 \\\\ -0.179 & -0.182 & -0.146 & -0.180 & -0.155 & -0.183 & 1 \end{bmatrix}</script><p><br><br></p>
<script type="math/tex; mode=display">feat\_value=\begin{bmatrix} 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1.080 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1.159 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1.205 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1.183 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 1.187 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1.186 \end{bmatrix}</script><p><br><br></p>
<script type="math/tex; mode=display">feat\_vector=\begin{bmatrix} -0.385 & -0.141 & 0.535 & -0.004 & 0.371 & 0.534 & -0.349 \\\\  -0.379 & -0.302 & 0.470 & -0.040 & 0.042 & -0.691 & 0.249 \\\\  -0.357 & 0.642 & -0.005 & -0.675 & -0.031 & -0.033 & 0.051 \\\\  -0.383 & -0.178 & -0.575 & -0.004 & 0.246 & -0.299 & -0.584 \\\\  -0.371 & 0.558 & 0.010 & 0.736 & -0.036 & -0.053 & 0.070 \\\\  -0.383 & -0.261 & -0.400 & -0.019 & 0.264 & 0.314 & 0.676 \\\\  -0.387 & -0.256 & -0.034 & -0.017 & -0.853 & 0.213 & -0.104 \end{bmatrix}</script><p>  <font size="4">取最小的两个特征值对应的特征向量可得：</font></p>
<script type="math/tex; mode=display">feature\_vector=\begin{bmatrix} -0.385 & -0.141 \\\\  -0.379 & -0.302 \\\\  -0.357 & 0.642 \\\\  -0.383 & -0.178 \\\\  -0.371 & 0.558 \\\\  -0.383 & -0.261 \\\\  -0.387 & -0.256 \end{bmatrix}</script><p>  <font size="4">特征向量按行归一化：</font></p>
<script type="math/tex; mode=display">feature\_vector=\begin{bmatrix} -0.939 & -0.344 \\\\ -0.782 & -0.623 \\\\ -0.486 & 0.874 \\\\ -0.907 & -0.422 \\\\ -0.553 & 0.833 \\\\ -0.827 & -0.563 \\\\ -0.834 & -0.552 \end{bmatrix}</script><p>  <font size="4">可以明显看出：${x_1,x_2,x_4,x_6,x_7} \in A_1\ ,\ {x_3,x_5} \in A_2$</font><br><img src="/images/MACHINE/spectral3.png" alt="SPECTRAL"></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/spectral9.png" alt="SPECTRAL"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="SPECTRAL-main-m"><a href="#SPECTRAL-main-m" class="headerlink" title="SPECTRAL_main.m"></a>SPECTRAL_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\\\cluster_mixture.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%希望划分的类别数</span><br><span class="line">class_num=3;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">y=SPECTRAL_classify(x_scale,sample_num,class_num);</span><br><span class="line">%如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    SPECTRAL_display(x,y,sample_num,class_num);</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="SPECTRAL-classify-m"><a href="#SPECTRAL-classify-m" class="headerlink" title="SPECTRAL_classify.m"></a>SPECTRAL_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function y=SPECTRAL_classify(x_scale,sample_num,class_num)</span><br><span class="line">%w为邻接矩阵</span><br><span class="line">w=zeros(sample_num);</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    w(i,:)=exp(-sum((x_scale-repmat(x_scale(:,i),1,sample_num)).^2)/2);</span><br><span class="line">    w(i,i)=0;</span><br><span class="line">end</span><br><span class="line">%D为度矩阵</span><br><span class="line">d=diag(sum(w,2));</span><br><span class="line">%标准化拉普拉斯矩阵</span><br><span class="line">l=d^(-0.5)*(d-w)*d^(-0.5);</span><br><span class="line">%求特征向量和特征值</span><br><span class="line">[feat_vector,feat_value_temp]=eig(l);</span><br><span class="line">feat_value=diag(feat_value_temp);</span><br><span class="line">temp=sort(feat_value);</span><br><span class="line">loc=feat_value&lt;=temp(class_num);</span><br><span class="line">%求出最小的class_num个特征向量</span><br><span class="line">class_feat_vector=feat_vector(:,loc);</span><br><span class="line">%特征向量归一化</span><br><span class="line">class_feat_vector=class_feat_vector./repmat(sqrt(sum(class_feat_vector.^2,2)),1,class_num);</span><br><span class="line">%利用kmeans进行分类</span><br><span class="line">y=SPECTRAL_kmeans(class_feat_vector',sample_num,class_num);</span><br></pre></td></tr></tbody></table></figure>
<h2 id="SPECTRAL-display-m"><a href="#SPECTRAL-display-m" class="headerlink" title="SPECTRAL_display.m"></a>SPECTRAL_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function SPECTRAL_display(x,y,sample_num,class_num)</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">hold on;</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    %绘制数据集，用o表示</span><br><span class="line">    plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<h2 id="SPECTRAL-kmeans-m"><a href="#SPECTRAL-kmeans-m" class="headerlink" title="SPECTRAL_kmeans.m"></a>SPECTRAL_kmeans.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function y=SPECTRAL_kmeans(class_feat_vector,sample_num,class_num)</span><br><span class="line">%类别中心位置</span><br><span class="line">loc_center=class_feat_vector(:,1:class_num);</span><br><span class="line">%设置迭代次数</span><br><span class="line">k=0;</span><br><span class="line">while 1</span><br><span class="line">    %初始化最新的分类中心</span><br><span class="line">    loc_center_new=zeros(size(loc_center));</span><br><span class="line">    distance=zeros(class_num,sample_num);</span><br><span class="line">    %distance为每一个样本到每一类的距离</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        distance(i,:)=sum((class_feat_vector-repmat(loc_center(:,i),1,sample_num)).^2);</span><br><span class="line">    end</span><br><span class="line">    %求出每个样本到哪一类最近</span><br><span class="line">    [~,y]=min(distance);</span><br><span class="line">    %更新分类中心</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        loc_center_new(:,i)=sum(class_feat_vector(:,y==i),2)/sum(y==i);</span><br><span class="line">    end</span><br><span class="line">    %如果分类中心和上一次分类中心相等则分类完毕</span><br><span class="line">    if isequal(loc_center_new,loc_center)</span><br><span class="line">        break;</span><br><span class="line">    %否则继续分类</span><br><span class="line">    else</span><br><span class="line">        loc_center=loc_center_new;</span><br><span class="line">        k=k+1;</span><br><span class="line">        %如果分类次数达到1000仍然没有结束，则强制分类结束</span><br><span class="line">        if k&gt;=1000</span><br><span class="line">            break;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/spectral.png" alt="SPECTRAL"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>不依赖初始数据点的选择</li>
<li>使用了降维技术，适合于高维数据的聚类</li>
<li>建立在谱图理论，能在大部分形状聚类，收敛于全局最优解</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>难以对圆形数据聚类</li>
<li>对噪声数据非常敏感</li>
<li>需要在测试前知道类别的个数</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>快速搜索聚类(CFDP)</title>
    <url>/2019/05/09/clustering_CFDP/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">快速搜索聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  CFDP(Clustering By Fast Search And Find Of Density Peaksd):经典的聚类算法K-means不能检测非球面类别的数据分布，DBSCAN必须指定一个密度阈值，CFDP通过对两种方法的改善，选择每个区域密度最大值，根据密度选择周围点的归属。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 求出每个点的密度ρ<sub>i</sub>(多种定义方法)</font></p>
<ul>
<li>k近邻均值倒数<script type="math/tex; mode=display">\rho_i = \frac{k}{\displaystyle \sum_{j=1}^k d_{ij}} \ , \ d_{i1} \leq d_{i2} \leq \cdots \leq d_{in}</script></li>
<li>高斯核相似度<script type="math/tex; mode=display">\rho_i = \underset{d_{ij} \leq d_c}{\sum}exp[-(\frac{d_{ij}}{d_c})^2]</script></li>
<li>周围点的个数<script type="math/tex; mode=display">\rho_i = \sum_{j=1}^n {\chi(d_{ij}-d_c)} \ , \ \chi(x)= \begin{cases} 1, & x<0 \\[2ex] 0, & otherwise \end{cases} \ , \ 其中d_c为截断距离</script></li>
</ul>
<p>  <font size="4">2. 密度从大到小排序，并求出最大密度ρ<sub>max</sub></font></p>
<script type="math/tex; mode=display">\rho_{x_1} \ge \rho_{x_2} \ge \cdots \ge \rho_{x_n} \ , \ \rho_{max} = \rho_{x_1}</script><ul>
<li>d<sub>ij</sub>:原序列i，j样本的距离</li>
<li>d(x<sub>i</sub>,x<sub>j</sub>):密度排序后，x<sub>i</sub>和x<sub>j</sub>样本的距离</li>
</ul>
<p>  <font size="4">3. 求出每个点的距离δ<sub>i</sub></font><br>  δ<sub>i</sub>：到密度大于i的最近点j的距离dist(ij)</p>
<script type="math/tex; mode=display">\delta_{x_i} = \begin{cases} \underset{j<i}{min}\ d(x_i,x_j) &  i \ge 2  \\[2ex] \underset{j \ge 2}{\max}\ \delta_{x_j} & i=1 \end{cases}</script><p>  <font size="4">4. 画出ρ-δ图，找到离群点(代表每一类的中心)</font><br><img src="/images/MACHINE/cfdp1.png" alt="CFDP"></p>
<p>  <font size="4">5. 按密度从大到小归属于距离最近点的类别</font></p>
<script type="math/tex; mode=display">x_i \in C_k \ , \ 其中k=\underset{j<i \ , \ x_j \in C_k}{arg \ min}\ d(x_i,x_j)</script><p>  <font size="4">6. 定义两类之间的最小距离d<sub>0</sub></font><br>  两类的最小距离：所有样本之间距离从小到大排序后第2%个称两类的最小距离。</p>
<p>  <font size="4">7. 定义边缘点，求出边缘点最大密度ρ<sub>b</sub></font><br>  边缘点：在k类数据到非k类数据的最小距离小于dist<sub>0</sub>的点，称为k类数据的边缘点。</p>
<script type="math/tex; mode=display">E = \{i | d_{ij}<dist_0 , \forall i \in C_k , j \in \overline{C_k} \}</script><script type="math/tex; mode=display">\rho_b = \underset{i \in E}{\max}\ \rho_i</script><p>  <font size="4">8. 判断噪声点</font><br>  噪声点：将k类中密度小于ρ<sub>b</sub>的所有数据记为噪声。</p>
<script type="math/tex; mode=display">N=\{i | \rho_i<\rho_b , \forall i \in C_k  \}</script><h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/cfdp9.png" alt="CFDP"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="CFDP-main-m"><a href="#CFDP-main-m" class="headerlink" title="CFDP_main.m"></a>CFDP_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_line.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%判断密度时检测周围点的个数</span><br><span class="line">k=round(sample_num/10);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">[y,density_max]=CFDP_classify(x_scale,sample_num,k);</span><br><span class="line">% 如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    CFDP_display(x,y,sample_num,density_max)</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="CFDP-classify-m"><a href="#CFDP-classify-m" class="headerlink" title="CFDP_classify.m"></a>CFDP_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,density_max]=CFDP_classify(x_scale,sample_num,k)</span><br><span class="line">y=zeros(1,sample_num);</span><br><span class="line">%p为每个样本的密度</span><br><span class="line">p=zeros(1,sample_num);</span><br><span class="line">%deta为高密度距离</span><br><span class="line">deta=zeros(1,sample_num);</span><br><span class="line">%distance(i,j)代表第i个样本到第j个样本的距离</span><br><span class="line">distance=zeros(sample_num);</span><br><span class="line">%利用k近邻均值定义密度较好，不会出现很多密度相同的点。如果采用半径内个数的定义方法，可能一块区域会出现很多的类别</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    distance(i,:)=sum((x_scale-repmat(x_scale(:,i),1,sample_num)).^2);</span><br><span class="line">    temp=sort(distance(i,:));</span><br><span class="line">    p(i)=k./sum(distance(i,distance(i,:)&lt;=temp(k)));</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    temp=find(p&gt;p(i));</span><br><span class="line">    %如果有多个最大点</span><br><span class="line">    if isempty(temp)</span><br><span class="line">        deta(i)=distance(i,find(p==max(p),1));</span><br><span class="line">    else</span><br><span class="line">        %找到密度大于该点的且距离该点最近的点</span><br><span class="line">        tem=find(distance(i,p&gt;p(i))==min(distance(i,p&gt;p(i))),1);</span><br><span class="line">        deta(i)=distance(i,temp(tem));</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%密度最大点赋值无穷   </span><br><span class="line">deta(find(p==max(p),1))=1;</span><br><span class="line">p_judge=max(p)/5;</span><br><span class="line">deta_judge=0.1;</span><br><span class="line">%获取类别的中心</span><br><span class="line">center_loc=p&gt;p_judge&amp;deta&gt;deta_judge;</span><br><span class="line">%找到类别中心所在位置</span><br><span class="line">density_max=find(center_loc);</span><br><span class="line">%将p和deta较大的值作为新的聚类中心</span><br><span class="line">y(center_loc)=1:sum(center_loc);</span><br><span class="line">%对密度从大到小排序</span><br><span class="line">[~,density_loc]=sort(p,'descend');</span><br><span class="line">%将某点划分到密度大于该点并且距离该点最近的一类</span><br><span class="line">for i=2:sample_num</span><br><span class="line">    if y(density_loc(i))==0</span><br><span class="line">        temp=density_loc(1:i-1);</span><br><span class="line">        y(density_loc(i))=y(temp(find(distance(density_loc(i),temp)==min(distance(density_loc(i),temp)),1)));</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%定义两类之间的最小距离</span><br><span class="line">distance_temp=distance.*triu(ones(sample_num));</span><br><span class="line">temp=sort(distance_temp(distance_temp&gt;0));</span><br><span class="line">%取出前%2的距离作为最小距离</span><br><span class="line">dc=temp(round(length(temp)/50));</span><br><span class="line">for i=1:sum(center_loc)</span><br><span class="line">    %得到边缘点</span><br><span class="line">    edge= min(distance(y==i,y~=i),[],2)&lt;dc;</span><br><span class="line">    if ~(isempty(edge)||isequal(edge,zeros(length(find(y==i)),1)))</span><br><span class="line">        tem=find(y==i);</span><br><span class="line">        %得到边缘区域密度最大的值</span><br><span class="line">        pb=max(p(tem(edge)));</span><br><span class="line">        %将密度小于该最大值的点作为噪声点</span><br><span class="line">        y(tem(p(y==i)&lt;=pb))=0;</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="CFDP-display-m"><a href="#CFDP-display-m" class="headerlink" title="CFDP_display.m"></a>CFDP_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function CFDP_display(x,y,sample_num,density_max)</span><br><span class="line">color_bar=zeros(length(density_max),3);</span><br><span class="line">hold on;</span><br><span class="line">for i=1:length(density_max)</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    if y(i)==0</span><br><span class="line">        plot(x(1,i),x(2,i),'ko');</span><br><span class="line">    else</span><br><span class="line">        if ismember(i,density_max)</span><br><span class="line">            plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','*');</span><br><span class="line">        else</span><br><span class="line">            plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/cfdp.png" alt="CFDP"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>对噪声数据不敏感</li>
<li>不依赖初始数据点的选择</li>
<li>可以完成任意形状的聚类</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>离群点的确定非常复杂</li>
<li>算法复杂，分类速度较慢</li>
<li>对于高维数据，距离的度量并不是很好</li>
<li>不适合数据集整体密度基本相同的情况</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>密度最大值聚类(MDCA)</title>
    <url>/2019/05/07/clustering_MDCA/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">密度最大值聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  MDCA(Maximum Density Clustering Application):将基于密度的思想引入到划分聚类中，使用<strong>密度</strong>而不是初始质心作为考察簇归属情况的依据，能够<strong>自动确定</strong>簇数量并发现任意形状的簇。MDCA一般不保留噪声，因此也避免了由于阈值选择不当而造成大量对象丢弃情况。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1.最大密度点：可用K近邻距离之和的倒数表示密度</font></p>
<script type="math/tex; mode=display">\rho_{max}=\{ \rho_{x} | x \in C, \forall x_i \in C, \rho_(x) \ge \rho_(x_i) \} \ , \ 其中C为数据集</script><p>  <font size="4">2. 密度曲线：根据所有对象与x的欧式距离对数据集重新排序</font></p>
<script type="math/tex; mode=display">S_{\rho_{max}}=\{x_1 , x_2 , \cdots , x_n | d(x,x_1) \leq d(x,x_2) \leq \cdots \leq d(x,x_n) \}</script><p><img src="/images/MACHINE/mdca1.png" alt="MDCA"></p>
<p>  <font size="4">3. 将密度曲线中第一个谷值之前的数据归为一类，并将其剔除</font></p>
<p>  <font size="4">4. 重复步骤1，2，3直到所有的点都在ρ<sub>0</sub>之下或者ρ<sub>0</sub>之上</font></p>
<p>  <font size="4">5. 两个簇C<sub>i</sub>和C<sub>j</sub>，用最近样本距离作为簇间距离</font></p>
<script type="math/tex; mode=display">d(c_i,c_j)=\underset{x_i \in C_i,x_j \in C_j}{\min}d(x_i,x_j)</script><p><img src="/images/MACHINE/mdca2.png" alt="MDCA"></p>
<p>  <font size="4">6. 根据簇间距离阈值d<sub>0</sub>，判断是否需要合并两类</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/mdca9.png" alt="MDCA"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="MDCA-main-m"><a href="#MDCA-main-m" class="headerlink" title="MDCA_main.m"></a>MDCA_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_gauss.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%判断密度时检测周围点的个数</span><br><span class="line">k=5;</span><br><span class="line">%最小阈值密度</span><br><span class="line">density_min=25000;</span><br><span class="line">%最小阈值距离</span><br><span class="line">distance_min=0.1;</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">[y,class_num]=MDCA_classify(x_scale,sample_num,k,density_min,distance_min);</span><br><span class="line">% 如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    MDCA_display(x,y,sample_num,class_num);</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="MDCA-classify-m"><a href="#MDCA-classify-m" class="headerlink" title="MDCA_classify.m"></a>MDCA_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,class_num]=MDCA_classify(x_scale,sample_num,k,density_min,distance_min)</span><br><span class="line">class_num=1;</span><br><span class="line">y=zeros(1,sample_num);</span><br><span class="line">%p为每个样本的密度</span><br><span class="line">p=zeros(1,sample_num);</span><br><span class="line">%distance(i,j)代表第i个样本到第j个样本的距离</span><br><span class="line">distance=zeros(sample_num);</span><br><span class="line">%利用k近邻均值定义密度较好，不会出现很多密度相同的点。如果采用半径内个数的定义方法，可能一块区域会出现很多的类别</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    distance(i,:)=sum((x_scale-repmat(x_scale(:,i),1,sample_num)).^2);</span><br><span class="line">    temp=sort(distance(i,:));</span><br><span class="line">    p(i)=k./sum(distance(i,distance(i,:)&lt;=temp(k)));</span><br><span class="line">end        </span><br><span class="line">[y,class_num]=MDCA_findclass(y,p,distance,density_min,class_num);    </span><br><span class="line">%设置两个标置位</span><br><span class="line">while 1</span><br><span class="line">    flag_2=0;</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        flag_1=0;</span><br><span class="line">        for j=i+1:class_num</span><br><span class="line">            if min(min(distance(y==i,y==j)))&lt;=distance_min</span><br><span class="line">                y(y==j)=i;</span><br><span class="line">                y(y&gt;j)=y(y&gt;j)-1;</span><br><span class="line">                class_num=class_num-1;</span><br><span class="line">                flag_1=1;</span><br><span class="line">                break;</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        if flag_1==1;</span><br><span class="line">            break;</span><br><span class="line">        end</span><br><span class="line">        flag_2=1;</span><br><span class="line">    end</span><br><span class="line">    if flag_2==1</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">loc=find(y~=0);</span><br><span class="line">[temp,tem]=min(distance(y==0,y~=0),[],2);</span><br><span class="line">y(y==0)=y(loc(tem)).*(temp&lt;=distance_min)';</span><br></pre></td></tr></tbody></table></figure>
<h2 id="MDCA-findclass-m"><a href="#MDCA-findclass-m" class="headerlink" title="MDCA_findclass.m"></a>MDCA_findclass.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,class_num]=MDCA_findclass(y,p,distance,density_min,class_num)</span><br><span class="line">tem=find(y==0);</span><br><span class="line">p_temp=p(tem);</span><br><span class="line">%找到最大的密度点</span><br><span class="line">p_max=tem(find(p_temp==max(p_temp),1));</span><br><span class="line">%按照到最大密度点的距离从小到大排序</span><br><span class="line">[~,b]=sort(distance(p_max,tem));</span><br><span class="line">temp=tem(b);</span><br><span class="line">curve=p(temp);</span><br><span class="line">if max(curve)&gt;density_min</span><br><span class="line">    loc=find(curve&lt;=density_min);</span><br><span class="line">    if ~isempty(loc)&amp;&amp;length(loc)&gt;=2</span><br><span class="line">        for i=1:length(loc)-1</span><br><span class="line">            if loc(i+1)-loc(i)&lt;=2</span><br><span class="line">                break;</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        y(temp(1:loc(i)))=class_num;</span><br><span class="line">        [y,class_num]=MDCA_findclass(y,p,distance,density_min,class_num+1);</span><br><span class="line">        return;</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="MDCA-display-m"><a href="#MDCA-display-m" class="headerlink" title="MDCA_display.m"></a>MDCA_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function MDCA_display(x,y,sample_num,class_num)</span><br><span class="line">figure;</span><br><span class="line">hold on;</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    if y(i)==0</span><br><span class="line">        %画出噪声点，用*表示</span><br><span class="line">        plot(x(1,i),x(2,i),'k*')</span><br><span class="line">    else</span><br><span class="line">        %画出每一类的样本数据，用o表示</span><br><span class="line">        plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/mdca.png" alt="MDCA"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>对噪声数据不敏感</li>
<li>不依赖初始数据点的选择</li>
<li>可以完成任意形状的聚类</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>算法复杂，分类速度较慢</li>
<li>需要在测试前确定密度阈值</li>
<li>对于高维数据，距离的度量并不是很好</li>
<li>不适合数据集密度差异较大或整体密度基本相同的情况</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>密度聚类(DBSCAN)</title>
    <url>/2019/05/05/clustering_DBSCAN/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">密度聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  DBSCAN(Density-Based Spatial Clustering Of Applications With Noise):DBSCAN需要两个参数，<strong>扫描半径 </strong>(eps)和<strong>最小包含点数</strong>(minPts)。 任选一个未被标记的点开始，找出与其距离在eps之内(包括eps)的所有附近点。如果<strong>附近点的数量大于等于minPts</strong>，则当前点与其附近点形成一个簇，并且出发点被标记。 然后递归，以相同的方法处理该簇内所有未被标记的点，从而对簇进行扩展。如果<strong>附近点的数量小于minPts</strong>，则该点被标记，不作扩展。如果簇充分地被扩展，即簇内的所有点被标记为已访问，然后用同样的算法去处理未被访问的点，直到所有的点都被标记。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 挑选一个未标记样本，置为一类，搜索附近样本</font><br><img src="/images/MACHINE/dbscan1.jpg" alt="DBSCAN"></p>
<p>  <font size="4">2. 如果附近样本数大于minPts，将这些样本归于该类，在此类中挑选未标记样本，继续搜索附近样本</font><br><img src="/images/MACHINE/dbscan2.png" alt="DBSCAN"></p>
<p>  <font size="4">3. 重复步骤2，直到该类中所有样本都被标记</font></p>
<p>  <font size="4">4. 重复步骤1，直到所有样本都被标记</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/dbscan9.png" alt="DBSCAN"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="DBSCAN-main-m"><a href="#DBSCAN-main-m" class="headerlink" title="DBSCAN_main.m"></a>DBSCAN_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_cicle.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%搜索半径</span><br><span class="line">eps=0.05;</span><br><span class="line">%圆内点数</span><br><span class="line">minpts=2;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">[y,color_bar]=DBSCAN_classify(x_scale,sample_num,eps,minpts);</span><br><span class="line">%如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    DBSCAN_display(x,y,color_bar,sample_num)</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="DBSCAN-classify-m"><a href="#DBSCAN-classify-m" class="headerlink" title="DBSCAN_classify.m"></a>DBSCAN_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,color_bar]=DBSCAN_classify(x_scale,sample_num,eps,minpts)</span><br><span class="line">%标记是否已经分过类</span><br><span class="line">flag=zeros(1,sample_num);</span><br><span class="line">y=zeros(1,sample_num);</span><br><span class="line">color_bar=[];</span><br><span class="line">%类别数目</span><br><span class="line">i=1;</span><br><span class="line">%找到未标记的数据点则继续循环</span><br><span class="line">while ~isempty(find(flag==0,1))</span><br><span class="line">    %求出该点C到其余各点的距离</span><br><span class="line">    distance=sum((x_scale-repmat(x_scale(:,find(flag==0,1)),1,sample_num)).^2);</span><br><span class="line">    %将找到的点标记</span><br><span class="line">    flag(find(flag==0,1))=1;</span><br><span class="line">    %找出距离找到的点小于半径的所有点</span><br><span class="line">    temp=find(distance&lt;eps^2);</span><br><span class="line">    %如果个数大于等于设定的个数</span><br><span class="line">    if length(temp)&gt;=minpts</span><br><span class="line">        %建立一个类别的颜色信息</span><br><span class="line">        color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">        %将这些点全部分为i类</span><br><span class="line">        y(temp)=i;</span><br><span class="line">        %找出i类中没有标记的点则继续循环</span><br><span class="line">        while ~isempty(find(y==i&amp;flag==0,1))</span><br><span class="line">            %求出该点D到其余各点的距离</span><br><span class="line">            distance_part=sum((x_scale-repmat(x_scale(:,find(y==i&amp;flag==0,1)),1,sample_num)).^2);</span><br><span class="line">            %将找到的点标记</span><br><span class="line">            flag(find(y==i&amp;flag==0,1))=1;</span><br><span class="line">            %找出距离找到的点小于半径的所有点</span><br><span class="line">            temp_part=find(distance_part&lt;eps^2);</span><br><span class="line">            %如果个数大于等于设定的个数,</span><br><span class="line">            if length(temp_part)&gt;=minpts</span><br><span class="line">                %将这些点全部分为i类</span><br><span class="line">                y(temp_part)=i;</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">    else</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %这一类找完时，类别加1</span><br><span class="line">    i=i+1;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="DBSCAN-display-m"><a href="#DBSCAN-display-m" class="headerlink" title="DBSCAN_display.m"></a>DBSCAN_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function DBSCAN_display(x,y,color_bar,sample_num)</span><br><span class="line">figure;</span><br><span class="line">hold on;</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    if y(i)==0</span><br><span class="line">        %画出噪声点，用*表示</span><br><span class="line">        plot(x(1,i),x(2,i),'k*')</span><br><span class="line">    else</span><br><span class="line">        %画出每一类的样本数据，用o表示</span><br><span class="line">        plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/dbscan.png" alt="DBSCAN"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>不依赖初始数据点的选择</li>
<li>可以完成任意形状的聚类</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对噪声数据敏感</li>
<li>需要在测试前确定eps和minPts</li>
<li>不适合数据集中密度差异较大的情况</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>迭代自组织分析聚类(ISODATA)</title>
    <url>/2019/05/04/clustering_ISODATA/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">迭代自组织分析聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  ISODATA(Iterative Selforganizing Data Analysis) :在k-均值算法的基础上，增加对聚类结果的<strong>合并</strong>和<strong>分裂</strong>两个操作，当聚类结果某一类中<strong>样本数太少，或两个类间的距离太近，或样本类别远大于设定类别数</strong>时，进行<strong>合并</strong>，当聚类结果某一类中<strong>样本数太多，或某个类内方差太大，或样本类别远小于设定类别数</strong>时，进行<strong>分裂</strong>。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 初始常量(c<sub>0</sub>,n<sub>0</sub>,d<sub>min</sub>,d<sub>max</sub>,T)</font><br>    c<sub>0</sub>：希望得到的聚类数<br>    n<sub>0</sub>：每类的样本数<br>    d<sub>min</sub>：最小类间距离<br>    d<sub>max</sub>：最大类内距离<br>    T：最大迭代次数</p>
<p>  <font size="4">2. 最小类间距离</font></p>
<script type="math/tex; mode=display">d_{min}=\underset{C_i,C_j \subseteq C}{min}{d( \overline {C_i},\overline {C_j} )} \ , \ 其中\overline {C_i}=\frac {1}{\lvert C_i \rvert}\underset{x_i \in C_i}{\sum}{x_i}</script><p>  <font size="4">3. 最大类内距离</font></p>
<script type="math/tex; mode=display">d_{max}=\underset{C_i \subseteq C}{max} \ \frac {1}{\lvert {C_i} \rvert}\underset{x_i \in C_i}{\sum}{d( x_i,\overline C_i )} \ , \ 其中\overline {C_i}=\frac {1}{\lvert C_i \rvert}\underset{x_i \in C_i}{\sum}{x_i}</script><table>
    <tbody><tr><td><center><img src="/images/MACHINE/isodata1.png">初始时刻状态</center></td>
    <td><center><img src="/images/MACHINE/isodata2.png">第一次迭代后</center></td>
</tr></tbody></table>
<table>
    <tbody><tr><td><center><img src="/images/MACHINE/isodata3.png">第二次迭代后</center></td>
    <td><center><img src="/images/MACHINE/isodata4.png">第三次迭代后</center></td>
</tr></tbody></table>
<table>
    <tbody><tr><td><center><img src="/images/MACHINE/isodata5.png">第四次迭代后</center></td>
    <td><center><img src="/images/MACHINE/isodata6.png">第五次迭代后</center></td>
</tr></tbody></table>

<p>  <font size="4">4. 判断是否达到分裂条件</font></p>
<ul>
<li>当前类别数是否小于希望得到聚类数的一半</li>
<li>当前每一类的数目是否大于每类样本数的二倍</li>
<li>当前类内距离是否大于最大类内距离</li>
</ul>
<p>  <font size="4">5. 分裂不满足条件的类别，回到步骤2，直到满足某个终止条件</font></p>
<p>  <font size="4">6. 判断是否达到合并条件</font></p>
<ul>
<li>当前类别数是否大于希望得到聚类数的二倍</li>
<li>当前每一类的数目是否小于每类样本数的一半</li>
<li>当前类间距离是否小于最小类间距离</li>
</ul>
<p>  <font size="4">7. 合并不满足条件的类别，回到步骤2，直到满足某个终止条件</font></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/isodata9.png" alt="ISODATA"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="ISODATA-main-m"><a href="#ISODATA-main-m" class="headerlink" title="ISODATA_main.m"></a>ISODATA_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_gauss.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%希望划分的类别数</span><br><span class="line">hope_class_num=3;</span><br><span class="line">%希望每一类的数目</span><br><span class="line">hope_num=20;</span><br><span class="line">%设定类内的最大距离,小一点</span><br><span class="line">max_class_inner_distance=0.1;</span><br><span class="line">%设定类间的最小距离,小一点</span><br><span class="line">min_class_between_distance=0.1;</span><br><span class="line">%最多迭代次数</span><br><span class="line">times=100;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">[y,class_num,class_center]=ISODATA_classify(x_scale,sample_num,hope_class_num,hope_num,max_class_inner_distance,min_class_between_distance,times);</span><br><span class="line">%样本中心尺度复原</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    class_center(i,:)=(max(x(i,:))-min(x(i,:)))*class_center(i,:)+min(x(i,:));</span><br><span class="line">end</span><br><span class="line">%如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    ISODATA_display(x,y,class_center,sample_num,class_num);</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ISODATA-classify-m"><a href="#ISODATA-classify-m" class="headerlink" title="ISODATA_classify.m"></a>ISODATA_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,class_num,class_center]=ISODATA_classify(x_scale,sample_num,hope_class_num,hope_num,max_class_inner_distance,min_class_between_distance,times)</span><br><span class="line">%给每一个样本都视为0类</span><br><span class="line">y=zeros(1,sample_num);</span><br><span class="line">%将前class_num个样本分为class_num类</span><br><span class="line">y(1:hope_class_num)=1:hope_class_num;</span><br><span class="line">%目前的类别数</span><br><span class="line">class_num=hope_class_num;</span><br><span class="line">k=0;</span><br><span class="line">while 1</span><br><span class="line">    class_center=zeros(2,class_num);</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        %更新类别的中心</span><br><span class="line">        class_center(:,i)=sum(x_scale(:,y==i),2)/sum(y==i);</span><br><span class="line">    end</span><br><span class="line">    %采用最近邻进行分类</span><br><span class="line">    for i=1:sample_num</span><br><span class="line">        distance=sum((class_center-repmat(x_scale(:,i),1,class_num)).^2);</span><br><span class="line">        y(i)=find(distance==min(distance),1);</span><br><span class="line">    end</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        %更新类别的中心</span><br><span class="line">        class_center(:,i)=sum(x_scale(:,y==i),2)/sum(y==i);</span><br><span class="line">    end</span><br><span class="line">    %如果迭代次数大于times，则停止迭代</span><br><span class="line">    if k&gt;=times</span><br><span class="line">        break;</span><br><span class="line">    end</span><br><span class="line">    each_class_num=zeros(1,class_num);</span><br><span class="line">    distance_between_class=zeros(class_num);</span><br><span class="line">    %统计每一类的个数,并求出类间距离</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        each_class_num(i)=sum(y==i);</span><br><span class="line">        distance_between_class(i,:)=sum((class_center-repmat(class_center(:,i),1,class_num)).^2);</span><br><span class="line">        distance_between_class(i,i)=inf;</span><br><span class="line">    end</span><br><span class="line">    %统计类内距离</span><br><span class="line">    distance_class_inner=zeros(1,class_num);</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        temp=x_scale(:,y==i);</span><br><span class="line">        distance_class_inner(i)=sum(sum((temp-repmat(class_center(:,i),1,sum(y==i))).^2))/sum(y==i);</span><br><span class="line">    end</span><br><span class="line">    %如果类内距离最大的一类的类内距离大于设定值，则分裂两类</span><br><span class="line">    if max(distance_class_inner)&gt;max_class_inner_distance</span><br><span class="line">        tem=find(distance_class_inner==max(distance_class_inner),1);</span><br><span class="line">        %temp为该类别的样本</span><br><span class="line">        temp=x_scale(:,y==tem);</span><br><span class="line">        %distance(i,j)指第i个样本到第j个样本的距离</span><br><span class="line">        distance=zeros(size(temp));</span><br><span class="line">        for i=1:sum(y==tem)</span><br><span class="line">            distance(i,:)=sum((temp-repmat(temp(:,i),1,sum(y==tem))).^2);</span><br><span class="line">        end</span><br><span class="line">        %找到距离最远的两个样本</span><br><span class="line">        [row,col]=find(distance==max(max(distance)),1);</span><br><span class="line">        %分别找到这个两个样本的所在位置</span><br><span class="line">        temp=find(y==tem);</span><br><span class="line">        row=temp(row);</span><br><span class="line">        col=temp(col);</span><br><span class="line">        %类别数+1</span><br><span class="line">        class_num=class_num+1;</span><br><span class="line">        %令该类别撤销</span><br><span class="line">        y(y==tem)=0;</span><br><span class="line">        %添加两个新类别，一个覆盖原类别，另一个类别为原类别数+1</span><br><span class="line">        y(row)=tem;</span><br><span class="line">        y(col)=class_num;</span><br><span class="line">        k=k+1;</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %如果两类之间的最小距离小于设定阈值，则合并两类</span><br><span class="line">    if min(min(distance_between_class))&lt;min_class_between_distance</span><br><span class="line">        %找到距离最近的两个类别</span><br><span class="line">        [row,col]=find(distance_between_class==min(min(distance_between_class)),1);</span><br><span class="line">        %类别数-1</span><br><span class="line">        class_num=class_num-1;</span><br><span class="line">        %将col类合并到row类中</span><br><span class="line">        y(y==col)=row;</span><br><span class="line">        %调整类别序号</span><br><span class="line">        y(y&gt;col)=y(y&gt;col)-1;</span><br><span class="line">        k=k+1;</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %如果某一类的最小数量小于等于希望数量的一半</span><br><span class="line">    if min(each_class_num)&lt;=hope_num/2</span><br><span class="line">        %找到该类别</span><br><span class="line">        tem=find(each_class_num==min(each_class_num),1);</span><br><span class="line">        %令该类别撤销</span><br><span class="line">        y(y==tem)=0;</span><br><span class="line">        %重新调整类别序号</span><br><span class="line">        y(y&gt;tem)=y(y&gt;tem)-1;</span><br><span class="line">        %类别数-1</span><br><span class="line">        class_num=class_num-1;</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %如果某一类的最小数量大于等于希望数量的2倍</span><br><span class="line">    if max(each_class_num)&gt;=hope_num*2</span><br><span class="line">        %找到该类别</span><br><span class="line">        tem=find(each_class_num==max(each_class_num),1);</span><br><span class="line">        %temp为该类别的样本</span><br><span class="line">        temp=x_scale(:,y==tem);</span><br><span class="line">        %distance(i,j)指第i个样本到第j个样本的距离</span><br><span class="line">        distance=zeros(size(temp));</span><br><span class="line">        for i=1:sum(y==tem)</span><br><span class="line">            distance(i,:)=sum((temp-repmat(temp(:,i),1,sum(y==tem))).^2);</span><br><span class="line">        end</span><br><span class="line">        %找到距离最远的两个样本</span><br><span class="line">        [row,col]=find(distance==max(max(distance)),1);</span><br><span class="line">        %分别找到这个两个样本的所在位置</span><br><span class="line">        temp=find(y==tem);</span><br><span class="line">        row=temp(row);</span><br><span class="line">        col=temp(col);</span><br><span class="line">        %类别数+1</span><br><span class="line">        class_num=class_num+1;</span><br><span class="line">        %令该类别撤销</span><br><span class="line">        y(y==tem)=0;</span><br><span class="line">        %添加两个新类别，一个覆盖原类别，另一个类别为原类别数+1</span><br><span class="line">        y(row)=tem;</span><br><span class="line">        y(col)=class_num;</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %如果现有类别数小于等于希望类别数的一半，拆分类内距离最大类别</span><br><span class="line">    if class_num&lt;=hope_class_num/2</span><br><span class="line">        tem=find(distance_class_inner==max(distance_class_inner),1);</span><br><span class="line">        %temp为该类别的样本</span><br><span class="line">        temp=x_scale(:,y==tem);</span><br><span class="line">        %distance(i,j)指第i个样本到第j个样本的距离</span><br><span class="line">        distance=zeros(size(temp));</span><br><span class="line">        for i=1:sum(y==tem)</span><br><span class="line">            distance(i,:)=sum((temp-repmat(temp(:,i),1,sum(y==tem))).^2);</span><br><span class="line">        end</span><br><span class="line">        %找到距离最远的两个样本</span><br><span class="line">        [row,col]=find(distance==max(max(distance)),1);</span><br><span class="line">        %分别找到这个两个样本的所在位置</span><br><span class="line">        temp=find(y==tem);</span><br><span class="line">        row=temp(row);</span><br><span class="line">        col=temp(col);</span><br><span class="line">        %类别数+1</span><br><span class="line">        class_num=class_num+1;</span><br><span class="line">        %令该类别撤销</span><br><span class="line">        y(y==tem)=0;</span><br><span class="line">        %添加两个新类别，一个覆盖原类别，另一个类别为原类别数+1</span><br><span class="line">        y(row)=tem;</span><br><span class="line">        y(col)=class_num;</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %如果现有类别数大于等于希望类别数的二倍，合并类间距离最小的两类</span><br><span class="line">    if class_num&gt;=hope_class_num*2</span><br><span class="line">        %找到距离最近的两个类别</span><br><span class="line">        [row,col]=find(distance_between_class==min(min(distance_between_class)),1);</span><br><span class="line">        %类别数-1</span><br><span class="line">        class_num=class_num-1;</span><br><span class="line">        %将col类合并到row类中</span><br><span class="line">        y(y==col)=row;</span><br><span class="line">        %调整类别序号</span><br><span class="line">        y(y&gt;col)=y(y&gt;col)-1;</span><br><span class="line">        continue;</span><br><span class="line">    end</span><br><span class="line">    %添加样本类内间距最大值</span><br><span class="line">    break;</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ISODATA-display-m"><a href="#ISODATA-display-m" class="headerlink" title="ISODATA_display.m"></a>ISODATA_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function ISODATA_display(x,y,class_center,sample_num,class_num)</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">hold on;</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">    %绘制样本中心，用*表示</span><br><span class="line">    plot(class_center(1,i),class_center(2,i),'color',color_bar(i,:),'marker','*')</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    %绘制数据集，用o表示</span><br><span class="line">    plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/isodata.png" alt="ISODATA"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>大数据集时，对噪声数据不敏感</li>
<li>可以动态调整类别个数和类别中心</li>
<li>在先验知识不足的情况下有较好的分类能力</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对初始中心点敏感</li>
<li>算法复杂，分类速度较慢</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>K均值聚类(K-MEANS)</title>
    <url>/2019/05/03/clustering_KMEANS/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">K-Means聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  K-Means :随机选取<strong>N个</strong>对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。每分配一个样本，聚类中心会根据聚类中现有的对象被<strong>重新计算</strong>。这个过程将不断重复直到满足某个终止条件。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 求出N个类别的聚类中心a<sub>1</sub>,a<sub>2</sub>, … ,a<sub>N</sub></font></p>
<script type="math/tex; mode=display">a_i=\frac {1}{\lvert C_i \rvert}\underset{x_i \in C_j}{\sum}{x_i}</script><p>  <font size="4">2. 对于每个样本x<sub>j</sub>，将其标记为距离类别中心a<sub>i</sub>最近的一类</font></p>
<script type="math/tex; mode=display">x_j \in C_i \ , \ 其中k=\underset{i,a_i \in C_k}{arg \ min}\ d(x_j,a_i)</script><p>  <font size="4">3. 重复步骤1，2直到满足某个终止条件</font><br><img src="/images/MACHINE/kmeans1.png" alt="KMEANS"></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/kmeans9.png" alt="KMEANS"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="KMEANS-main-m"><a href="#KMEANS-main-m" class="headerlink" title="KMEANS_main.m"></a>KMEANS_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_gauss.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%类别数目，请输入大于1的数</span><br><span class="line">class_num=3;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">%类别中心位置</span><br><span class="line">loc_center=zeros(feat_num,class_num);</span><br><span class="line">%如果类别数大于样本数或者类别数小于1，则无法分类</span><br><span class="line">if class_num&gt;sample_num||class_num&lt;1</span><br><span class="line">    disp('ERROR!')</span><br><span class="line">else</span><br><span class="line">    %如果类别数等于1，则所有的样本都属于该类别,聚类中心为所有样本的中点</span><br><span class="line">    if class_num==1</span><br><span class="line">        y=ones(1,sample_num);</span><br><span class="line">        loc_center(:,1)=sum(x,2)/sample_num;</span><br><span class="line">        k=0;</span><br><span class="line">    else</span><br><span class="line">        %取前class_num个样本作为初始类别</span><br><span class="line">        loc_center=x_scale(:,1:class_num);</span><br><span class="line">        %ISO聚类法</span><br><span class="line">        [y,loc_center,k]=KMEANS_classify(x_scale,loc_center,sample_num,class_num);</span><br><span class="line">        %将缩放后的聚类中心复原</span><br><span class="line">        for i=1:feat_num</span><br><span class="line">            loc_center(i,:)=loc_center(i,:)*(max(x(i,:))-min(x(i,:)))+min(x(i,:));</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    if k&gt;=1000</span><br><span class="line">        disp('Incorrect Classify')</span><br><span class="line">    else</span><br><span class="line">        %如果数据的特征是二维的，可以绘图表示</span><br><span class="line">        if feat_num==2</span><br><span class="line">            KMEANS_display(x,y,loc_center,sample_num,class_num)</span><br><span class="line">        else</span><br><span class="line">            disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="KMEANS-classify-m"><a href="#KMEANS-classify-m" class="headerlink" title="KMEANS_classify.m"></a>KMEANS_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,loc_center,k]=KMEANS_classify(x_scale,loc_center,sample_num,class_num)</span><br><span class="line">%设置迭代次数</span><br><span class="line">k=0;</span><br><span class="line">while 1</span><br><span class="line">    %初始化最新的分类中心</span><br><span class="line">    loc_center_new=zeros(size(loc_center));</span><br><span class="line">    distance=zeros(class_num,sample_num);</span><br><span class="line">    %distance为每一个样本到每一类的距离</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        distance(i,:)=sum((x_scale-repmat(loc_center(:,i),1,sample_num)).^2);</span><br><span class="line">    end</span><br><span class="line">    %求出每个样本到哪一类最近</span><br><span class="line">    [~,y]=min(distance);</span><br><span class="line">    %更新分类中心</span><br><span class="line">    for i=1:class_num</span><br><span class="line">        loc_center_new(:,i)=sum(x_scale(:,y==i),2)/sum(y==i);</span><br><span class="line">    end</span><br><span class="line">    %如果分类中心和上一次分类中心相等则分类完毕</span><br><span class="line">    if isequal(loc_center_new,loc_center)</span><br><span class="line">        break;</span><br><span class="line">    %否则继续分类</span><br><span class="line">    else</span><br><span class="line">        loc_center=loc_center_new;</span><br><span class="line">        k=k+1;</span><br><span class="line">        %如果分类次数达到1000仍然没有结束，则强制分类结束</span><br><span class="line">        if k&gt;=1000</span><br><span class="line">            break;</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="KMEANS-display-m"><a href="#KMEANS-display-m" class="headerlink" title="KMEANS_display.m"></a>KMEANS_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function KMEANS_display(x,y,loc_center,sample_num,class_num)</span><br><span class="line">hold on;</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">%画出每一类的聚类中心，用*表示</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">    plot(loc_center(1,i),loc_center(2,i),'color',color_bar(i,:),'marker','*')</span><br><span class="line">end</span><br><span class="line">%画出每一类的样本数据，用o表示</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/kmeans.png" alt="KMEANS"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>大数据集时，对噪声数据不敏感</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对初始中心点敏感</li>
<li>需要在测试前知道类别的个数</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>分裂的层次聚类(DIANA)</title>
    <url>/2019/05/02/clustering_DIANA/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">分裂的层次聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  DIANA(Divisive Analysis):采用<strong>自顶向下</strong>的策略，最初将所有对象置于一个类中，然后根据某些准则将这些类别<strong>逐渐细分</strong>。细分过程反复进行直到类别达到预期的数目。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 将所有样本都作为同一类</font></p>
<p>  <font size="4">2. 分裂所有类别中到该类中心距离最大的样本，将其单独作为一类，按照最近邻分类，直到满足某个终止条件</font></p>
<script type="math/tex; mode=display">d_{max}=\underset{C_i \subseteq C}{max} \ (\underset{x_i \in C_i}{max} \ {d(x_i,\overline C_i)}) \ , \ 其中\overline {C_i}=\frac {1}{\lvert C_i \rvert}\underset{x_i \in C_i}{\sum}{x_i}</script><p><img src="/images/MACHINE/diana1.png" alt="DIANA"></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/diana9.png" alt="DIANA"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="DIANA-main-m"><a href="#DIANA-main-m" class="headerlink" title="DIANA_main.m"></a>DIANA_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_gauss.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%希望划分的类别数</span><br><span class="line">class_num=3;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">[y,class_center]=DIANA_classify(x_scale,sample_num,class_num);</span><br><span class="line">%样本中心尺度复原</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    class_center(i,:)=(max(x(i,:))-min(x(i,:)))*class_center(i,:)+min(x(i,:));</span><br><span class="line">end</span><br><span class="line">%如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    DIANA_display(x,y,class_center,sample_num,class_num);</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="DIANA-classify-m"><a href="#DIANA-classify-m" class="headerlink" title="DIANA_classify.m"></a>DIANA_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,class_center]=DIANA_classify(x_scale,sample_num,class_num)</span><br><span class="line">if class_num==1</span><br><span class="line">    class_center=sum(x_scale,2)/sample_num;</span><br><span class="line">    y=ones(1,sample_num);</span><br><span class="line">else</span><br><span class="line">    %给每一个样本都视为0类</span><br><span class="line">    y=zeros(1,sample_num);</span><br><span class="line">    distance=zeros(sample_num);</span><br><span class="line">    for i=1:sample_num</span><br><span class="line">        distance(i,:)=sum((x_scale-repmat(x_scale(:,i),1,sample_num)).^2);</span><br><span class="line">    end</span><br><span class="line">    %找到距离最远的两个样本</span><br><span class="line">    [row,col]=find(distance==max(max(distance)),1);</span><br><span class="line">    %将row分为第一类,col分为第二类</span><br><span class="line">    y(row)=1;</span><br><span class="line">    y(col)=2;</span><br><span class="line">    %设置第一类和第二类的中心</span><br><span class="line">    class_center(:,1)=x_scale(:,row);</span><br><span class="line">    class_center(:,2)=x_scale(:,col);</span><br><span class="line">    %目前的类别数</span><br><span class="line">    class_num_temp=2;</span><br><span class="line">    distance_min=zeros(1,sample_num);</span><br><span class="line">    while class_num_temp~=class_num</span><br><span class="line">        for i=1:sample_num</span><br><span class="line">            %求每个样本到每一类的距离</span><br><span class="line">            distance=sum((class_center-repmat(x_scale(:,i),1,class_num_temp)).^2);</span><br><span class="line">            %求出每个样本到每一类距离最小值</span><br><span class="line">            distance_min(i)=distance(find(distance==min(distance),1));</span><br><span class="line">        end</span><br><span class="line">        %找到距离最大值作为一类</span><br><span class="line">        temp=find(distance_min==max(distance_min),1);</span><br><span class="line">        %类别数+1</span><br><span class="line">        class_num_temp=class_num_temp+1;</span><br><span class="line">        %修改类别信息</span><br><span class="line">        y(temp)=class_num_temp;</span><br><span class="line">        for i=1:class_num_temp</span><br><span class="line">            %更新类别的中心</span><br><span class="line">            class_center(:,i)=sum(x_scale(:,y==i),2)/sum(y==i);</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">    %采用最近邻进行分类</span><br><span class="line">    for i=1:sample_num</span><br><span class="line">        distance=sum((class_center-repmat(x_scale(:,i),1,class_num_temp)).^2);</span><br><span class="line">        y(i)=find(distance==min(distance),1);</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="DIANA-display-m"><a href="#DIANA-display-m" class="headerlink" title="DIANA_display.m"></a>DIANA_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function DIANA_display(x,y,class_center,sample_num,class_num)</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">hold on;</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">    %绘制样本中心，用*表示</span><br><span class="line">    plot(class_center(1,i),class_center(2,i),'color',color_bar(i,:),'marker','*')</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    %绘制数据集，用o表示</span><br><span class="line">    plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/diana.png" alt="DIANA"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>算法简单，容易理解</li>
<li>不依赖初始值的选择</li>
<li>对于类别较少的训练集分类较快</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>对噪声数据敏感</li>
<li>分裂操作不能撤销</li>
<li>需要在测试前知道类别的个数</li>
<li>对于类别较多的训练集分类较慢</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>凝聚的层次聚类(AGNES)</title>
    <url>/2019/05/01/clustering_AGNES/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">凝聚的层次聚类方法</font></strong></center><p></p>
<h1 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a><font size="5" color="red">原理解读</font></h1><p>  AGNES(Agglomerative Nesting):采用<strong>自底向上</strong>的策略，最初将每个对象作为一个类，然后根据某些准则将这些类别<strong>逐一合并</strong>。合并的过程反复进行直到类别达到预期的数目。<br><a id="more"></a></p>
<h1 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a><font size="5" color="red">核心思想</font></h1><p>  <font size="4">1. 将每一个样本都单独作为一类</font></p>
<p>  <font size="4">2. 合并两类(多种定义方法)，直到满足某个终止条件</font></p>
<ul>
<li><p>最小距离：将两个类别之间最近的两个样本之间的距离作为两个类别之间的距离</p>
<script type="math/tex; mode=display">d_{min}=\underset{x_i \in C_i,x_j \in C_j}{min}d(x_i,x_j)</script></li>
<li><p>最大距离：将两个类别之间最远的两个样本之间的距离作为两个类别之间的距离</p>
<script type="math/tex; mode=display">d_{max}=\underset{x_i \in C_i,x_j \in C_j}{max}d(x_i-x_j)</script></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/agnes1.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/agnes2.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<ul>
<li><p>均值距离：将两个类别中样本的平均值之间的距离作为两个类别之间的距离</p>
<script type="math/tex; mode=display">d_{mean}=d(\overline {C_i}- \overline {C_j}) \ , \ 其中\overline {C_i}=\frac {1}{\lvert C_i \rvert}\underset{x_i \in C_i}{\sum}{x_i}</script></li>
<li><p>平均距离：将两个类别中样本间两两距离的平均值作为两个类别之间的距离</p>
<script type="math/tex; mode=display">d_{avg}=\frac {1}{\lvert C_i \rvert \lvert C_j \rvert}\underset{x_i \in C_i}{\sum}\underset{x_j \in C_j}{\sum}d(x_i-x_j)</script></li>
</ul>
<p></p><center><div style="float:left;margin-left:50px"><img src="/images/MACHINE/agnes3.png" width="200" height="260"></div></center><p></p>
<div style="float:right;margin-right:50px"><img src="/images/MACHINE/agnes4.png" width="200" height="260"></div>
<div style="float:none;clear:both;"></div>

<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a><font size="5" color="red">算法流程</font></h1><p><img src="/images/MACHINE/agnes9.png" alt="AGNES"></p>
<p><br><br></p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><p><font size="4">代码中所用数据集可以查看相关文档，<a href="https://ustccoder.github.io/2019/04/25/clustering_Dataset/">数据集(Data Set)</a></font></p>
<h2 id="AGNES-main-m"><a href="#AGNES-main-m" class="headerlink" title="AGNES_main.m"></a>AGNES_main.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">load('..\\cluster_gauss.mat');</span><br><span class="line">%输入x的矩阵</span><br><span class="line">x=data;</span><br><span class="line">randIndex = randperm(size(x,2));</span><br><span class="line">x=x(:,randIndex);</span><br><span class="line">%希望划分的类别数</span><br><span class="line">class_num=3;</span><br><span class="line">%样本数</span><br><span class="line">sample_num=size(x,2);</span><br><span class="line">%特征数目</span><br><span class="line">feat_num=size(x,1);</span><br><span class="line">%尺度缩放到0-1</span><br><span class="line">x_scale=zeros(size(x));</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    x_scale(i,:)=(x(i,:)-min(x(i,:)))/(max(x(i,:))-min(x(i,:)));</span><br><span class="line">end</span><br><span class="line">[y,class_center]=AGNES_classify(x_scale,sample_num,class_num);</span><br><span class="line">%样本中心尺度复原</span><br><span class="line">for i=1:feat_num</span><br><span class="line">    class_center(i,:)=(max(x(i,:))-min(x(i,:)))*class_center(i,:)+min(x(i,:));</span><br><span class="line">end</span><br><span class="line">%如果数据的特征是二维的，可以绘图表示</span><br><span class="line">if feat_num==2</span><br><span class="line">    AGNES_display(x,y,class_center,sample_num,class_num);</span><br><span class="line">else</span><br><span class="line">    disp('The Feature Is Not Two-Dimensional');</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="AGNES-classify-m"><a href="#AGNES-classify-m" class="headerlink" title="AGNES_classify.m"></a>AGNES_classify.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function [y,class_center]=AGNES_classify(x_scale,sample_num,class_num)</span><br><span class="line">%给每一个样本分配一个初始类别</span><br><span class="line">y=1:sample_num;</span><br><span class="line">%当前的类别数</span><br><span class="line">class_num_temp=sample_num;</span><br><span class="line">%初始化当前每一类的中心</span><br><span class="line">class_center=x_scale;</span><br><span class="line">while class_num_temp~=class_num</span><br><span class="line">    %初始化类别中心距</span><br><span class="line">    center_distance=zeros(class_num_temp);</span><br><span class="line">    for i=1:class_num_temp</span><br><span class="line">        %计算类别中心距</span><br><span class="line">        center_distance(i,:)=sum((class_center-repmat(class_center(:,i),1,class_num_temp)).^2);</span><br><span class="line">        center_distance(i,i)=inf;</span><br><span class="line">    end</span><br><span class="line">    %从中心距中找到最小值</span><br><span class="line">    [row,col]=find(center_distance==min(min(center_distance)),1);</span><br><span class="line">    %将两类合并</span><br><span class="line">    y(y==col)=row;</span><br><span class="line">    %更新类别，从第1类连续分类</span><br><span class="line">    y(y&gt;col)=y(y&gt;col)-1;</span><br><span class="line">    %类别数-1</span><br><span class="line">    class_num_temp=class_num_temp-1;</span><br><span class="line">    %初始化样本中心</span><br><span class="line">    class_center=zeros(2,class_num_temp);</span><br><span class="line">    for i=1:class_num_temp</span><br><span class="line">        %计算当前每一类的样本中心</span><br><span class="line">        class_center(:,i)=sum(x_scale(:,y==i),2)/sum(y==i);</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure>
<h2 id="AGNES-display-m"><a href="#AGNES-display-m" class="headerlink" title="AGNES_display.m"></a>AGNES_display.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">function AGNES_display(x,y,class_center,sample_num,class_num)</span><br><span class="line">color_bar=zeros(class_num,3);</span><br><span class="line">hold on;</span><br><span class="line">for i=1:class_num</span><br><span class="line">    color_bar(i,:)=[rand(1),rand(1),rand(1)];</span><br><span class="line">    %绘制样本中心，用*表示</span><br><span class="line">    plot(class_center(1,i),class_center(2,i),'color',color_bar(i,:),'marker','*')</span><br><span class="line">end</span><br><span class="line">for i=1:sample_num</span><br><span class="line">    %绘制数据集，用o表示</span><br><span class="line">    plot(x(1,i),x(2,i),'color',color_bar(y(i),:),'marker','o');</span><br><span class="line">end</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><br><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font size="5" color="red">实验结果</font></h1><p><img src="/images/MACHINE/agnes.png" alt="AGNES"></p>
<h1 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a><font size="5" color="red">性能比较</font></h1><ul>
<li><font size="4"><strong>优点：</strong><ul>
<li>对噪声数据不敏感</li>
<li>算法简单，容易理解</li>
<li>不依赖初始值的选择</li>
<li>对于类别较多的训练集分类较快</li>
</ul>
</font></li>
<li><font size="4"><strong>缺点：</strong><ul>
<li>合并操作不能撤销</li>
<li>需要在测试前知道类别的个数</li>
<li>对于类别较少的训练集分类较慢</li>
<li>只适合分布呈凸型或者球形的数据集</li>
<li>对于高维数据，距离的度量并不是很好</li>
</ul>
</font></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>数据集(Data Set)</title>
    <url>/2019/04/25/clustering_Dataset/</url>
    <content><![CDATA[<p><strong><font size="5" color="gray"></font></strong></p><center><strong><font size="5" color="gray">数据集说明</font></strong></center><p></p>
<h1 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><font size="5" color="red">原理介绍</font></h1><p>  Data Set:对于机器学习领域来说，数据集的选择是<strong>至关重要</strong>的，一个数据集的好坏往往可以<strong>直接决定聚类结果</strong>，通常一个算法<strong>很难</strong>适用于所有的数据集。因此我们需要设计各种数据集，并且<strong>分析哪一种数据类型适合用哪一种算法</strong>，只有这样，在今后的使用中才能得心应手。<a id="more"></a>考虑到数据集的适应性，设计了以下五种不同的数据集，包括<strong>水平竖直型</strong>数据，<strong>斜线型</strong>数据，<strong>圆形</strong>数据，<strong>高斯型</strong>数据和<strong>混合型</strong>数据。</p>
<h1 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a><font size="5" color="red">代码实战</font></h1><h2 id="line-data-m"><a href="#line-data-m" class="headerlink" title="line_data.m"></a>line_data.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">hold on;</span><br><span class="line">axis equal;</span><br><span class="line">%线的长度 </span><br><span class="line">long=[10,10,10];</span><br><span class="line">%线的宽度</span><br><span class="line">wide=[1,1,1];</span><br><span class="line">%线的起始位置</span><br><span class="line">x_0=[0,0,0];</span><br><span class="line">y_0=[2,5,8];</span><br><span class="line">%每一条线上元素的个数</span><br><span class="line">num=[500,500,500];</span><br><span class="line">data_temp=zeros(2,sum(num));</span><br><span class="line">for i=1:length(long)</span><br><span class="line">    if i==1</span><br><span class="line">        data_temp(:,1:num(i))=[rand(1,num(i))*long(i)+x_0(i);rand(1,num(i))*wide(i)+y_0(i)];</span><br><span class="line">    else</span><br><span class="line">        data_temp(:,sum(num(1:i-1))+1:sum(num(1:i)))=[rand(1,sum(num(1:i))-sum(num(1:i-1)))*long(i)+x_0(i);rand(1,sum(num(1:i))-sum(num(1:i-1)))*wide(i)+y_0(i)];</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%随机打乱顺序</span><br><span class="line">randIndex = randperm(size(data_temp,2));</span><br><span class="line">data=data_temp(:,randIndex);</span><br><span class="line">plot(data(1,:),data(2,:),'o');</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/MACHINE/cluster_line.png" alt="line"></p>
<h2 id="slash-data-m"><a href="#slash-data-m" class="headerlink" title="slash_data.m"></a>slash_data.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">hold on;</span><br><span class="line">axis equal;</span><br><span class="line">%x的起始和终止位置</span><br><span class="line">begend=[0,0,1,6;...</span><br><span class="line">    10,10,5,10];</span><br><span class="line">%斜率和截距</span><br><span class="line">kb=[1,1,-5,-5;...</span><br><span class="line">    -2,7,20,50];</span><br><span class="line">data_temp=[];</span><br><span class="line">for i=1:size(begend,2)</span><br><span class="line">    x=begend(1,i):0.1:begend(2,i);</span><br><span class="line">    data_temp=[data_temp,[x+rand(1,length(x))-0.5;kb(1,i)*x+kb(2,i)+rand(1,length(x))-0.5]];</span><br><span class="line">end</span><br><span class="line">%随机打乱顺序</span><br><span class="line">randIndex = randperm(size(data_temp,2));</span><br><span class="line">data=data_temp(:,randIndex);</span><br><span class="line">plot(data(1,:),data(2,:),'o');</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/MACHINE/cluster_slash.png" alt="slash"></p>
<h2 id="gauss-data-m"><a href="#gauss-data-m" class="headerlink" title="gauss_data.m"></a>gauss_data.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">hold on;</span><br><span class="line">axis equal;</span><br><span class="line">%簇个数</span><br><span class="line">num=3;</span><br><span class="line">%每一类的个数</span><br><span class="line">number=300;</span><br><span class="line">%u和sigma</span><br><span class="line">data_temp=zeros(2,num*number);</span><br><span class="line">usigma_x=[0,2,6;</span><br><span class="line">    1,1,1];</span><br><span class="line">usigma_y=[0,6,2;</span><br><span class="line">    1,1,1];</span><br><span class="line">for i=1:num</span><br><span class="line">    data_temp(:,(i-1)*number+1:i*number)=[normrnd(usigma_x(1,i),usigma_x(2,i),1,number);normrnd(usigma_y(1,i),usigma_y(2,i),1,number)];</span><br><span class="line">end</span><br><span class="line">%随机打乱顺序</span><br><span class="line">randIndex = randperm(size(data_temp,2));</span><br><span class="line">data=data_temp(:,randIndex);</span><br><span class="line">plot(data(1,:),data(2,:),'o');</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/MACHINE/cluster_gauss.png" alt="gauss"></p>
<h2 id="cicle-data-m"><a href="#cicle-data-m" class="headerlink" title="cicle_data.m"></a>cicle_data.m</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">hold on;</span><br><span class="line">axis equal;</span><br><span class="line">theta = 0:0.05:2*pi;</span><br><span class="line">x=cos(theta);</span><br><span class="line">y=sin(theta);</span><br><span class="line">%椭圆方程(x+x0)^2/a^2+(y+y0)^2/b^2=1</span><br><span class="line">ab=[3,4,6,10;...</span><br><span class="line">    3,4,6,10];</span><br><span class="line">xy_0=[0,0,0,0;...</span><br><span class="line">    0,0,0,0];</span><br><span class="line">data_temp=zeros(2,length(theta)*size(ab,2));</span><br><span class="line">for i=1:size(ab,2)</span><br><span class="line">    data_temp(:,(i-1)*length(theta)+1:i*length(theta))=([x;y].*repmat(ab(:,i),1,length(theta)))+repmat(xy_0(:,i),1,length(theta));</span><br><span class="line">end</span><br><span class="line">%随机打乱顺序</span><br><span class="line">randIndex = randperm(size(data_temp,2));</span><br><span class="line">data=data_temp(:,randIndex);</span><br><span class="line">plot(data(1,:),data(2,:),'o');</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/MACHINE/cluster_cicle.png" alt="cicle"></p>
<h2 id="mixture-data-m"><a href="#mixture-data-m" class="headerlink" title="mixture_data.m"></a>mixture_data.m</h2><p><font size="4">由上面的四种数据集组合之后可以形成混合数据集。</font><br></p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">clear;clc;close all;</span><br><span class="line">hold on;</span><br><span class="line">axis equal;</span><br><span class="line">%x1的起始和终止位置</span><br><span class="line">x_1=2:0.1:6;</span><br><span class="line">%x1的斜率和截距</span><br><span class="line">kb_1=[1;4];</span><br><span class="line">data_1=[x_1+rand(1,length(x_1))-0.5;kb_1(1)*x_1+kb_1(2)+rand(1,length(x_1))-0.5];</span><br><span class="line">%x2的起始和终止位置</span><br><span class="line">x_2=1:0.05:7;</span><br><span class="line">%x2的斜率和截距</span><br><span class="line">kb_2=[-1;12];</span><br><span class="line">data_2=[x_2+rand(1,length(x_2))-0.5;kb_2(1)*x_2+kb_2(2)+rand(1,length(x_2))-0.5];</span><br><span class="line">%产生高斯数据集</span><br><span class="line">data_3=normrnd(12,1.5,2,200);</span><br><span class="line">%线的长度 </span><br><span class="line">long=[5,1];</span><br><span class="line">%线的宽度</span><br><span class="line">wide=[1,5];</span><br><span class="line">%线的起始位置</span><br><span class="line">x_0=[6,11];</span><br><span class="line">y_0=[1,1];</span><br><span class="line">%每一条线上元素的个数</span><br><span class="line">num=[100,100];</span><br><span class="line">data_4=zeros(2,sum(num));</span><br><span class="line">for i=1:length(long)</span><br><span class="line">    if i==1</span><br><span class="line">        data_4(:,1:num(i))=[rand(1,num(i))*long(i)+x_0(i);rand(1,num(i))*wide(i)+y_0(i)];</span><br><span class="line">    else</span><br><span class="line">        data_4(:,sum(num(1:i-1))+1:sum(num(1:i)))=[rand(1,sum(num(1:i))-sum(num(1:i-1)))*long(i)+x_0(i);rand(1,sum(num(1:i))-sum(num(1:i-1)))*wide(i)+y_0(i)];</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">%产生噪声点</span><br><span class="line">data_5=rand(2,38)*16;</span><br><span class="line">data_temp=[data_1,data_2,data_3,data_4,data_5];</span><br><span class="line">%随机打乱顺序</span><br><span class="line">randIndex = randperm(size(data_temp,2));</span><br><span class="line">data=data_temp(:,randIndex);</span><br><span class="line">plot(data(1,:),data(2,:),'o');</span><br><span class="line">hold off;</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="/images/MACHINE/cluster_mixture.png" alt="mixture"></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>机器学习</category>
        <category>无监督学习</category>
      </categories>
  </entry>
  <entry>
    <title>Turing Reward in 2018</title>
    <url>/2018/03/30/TuringReward-2018/</url>
    <content><![CDATA[<p>  2019 年 3 月 27 日，ACM 宣布，深度学习三位大牛 Yoshua Bengio、Yann LeCun、Geoffrey Hinton 因“在概念和工程方面使深度神经网络成为计算的关键组成部分的突破”获得了 2018 年的图灵奖。近年来，深度学习方法一直是计算机视觉、语音识别、自然语言处理和机器人技术以及其他应用中惊人突破的原因。<a id="more"></a>在 ACM 的公告中是这样写道的：虽然在 20 世纪 80 年代引入了人工神经网络作为帮助计算机识别模式和模拟人类智能的工具，但到了 21 世纪初，LeCun、Hinton 和 Bengio 仍坚持这种方法的小团体。虽然他们重新点燃人工智能社区对神经网络兴趣的努力在最初曾遭到怀疑，但其想法引发了重大的技术进步，其方法现在已成为该领域的主导范例。此前他们在深度学习领域的地位早已是无人不知，尽管三人走向了不同的方向，但他们仍然是多年的合作伙伴和挚友。让我们先来看看三位所作出的主要贡献：<br><strong>杰弗里·辛顿(Geoffery Hinton)</strong><br><img src="/images/TURING/hinton.jpeg" alt="Geoffery Hinton"><br>  <strong>反向传播(Back Propagation)</strong>：在 1986 年与 David Rumelhart 和 Ronald Williams 共同撰写的 “Learning Internal Representations by Error Propagation” 一文中，Hinton 证明了反向传播算法允许神经网络发现自己的数据内部表示，这使得使用神经网络成为可能网络解决以前被认为超出其范围的问题。如今，反向传播算法是大多数神经网络的标准。 </p>
<p>  <strong>玻尔兹曼机(Boltzmann Machines)</strong>：1983 年，Hinton 与 Terrence Sejnowski 一起，发明了玻尔兹曼机，这是第一个能够学习不属于输入或输出的神经元内部表示的神经网络之一。 </p>
<p>  <strong>对卷积神经网络的改进(Improvement of Convolutional Neural Network)</strong>：2012 年，Hinton 和他的学生 Alex Krizhevsky 以及 Ilya Sutskever 通过 Rectified Linear Neurons 和 Dropout Regularization 改进了卷积神经网络，并在著名的 ImageNet 评测中将对象识别的错误率减半，在计算机视觉领域掀起一场革命。 </p>
<p><strong>约书亚·本吉奥(Yoshua Bengio)</strong><br><img src="/images/TURING/bengio.jpeg" alt="Yoshua Bengio"><br>  <strong>序列的概率模型(Probabilistic models of sequences)</strong>：在 20 世纪 90 年代，Bengio 将神经网络与序列的概率模型相结合，例如隐马尔可夫模型。这些想法被纳入 AT＆T / NCR 用于阅读手写支票中，被认为是 20 世纪 90 年代神经网络研究的巅峰之作。现代深度学习语音识别系统也是这些概念的扩展。 </p>
<p>  <strong>高维词向量嵌入和注意力(High-dimensional word embeddings and attention)</strong>：2000 年，Bengio 撰写了具有里程碑意义的论文“A Neural Probabilistic Language Model”，它引入了高维词向量作为词义的表示。Bengio 的见解对自然语言处理任务产生了巨大而持久的影响，包括语言翻译、问答和视觉问答。他的团队还引入了注意力机制，这种机制促使了机器翻译的突破，并构成了深度学习的序列处理的关键组成部分。 </p>
<p>  <strong>生成式对抗网络(Generative Adversarial Networks)</strong>：自 2010 年以来，Bengio 关于生成性深度学习的论文，特别是与 Ian Goodfellow 共同开发的生成性对抗网络（GAN），引发了计算机视觉和计算机图形学的革命。 </p>
<p><strong>杨立昆(Yann LeCun)</strong><br><img src="/images/TURING/lecun.jpeg" alt="Yann LeCun"><br>  <strong>卷积神经网络(Convolutional Neural Networks)</strong>：在 20 世纪 80 年代，LeCun 开发了卷积神经网络，现已成为该领域的基本理论基础。除了其他优点之外，它还具有使深度学习更有效的必要性。在 20 世纪 80 年代后期，多伦多大学和贝尔实验室工作期间，LeCun 是第一个在手写数字图像上训练卷积神经网络系统的人。如今，卷积神经网络是计算机视觉以及语音识别、语音合成、图像合成和自然语言处理的行业标准。它们用于各种应用，包括自动驾驶、医学图像分析、语音激活助手和信息过滤。 </p>
<p>  <strong>改进反向传播算法(Improved Back Propagation Algorithms)</strong>：LeCun 提出了一个早期的反向传播算法 backprop，并根据变分原理对其进行了简洁的推导。他的工作让加快了反向传播算，包括描述两种加速学习时间的简单方法。 </p>
<p>  <strong>拓宽神经网络的范围(Widening the Range of Neural Networks)</strong>：LeCun 还将神经网络作为可以完成更为广泛任务的计算模型，其早期工作现已成为 AI 的基础概念。例如，在图像识别领域，他研究了如何在神经网络中学习分层特征表示，这个理念现在通常用于许多识别任务中。与 LéonBottou 一起，他还提出了学习系统可以构建为复杂的模块网络，其中通过自动区分来执行反向传播，目前在每个现代深度学习软件中得到使用。他们还提出了可以操作结构化数据的深度学习架构，如图形。 在《连线》杂志的报道中，Geoffery Hinton 被问及获得图领奖的意义时，他表示十分惊讶，“我猜神经网络现在是受人尊敬的计算机科学”，因为在他看来图灵将是计算机科学中最值得尊敬的学科了。 据了解，图灵奖由 ACM 于 1966 年设置，每年颁发一次，设立目的之一是纪念著名的计算机科学先驱艾伦 • 图灵（Alan Turing），他在 20 世纪 30 年代、40 年代和 50 年代奠定了计算和人工智能的早期基础。 图灵奖是计算机科学领域的最高奖。获奖者必须在计算机领域具有持久重大的先进性技术贡献。人工智能领域的先驱马文 • 明斯基（Marvin Lee Minsky）、约翰 • 麦卡锡（John McCarthy）、艾伦 • 纽厄尔（Allen Newell）和司马贺（Herbert Alexander Simon）等人都曾经获奖。华人科学家姚期智 2000 年因为伪随机数生成等计算领域的重要贡献获奖。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Turing Reward</category>
      </categories>
  </entry>
  <entry>
    <title>Turing Reward in 2017</title>
    <url>/2018/03/21/TuringReward-2017/</url>
    <content><![CDATA[<p>  2018 年 3 月 21 日，美国计算机协会（ACM）将2017年图灵奖授予斯坦福大学前校长约翰·轩尼诗（John L. Hennessy）和加州大学伯克利分校退休教授大卫·帕特森（David A. Patterson），以表彰他们开创了一种系统的、定量的方法来设计和评价计算机体系结构，并对RISC微处理器行业产生了持久的影响。</p>
<a id="more"></a>
<p><img src="/images/TURING/hennessyandpatterson.jpeg" alt="Group photo"></p>
<p>  降低处理器复杂性的概念架构研究可以追溯到1960年，也就是由IBM资助的801项目，由轩尼诗和帕特森负责。斯坦福大学和加州大学伯克利分校都在大力研究RISC架构的可行性方法,推广其概念,并介绍给学术界和产业界。RISC方法不同于当时流行的复杂指令集计算机(CISC)，因为它只需要一组简单和通用的指令(计算机必须执行的功能)，需要的晶体管数量比复杂指令集少，并且减少了计算机必须执行的工作量。</p>
<p>  帕特森的伯克利团队创造了RISC这个词，并在1982年建立并演示了他们的RISC-1型处理器。RISC-1型处理器采用了44000个晶体管中，其性能要优于传统的CISC设计，后者的实现往往需要100,000个晶体管。轩尼诗于1984年联合创立了MIPS电脑系统公司，将斯坦福团队的工作市场化。后来，伯克利团队的研究成果通过Sun Microsystems公司的SPARC微处理器架构商业化。</p>
<p>  尽管许多计算机架构师最初对RISC持怀疑态度，但MIPS和SPARC市场化的成功，RISC设计较低的生产成本，以及更多的研究进展，使RISC得到了业界的广泛接纳。到20世纪90年代中期，RISC微处理器已经在整个领域占据主导地位。</p>
<p><strong>约翰·轩尼诗(John L. Hennessy)</strong></p>
<p><img src="/images/TURING/hennessy.jpeg" alt="John L. Hennessy"></p>
<p>  约翰·轩尼诗，为 MIPS 科技公司创始人，第十任斯坦福大学校长、Alphabet公司董事长。</p>
<p>  Hennessy出生于1953年。</p>
<p>  1973年，他从维拉诺瓦大学获取电机工程学士学位。</p>
<p>  1975年以及1977年，分别从纽约石溪大学获取计算机科学硕士及博士学位。</p>
<p>  1977年成为斯坦福大学的教师。</p>
<p>  1981年，他开始进行MIPS项目，并研究RISC处理器。</p>
<p>  1984年，他利用年度休假的时间创建了 MIPS Computer Systems Inc.，将他研究开发的技术进行商业化。</p>
<p>  1987年，他成为电气工程和计算机科学的 Willard 和 Inez Kerr Bell 教授。</p>
<p>  1989年到1993年，Hennessy担任了斯坦福大学计算机系统实验室主任。</p>
<p>  1994年到1996年，他曾担任斯坦福大学计算机科学系主任。</p>
<p>  1996年到1999年，他担任斯坦福大学工程学院院长。</p>
<p>  1999年，斯坦福大学校长格哈德·卡斯帕（Gerhard Casper）任命Hennessy接任斯坦福大学教务长。</p>
<p>  随后 2000年卡斯帕卸任后，斯坦福董事会任命Hennessy接替卡斯帕出任校长一职，并一直延续到 2016年。在这段时间内斯坦福完成了从一个地区性教育机构到世界顶级大学的蜕变，斯坦福外围的硅谷也成为了世界创新的引擎，而Hennessy教授则成为公认的「硅谷教父」。</p>
<p>  此外值得注意的是Hennessy从2004年起便加入了Google（后来的Alphabet公司）的董事会，并于2007年担任独立董事。</p>
<p>  在 2018年 2 月，伴随着 Alphabet 公司（Google 的母公司）发布 2017年财报，还同时宣布 66 岁的Hennessy为 Alphabet 的第三任董事长。（雷锋网曾经有详细报道：全年营收破千亿美元的 Google，迎来了 20年来最大的人事变动）</p>
<p>  在研究方面，Hennessy与Patterson共同为RISC微处理器创建了一个系统的量化方法。同时他们编写的《计算机体系结构（量化研究方法）》（Computer Architecture: A Quantitative Approach），从1990年以来一直被广泛用作研究生的权威教材，另一方面，Hennessy将 Donald Knuth 的 MIX 处理器更新为 MMIX 做出了贡献。</p>
<p>  2004年，他1989年合作的一篇关于高性能缓存层次结构的论文获得了计算机械协会 SIGARCH ISCA 的影响论文奖。</p>
<p>  2009年，Hennessy再次获得该奖，这次是他在1994年合作的有关斯坦福 FLASH 多处理器的论文。</p>
<p><strong>大卫·帕特森(David A. Patterson)</strong></p>
<p><img src="/images/TURING/patterson.jpeg" alt="David A. Patterson"></p>
<p>  Patterson 出生于1947年，</p>
<p>  1969年从加州大学洛杉矶分校获数学学士学位。</p>
<p>  1970年和1976年，从加州大学洛杉矶分校分别获得计算机硕士和博士学位。</p>
<p>  1976年，博士毕业后，加入加州大学伯克利分校计算机系。</p>
<p>  1994年，当选美国计算机协会会士（ACM Fellow）。</p>
<p>  2004年至 2006年，任美国计算机协会主席。</p>
<p>  2016年，DavidPatterson教授宣布从加州大学伯克利分校退休，学校给他举办了一个退休典礼，纪念他在计算机架构方面的 40年学术生涯。一年之后，教授公开宣布自己加入谷歌 TPU 团队，谷歌的 TPU 论文中也有他的署名。（雷锋网详细报道：David Patterson教授公开宣布加入谷歌TPU团队，好戏才刚刚开场）</p>
<p>  Patterson教授在伯克利大学带领团队长期进行RISC的研究，对全世界RISC处理器的研发和相关应用做出了巨大贡献；他在 2003年到 2005年间是美国总统信息技术咨询委员会成员，2004 到 2006年间任国际计算机学会主席；他还是磁盘阵列 RAID 的研发者之一。</p>
<p>  威斯康星大学麦迪逊分校计算机系的主任Mark Hill认为，Patterson教授在计算机架构方面是「20世纪后50年里最杰出的几个人之一」。他同时还表示，Patterson教授与Hennessy教授合著的那本计算机架构书是这个领域近25年来最有影响力的教科书。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>Computer Science</category>
        <category>Turing Reward</category>
      </categories>
  </entry>
</search>
